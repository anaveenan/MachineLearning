{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# <center> Scott Zuehlke Homework 1 </center>\n",
    "#### <center> This homework assignment was done in large partnership with Renee Murray, who was a significant help in the Python coding of the homework assignments.</center>\n",
    "\n",
    "## <center>  Written on a Mac, for a Mac </center>\n",
    "\n",
    "\n",
    "## HW1.0.0. \n",
    "### Define big data. Provide an example of a big data problem in your domain of expertise. \n",
    "\n",
    "#### _Big data is a generic term to represent data sets that are so large, or possibly so complex, that traditional methods of processing and analysis are inadequate.  While the cutoff of what represents \"big data\" is relative to a company and its technological capabilities, there is a tipping point where basic methods (SQL, for example) cannot process the large amounts of data in a sufficient amount of time.  The other side of that tipping point is what is referred to as \"big data.\"_\n",
    "\n",
    "#### _In my domain of retail and e-commerce, a perfect example of \"big data\" would be the data generated by our Target.com website.  A specific use case for this data is the Target.com Personalization Engine.  The Personalization Engine runs in a fraction of a second and pulls data from a Hadoop environment to create a \"people with similar purchase history have also bought...\" type recommendation.  The amount of data to process would take days with a traditional processing technique, but through Hadoop and Spark algorithms, millions of records can be processed almost instantaneously._\n",
    "\n",
    "\n",
    "### What is a race condition in the context of parallel computation? Give an example.\n",
    "\n",
    "#### _A race condition, in the context of parallel computation, is a situation where more than one process reaches the same variable, file, or data set concurrently and alters the final result._\n",
    "\n",
    "#### _A real world example would be a deposit/withdrawal at a bank.  If a customer has 10 dollars in their account on Monday, deposits 25 on Tuesday and tries to withdraw 20 on Wednesday, the withdrawal's success would depend on the deposit happeing BEFORE the withdrawal processes.  Below is some pseudocode to illustrate._\n",
    "```\n",
    "class BankAccount:\n",
    "    \n",
    "    def __init__(self, balance, deposit, withdraw):    \n",
    "        self.balance = balance\n",
    "        self.deposit = deposit\n",
    "        self.withdraw = withdraw\n",
    "    \n",
    "    def ProcessDeposit(balance, deposit):\n",
    "        new_balance = balance + deposit_amt\n",
    "        yield new_balance\n",
    "        \n",
    "        \n",
    "    def ProcessWithdrawal(balance, withdraw):\n",
    "        \n",
    "        if new_balance >= withdraw then:\n",
    "            new_balance = balance + deposit_amt\n",
    "            yield new_balance \n",
    "        else:\n",
    "            yield \"Withdrawal would cause overdraft.\"\n",
    "```\n",
    "            \n",
    "####  _Ideally, if a person were to start with an initial balance of 10 dollars, deposits 25 and then withdraws 20, the ending balance should be 10+25-20 = 15.  However, if the withdrawal were to post first, then balance would actually go negative, i.e. 10 - 20 + 25._ Mathematically, this would yield the same result of 15, but in the example above, since the new_balance would be less than the withdrawal, it would fail to post and yield outcome,\"Withdrawal would cause overdraft.\"_\n",
    "        \n",
    "\n",
    "\n",
    "## What is MapReduce?\n",
    "\n",
    "#### _MapReduce is a programming algorithm for processing, and generating, large data sets.  A mapper is created to apply a specific algorithm to each of a smaller piece of the original data spread out across multiple computers or nodes, creates a key-value pair with the resulting output from each defined key, and then a reducer will merge the key value pairs to create a single output, which is the desired result of analysis on the larger, initial data set._\n",
    "\n",
    "\n",
    "\n",
    "## How does it differ from Hadoop?\n",
    "\n",
    "#### _MapReduce is a \"divide and conquer\" algorithm that allows for processing of \"big data\" by splitting chunks across multiple nodes or clusters.  Hadoop is an infrastructure that utilizes MapReduce to process large, or unstructured/complex, data sets._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW1.0.1 \n",
    "\n",
    "## Which programming paradigm is Hadoop based on? Explain and give a simple example of functional programming in raw python code and show the code running. E.g., in raw python find the average length of a string in and of strings using a python \"map-reduce\" (functional programming) job. Alternatively, you can do this in python Hadoop Streaming.   \n",
    "\n",
    "#### _Hadoop is based on the MapReduce programming paradigm, which is based on functional programming.  So, by extension, it could be said that Hadoop is, actually, based on the functional programming._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **_The below code calculates the average string length in a string of strings.  The provided string was provided in the original homework assignment._**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input string  ['str1', 'string2', 'w261', 'MAchine learning at SCALE'] has an average length of "
     ]
    },
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def stringlength(string):\n",
    "    return len(string)\n",
    "\n",
    "def numelements(string):\n",
    "    return len(string.split())\n",
    " \n",
    "strings = [\"str1\", \"string2\", \"w261\", \"MAchine learning at SCALE\"]\n",
    "stringlengthmap = map(stringlength, strings)\n",
    "\n",
    "import functools\n",
    "print \"The input string \", strings, \"has an average length of \", \n",
    "functools.reduce(lambda x, y: x + y / float(len(stringlengthmap)), stringlengthmap, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **_The below code is now to prove that the code does work, by providing a different, custom string with different string lengths.  _**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input string  ['Really hope', 'this assignment', 'ends better than', 'it started!'] has an average length of "
     ]
    },
    {
     "data": {
      "text/plain": [
       "13.25"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def stringlength(string):\n",
    "    return len(string)\n",
    "\n",
    "def numelements(string):\n",
    "    return len(string.split())\n",
    " \n",
    "strings = [\"Really hope\", \"this assignment\", \"ends better than\", \"it started!\"]\n",
    "stringlengthmap = map(stringlength, strings)\n",
    "\n",
    "import functools\n",
    "print \"The input string \", strings, \"has an average length of \", \n",
    "functools.reduce(lambda x, y: x + y / float(len(stringlengthmap)), stringlengthmap, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW1.1 Cross fold validation \n",
    "\n",
    "## What is cross validation (in partiticular 10-fold cross validation)?\n",
    "\n",
    "#### _Cross-validation is a technique to evaluate predictive models by partitioning the original sample into a training set to train the model, and a test set to evaluate it.  10-fold cross validation is partitioning the original sample into 10 partitions; 9 to train and one to test.  Here's a basic outline of a 10 fold cross validation on a modeling data set:_\n",
    "\n",
    "   * Partition data into, approximately, n/10 where n is the size of the data set.  (If the data set has 1000 records, there would be roughly 1000/10 = 100 data points in each partition).\n",
    "\n",
    "   * Train a model on 9 of the 10 partitions, holding the last for validation.\n",
    "\n",
    "   * Repeat 9 times, with each iteration a different holding partition for validation.\n",
    "\n",
    "   * Calculate a desired metric for the 10 validations (MSE, RMSE, MAPE, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Info for the rest of the assignment: \n",
    "\n",
    "===== SPAM Dataset \n",
    "In the remainder of this assignment you will produce a spam filter\n",
    "that is backed by a multinomial naive Bayes classifier  (see http://nlp.stanford.edu/IR-book/html/htmledition/properties-of-naive-bayes-1.html).\n",
    "\n",
    "For the sake of this assignment we will focus on the basic construction \n",
    "of the parallelized classifier, and not consider its validation or calibration,\n",
    "and so you will have the classifier operate on its own training data (unlike a \n",
    "field application where one would use non-overlapping subsets for training, validation and testing).\n",
    "\n",
    "The data you will use is a curated subset of the Enron email corpus\n",
    "(whose details you may find in the file enronemail_README.txt  in the directory surrounding these instructions).\n",
    "\n",
    "NOTE: please use the subject field and the body field for all your Naive Bayes modeling. \n",
    "\n",
    "NOTE: This SPAM/HAM dataset for HW1 contains 100 records from the Enron SPAM/HAM corpus. Please limit your study to this unless otherwise instructed. There are about 93,000 emails in the original SPAM/HAM corpus. There are several versions of the SPAM/HAM corpus. Other Enron-Spam datasets are available from http://www.aueb.gr/users/ion/data/enron-spam/index.html and http://www.aueb.gr/users/ion/publications.html in both raw and pre-processed form. \n",
    "\n",
    "Doing some exploratory data analysis you will see (with this very small dataset) the following:\n",
    "> wc -l enronemail_1h.txt  #100 email records\n",
    "     100 enronemail_1h.txt\n",
    "> cut -f2 -d$'\\t' enronemail_1h.txt|wc  #extract second field which is SPAM flag\n",
    "     101     394    3999\n",
    "JAMES-SHANAHANs-Desktop-Pro-2:HW1-Questions jshanahan$ cut -f2 -d$'\\t' enronemail_1h.txt|head\n",
    "0\n",
    "0\n",
    "0\n",
    "0\n",
    "0\n",
    "0\n",
    "0\n",
    "0\n",
    "1\n",
    "1\n",
    "\n",
    "> head -n 100 enronemail_1h.txt|tail -1|less \n",
    "\n",
    "### An example SPAM email record\n",
    "018.2001-07-13.SA_and_HP       1        [ilug] we need your assistance to invest in your country        dear sir/madam,  i am well confident of your capability to assist me in  a transaction for mutual benefit of both parties, ie  (me and you) i am also believing that you will not  expose or betray the trust and confidence i am about  to establish with you. i have decided to contact you  with greatest delight and personal respect.  well, i am victor sankoh, son to mr. foday  sankoh  who was arrested by the ecomog peace keeping force  months ago in my country sierra leone. …."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW1.2 \n",
    "\n",
    "### WORDCOUNT\n",
    "Using the Enron dataset and Hadoop MapReduce streaming (or MRJob), write the mapper/reducer job that  will determine the word count (number of occurrences) of each white-space delimitted token (assume spaces, fullstops, comma as delimiters). Examine the word “assistance” and report its word count results.\n",
    "\n",
    " \n",
    "CROSSCHECK: >grep assistance enronemail_1h.txt|cut -d$'\\t' -f4| grep assistance|wc -l    \n",
    "       8   \n",
    "       \n",
    "NOTE:  \"assistance\" occurs on 8 lines but how many times does the token occur? 10 times! This is the number we are looking for!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting WordCountHW12.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile WordCountHW12.py\n",
    "\n",
    "from mrjob.job import MRJob\n",
    "import re, string\n",
    "\n",
    "class MRJobWordCount(MRJob):\n",
    "\n",
    "    def mapper(self, _, line):\n",
    "        regex = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "        token = line.strip().split('\\t', 2)[-1]\n",
    "        token = regex.sub(' ', token.lower())\n",
    "        token = re.sub( '\\s+', ' ', token )\n",
    "        words = token.split()\n",
    "\n",
    "        for word in words:\n",
    "            if len(word) > 1:\n",
    "                yield (word, 1)\n",
    "\n",
    "    def combiner(self, word, counts):\n",
    "        yield(word, sum(counts))\n",
    "\n",
    "    def reducer(self, word, counts):\n",
    "        yield word, sum(counts)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    MRJobWordCount.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "Creating temp directory /var/folders/0r/78q4n41j3dgdb6ndrr46gw3430x2wk/T/WordCountHW12.z086769.20160628.084016.846168\n",
      "Running step 1 of 1...\n",
      "Streaming final output from /var/folders/0r/78q4n41j3dgdb6ndrr46gw3430x2wk/T/WordCountHW12.z086769.20160628.084016.846168/output...\n",
      "\"00\"\t33\n",
      "\"000\"\t52\n",
      "\"001\"\t3\n",
      "\"0011\"\t1\n",
      "\"00450\"\t1\n",
      "\"0080\"\t1\n",
      "\"01\"\t25\n",
      "\"012\"\t4\n",
      "\"02\"\t19\n",
      "\"028\"\t1\n",
      "\"0281\"\t1\n",
      "\"03\"\t3\n",
      "\"036474336\"\t1\n",
      "\"04\"\t7\n",
      "\"048\"\t1\n",
      "\"05\"\t4\n",
      "\"055\"\t2\n",
      "\"06\"\t21\n",
      "\"0643\"\t1\n",
      "\"07\"\t10\n",
      "\"08\"\t22\n",
      "\"081\"\t2\n",
      "\"088889774\"\t1\n",
      "\"09\"\t21\n",
      "\"10\"\t44\n",
      "\"100\"\t19\n",
      "\"100038\"\t1\n",
      "\"1016\"\t1\n",
      "\"103\"\t1\n",
      "\"107\"\t1\n",
      "\"108\"\t1\n",
      "\"11\"\t15\n",
      "\"114427\"\t1\n",
      "\"12\"\t74\n",
      "\"120\"\t1\n",
      "\"1200\"\t2\n",
      "\"122\"\t1\n",
      "\"123\"\t3\n",
      "\"123395\"\t1\n",
      "\"124\"\t3\n",
      "\"125\"\t2\n",
      "\"126\"\t2\n",
      "\"13\"\t13\n",
      "\"134\"\t1\n",
      "\"14\"\t33\n",
      "\"146907159\"\t1\n",
      "\"148415904\"\t1\n",
      "\"1488230796\"\t1\n",
      "\"149\"\t1\n",
      "\"15\"\t25\n",
      "\"150\"\t1\n",
      "\"1500\"\t1\n",
      "\"151\"\t1\n",
      "\"1517\"\t1\n",
      "\"16\"\t5\n",
      "\"161\"\t1\n",
      "\"1687\"\t1\n",
      "\"1689\"\t1\n",
      "\"17\"\t19\n",
      "\"18\"\t18\n",
      "\"1814\"\t1\n",
      "\"1848\"\t1\n",
      "\"1864\"\t1\n",
      "\"19\"\t9\n",
      "\"1928\"\t1\n",
      "\"1930\"\t1\n",
      "\"1932\"\t1\n",
      "\"1933\"\t1\n",
      "\"1934\"\t1\n",
      "\"1935\"\t1\n",
      "\"1936\"\t1\n",
      "\"1938\"\t1\n",
      "\"1941\"\t1\n",
      "\"1942\"\t1\n",
      "\"1944\"\t1\n",
      "\"1945\"\t1\n",
      "\"1947\"\t1\n",
      "\"1949\"\t1\n",
      "\"1953\"\t1\n",
      "\"1980\"\t2\n",
      "\"1990\"\t2\n",
      "\"1992\"\t3\n",
      "\"1997\"\t3\n",
      "\"1998\"\t2\n",
      "\"1999\"\t10\n",
      "\"20\"\t20\n",
      "\"200\"\t3\n",
      "\"2000\"\t30\n",
      "\"2001\"\t29\n",
      "\"2002\"\t2\n",
      "\"2003\"\t19\n",
      "\"2004\"\t16\n",
      "\"2005\"\t3\n",
      "\"201\"\t2\n",
      "\"2020\"\t1\n",
      "\"2086\"\t1\n",
      "\"209318\"\t1\n",
      "\"21\"\t3\n",
      "\"211075433222\"\t2\n",
      "\"212\"\t3\n",
      "\"213\"\t1\n",
      "\"2152\"\t1\n",
      "\"22\"\t8\n",
      "\"224\"\t1\n",
      "\"229\"\t2\n",
      "\"23\"\t4\n",
      "\"230\"\t1\n",
      "\"234\"\t1\n",
      "\"24\"\t27\n",
      "\"249\"\t2\n",
      "\"2497\"\t1\n",
      "\"25\"\t4\n",
      "\"250\"\t1\n",
      "\"2500\"\t1\n",
      "\"252050406\"\t1\n",
      "\"255326837\"\t1\n",
      "\"256\"\t1\n",
      "\"25711\"\t2\n",
      "\"2575\"\t4\n",
      "\"259\"\t1\n",
      "\"26\"\t5\n",
      "\"260\"\t2\n",
      "\"263\"\t2\n",
      "\"2666\"\t1\n",
      "\"27\"\t6\n",
      "\"27049\"\t2\n",
      "\"2753\"\t1\n",
      "\"28\"\t10\n",
      "\"2807\"\t1\n",
      "\"281\"\t1\n",
      "\"2868\"\t1\n",
      "\"29\"\t10\n",
      "\"29155\"\t1\n",
      "\"2963\"\t1\n",
      "\"299\"\t1\n",
      "\"30\"\t20\n",
      "\"300\"\t9\n",
      "\"3000\"\t2\n",
      "\"3011\"\t1\n",
      "\"306\"\t2\n",
      "\"31\"\t4\n",
      "\"312\"\t1\n",
      "\"3130\"\t1\n",
      "\"31615304791\"\t1\n",
      "\"32\"\t12\n",
      "\"321\"\t1\n",
      "\"3267\"\t1\n",
      "\"3300\"\t1\n",
      "\"33155\"\t1\n",
      "\"332\"\t1\n",
      "\"33282\"\t1\n",
      "\"33465\"\t1\n",
      "\"3359\"\t1\n",
      "\"33597\"\t1\n",
      "\"34\"\t4\n",
      "\"3404\"\t1\n",
      "\"3405\"\t2\n",
      "\"34357\"\t1\n",
      "\"345\"\t1\n",
      "\"34710\"\t1\n",
      "\"349\"\t2\n",
      "\"35\"\t2\n",
      "\"35615\"\t1\n",
      "\"35782\"\t1\n",
      "\"36\"\t2\n",
      "\"37\"\t1\n",
      "\"37159\"\t2\n",
      "\"375\"\t1\n",
      "\"38\"\t5\n",
      "\"39\"\t5\n",
      "\"392\"\t2\n",
      "\"39510\"\t2\n",
      "\"399\"\t1\n",
      "\"39934\"\t2\n",
      "\"40\"\t9\n",
      "\"4073\"\t1\n",
      "\"409055\"\t1\n",
      "\"41\"\t1\n",
      "\"415\"\t4\n",
      "\"418\"\t4\n",
      "\"419\"\t1\n",
      "\"420\"\t1\n",
      "\"422\"\t4\n",
      "\"423\"\t2\n",
      "\"43\"\t2\n",
      "\"431\"\t1\n",
      "\"436425795822\"\t1\n",
      "\"44\"\t6\n",
      "\"449\"\t1\n",
      "\"45\"\t6\n",
      "\"4500\"\t2\n",
      "\"46\"\t2\n",
      "\"47\"\t2\n",
      "\"474\"\t1\n",
      "\"4748\"\t1\n",
      "\"4887\"\t1\n",
      "\"49\"\t1\n",
      "\"499\"\t2\n",
      "\"50\"\t15\n",
      "\"500\"\t8\n",
      "\"5000\"\t3\n",
      "\"5022\"\t1\n",
      "\"51\"\t1\n",
      "\"512517\"\t2\n",
      "\"519\"\t1\n",
      "\"52\"\t3\n",
      "\"521\"\t1\n",
      "\"52109\"\t1\n",
      "\"52477\"\t1\n",
      "\"529\"\t3\n",
      "\"5290\"\t2\n",
      "\"54\"\t4\n",
      "\"54804\"\t1\n",
      "\"549\"\t1\n",
      "\"55\"\t4\n",
      "\"553\"\t1\n",
      "\"5555\"\t2\n",
      "\"56\"\t1\n",
      "\"560\"\t1\n",
      "\"57\"\t1\n",
      "\"58\"\t1\n",
      "\"584\"\t1\n",
      "\"59\"\t2\n",
      "\"599\"\t1\n",
      "\"60\"\t6\n",
      "\"600\"\t1\n",
      "\"602\"\t1\n",
      "\"609\"\t1\n",
      "\"61\"\t2\n",
      "\"6207\"\t1\n",
      "\"62163\"\t1\n",
      "\"62413\"\t1\n",
      "\"630\"\t1\n",
      "\"6396\"\t1\n",
      "\"64\"\t1\n",
      "\"642\"\t1\n",
      "\"645\"\t2\n",
      "\"64610\"\t2\n",
      "\"6484\"\t1\n",
      "\"66\"\t1\n",
      "\"6614102\"\t1\n",
      "\"67\"\t2\n",
      "\"674\"\t1\n",
      "\"6761\"\t1\n",
      "\"68\"\t1\n",
      "\"69\"\t1\n",
      "\"6902\"\t1\n",
      "\"69545\"\t1\n",
      "\"6992\"\t2\n",
      "\"70\"\t1\n",
      "\"700\"\t3\n",
      "\"703\"\t1\n",
      "\"706\"\t2\n",
      "\"71\"\t1\n",
      "\"713\"\t6\n",
      "\"7168\"\t1\n",
      "\"7247\"\t1\n",
      "\"7268\"\t3\n",
      "\"731\"\t1\n",
      "\"735670\"\t1\n",
      "\"7358\"\t2\n",
      "\"738\"\t1\n",
      "\"7394\"\t1\n",
      "\"74949\"\t1\n",
      "\"75\"\t5\n",
      "\"7517\"\t1\n",
      "\"7578\"\t1\n",
      "\"76\"\t1\n",
      "\"763\"\t1\n",
      "\"7675213911\"\t1\n",
      "\"77\"\t1\n",
      "\"77056\"\t2\n",
      "\"78\"\t2\n",
      "\"783019\"\t1\n",
      "\"783518\"\t1\n",
      "\"7877\"\t6\n",
      "\"789118270\"\t1\n",
      "\"793\"\t1\n",
      "\"80\"\t5\n",
      "\"800\"\t3\n",
      "\"802\"\t1\n",
      "\"8038\"\t1\n",
      "\"81\"\t2\n",
      "\"816\"\t2\n",
      "\"82\"\t1\n",
      "\"825854664\"\t1\n",
      "\"840\"\t1\n",
      "\"8434\"\t1\n",
      "\"847\"\t1\n",
      "\"8507\"\t1\n",
      "\"8561513507\"\t1\n",
      "\"869279893\"\t1\n",
      "\"87\"\t3\n",
      "\"877\"\t3\n",
      "\"878\"\t1\n",
      "\"8859\"\t10\n",
      "\"888\"\t5\n",
      "\"89\"\t1\n",
      "\"8901\"\t1\n",
      "\"8919\"\t1\n",
      "\"893\"\t1\n",
      "\"90\"\t3\n",
      "\"900\"\t1\n",
      "\"908\"\t1\n",
      "\"9100\"\t1\n",
      "\"92\"\t1\n",
      "\"9213\"\t1\n",
      "\"9237\"\t1\n",
      "\"925\"\t2\n",
      "\"928976257\"\t1\n",
      "\"9291\"\t1\n",
      "\"932\"\t2\n",
      "\"9381\"\t1\n",
      "\"94105\"\t1\n",
      "\"9434\"\t2\n",
      "\"944\"\t1\n",
      "\"9489\"\t1\n",
      "\"95\"\t15\n",
      "\"95394\"\t1\n",
      "\"96\"\t1\n",
      "\"96006681\"\t1\n",
      "\"9610\"\t1\n",
      "\"964\"\t2\n",
      "\"9643\"\t2\n",
      "\"965\"\t1\n",
      "\"97\"\t1\n",
      "\"973\"\t2\n",
      "\"98\"\t1\n",
      "\"982\"\t1\n",
      "\"986782\"\t1\n",
      "\"99\"\t64\n",
      "\"999\"\t3\n",
      "\"ab\"\t5\n",
      "\"abidjan\"\t2\n",
      "\"ability\"\t2\n",
      "\"able\"\t14\n",
      "\"abn\"\t1\n",
      "\"about\"\t52\n",
      "\"above\"\t11\n",
      "\"absent\"\t1\n",
      "\"absenteeism\"\t1\n",
      "\"absolute\"\t2\n",
      "\"absolutely\"\t1\n",
      "\"absorb\"\t1\n",
      "\"abuse\"\t2\n",
      "\"abused\"\t1\n",
      "\"acce\"\t1\n",
      "\"accelerate\"\t1\n",
      "\"accelerated\"\t1\n",
      "\"accept\"\t3\n",
      "\"acceptable\"\t1\n",
      "\"accepted\"\t1\n",
      "\"accepting\"\t2\n",
      "\"accepts\"\t1\n",
      "\"access\"\t12\n",
      "\"accomodate\"\t4\n",
      "\"accomodates\"\t1\n",
      "\"accompanied\"\t1\n",
      "\"according\"\t2\n",
      "\"accordingly\"\t1\n",
      "\"account\"\t36\n",
      "\"accountability\"\t1\n",
      "\"accounting\"\t5\n",
      "\"accounts\"\t1\n",
      "\"accrual\"\t2\n",
      "\"accurate\"\t1\n",
      "\"aches\"\t1\n",
      "\"achieve\"\t1\n",
      "\"achieved\"\t1\n",
      "\"acid\"\t1\n",
      "\"acquire\"\t1\n",
      "\"acquisition\"\t1\n",
      "\"acrobaat\"\t1\n",
      "\"acrobat\"\t1\n",
      "\"across\"\t10\n",
      "\"act\"\t7\n",
      "\"action\"\t1\n",
      "\"activate\"\t4\n",
      "\"active\"\t1\n",
      "\"activists\"\t1\n",
      "\"activities\"\t10\n",
      "\"actor\"\t1\n",
      "\"actress\"\t1\n",
      "\"actual\"\t4\n",
      "\"actually\"\t2\n",
      "\"ad\"\t31\n",
      "\"adage\"\t1\n",
      "\"adams\"\t1\n",
      "\"adapted\"\t1\n",
      "\"add\"\t12\n",
      "\"added\"\t2\n",
      "\"adding\"\t2\n",
      "\"addition\"\t5\n",
      "\"additional\"\t13\n",
      "\"additionally\"\t2\n",
      "\"address\"\t27\n",
      "\"addressed\"\t1\n",
      "\"addresses\"\t5\n",
      "\"addressing\"\t1\n",
      "\"addtional\"\t1\n",
      "\"adequately\"\t1\n",
      "\"adhesion\"\t1\n",
      "\"adm\"\t1\n",
      "\"admin\"\t1\n",
      "\"adminder\"\t2\n",
      "\"administration\"\t3\n",
      "\"admitted\"\t1\n",
      "\"admixture\"\t1\n",
      "\"adobe\"\t12\n",
      "\"adobee\"\t1\n",
      "\"adolescent\"\t1\n",
      "\"adr\"\t1\n",
      "\"adrianbold\"\t2\n",
      "\"ads\"\t5\n",
      "\"adult\"\t3\n",
      "\"adv\"\t1\n",
      "\"advance\"\t4\n",
      "\"advanced\"\t1\n",
      "\"advantage\"\t1\n",
      "\"advantages\"\t1\n",
      "\"advertise\"\t2\n",
      "\"advertised\"\t1\n",
      "\"advertisement\"\t4\n",
      "\"advertisements\"\t1\n",
      "\"advertising\"\t7\n",
      "\"advertisments\"\t1\n",
      "\"advice\"\t4\n",
      "\"advise\"\t2\n",
      "\"advises\"\t1\n",
      "\"advocate\"\t1\n",
      "\"advocates\"\t1\n",
      "\"advs\"\t1\n",
      "\"aec\"\t2\n",
      "\"aeopublishing\"\t29\n",
      "\"afeee\"\t1\n",
      "\"aff\"\t1\n",
      "\"affairs\"\t1\n",
      "\"affect\"\t2\n",
      "\"affectate\"\t1\n",
      "\"affiliate\"\t2\n",
      "\"affiliates\"\t6\n",
      "\"afford\"\t1\n",
      "\"afirst\"\t1\n",
      "\"afraid\"\t4\n",
      "\"africa\"\t10\n",
      "\"after\"\t19\n",
      "\"afternoon\"\t4\n",
      "\"again\"\t12\n",
      "\"against\"\t6\n",
      "\"age\"\t5\n",
      "\"agendas\"\t1\n",
      "\"agent\"\t3\n",
      "\"aggressive\"\t1\n",
      "\"aggressively\"\t3\n",
      "\"ago\"\t1\n",
      "\"agonizing\"\t1\n",
      "\"agouti\"\t1\n",
      "\"agree\"\t3\n",
      "\"agreed\"\t2\n",
      "\"agreeing\"\t1\n",
      "\"agreement\"\t16\n",
      "\"agreements\"\t3\n",
      "\"ague\"\t1\n",
      "\"ah\"\t1\n",
      "\"ahead\"\t1\n",
      "\"aid\"\t1\n",
      "\"aids\"\t1\n",
      "\"air\"\t6\n",
      "\"airport\"\t2\n",
      "\"airs\"\t1\n",
      "\"aka\"\t1\n",
      "\"akkabay\"\t4\n",
      "\"al\"\t2\n",
      "\"albuquerque\"\t2\n",
      "\"alertness\"\t1\n",
      "\"alex\"\t4\n",
      "\"alexios\"\t1\n",
      "\"alhaji\"\t2\n",
      "\"all\"\t111\n",
      "\"allay\"\t1\n",
      "\"allen\"\t5\n",
      "\"alleviates\"\t1\n",
      "\"alli\"\t1\n",
      "\"allocate\"\t1\n",
      "\"allocated\"\t2\n",
      "\"allocating\"\t2\n",
      "\"allocation\"\t6\n",
      "\"allocations\"\t4\n",
      "\"allow\"\t12\n",
      "\"allows\"\t3\n",
      "\"almost\"\t3\n",
      "\"alone\"\t2\n",
      "\"along\"\t4\n",
      "\"alpra\"\t2\n",
      "\"already\"\t13\n",
      "\"alsdorf\"\t1\n",
      "\"also\"\t56\n",
      "\"alternative\"\t1\n",
      "\"alternatively\"\t1\n",
      "\"although\"\t3\n",
      "\"altra\"\t1\n",
      "\"alum\"\t1\n",
      "\"always\"\t10\n",
      "\"am\"\t86\n",
      "\"amadol\"\t2\n",
      "\"amazed\"\t1\n",
      "\"amb\"\t2\n",
      "\"ambien\"\t2\n",
      "\"ambrose\"\t1\n",
      "\"amended\"\t1\n",
      "\"americ\"\t2\n",
      "\"america\"\t15\n",
      "\"american\"\t2\n",
      "\"amex\"\t1\n",
      "\"ami\"\t1\n",
      "\"amiable\"\t1\n",
      "\"amigo\"\t1\n",
      "\"amitava\"\t4\n",
      "\"among\"\t7\n",
      "\"amortize\"\t4\n",
      "\"amount\"\t7\n",
      "\"amounts\"\t2\n",
      "\"amsterdam\"\t1\n",
      "\"amy\"\t2\n",
      "\"an\"\t77\n",
      "\"anabel\"\t1\n",
      "\"anal\"\t1\n",
      "\"analyses\"\t1\n",
      "\"analysis\"\t3\n",
      "\"analyst\"\t2\n",
      "\"analyze\"\t1\n",
      "\"ancillary\"\t2\n",
      "\"and\"\t670\n",
      "\"andorra\"\t1\n",
      "\"andrea\"\t3\n",
      "\"angelova\"\t4\n",
      "\"angels\"\t2\n",
      "\"angrily\"\t1\n",
      "\"angry\"\t1\n",
      "\"anheuser\"\t1\n",
      "\"anita\"\t2\n",
      "\"annals\"\t1\n",
      "\"annie\"\t2\n",
      "\"announcement\"\t7\n",
      "\"announcements\"\t4\n",
      "\"annoy\"\t1\n",
      "\"annoying\"\t1\n",
      "\"annuallouy\"\t1\n",
      "\"anonymise\"\t1\n",
      "\"anonymizer\"\t1\n",
      "\"anonymously\"\t1\n",
      "\"another\"\t15\n",
      "\"answer\"\t7\n",
      "\"answered\"\t1\n",
      "\"answering\"\t3\n",
      "\"answers\"\t7\n",
      "\"ante\"\t1\n",
      "\"anticipate\"\t1\n",
      "\"antivirus\"\t1\n",
      "\"antoine\"\t1\n",
      "\"any\"\t77\n",
      "\"anyare\"\t1\n",
      "\"anybody\"\t1\n",
      "\"anyhow\"\t5\n",
      "\"anyone\"\t7\n",
      "\"anything\"\t11\n",
      "\"anyway\"\t2\n",
      "\"anywhere\"\t3\n",
      "\"anz\"\t2\n",
      "\"aol\"\t6\n",
      "\"apachi\"\t1\n",
      "\"apart\"\t2\n",
      "\"apex\"\t1\n",
      "\"aphrodite\"\t1\n",
      "\"apoligize\"\t2\n",
      "\"apollo\"\t1\n",
      "\"apologies\"\t2\n",
      "\"apologize\"\t3\n",
      "\"apparently\"\t2\n",
      "\"appeals\"\t4\n",
      "\"appear\"\t7\n",
      "\"appearance\"\t2\n",
      "\"appears\"\t3\n",
      "\"appellate\"\t1\n",
      "\"appetite\"\t2\n",
      "\"application\"\t4\n",
      "\"applied\"\t5\n",
      "\"apply\"\t4\n",
      "\"appreciate\"\t2\n",
      "\"appreciated\"\t1\n",
      "\"appreciation\"\t2\n",
      "\"approach\"\t2\n",
      "\"appropriate\"\t3\n",
      "\"approval\"\t1\n",
      "\"approved\"\t6\n",
      "\"approximately\"\t4\n",
      "\"aqmd\"\t2\n",
      "\"aqoj\"\t1\n",
      "\"arbitrage\"\t4\n",
      "\"architect\"\t1\n",
      "\"archive\"\t1\n",
      "\"arcy\"\t7\n",
      "\"are\"\t169\n",
      "\"area\"\t4\n",
      "\"areas\"\t3\n",
      "\"aren\"\t3\n",
      "\"argentine\"\t4\n",
      "\"argue\"\t1\n",
      "\"argument\"\t2\n",
      "\"arizona\"\t1\n",
      "\"ark\"\t1\n",
      "\"arlene\"\t2\n",
      "\"arm\"\t1\n",
      "\"armstrong\"\t2\n",
      "\"around\"\t6\n",
      "\"arousing\"\t1\n",
      "\"arrange\"\t5\n",
      "\"arranged\"\t1\n",
      "\"arrangement\"\t2\n",
      "\"arrangements\"\t3\n",
      "\"arrest\"\t4\n",
      "\"arrested\"\t1\n",
      "\"arrival\"\t1\n",
      "\"art\"\t2\n",
      "\"arthur\"\t1\n",
      "\"article\"\t3\n",
      "\"articles\"\t2\n",
      "\"as\"\t138\n",
      "\"asap\"\t1\n",
      "\"ascii\"\t1\n",
      "\"ashburton\"\t3\n",
      "\"asia\"\t1\n",
      "\"aside\"\t4\n",
      "\"ask\"\t9\n",
      "\"asked\"\t3\n",
      "\"asking\"\t10\n",
      "\"asks\"\t1\n",
      "\"aspermont\"\t3\n",
      "\"assault\"\t1\n",
      "\"assay\"\t1\n",
      "\"assays\"\t1\n",
      "\"assembly\"\t2\n",
      "\"assemblyman\"\t3\n",
      "\"asset\"\t1\n",
      "\"assets\"\t14\n",
      "\"assignment\"\t1\n",
      "\"assist\"\t7\n",
      "\"assistance\"\t10\n",
      "\"assistant\"\t2\n",
      "\"associate\"\t3\n",
      "\"associated\"\t4\n",
      "\"association\"\t3\n",
      "\"assortment\"\t1\n",
      "\"assume\"\t1\n",
      "\"assuming\"\t1\n",
      "\"assumption\"\t1\n",
      "\"assure\"\t4\n",
      "\"asthma\"\t1\n",
      "\"at\"\t146\n",
      "\"ate\"\t3\n",
      "\"ativan\"\t1\n",
      "\"atop\"\t1\n",
      "\"atreus\"\t1\n",
      "\"attached\"\t8\n",
      "\"attack\"\t1\n",
      "\"attacked\"\t1\n",
      "\"attatched\"\t2\n",
      "\"attempt\"\t2\n",
      "\"attend\"\t7\n",
      "\"attendance\"\t2\n",
      "\"attended\"\t1\n",
      "\"attendees\"\t2\n",
      "\"attending\"\t1\n",
      "\"attention\"\t3\n",
      "\"attest\"\t1\n",
      "\"attitudinal\"\t1\n",
      "\"attl\"\t1\n",
      "\"attn\"\t2\n",
      "\"attractive\"\t2\n",
      "\"attributable\"\t1\n",
      "\"audience\"\t10\n",
      "\"audio\"\t2\n",
      "\"audit\"\t3\n",
      "\"auditor\"\t1\n",
      "\"august\"\t1\n",
      "\"australia\"\t10\n",
      "\"australian\"\t3\n",
      "\"australiasds\"\t1\n",
      "\"authenticity\"\t1\n",
      "\"author\"\t4\n",
      "\"authorities\"\t1\n",
      "\"authority\"\t1\n",
      "\"authorized\"\t1\n",
      "\"authors\"\t1\n",
      "\"automated\"\t2\n",
      "\"automatically\"\t7\n",
      "\"automobile\"\t1\n",
      "\"availability\"\t2\n",
      "\"available\"\t23\n",
      "\"average\"\t4\n",
      "\"aviation\"\t1\n",
      "\"avoid\"\t10\n",
      "\"avoided\"\t1\n",
      "\"await\"\t4\n",
      "\"awaking\"\t1\n",
      "\"award\"\t1\n",
      "\"aware\"\t1\n",
      "\"away\"\t9\n",
      "\"awesome\"\t1\n",
      "\"ax\"\t2\n",
      "\"axe\"\t1\n",
      "\"axel\"\t2\n",
      "\"ay\"\t1\n",
      "\"azepam\"\t2\n",
      "\"azurix\"\t10\n",
      "\"baby\"\t2\n",
      "\"baccarat\"\t1\n",
      "\"bachelors\"\t1\n",
      "\"back\"\t26\n",
      "\"backed\"\t1\n",
      "\"background\"\t9\n",
      "\"backgrounds\"\t1\n",
      "\"backup\"\t2\n",
      "\"bacon\"\t1\n",
      "\"bacterial\"\t1\n",
      "\"bad\"\t5\n",
      "\"bade\"\t1\n",
      "\"baggage\"\t1\n",
      "\"bail\"\t9\n",
      "\"bailout\"\t8\n",
      "\"balance\"\t1\n",
      "\"ballot\"\t1\n",
      "\"banging\"\t1\n",
      "\"bank\"\t7\n",
      "\"banked\"\t1\n",
      "\"banker\"\t3\n",
      "\"banking\"\t4\n",
      "\"bankruptcy\"\t20\n",
      "\"banks\"\t1\n",
      "\"bannerco\"\t4\n",
      "\"banners\"\t1\n",
      "\"bannersgomlm\"\t8\n",
      "\"bar\"\t1\n",
      "\"bareback\"\t1\n",
      "\"barely\"\t1\n",
      "\"bargaain\"\t1\n",
      "\"barnard\"\t1\n",
      "\"barney\"\t3\n",
      "\"barraged\"\t1\n",
      "\"barrier\"\t2\n",
      "\"barrow\"\t1\n",
      "\"base\"\t4\n",
      "\"based\"\t15\n",
      "\"basically\"\t1\n",
      "\"basis\"\t5\n",
      "\"baskets\"\t5\n",
      "\"batch\"\t3\n",
      "\"bauxite\"\t1\n",
      "\"bawled\"\t1\n",
      "\"bazzd\"\t1\n",
      "\"bc\"\t1\n",
      "\"bcli\"\t1\n",
      "\"bd\"\t7\n",
      "\"bdf\"\t1\n",
      "\"be\"\t222\n",
      "\"beale\"\t1\n",
      "\"beans\"\t1\n",
      "\"bear\"\t4\n",
      "\"beard\"\t1\n",
      "\"beca\"\t1\n",
      "\"became\"\t4\n",
      "\"because\"\t19\n",
      "\"beck\"\t5\n",
      "\"become\"\t6\n",
      "\"bed\"\t1\n",
      "\"bedfellow\"\t1\n",
      "\"beds\"\t3\n",
      "\"been\"\t52\n",
      "\"beers\"\t1\n",
      "\"beetcn\"\t1\n",
      "\"before\"\t23\n",
      "\"began\"\t6\n",
      "\"begin\"\t5\n",
      "\"beginning\"\t4\n",
      "\"begins\"\t2\n",
      "\"behalf\"\t1\n",
      "\"being\"\t14\n",
      "\"belgium\"\t1\n",
      "\"believable\"\t2\n",
      "\"believe\"\t14\n",
      "\"believed\"\t2\n",
      "\"believes\"\t1\n",
      "\"believing\"\t1\n",
      "\"belong\"\t1\n",
      "\"belonged\"\t1\n",
      "\"belongs\"\t2\n",
      "\"below\"\t16\n",
      "\"benchmarks\"\t3\n",
      "\"bendickson\"\t2\n",
      "\"benedicta\"\t2\n",
      "\"beneficiary\"\t1\n",
      "\"benefit\"\t10\n",
      "\"benefits\"\t11\n",
      "\"beneteau\"\t1\n",
      "\"benewm\"\t1\n",
      "\"bennett\"\t1\n",
      "\"benson\"\t1\n",
      "\"ber\"\t1\n",
      "\"berkovitz\"\t2\n",
      "\"bernice\"\t1\n",
      "\"best\"\t27\n",
      "\"bestowal\"\t1\n",
      "\"bestwaytoshop\"\t1\n",
      "\"betray\"\t1\n",
      "\"better\"\t10\n",
      "\"between\"\t7\n",
      "\"beware\"\t1\n",
      "\"beyond\"\t3\n",
      "\"bgmlm\"\t1\n",
      "\"bharat\"\t1\n",
      "\"bid\"\t1\n",
      "\"big\"\t10\n",
      "\"biggest\"\t1\n",
      "\"bill\"\t8\n",
      "\"billed\"\t2\n",
      "\"billion\"\t6\n",
      "\"bills\"\t6\n",
      "\"birch\"\t1\n",
      "\"bit\"\t2\n",
      "\"biwven\"\t1\n",
      "\"biz\"\t4\n",
      "\"bjeffrie\"\t1\n",
      "\"bjwl\"\t1\n",
      "\"blainey\"\t1\n",
      "\"bless\"\t3\n",
      "\"blessed\"\t2\n",
      "\"block\"\t5\n",
      "\"blocked\"\t2\n",
      "\"blocking\"\t2\n",
      "\"blong\"\t1\n",
      "\"blood\"\t1\n",
      "\"blow\"\t1\n",
      "\"blows\"\t1\n",
      "\"blues\"\t2\n",
      "\"blush\"\t1\n",
      "\"bmar\"\t1\n",
      "\"bmf\"\t1\n",
      "\"bmlm\"\t4\n",
      "\"board\"\t3\n",
      "\"bob\"\t7\n",
      "\"bodies\"\t1\n",
      "\"body\"\t9\n",
      "\"bodyfrankfurter\"\t1\n",
      "\"bold\"\t2\n",
      "\"bolnisi\"\t1\n",
      "\"bombs\"\t3\n",
      "\"bond\"\t1\n",
      "\"bondholders\"\t1\n",
      "\"bonds\"\t6\n",
      "\"bone\"\t1\n",
      "\"bonnard\"\t1\n",
      "\"bonus\"\t5\n",
      "\"bonuses\"\t4\n",
      "\"book\"\t5\n",
      "\"books\"\t2\n",
      "\"boost\"\t1\n",
      "\"boosts\"\t1\n",
      "\"booth\"\t1\n",
      "\"boots\"\t1\n",
      "\"booze\"\t1\n",
      "\"borlan\"\t1\n",
      "\"borland\"\t1\n",
      "\"borrowers\"\t1\n",
      "\"boss\"\t1\n",
      "\"both\"\t15\n",
      "\"bother\"\t1\n",
      "\"bottom\"\t2\n",
      "\"bought\"\t3\n",
      "\"bound\"\t2\n",
      "\"boundary\"\t1\n",
      "\"box\"\t20\n",
      "\"boxes\"\t1\n",
      "\"boy\"\t2\n",
      "\"bp\"\t3\n",
      "\"br\"\t2\n",
      "\"brad\"\t2\n",
      "\"bradford\"\t1\n",
      "\"brainstorm\"\t1\n",
      "\"brand\"\t6\n",
      "\"branded\"\t1\n",
      "\"branding\"\t8\n",
      "\"brazil\"\t8\n",
      "\"brazilian\"\t4\n",
      "\"break\"\t5\n",
      "\"breaking\"\t1\n",
      "\"breakthrough\"\t1\n",
      "\"breath\"\t5\n",
      "\"breathe\"\t2\n",
      "\"bredd\"\t1\n",
      "\"brenda\"\t1\n",
      "\"brennan\"\t2\n",
      "\"brent\"\t2\n",
      "\"brett\"\t3\n",
      "\"brex\"\t2\n",
      "\"brian\"\t1\n",
      "\"brick\"\t5\n",
      "\"bridge\"\t1\n",
      "\"brighton\"\t1\n",
      "\"brim\"\t1\n",
      "\"bring\"\t1\n",
      "\"brings\"\t5\n",
      "\"broad\"\t2\n",
      "\"broker\"\t3\n",
      "\"brought\"\t1\n",
      "\"brown\"\t3\n",
      "\"browser\"\t2\n",
      "\"brutal\"\t1\n",
      "\"bryan\"\t6\n",
      "\"bs\"\t2\n",
      "\"btu\"\t2\n",
      "\"buchsbaum\"\t1\n",
      "\"buck\"\t1\n",
      "\"bucolic\"\t1\n",
      "\"build\"\t12\n",
      "\"building\"\t7\n",
      "\"buildings\"\t1\n",
      "\"buka\"\t2\n",
      "\"bull\"\t1\n",
      "\"bullet\"\t5\n",
      "\"bulleted\"\t2\n",
      "\"bullets\"\t1\n",
      "\"burning\"\t2\n",
      "\"burst\"\t1\n",
      "\"burton\"\t13\n",
      "\"bus\"\t4\n",
      "\"busine\"\t1\n",
      "\"busines\"\t1\n",
      "\"business\"\t64\n",
      "\"businesses\"\t4\n",
      "\"businessopps\"\t2\n",
      "\"bussell\"\t1\n",
      "\"busy\"\t1\n",
      "\"but\"\t67\n",
      "\"butler\"\t1\n",
      "\"button\"\t1\n",
      "\"buy\"\t8\n",
      "\"buybacks\"\t1\n",
      "\"buying\"\t1\n",
      "\"by\"\t143\n",
      "\"bybb\"\t1\n",
      "\"bybtb\"\t1\n",
      "\"bye\"\t1\n",
      "\"byee\"\t2\n",
      "\"bypass\"\t1\n",
      "\"bypasses\"\t1\n",
      "\"bytesize\"\t1\n",
      "\"ca\"\t6\n",
      "\"cabinet\"\t1\n",
      "\"cabinets\"\t1\n",
      "\"caboose\"\t1\n",
      "\"cage\"\t1\n",
      "\"cagey\"\t1\n",
      "\"cal\"\t3\n",
      "\"calamity\"\t2\n",
      "\"calculations\"\t2\n",
      "\"cali\"\t1\n",
      "\"california\"\t12\n",
      "\"call\"\t15\n",
      "\"called\"\t3\n",
      "\"calme\"\t1\n",
      "\"calpine\"\t3\n",
      "\"came\"\t2\n",
      "\"camp\"\t7\n",
      "\"campus\"\t1\n",
      "\"can\"\t90\n",
      "\"canada\"\t4\n",
      "\"canadian\"\t1\n",
      "\"canary\"\t1\n",
      "\"cancel\"\t1\n",
      "\"candidate\"\t1\n",
      "\"cankerworm\"\t1\n",
      "\"cannot\"\t5\n",
      "\"cano\"\t1\n",
      "\"canyonu\"\t1\n",
      "\"capabilities\"\t1\n",
      "\"capability\"\t3\n",
      "\"capacity\"\t2\n",
      "\"capital\"\t7\n",
      "\"capitalisation\"\t1\n",
      "\"capitalize\"\t2\n",
      "\"capitol\"\t1\n",
      "\"car\"\t6\n",
      "\"card\"\t5\n",
      "\"cards\"\t5\n",
      "\"care\"\t9\n",
      "\"careful\"\t1\n",
      "\"carefully\"\t4\n",
      "\"cares\"\t1\n",
      "\"cargill\"\t2\n",
      "\"carlo\"\t1\n",
      "\"carlos\"\t5\n",
      "\"carmody\"\t1\n",
      "\"carol\"\t1\n",
      "\"carolyn\"\t1\n",
      "\"carrera\"\t1\n",
      "\"carriage\"\t1\n",
      "\"carrie\"\t1\n",
      "\"carried\"\t1\n",
      "\"carroll\"\t6\n",
      "\"carry\"\t1\n",
      "\"cars\"\t4\n",
      "\"cart\"\t2\n",
      "\"case\"\t13\n",
      "\"cases\"\t2\n",
      "\"cash\"\t18\n",
      "\"cashpo\"\t2\n",
      "\"cashpromotions\"\t4\n",
      "\"casinos\"\t2\n",
      "\"cat\"\t2\n",
      "\"catalog\"\t5\n",
      "\"catalyze\"\t2\n",
      "\"catchy\"\t1\n",
      "\"category\"\t2\n",
      "\"caucasians\"\t1\n",
      "\"caught\"\t1\n",
      "\"cause\"\t1\n",
      "\"caused\"\t1\n",
      "\"causey\"\t7\n",
      "\"cc\"\t40\n",
      "\"ccprod\"\t3\n",
      "\"cd\"\t2\n",
      "\"ceased\"\t1\n",
      "\"cede\"\t1\n",
      "\"cele\"\t2\n",
      "\"celebrate\"\t1\n",
      "\"celebration\"\t3\n",
      "\"celias\"\t1\n",
      "\"cell\"\t1\n",
      "\"cellulite\"\t1\n",
      "\"cemented\"\t1\n",
      "\"cenochs\"\t1\n",
      "\"cent\"\t1\n",
      "\"center\"\t13\n",
      "\"central\"\t3\n",
      "\"cents\"\t7\n",
      "\"century\"\t1\n",
      "\"ceo\"\t1\n",
      "\"ceos\"\t1\n",
      "\"cernosek\"\t1\n",
      "\"certain\"\t1\n",
      "\"certainly\"\t4\n",
      "\"certificates\"\t1\n",
      "\"cgi\"\t5\n",
      "\"cha\"\t1\n",
      "\"chaeap\"\t1\n",
      "\"chairing\"\t1\n",
      "\"chairman\"\t4\n",
      "\"challenge\"\t1\n",
      "\"challenges\"\t1\n",
      "\"challenging\"\t3\n",
      "\"chambers\"\t1\n",
      "\"champion\"\t3\n",
      "\"chance\"\t6\n",
      "\"chances\"\t4\n",
      "\"chancesto\"\t1\n",
      "\"change\"\t16\n",
      "\"changed\"\t1\n",
      "\"changes\"\t4\n",
      "\"changing\"\t1\n",
      "\"channel\"\t1\n",
      "\"chapman\"\t4\n",
      "\"char\"\t2\n",
      "\"charge\"\t11\n",
      "\"charges\"\t1\n",
      "\"charlie\"\t1\n",
      "\"charset\"\t11\n",
      "\"chart\"\t1\n",
      "\"charter\"\t2\n",
      "\"chartroom\"\t1\n",
      "\"charts\"\t2\n",
      "\"chatham\"\t1\n",
      "\"cheaep\"\t1\n",
      "\"cheap\"\t1\n",
      "\"cheapsoft\"\t3\n",
      "\"cheated\"\t4\n",
      "\"check\"\t3\n",
      "\"checking\"\t4\n",
      "\"checks\"\t1\n",
      "\"cheeap\"\t1\n",
      "\"cheeky\"\t1\n",
      "\"cheers\"\t1\n",
      "\"chewing\"\t2\n",
      "\"chief\"\t4\n",
      "\"child\"\t3\n",
      "\"children\"\t3\n",
      "\"chile\"\t2\n",
      "\"chill\"\t1\n",
      "\"china\"\t3\n",
      "\"chinamen\"\t1\n",
      "\"chinese\"\t1\n",
      "\"chip\"\t1\n",
      "\"chirano\"\t4\n",
      "\"chisholm\"\t1\n",
      "\"choice\"\t2\n",
      "\"chokshi\"\t1\n",
      "\"cholesterol\"\t1\n",
      "\"choose\"\t4\n",
      "\"chosen\"\t4\n",
      "\"chris\"\t1\n",
      "\"christi\"\t1\n",
      "\"christian\"\t1\n",
      "\"christine\"\t1\n",
      "\"christmas\"\t20\n",
      "\"chromium\"\t1\n",
      "\"chronicles\"\t1\n",
      "\"chuck\"\t1\n",
      "\"chumming\"\t1\n",
      "\"chums\"\t1\n",
      "\"chunk\"\t1\n",
      "\"cialis\"\t2\n",
      "\"cigars\"\t1\n",
      "\"cindy\"\t5\n",
      "\"cinergy\"\t1\n",
      "\"circumstances\"\t1\n",
      "\"citizens\"\t2\n",
      "\"citrus\"\t2\n",
      "\"city\"\t5\n",
      "\"civilizirano\"\t1\n",
      "\"cj\"\t5\n",
      "\"ckgby\"\t1\n",
      "\"ckily\"\t1\n",
      "\"claiis\"\t1\n",
      "\"claim\"\t3\n",
      "\"claimed\"\t1\n",
      "\"claiming\"\t1\n",
      "\"claims\"\t4\n",
      "\"clamp\"\t1\n",
      "\"clare\"\t1\n",
      "\"clarification\"\t2\n",
      "\"clarity\"\t1\n",
      "\"clark\"\t1\n",
      "\"class\"\t2\n",
      "\"classes\"\t1\n",
      "\"classic\"\t1\n",
      "\"classifieds\"\t1\n",
      "\"classrom\"\t1\n",
      "\"claude\"\t1\n",
      "\"clear\"\t12\n",
      "\"clearing\"\t1\n",
      "\"clearly\"\t1\n",
      "\"clem\"\t1\n",
      "\"clemmons\"\t1\n",
      "\"clemons\"\t1\n",
      "\"click\"\t41\n",
      "\"clicking\"\t1\n",
      "\"client\"\t1\n",
      "\"clients\"\t1\n",
      "\"cliffhanger\"\t2\n",
      "\"cliickk\"\t2\n",
      "\"climate\"\t1\n",
      "\"clinches\"\t1\n",
      "\"clinging\"\t1\n",
      "\"clips\"\t1\n",
      "\"clon\"\t2\n",
      "\"clonazepam\"\t1\n",
      "\"close\"\t6\n",
      "\"closed\"\t1\n",
      "\"closely\"\t5\n",
      "\"closer\"\t1\n",
      "\"closure\"\t1\n",
      "\"clu\"\t1\n",
      "\"club\"\t1\n",
      "\"cmenergy\"\t1\n",
      "\"co\"\t5\n",
      "\"coaching\"\t1\n",
      "\"coal\"\t2\n",
      "\"coastenergy\"\t1\n",
      "\"cobalt\"\t1\n",
      "\"cochilco\"\t1\n",
      "\"coding\"\t2\n",
      "\"coe\"\t4\n",
      "\"coffee\"\t5\n",
      "\"cohen\"\t1\n",
      "\"cold\"\t2\n",
      "\"coleman\"\t1\n",
      "\"collaborate\"\t3\n",
      "\"collect\"\t2\n",
      "\"college\"\t3\n",
      "\"colliw\"\t1\n",
      "\"colloquy\"\t1\n",
      "\"color\"\t19\n",
      "\"colored\"\t2\n",
      "\"colors\"\t1\n",
      "\"colour\"\t1\n",
      "\"columnar\"\t1\n",
      "\"com\"\t227\n",
      "\"combo\"\t1\n",
      "\"comclick\"\t1\n",
      "\"come\"\t19\n",
      "\"comes\"\t6\n",
      "\"comhttp\"\t1\n",
      "\"coming\"\t5\n",
      "\"commence\"\t2\n",
      "\"commenced\"\t1\n",
      "\"commencement\"\t1\n",
      "\"commentaries\"\t3\n",
      "\"commentary\"\t18\n",
      "\"commentaryto\"\t1\n",
      "\"comments\"\t13\n",
      "\"commercial\"\t20\n",
      "\"commission\"\t3\n",
      "\"commissions\"\t2\n",
      "\"committee\"\t2\n",
      "\"commodities\"\t1\n",
      "\"commodity\"\t8\n",
      "\"common\"\t2\n",
      "\"communicate\"\t2\n",
      "\"communicating\"\t2\n",
      "\"communication\"\t9\n",
      "\"communities\"\t3\n",
      "\"community\"\t23\n",
      "\"companies\"\t8\n",
      "\"company\"\t25\n",
      "\"compare\"\t6\n",
      "\"compared\"\t1\n",
      "\"compelling\"\t1\n",
      "\"compensation\"\t2\n",
      "\"compete\"\t2\n",
      "\"competencies\"\t2\n",
      "\"competing\"\t3\n",
      "\"competition\"\t2\n",
      "\"competitive\"\t3\n",
      "\"complete\"\t4\n",
      "\"completed\"\t2\n",
      "\"completely\"\t2\n",
      "\"completing\"\t1\n",
      "\"completion\"\t3\n",
      "\"compliance\"\t1\n",
      "\"complicated\"\t3\n",
      "\"complications\"\t1\n",
      "\"complimentary\"\t1\n",
      "\"compliments\"\t1\n",
      "\"components\"\t1\n",
      "\"comprehensive\"\t1\n",
      "\"computational\"\t1\n",
      "\"computer\"\t7\n",
      "\"comwww\"\t11\n",
      "\"concealed\"\t2\n",
      "\"conceived\"\t1\n",
      "\"concept\"\t1\n",
      "\"concern\"\t1\n",
      "\"concerned\"\t1\n",
      "\"concernig\"\t2\n",
      "\"concerning\"\t8\n",
      "\"concerns\"\t4\n",
      "\"concluding\"\t2\n",
      "\"condition\"\t2\n",
      "\"conduct\"\t2\n",
      "\"conductor\"\t1\n",
      "\"conference\"\t7\n",
      "\"conferences\"\t1\n",
      "\"confided\"\t1\n",
      "\"confidence\"\t1\n",
      "\"confident\"\t1\n",
      "\"confidential\"\t5\n",
      "\"configuration\"\t1\n",
      "\"confirmation\"\t3\n",
      "\"confirmations\"\t5\n",
      "\"confirmed\"\t1\n",
      "\"conflict\"\t1\n",
      "\"confuses\"\t1\n",
      "\"confusing\"\t1\n",
      "\"congrats\"\t1\n",
      "\"congratulations\"\t6\n",
      "\"congratulatory\"\t1\n",
      "\"conn\"\t1\n",
      "\"connected\"\t1\n",
      "\"connection\"\t3\n",
      "\"connective\"\t1\n",
      "\"connie\"\t1\n",
      "\"conscience\"\t1\n",
      "\"consciously\"\t1\n",
      "\"consequently\"\t1\n",
      "\"consider\"\t4\n",
      "\"considered\"\t1\n",
      "\"consistent\"\t1\n",
      "\"consistently\"\t2\n",
      "\"consisting\"\t1\n",
      "\"consolidation\"\t6\n",
      "\"constantly\"\t1\n",
      "\"consternation\"\t1\n",
      "\"construction\"\t1\n",
      "\"constructive\"\t1\n",
      "\"consultant\"\t3\n",
      "\"consultation\"\t2\n",
      "\"consumer\"\t5\n",
      "\"consumers\"\t3\n",
      "\"consummating\"\t1\n",
      "\"contact\"\t31\n",
      "\"contacts\"\t1\n",
      "\"containing\"\t3\n",
      "\"contains\"\t4\n",
      "\"contemplation\"\t1\n",
      "\"content\"\t13\n",
      "\"continents\"\t1\n",
      "\"continue\"\t15\n",
      "\"continued\"\t3\n",
      "\"continues\"\t3\n",
      "\"continuing\"\t1\n",
      "\"contract\"\t10\n",
      "\"contracted\"\t2\n",
      "\"contracts\"\t12\n",
      "\"contratulations\"\t1\n",
      "\"contribution\"\t1\n",
      "\"control\"\t8\n",
      "\"controlled\"\t2\n",
      "\"controls\"\t6\n",
      "\"convenience\"\t1\n",
      "\"convenient\"\t1\n",
      "\"conversation\"\t1\n",
      "\"conversations\"\t1\n",
      "\"convince\"\t2\n",
      "\"convincible\"\t1\n",
      "\"cook\"\t3\n",
      "\"cool\"\t3\n",
      "\"cooler\"\t1\n",
      "\"cooperation\"\t3\n",
      "\"coordinate\"\t5\n",
      "\"coordinating\"\t1\n",
      "\"coordination\"\t3\n",
      "\"coordinator\"\t1\n",
      "\"cop\"\t2\n",
      "\"copartnery\"\t1\n",
      "\"copenhagen\"\t1\n",
      "\"copper\"\t7\n",
      "\"copy\"\t12\n",
      "\"copying\"\t1\n",
      "\"copyright\"\t7\n",
      "\"coral\"\t4\n",
      "\"cordes\"\t1\n",
      "\"core\"\t1\n",
      "\"corel\"\t4\n",
      "\"coreldraw\"\t2\n",
      "\"corey\"\t2\n",
      "\"cornet\"\t2\n",
      "\"corp\"\t31\n",
      "\"corporate\"\t8\n",
      "\"corporation\"\t4\n",
      "\"correction\"\t2\n",
      "\"correspondence\"\t2\n",
      "\"cost\"\t8\n",
      "\"costed\"\t1\n",
      "\"costs\"\t2\n",
      "\"cote\"\t3\n",
      "\"cotroneo\"\t1\n",
      "\"cough\"\t1\n",
      "\"could\"\t18\n",
      "\"couldn\"\t1\n",
      "\"counted\"\t1\n",
      "\"counterparty\"\t2\n",
      "\"countries\"\t2\n",
      "\"country\"\t23\n",
      "\"couple\"\t2\n",
      "\"course\"\t11\n",
      "\"courses\"\t1\n",
      "\"court\"\t4\n",
      "\"courtesy\"\t1\n",
      "\"cover\"\t2\n",
      "\"coverage\"\t3\n",
      "\"cowry\"\t1\n",
      "\"cp\"\t1\n",
      "\"cpm\"\t6\n",
      "\"cpuc\"\t3\n",
      "\"craft\"\t1\n",
      "\"craig\"\t1\n",
      "\"crank\"\t1\n",
      "\"crapbedspring\"\t1\n",
      "\"crawled\"\t1\n",
      "\"crazy\"\t1\n",
      "\"cre\"\t1\n",
      "\"create\"\t13\n",
      "\"created\"\t7\n",
      "\"creates\"\t2\n",
      "\"creating\"\t2\n",
      "\"creation\"\t3\n",
      "\"creativity\"\t1\n",
      "\"credi\"\t1\n",
      "\"credibility\"\t1\n",
      "\"credit\"\t20\n",
      "\"creditor\"\t1\n",
      "\"creditors\"\t4\n",
      "\"credits\"\t1\n",
      "\"crenshaw\"\t13\n",
      "\"crespigny\"\t2\n",
      "\"crest\"\t1\n",
      "\"critical\"\t10\n",
      "\"critically\"\t2\n",
      "\"critique\"\t1\n",
      "\"crooked\"\t1\n",
      "\"cross\"\t3\n",
      "\"crowd\"\t2\n",
      "\"crowdbut\"\t1\n",
      "\"cryogenic\"\t1\n",
      "\"crystal\"\t2\n",
      "\"cs\"\t2\n",
      "\"csikos\"\t1\n",
      "\"cst\"\t1\n",
      "\"ctise\"\t1\n",
      "\"cultural\"\t1\n",
      "\"cure\"\t2\n",
      "\"cures\"\t1\n",
      "\"curio\"\t1\n",
      "\"currency\"\t1\n",
      "\"current\"\t9\n",
      "\"currently\"\t16\n",
      "\"curricula\"\t1\n",
      "\"curriculum\"\t5\n",
      "\"curtain\"\t1\n",
      "\"cushion\"\t1\n",
      "\"custody\"\t1\n",
      "\"custom\"\t1\n",
      "\"customer\"\t24\n",
      "\"customers\"\t4\n",
      "\"customizable\"\t1\n",
      "\"cuts\"\t1\n",
      "\"cyberopps\"\t2\n",
      "\"cynthia\"\t1\n",
      "\"czkkrxht\"\t1\n",
      "\"dahlienweg\"\t1\n",
      "\"daily\"\t3\n",
      "\"dale\"\t1\n",
      "\"damage\"\t1\n",
      "\"damages\"\t1\n",
      "\"damned\"\t1\n",
      "\"damorganjr\"\t1\n",
      "\"damorgarjr\"\t1\n",
      "\"dana\"\t1\n",
      "\"dancing\"\t1\n",
      "\"dangerous\"\t1\n",
      "\"daniel\"\t2\n",
      "\"danielle\"\t2\n",
      "\"daniels\"\t1\n",
      "\"danny\"\t1\n",
      "\"daren\"\t7\n",
      "\"darren\"\t2\n",
      "\"database\"\t1\n",
      "\"datacenter\"\t1\n",
      "\"date\"\t5\n",
      "\"dates\"\t4\n",
      "\"dave\"\t9\n",
      "\"davenport\"\t1\n",
      "\"david\"\t19\n",
      "\"davidyi\"\t1\n",
      "\"davis\"\t10\n",
      "\"daw\"\t1\n",
      "\"dawn\"\t1\n",
      "\"day\"\t22\n",
      "\"days\"\t10\n",
      "\"daysor\"\t1\n",
      "\"daytime\"\t2\n",
      "\"dc\"\t1\n",
      "\"dci\"\t1\n",
      "\"dclemons\"\t1\n",
      "\"dcoit\"\t1\n",
      "\"de\"\t3\n",
      "\"dea\"\t1\n",
      "\"dead\"\t3\n",
      "\"deadline\"\t6\n",
      "\"deadlines\"\t1\n",
      "\"deal\"\t15\n",
      "\"deals\"\t3\n",
      "\"dean\"\t1\n",
      "\"dear\"\t6\n",
      "\"death\"\t3\n",
      "\"debt\"\t12\n",
      "\"debts\"\t3\n",
      "\"dec\"\t11\n",
      "\"december\"\t19\n",
      "\"decided\"\t5\n",
      "\"decides\"\t1\n",
      "\"decision\"\t2\n",
      "\"decreases\"\t1\n",
      "\"deeds\"\t2\n",
      "\"deemed\"\t2\n",
      "\"deep\"\t1\n",
      "\"deeper\"\t1\n",
      "\"defeat\"\t1\n",
      "\"deficient\"\t1\n",
      "\"defined\"\t1\n",
      "\"delainey\"\t8\n",
      "\"delay\"\t1\n",
      "\"delayed\"\t2\n",
      "\"delays\"\t2\n",
      "\"delegating\"\t1\n",
      "\"delete\"\t8\n",
      "\"delight\"\t1\n",
      "\"delinquent\"\t1\n",
      "\"deliv\"\t2\n",
      "\"deliver\"\t1\n",
      "\"delivered\"\t5\n",
      "\"deliveries\"\t2\n",
      "\"delivering\"\t1\n",
      "\"delivery\"\t11\n",
      "\"delphi\"\t1\n",
      "\"delusive\"\t1\n",
      "\"delux\"\t1\n",
      "\"demand\"\t3\n",
      "\"democratic\"\t2\n",
      "\"democrats\"\t3\n",
      "\"demonstrate\"\t2\n",
      "\"denied\"\t1\n",
      "\"dennis\"\t3\n",
      "\"density\"\t1\n",
      "\"denys\"\t1\n",
      "\"department\"\t1\n",
      "\"depending\"\t2\n",
      "\"deposit\"\t4\n",
      "\"deposited\"\t3\n",
      "\"deposits\"\t2\n",
      "\"depression\"\t1\n",
      "\"dept\"\t2\n",
      "\"derivatives\"\t3\n",
      "\"descendent\"\t1\n",
      "\"described\"\t2\n",
      "\"description\"\t2\n",
      "\"desert\"\t1\n",
      "\"design\"\t9\n",
      "\"designed\"\t5\n",
      "\"designl\"\t1\n",
      "\"designs\"\t4\n",
      "\"desire\"\t3\n",
      "\"desk\"\t12\n",
      "\"desks\"\t2\n",
      "\"desktop\"\t1\n",
      "\"desmeules\"\t1\n",
      "\"desperate\"\t1\n",
      "\"despise\"\t1\n",
      "\"despite\"\t2\n",
      "\"destination\"\t2\n",
      "\"destroy\"\t1\n",
      "\"detail\"\t2\n",
      "\"detailed\"\t4\n",
      "\"details\"\t3\n",
      "\"determine\"\t1\n",
      "\"detract\"\t1\n",
      "\"developed\"\t5\n",
      "\"developing\"\t2\n",
      "\"development\"\t16\n",
      "\"device\"\t1\n",
      "\"devoid\"\t1\n",
      "\"dextails\"\t1\n",
      "\"dfelsinger\"\t1\n",
      "\"dfur\"\t1\n",
      "\"dhar\"\t4\n",
      "\"dhyngem\"\t1\n",
      "\"dial\"\t2\n",
      "\"diamond\"\t2\n",
      "\"diamonds\"\t1\n",
      "\"diane\"\t1\n",
      "\"diaz\"\t2\n",
      "\"dicine\"\t1\n",
      "\"dictate\"\t1\n",
      "\"dictating\"\t1\n",
      "\"dictionary\"\t1\n",
      "\"did\"\t8\n",
      "\"didn\"\t4\n",
      "\"didrex\"\t1\n",
      "\"different\"\t5\n",
      "\"difficult\"\t5\n",
      "\"difficulty\"\t1\n",
      "\"digging\"\t1\n",
      "\"digital\"\t1\n",
      "\"dignity\"\t1\n",
      "\"digression\"\t1\n",
      "\"diligence\"\t1\n",
      "\"diminished\"\t1\n",
      "\"dinner\"\t2\n",
      "\"direct\"\t4\n",
      "\"directed\"\t1\n",
      "\"directing\"\t1\n",
      "\"direction\"\t4\n",
      "\"directions\"\t4\n",
      "\"directly\"\t7\n",
      "\"director\"\t6\n",
      "\"directories\"\t2\n",
      "\"dirtier\"\t1\n",
      "\"disable\"\t1\n",
      "\"disagreement\"\t1\n",
      "\"disappearance\"\t1\n",
      "\"disappointed\"\t1\n",
      "\"discarded\"\t3\n",
      "\"disclaimer\"\t1\n",
      "\"disclosed\"\t2\n",
      "\"discontinue\"\t2\n",
      "\"discoount\"\t1\n",
      "\"discoouunt\"\t1\n",
      "\"discounnt\"\t1\n",
      "\"discount\"\t1\n",
      "\"discounted\"\t1\n",
      "\"discounts\"\t1\n",
      "\"discover\"\t3\n",
      "\"discretely\"\t1\n",
      "\"discretion\"\t1\n",
      "\"discuss\"\t6\n",
      "\"discussed\"\t2\n",
      "\"discussion\"\t8\n",
      "\"disease\"\t1\n",
      "\"dish\"\t3\n",
      "\"dishes\"\t1\n",
      "\"disintegration\"\t1\n",
      "\"dismissed\"\t1\n",
      "\"disordersclump\"\t1\n",
      "\"disordersshrink\"\t1\n",
      "\"disparate\"\t1\n",
      "\"displayed\"\t1\n",
      "\"disposed\"\t1\n",
      "\"disqualified\"\t1\n",
      "\"dissemination\"\t1\n",
      "\"distance\"\t5\n",
      "\"distort\"\t1\n",
      "\"distracted\"\t1\n",
      "\"distributed\"\t1\n",
      "\"distribution\"\t3\n",
      "\"distributions\"\t2\n",
      "\"district\"\t4\n",
      "\"ditch\"\t1\n",
      "\"divert\"\t1\n",
      "\"diverted\"\t1\n",
      "\"divided\"\t1\n",
      "\"division\"\t1\n",
      "\"dkohler\"\t1\n",
      "\"dmao\"\t1\n",
      "\"dnb\"\t1\n",
      "\"do\"\t41\n",
      "\"dobmeos\"\t1\n",
      "\"doc\"\t3\n",
      "\"doctor\"\t2\n",
      "\"doctoral\"\t1\n",
      "\"doctors\"\t2\n",
      "\"doctrine\"\t4\n",
      "\"documenting\"\t2\n",
      "\"documents\"\t4\n",
      "\"does\"\t11\n",
      "\"doesn\"\t10\n",
      "\"doff\"\t1\n",
      "\"dog\"\t1\n",
      "\"doing\"\t6\n",
      "\"dol\"\t1\n",
      "\"dollar\"\t1\n",
      "\"dollars\"\t7\n",
      "\"dolls\"\t1\n",
      "\"domain\"\t5\n",
      "\"domestic\"\t1\n",
      "\"don\"\t33\n",
      "\"done\"\t6\n",
      "\"dont\"\t1\n",
      "\"door\"\t5\n",
      "\"double\"\t2\n",
      "\"doubt\"\t3\n",
      "\"doubts\"\t1\n",
      "\"doug\"\t1\n",
      "\"down\"\t11\n",
      "\"download\"\t1\n",
      "\"dozens\"\t1\n",
      "\"draft\"\t2\n",
      "\"drafting\"\t1\n",
      "\"dramatic\"\t1\n",
      "\"draw\"\t5\n",
      "\"drawing\"\t5\n",
      "\"drawn\"\t2\n",
      "\"dreamwaver\"\t2\n",
      "\"drew\"\t3\n",
      "\"drinking\"\t2\n",
      "\"drive\"\t2\n",
      "\"drives\"\t1\n",
      "\"dronn\"\t1\n",
      "\"drown\"\t1\n",
      "\"drowning\"\t1\n",
      "\"drug\"\t1\n",
      "\"drugs\"\t2\n",
      "\"dryblower\"\t1\n",
      "\"dubhe\"\t1\n",
      "\"dubuque\"\t3\n",
      "\"duck\"\t1\n",
      "\"due\"\t9\n",
      "\"duke\"\t4\n",
      "\"dunns\"\t1\n",
      "\"duns\"\t2\n",
      "\"duplicate\"\t1\n",
      "\"during\"\t9\n",
      "\"dutchess\"\t1\n",
      "\"dutyfreesoft\"\t1\n",
      "\"dvd\"\t1\n",
      "\"dwr\"\t3\n",
      "\"dxqrgu\"\t1\n",
      "\"dycmpf\"\t1\n",
      "\"dynamic\"\t2\n",
      "\"dynamically\"\t1\n",
      "\"dynamics\"\t2\n",
      "\"dynegy\"\t11\n",
      "\"each\"\t27\n",
      "\"earlier\"\t4\n",
      "\"early\"\t8\n",
      "\"earn\"\t6\n",
      "\"earning\"\t1\n",
      "\"earth\"\t1\n",
      "\"earths\"\t1\n",
      "\"easily\"\t4\n",
      "\"east\"\t1\n",
      "\"eastern\"\t1\n",
      "\"easy\"\t16\n",
      "\"eat\"\t3\n",
      "\"eatables\"\t1\n",
      "\"eating\"\t2\n",
      "\"eb\"\t16\n",
      "\"ebl\"\t1\n",
      "\"ebook\"\t3\n",
      "\"ebooks\"\t1\n",
      "\"ebs\"\t1\n",
      "\"ecarmst\"\t1\n",
      "\"eclassifiedshq\"\t1\n",
      "\"ecole\"\t1\n",
      "\"ecom\"\t1\n",
      "\"ecomog\"\t3\n",
      "\"economic\"\t2\n",
      "\"economically\"\t1\n",
      "\"economics\"\t1\n",
      "\"economy\"\t1\n",
      "\"ect\"\t382\n",
      "\"ed\"\t1\n",
      "\"edge\"\t1\n",
      "\"edison\"\t4\n",
      "\"edit\"\t11\n",
      "\"edition\"\t5\n",
      "\"editor\"\t3\n",
      "\"editorial\"\t1\n",
      "\"edt\"\t2\n",
      "\"ee\"\t2\n",
      "\"ees\"\t10\n",
      "\"effect\"\t2\n",
      "\"effective\"\t11\n",
      "\"effectively\"\t5\n",
      "\"effects\"\t1\n",
      "\"efficiency\"\t2\n",
      "\"effort\"\t6\n",
      "\"efforts\"\t2\n",
      "\"efs\"\t1\n",
      "\"egep\"\t1\n",
      "\"ego\"\t2\n",
      "\"eh\"\t1\n",
      "\"ehronline\"\t1\n",
      "\"eiben\"\t1\n",
      "\"eight\"\t2\n",
      "\"eighty\"\t1\n",
      "\"eileen\"\t1\n",
      "\"eincomplete\"\t1\n",
      "\"either\"\t9\n",
      "\"el\"\t2\n",
      "\"elbow\"\t1\n",
      "\"elderly\"\t1\n",
      "\"election\"\t1\n",
      "\"elections\"\t1\n",
      "\"electric\"\t1\n",
      "\"electricity\"\t1\n",
      "\"eliminate\"\t3\n",
      "\"eliminates\"\t1\n",
      "\"eliminationstop\"\t1\n",
      "\"ellendale\"\t2\n",
      "\"ello\"\t1\n",
      "\"elmira\"\t1\n",
      "\"else\"\t2\n",
      "\"elses\"\t2\n",
      "\"emai\"\t1\n",
      "\"email\"\t46\n",
      "\"emailing\"\t2\n",
      "\"embargo\"\t1\n",
      "\"emeet\"\t1\n",
      "\"emerged\"\t1\n",
      "\"emerging\"\t2\n",
      "\"emigrant\"\t1\n",
      "\"emigrants\"\t1\n",
      "\"eminent\"\t2\n",
      "\"emma\"\t1\n",
      "\"emotion\"\t1\n",
      "\"emotional\"\t1\n",
      "\"emove\"\t1\n",
      "\"emphasis\"\t1\n",
      "\"emphasize\"\t1\n",
      "\"emphatically\"\t1\n",
      "\"employed\"\t2\n",
      "\"employee\"\t6\n",
      "\"employees\"\t7\n",
      "\"employer\"\t1\n",
      "\"employment\"\t1\n",
      "\"empowered\"\t1\n",
      "\"en\"\t3\n",
      "\"ena\"\t10\n",
      "\"enable\"\t4\n",
      "\"enacted\"\t2\n",
      "\"encarta\"\t1\n",
      "\"encoding\"\t2\n",
      "\"encompassing\"\t1\n",
      "\"encounters\"\t1\n",
      "\"encourage\"\t4\n",
      "\"encouraged\"\t3\n",
      "\"encyclopedia\"\t1\n",
      "\"end\"\t19\n",
      "\"ending\"\t2\n",
      "\"endless\"\t1\n",
      "\"endorsements\"\t1\n",
      "\"ends\"\t1\n",
      "\"energetic\"\t1\n",
      "\"energy\"\t44\n",
      "\"eneric\"\t1\n",
      "\"eng\"\t1\n",
      "\"engageenergy\"\t1\n",
      "\"engine\"\t3\n",
      "\"engineergeodetic\"\t1\n",
      "\"engineering\"\t2\n",
      "\"engines\"\t2\n",
      "\"enhance\"\t3\n",
      "\"enhancing\"\t1\n",
      "\"enjoy\"\t2\n",
      "\"enormous\"\t1\n",
      "\"enough\"\t6\n",
      "\"enron\"\t127\n",
      "\"enrononline\"\t4\n",
      "\"ensure\"\t3\n",
      "\"ensuring\"\t2\n",
      "\"enter\"\t7\n",
      "\"entered\"\t10\n",
      "\"entergy\"\t6\n",
      "\"entergyr\"\t1\n",
      "\"entering\"\t2\n",
      "\"enterprise\"\t4\n",
      "\"enters\"\t1\n",
      "\"entertaining\"\t1\n",
      "\"entex\"\t14\n",
      "\"entire\"\t2\n",
      "\"entirely\"\t2\n",
      "\"entity\"\t3\n",
      "\"entries\"\t3\n",
      "\"entry\"\t1\n",
      "\"environment\"\t3\n",
      "\"environmental\"\t1\n",
      "\"envy\"\t1\n",
      "\"eo\"\t1\n",
      "\"eops\"\t1\n",
      "\"epam\"\t2\n",
      "\"epcm\"\t2\n",
      "\"epenergy\"\t5\n",
      "\"epmi\"\t2\n",
      "\"eprm\"\t1\n",
      "\"epsc\"\t1\n",
      "\"equity\"\t5\n",
      "\"equivelant\"\t1\n",
      "\"er\"\t2\n",
      "\"ere\"\t1\n",
      "\"ernest\"\t1\n",
      "\"erroneously\"\t1\n",
      "\"error\"\t8\n",
      "\"errors\"\t6\n",
      "\"esa\"\t1\n",
      "\"escape\"\t2\n",
      "\"esiear\"\t2\n",
      "\"espcially\"\t1\n",
      "\"especially\"\t4\n",
      "\"essentially\"\t1\n",
      "\"est\"\t1\n",
      "\"establish\"\t8\n",
      "\"established\"\t3\n",
      "\"establishes\"\t1\n",
      "\"establishthe\"\t1\n",
      "\"estimate\"\t2\n",
      "\"etacitne\"\t1\n",
      "\"etc\"\t9\n",
      "\"eternal\"\t1\n",
      "\"ethic\"\t1\n",
      "\"etringer\"\t2\n",
      "\"europe\"\t1\n",
      "\"european\"\t2\n",
      "\"evaluate\"\t2\n",
      "\"evaluating\"\t1\n",
      "\"evaluation\"\t1\n",
      "\"evelon\"\t1\n",
      "\"even\"\t16\n",
      "\"evening\"\t3\n",
      "\"events\"\t2\n",
      "\"eventually\"\t2\n",
      "\"ever\"\t5\n",
      "\"every\"\t14\n",
      "\"everyday\"\t2\n",
      "\"everyone\"\t17\n",
      "\"everything\"\t8\n",
      "\"evolution\"\t1\n",
      "\"eworld\"\t4\n",
      "\"exact\"\t2\n",
      "\"exactly\"\t4\n",
      "\"exaggerate\"\t1\n",
      "\"examination\"\t1\n",
      "\"examine\"\t3\n",
      "\"examing\"\t1\n",
      "\"examining\"\t1\n",
      "\"example\"\t7\n",
      "\"examples\"\t1\n",
      "\"exceed\"\t1\n",
      "\"exceeded\"\t2\n",
      "\"excellent\"\t4\n",
      "\"except\"\t1\n",
      "\"exception\"\t1\n",
      "\"excerpts\"\t1\n",
      "\"excess\"\t1\n",
      "\"exchange\"\t13\n",
      "\"exchanges\"\t1\n",
      "\"exchanging\"\t1\n",
      "\"excited\"\t3\n",
      "\"exciting\"\t1\n",
      "\"excluding\"\t2\n",
      "\"exclusive\"\t1\n",
      "\"execute\"\t1\n",
      "\"executed\"\t1\n",
      "\"executing\"\t2\n",
      "\"execution\"\t1\n",
      "\"executive\"\t6\n",
      "\"executives\"\t1\n",
      "\"exemptions\"\t2\n",
      "\"exhausted\"\t1\n",
      "\"exhibit\"\t5\n",
      "\"exhibits\"\t2\n",
      "\"exist\"\t2\n",
      "\"existing\"\t5\n",
      "\"expanded\"\t1\n",
      "\"expanding\"\t1\n",
      "\"expanse\"\t1\n",
      "\"expect\"\t9\n",
      "\"expectation\"\t2\n",
      "\"expectations\"\t4\n",
      "\"expected\"\t6\n",
      "\"expecting\"\t2\n",
      "\"expects\"\t3\n",
      "\"expended\"\t1\n",
      "\"expenditures\"\t1\n",
      "\"expenses\"\t3\n",
      "\"experience\"\t17\n",
      "\"experiences\"\t1\n",
      "\"experiment\"\t1\n",
      "\"expertise\"\t8\n",
      "\"expire\"\t1\n",
      "\"expired\"\t1\n",
      "\"explain\"\t2\n",
      "\"explained\"\t1\n",
      "\"explaing\"\t2\n",
      "\"explaining\"\t2\n",
      "\"explicitly\"\t1\n",
      "\"exploration\"\t2\n",
      "\"explorer\"\t3\n",
      "\"exploring\"\t2\n",
      "\"expose\"\t1\n",
      "\"exposure\"\t2\n",
      "\"express\"\t4\n",
      "\"expressed\"\t1\n",
      "\"expressway\"\t1\n",
      "\"ext\"\t3\n",
      "\"extend\"\t1\n",
      "\"extended\"\t3\n",
      "\"extension\"\t1\n",
      "\"extent\"\t1\n",
      "\"externally\"\t2\n",
      "\"extra\"\t7\n",
      "\"extremal\"\t1\n",
      "\"extreme\"\t1\n",
      "\"exultant\"\t1\n",
      "\"eye\"\t1\n",
      "\"eyebrow\"\t2\n",
      "\"eyes\"\t2\n",
      "\"ezine\"\t5\n",
      "\"fabaclbo\"\t1\n",
      "\"face\"\t1\n",
      "\"facelift\"\t1\n",
      "\"faces\"\t1\n",
      "\"facilitate\"\t4\n",
      "\"facilitators\"\t1\n",
      "\"facility\"\t1\n",
      "\"faclities\"\t1\n",
      "\"fact\"\t8\n",
      "\"factor\"\t1\n",
      "\"factual\"\t1\n",
      "\"faded\"\t1\n",
      "\"fails\"\t1\n",
      "\"fainted\"\t1\n",
      "\"fair\"\t2\n",
      "\"faith\"\t1\n",
      "\"fall\"\t2\n",
      "\"fallon\"\t1\n",
      "\"fame\"\t3\n",
      "\"families\"\t2\n",
      "\"family\"\t3\n",
      "\"famous\"\t1\n",
      "\"fanny\"\t1\n",
      "\"fantastic\"\t1\n",
      "\"far\"\t5\n",
      "\"farm\"\t1\n",
      "\"farmer\"\t5\n",
      "\"fashion\"\t1\n",
      "\"fast\"\t4\n",
      "\"faster\"\t2\n",
      "\"fat\"\t1\n",
      "\"father\"\t4\n",
      "\"fathers\"\t1\n",
      "\"fattroglodyte\"\t1\n",
      "\"fault\"\t1\n",
      "\"favor\"\t4\n",
      "\"favorably\"\t1\n",
      "\"favorite\"\t7\n",
      "\"favourably\"\t1\n",
      "\"fax\"\t9\n",
      "\"fe\"\t1\n",
      "\"fear\"\t4\n",
      "\"feature\"\t1\n",
      "\"featured\"\t2\n",
      "\"features\"\t6\n",
      "\"feb\"\t3\n",
      "\"february\"\t10\n",
      "\"federal\"\t4\n",
      "\"fee\"\t6\n",
      "\"feel\"\t19\n",
      "\"feeling\"\t3\n",
      "\"feelings\"\t1\n",
      "\"fees\"\t1\n",
      "\"feet\"\t1\n",
      "\"felipe\"\t2\n",
      "\"fell\"\t2\n",
      "\"fellow\"\t1\n",
      "\"felt\"\t2\n",
      "\"female\"\t3\n",
      "\"few\"\t12\n",
      "\"ffffa\"\t2\n",
      "\"fh\"\t2\n",
      "\"fiducial\"\t1\n",
      "\"field\"\t3\n",
      "\"fields\"\t1\n",
      "\"fifteen\"\t1\n",
      "\"fifth\"\t1\n",
      "\"fight\"\t2\n",
      "\"figure\"\t1\n",
      "\"figured\"\t1\n",
      "\"file\"\t6\n",
      "\"filed\"\t6\n",
      "\"files\"\t3\n",
      "\"filing\"\t11\n",
      "\"fill\"\t6\n",
      "\"filled\"\t2\n",
      "\"filling\"\t1\n",
      "\"filter\"\t1\n",
      "\"final\"\t6\n",
      "\"finalization\"\t2\n",
      "\"finalize\"\t1\n",
      "\"finally\"\t3\n",
      "\"finance\"\t4\n",
      "\"financial\"\t12\n",
      "\"financials\"\t1\n",
      "\"financing\"\t4\n",
      "\"find\"\t5\n",
      "\"finding\"\t1\n",
      "\"fine\"\t2\n",
      "\"finger\"\t1\n",
      "\"finished\"\t6\n",
      "\"finishing\"\t1\n",
      "\"finland\"\t1\n",
      "\"fior\"\t2\n",
      "\"fioricet\"\t1\n",
      "\"fired\"\t1\n",
      "\"fireworks\"\t1\n",
      "\"firing\"\t1\n",
      "\"firm\"\t5\n",
      "\"first\"\t34\n",
      "\"fischer\"\t1\n",
      "\"fishbeck\"\t1\n",
      "\"fit\"\t2\n",
      "\"five\"\t4\n",
      "\"fixed\"\t1\n",
      "\"fl\"\t1\n",
      "\"flash\"\t2\n",
      "\"flat\"\t5\n",
      "\"flatter\"\t1\n",
      "\"flight\"\t1\n",
      "\"flip\"\t1\n",
      "\"fln\"\t1\n",
      "\"floe\"\t1\n",
      "\"flood\"\t2\n",
      "\"floods\"\t1\n",
      "\"floor\"\t4\n",
      "\"flow\"\t8\n",
      "\"fluid\"\t1\n",
      "\"flustrated\"\t1\n",
      "\"flutter\"\t1\n",
      "\"flyers\"\t1\n",
      "\"flynn\"\t1\n",
      "\"focus\"\t4\n",
      "\"focusing\"\t4\n",
      "\"foday\"\t1\n",
      "\"folks\"\t3\n",
      "\"follow\"\t10\n",
      "\"followed\"\t2\n",
      "\"following\"\t27\n",
      "\"font\"\t3\n",
      "\"fonts\"\t2\n",
      "\"foo\"\t1\n",
      "\"foolishness\"\t1\n",
      "\"foot\"\t3\n",
      "\"footmen\"\t1\n",
      "\"fooxr\"\t1\n",
      "\"for\"\t374\n",
      "\"forbearance\"\t4\n",
      "\"force\"\t5\n",
      "\"forced\"\t1\n",
      "\"forces\"\t5\n",
      "\"forcing\"\t1\n",
      "\"ford\"\t1\n",
      "\"forecast\"\t1\n",
      "\"forecasts\"\t2\n",
      "\"foreigner\"\t1\n",
      "\"foreigners\"\t1\n",
      "\"forest\"\t1\n",
      "\"forestall\"\t1\n",
      "\"foretell\"\t1\n",
      "\"forever\"\t3\n",
      "\"forget\"\t1\n",
      "\"forgotten\"\t1\n",
      "\"forhome\"\t1\n",
      "\"fork\"\t2\n",
      "\"form\"\t11\n",
      "\"formal\"\t1\n",
      "\"formally\"\t2\n",
      "\"format\"\t3\n",
      "\"forms\"\t1\n",
      "\"formula\"\t2\n",
      "\"formulated\"\t1\n",
      "\"forp\"\t1\n",
      "\"fort\"\t1\n",
      "\"forthis\"\t1\n",
      "\"fortunately\"\t2\n",
      "\"forty\"\t1\n",
      "\"forum\"\t1\n",
      "\"forward\"\t13\n",
      "\"forwarded\"\t29\n",
      "\"forwarding\"\t1\n",
      "\"found\"\t6\n",
      "\"founder\"\t1\n",
      "\"founding\"\t1\n",
      "\"four\"\t8\n",
      "\"fp\"\t1\n",
      "\"fraction\"\t4\n",
      "\"frame\"\t1\n",
      "\"frames\"\t1\n",
      "\"fran\"\t2\n",
      "\"francisco\"\t1\n",
      "\"frank\"\t1\n",
      "\"fraternal\"\t1\n",
      "\"fraud\"\t1\n",
      "\"fred\"\t1\n",
      "\"free\"\t86\n",
      "\"freebie\"\t2\n",
      "\"freehand\"\t1\n",
      "\"freelinksnetwork\"\t4\n",
      "\"freeonline\"\t1\n",
      "\"freepicklotto\"\t2\n",
      "\"freese\"\t1\n",
      "\"freeze\"\t3\n",
      "\"frequently\"\t1\n",
      "\"frevert\"\t3\n",
      "\"friday\"\t6\n",
      "\"friend\"\t2\n",
      "\"friends\"\t3\n",
      "\"frightened\"\t1\n",
      "\"frightrob\"\t1\n",
      "\"from\"\t135\n",
      "\"front\"\t3\n",
      "\"fronts\"\t1\n",
      "\"frqee\"\t1\n",
      "\"fruit\"\t1\n",
      "\"frusco\"\t3\n",
      "\"frustration\"\t1\n",
      "\"ft\"\t2\n",
      "\"ftp\"\t1\n",
      "\"fuel\"\t1\n",
      "\"fulfill\"\t2\n",
      "\"full\"\t28\n",
      "\"fully\"\t3\n",
      "\"fun\"\t5\n",
      "\"function\"\t5\n",
      "\"functionality\"\t4\n",
      "\"functions\"\t5\n",
      "\"fund\"\t4\n",
      "\"fundamental\"\t2\n",
      "\"funded\"\t1\n",
      "\"funding\"\t1\n",
      "\"funds\"\t10\n",
      "\"fuohqjlsjcqp\"\t1\n",
      "\"further\"\t9\n",
      "\"furthermore\"\t1\n",
      "\"future\"\t14\n",
      "\"fw\"\t3\n",
      "\"fyi\"\t6\n",
      "\"fyl\"\t2\n",
      "\"gaining\"\t1\n",
      "\"game\"\t4\n",
      "\"gary\"\t7\n",
      "\"gas\"\t37\n",
      "\"gb\"\t1\n",
      "\"gee\"\t1\n",
      "\"gemstone\"\t1\n",
      "\"general\"\t5\n",
      "\"generalist\"\t1\n",
      "\"generalities\"\t1\n",
      "\"generalize\"\t1\n",
      "\"generalizing\"\t1\n",
      "\"generate\"\t1\n",
      "\"generating\"\t2\n",
      "\"generation\"\t5\n",
      "\"generators\"\t2\n",
      "\"generic\"\t6\n",
      "\"genuine\"\t2\n",
      "\"geoffrey\"\t1\n",
      "\"geographic\"\t4\n",
      "\"geomatics\"\t1\n",
      "\"george\"\t9\n",
      "\"georgel\"\t2\n",
      "\"georgia\"\t1\n",
      "\"germany\"\t3\n",
      "\"gerry\"\t2\n",
      "\"ges\"\t2\n",
      "\"get\"\t76\n",
      "\"gets\"\t3\n",
      "\"getterscan\"\t1\n",
      "\"getthe\"\t1\n",
      "\"getting\"\t8\n",
      "\"getyour\"\t1\n",
      "\"ghana\"\t2\n",
      "\"ghz\"\t1\n",
      "\"gibner\"\t8\n",
      "\"gibson\"\t1\n",
      "\"gift\"\t13\n",
      "\"gifts\"\t2\n",
      "\"gigabyte\"\t1\n",
      "\"gilbert\"\t1\n",
      "\"gilchrist\"\t1\n",
      "\"gimg\"\t1\n",
      "\"ginsu\"\t1\n",
      "\"girl\"\t4\n",
      "\"gis\"\t2\n",
      "\"gist\"\t2\n",
      "\"giv\"\t1\n",
      "\"give\"\t17\n",
      "\"glad\"\t1\n",
      "\"glandular\"\t1\n",
      "\"glaspie\"\t1\n",
      "\"glen\"\t1\n",
      "\"glencore\"\t2\n",
      "\"glenda\"\t1\n",
      "\"global\"\t44\n",
      "\"globe\"\t3\n",
      "\"glover\"\t1\n",
      "\"glut\"\t1\n",
      "\"gmx\"\t2\n",
      "\"go\"\t11\n",
      "\"goage\"\t1\n",
      "\"goal\"\t5\n",
      "\"goals\"\t1\n",
      "\"goatee\"\t1\n",
      "\"god\"\t3\n",
      "\"godly\"\t1\n",
      "\"goes\"\t1\n",
      "\"going\"\t27\n",
      "\"gold\"\t14\n",
      "\"golnaraghi\"\t1\n",
      "\"gone\"\t2\n",
      "\"gonzalez\"\t1\n",
      "\"good\"\t23\n",
      "\"goodbye\"\t1\n",
      "\"goodmorning\"\t2\n",
      "\"goods\"\t1\n",
      "\"gosnell\"\t1\n",
      "\"got\"\t7\n",
      "\"gov\"\t1\n",
      "\"government\"\t7\n",
      "\"governor\"\t5\n",
      "\"gpg\"\t1\n",
      "\"gpt\"\t1\n",
      "\"gra\"\t3\n",
      "\"grabbing\"\t1\n",
      "\"grabs\"\t1\n",
      "\"gracie\"\t2\n",
      "\"grade\"\t2\n",
      "\"grading\"\t1\n",
      "\"gradually\"\t1\n",
      "\"grammar\"\t1\n",
      "\"grand\"\t3\n",
      "\"grandfathered\"\t1\n",
      "\"grandma\"\t1\n",
      "\"grant\"\t6\n",
      "\"granted\"\t1\n",
      "\"granting\"\t1\n",
      "\"graphics\"\t5\n",
      "\"gratis\"\t1\n",
      "\"gravel\"\t1\n",
      "\"graves\"\t2\n",
      "\"gray\"\t2\n",
      "\"great\"\t20\n",
      "\"greater\"\t1\n",
      "\"greatest\"\t2\n",
      "\"greatly\"\t1\n",
      "\"greedily\"\t1\n",
      "\"greeted\"\t1\n",
      "\"greetings\"\t1\n",
      "\"greg\"\t3\n",
      "\"gregory\"\t1\n",
      "\"griddle\"\t1\n",
      "\"grief\"\t1\n",
      "\"grizzly\"\t1\n",
      "\"gross\"\t3\n",
      "\"ground\"\t1\n",
      "\"group\"\t22\n",
      "\"groups\"\t4\n",
      "\"growing\"\t1\n",
      "\"grown\"\t2\n",
      "\"growth\"\t4\n",
      "\"gs\"\t1\n",
      "\"gssgeomatics\"\t1\n",
      "\"guarantee\"\t5\n",
      "\"guaranteed\"\t4\n",
      "\"guerrilla\"\t1\n",
      "\"guess\"\t1\n",
      "\"guides\"\t1\n",
      "\"guinea\"\t1\n",
      "\"gullweig\"\t1\n",
      "\"gunners\"\t1\n",
      "\"guns\"\t1\n",
      "\"guru\"\t2\n",
      "\"gutierrez\"\t1\n",
      "\"guy\"\t2\n",
      "\"guys\"\t3\n",
      "\"gwen\"\t1\n",
      "\"gxol\"\t1\n",
      "\"gxxu\"\t1\n",
      "\"habitually\"\t1\n",
      "\"had\"\t20\n",
      "\"hair\"\t1\n",
      "\"hal\"\t1\n",
      "\"half\"\t2\n",
      "\"hall\"\t2\n",
      "\"hand\"\t5\n",
      "\"handle\"\t1\n",
      "\"handled\"\t2\n",
      "\"hands\"\t2\n",
      "\"hang\"\t1\n",
      "\"hangover\"\t1\n",
      "\"hans\"\t1\n",
      "\"happen\"\t4\n",
      "\"happens\"\t1\n",
      "\"happy\"\t4\n",
      "\"harbour\"\t1\n",
      "\"hard\"\t10\n",
      "\"hardly\"\t2\n",
      "\"hardware\"\t1\n",
      "\"harriman\"\t1\n",
      "\"harris\"\t2\n",
      "\"harrison\"\t2\n",
      "\"harry\"\t1\n",
      "\"harvey\"\t4\n",
      "\"has\"\t67\n",
      "\"hash\"\t1\n",
      "\"hassle\"\t2\n",
      "\"hate\"\t4\n",
      "\"haunch\"\t1\n",
      "\"have\"\t170\n",
      "\"having\"\t6\n",
      "\"hc\"\t2\n",
      "\"hcokyovrdsprayz\"\t1\n",
      "\"he\"\t47\n",
      "\"head\"\t3\n",
      "\"headache\"\t1\n",
      "\"headachesmerle\"\t1\n",
      "\"heading\"\t1\n",
      "\"headline\"\t2\n",
      "\"headlines\"\t4\n",
      "\"heal\"\t1\n",
      "\"healing\"\t1\n",
      "\"health\"\t2\n",
      "\"hear\"\t3\n",
      "\"heard\"\t2\n",
      "\"hearers\"\t1\n",
      "\"heart\"\t1\n",
      "\"heartburnwestfield\"\t1\n",
      "\"heathman\"\t1\n",
      "\"heating\"\t2\n",
      "\"held\"\t6\n",
      "\"hello\"\t6\n",
      "\"help\"\t16\n",
      "\"helpdesk\"\t2\n",
      "\"helped\"\t1\n",
      "\"helpful\"\t2\n",
      "\"helping\"\t3\n",
      "\"helpless\"\t2\n",
      "\"helps\"\t2\n",
      "\"hemingway\"\t1\n",
      "\"hemisphere\"\t2\n",
      "\"hence\"\t1\n",
      "\"hendricks\"\t2\n",
      "\"heno\"\t1\n",
      "\"her\"\t12\n",
      "\"herbalonline\"\t1\n",
      "\"herbs\"\t1\n",
      "\"here\"\t61\n",
      "\"herem\"\t1\n",
      "\"herewe\"\t1\n",
      "\"herod\"\t1\n",
      "\"hesitate\"\t4\n",
      "\"hey\"\t2\n",
      "\"hgh\"\t5\n",
      "\"hi\"\t2\n",
      "\"hidd\"\t2\n",
      "\"high\"\t15\n",
      "\"higher\"\t4\n",
      "\"highlands\"\t2\n",
      "\"highlight\"\t3\n",
      "\"highly\"\t1\n",
      "\"highs\"\t1\n",
      "\"hijacked\"\t2\n",
      "\"hike\"\t1\n",
      "\"hikes\"\t4\n",
      "\"hillis\"\t1\n",
      "\"hillmancarthage\"\t1\n",
      "\"him\"\t9\n",
      "\"himhe\"\t1\n",
      "\"himself\"\t1\n",
      "\"hindering\"\t1\n",
      "\"hinsch\"\t2\n",
      "\"hint\"\t1\n",
      "\"hire\"\t2\n",
      "\"his\"\t39\n",
      "\"historical\"\t3\n",
      "\"history\"\t2\n",
      "\"hit\"\t2\n",
      "\"hje\"\t1\n",
      "\"hm\"\t1\n",
      "\"hme\"\t1\n",
      "\"ho\"\t3\n",
      "\"hoferc\"\t1\n",
      "\"hoffman\"\t2\n",
      "\"hold\"\t3\n",
      "\"holders\"\t1\n",
      "\"holding\"\t1\n",
      "\"holiday\"\t3\n",
      "\"holidays\"\t2\n",
      "\"home\"\t20\n",
      "\"homemakers\"\t1\n",
      "\"homes\"\t2\n",
      "\"homestead\"\t1\n",
      "\"hone\"\t1\n",
      "\"honest\"\t1\n",
      "\"honesty\"\t1\n",
      "\"hood\"\t1\n",
      "\"hook\"\t2\n",
      "\"hope\"\t9\n",
      "\"hopefully\"\t2\n",
      "\"hopes\"\t1\n",
      "\"hopkins\"\t1\n",
      "\"horizons\"\t1\n",
      "\"hormone\"\t2\n",
      "\"horn\"\t1\n",
      "\"hornbuckle\"\t1\n",
      "\"horror\"\t1\n",
      "\"horse\"\t2\n",
      "\"host\"\t1\n",
      "\"hosted\"\t1\n",
      "\"hot\"\t2\n",
      "\"hotmail\"\t2\n",
      "\"hottest\"\t1\n",
      "\"hou\"\t206\n",
      "\"hour\"\t1\n",
      "\"hourhelp\"\t1\n",
      "\"hours\"\t26\n",
      "\"house\"\t1\n",
      "\"houston\"\t13\n",
      "\"how\"\t36\n",
      "\"howard\"\t14\n",
      "\"however\"\t14\n",
      "\"howl\"\t1\n",
      "\"hp\"\t1\n",
      "\"hpl\"\t12\n",
      "\"hplc\"\t1\n",
      "\"hplr\"\t1\n",
      "\"hr\"\t14\n",
      "\"hrgovcic\"\t5\n",
      "\"hrice\"\t2\n",
      "\"hris\"\t1\n",
      "\"ht\"\t4\n",
      "\"htm\"\t2\n",
      "\"html\"\t9\n",
      "\"http\"\t65\n",
      "\"huang\"\t4\n",
      "\"hubs\"\t3\n",
      "\"huge\"\t2\n",
      "\"hulmeville\"\t1\n",
      "\"human\"\t14\n",
      "\"humble\"\t1\n",
      "\"humility\"\t2\n",
      "\"hundred\"\t2\n",
      "\"hundreds\"\t2\n",
      "\"hunger\"\t1\n",
      "\"hungry\"\t1\n",
      "\"hunt\"\t1\n",
      "\"hunter\"\t2\n",
      "\"hurdles\"\t1\n",
      "\"hurrah\"\t1\n",
      "\"hurry\"\t4\n",
      "\"hurtling\"\t1\n",
      "\"husband\"\t4\n",
      "\"huse\"\t1\n",
      "\"hyde\"\t1\n",
      "\"hydro\"\t2\n",
      "\"hydroxylate\"\t1\n",
      "\"hype\"\t1\n",
      "\"hzriubp\"\t1\n",
      "\"iain\"\t1\n",
      "\"ica\"\t1\n",
      "\"iccenergy\"\t1\n",
      "\"icet\"\t2\n",
      "\"icon\"\t1\n",
      "\"icop\"\t1\n",
      "\"id\"\t14\n",
      "\"idea\"\t5\n",
      "\"ideas\"\t6\n",
      "\"identified\"\t1\n",
      "\"identifies\"\t1\n",
      "\"identify\"\t2\n",
      "\"idiot\"\t1\n",
      "\"idirect\"\t1\n",
      "\"ids\"\t1\n",
      "\"ie\"\t4\n",
      "\"ien\"\t2\n",
      "\"if\"\t107\n",
      "\"igh\"\t1\n",
      "\"ihf\"\t1\n",
      "\"ii\"\t3\n",
      "\"illness\"\t1\n",
      "\"illustrate\"\t2\n",
      "\"illustration\"\t1\n",
      "\"illustrator\"\t2\n",
      "\"ilug\"\t3\n",
      "\"ilydiatt\"\t1\n",
      "\"im\"\t1\n",
      "\"image\"\t9\n",
      "\"imagine\"\t1\n",
      "\"imaging\"\t1\n",
      "\"imitate\"\t2\n",
      "\"immediate\"\t2\n",
      "\"immediately\"\t22\n",
      "\"imminent\"\t1\n",
      "\"immunity\"\t1\n",
      "\"impact\"\t3\n",
      "\"impacted\"\t1\n",
      "\"impacts\"\t1\n",
      "\"impaired\"\t1\n",
      "\"impede\"\t1\n",
      "\"imperial\"\t2\n",
      "\"implement\"\t1\n",
      "\"implementation\"\t9\n",
      "\"implementing\"\t1\n",
      "\"important\"\t12\n",
      "\"importantly\"\t1\n",
      "\"impossible\"\t1\n",
      "\"impresses\"\t1\n",
      "\"impression\"\t3\n",
      "\"impressive\"\t1\n",
      "\"improve\"\t1\n",
      "\"improved\"\t5\n",
      "\"improving\"\t1\n",
      "\"impulse\"\t1\n",
      "\"in\"\t418\n",
      "\"iname\"\t1\n",
      "\"inappropriate\"\t1\n",
      "\"inbox\"\t1\n",
      "\"inc\"\t12\n",
      "\"incessantly\"\t1\n",
      "\"include\"\t12\n",
      "\"included\"\t8\n",
      "\"includes\"\t1\n",
      "\"including\"\t16\n",
      "\"inclusive\"\t1\n",
      "\"income\"\t4\n",
      "\"incomeunlimited\"\t1\n",
      "\"incorporated\"\t1\n",
      "\"incorrectly\"\t1\n",
      "\"increase\"\t12\n",
      "\"increased\"\t5\n",
      "\"increases\"\t2\n",
      "\"increasing\"\t4\n",
      "\"increasingly\"\t1\n",
      "\"incredibily\"\t1\n",
      "\"incredible\"\t1\n",
      "\"incredibly\"\t1\n",
      "\"incurred\"\t3\n",
      "\"india\"\t1\n",
      "\"indicated\"\t1\n",
      "\"indication\"\t1\n",
      "\"indicator\"\t1\n",
      "\"indices\"\t1\n",
      "\"individual\"\t8\n",
      "\"individualized\"\t3\n",
      "\"individuals\"\t4\n",
      "\"indubitable\"\t1\n",
      "\"industries\"\t1\n",
      "\"industry\"\t9\n",
      "\"inferior\"\t1\n",
      "\"influence\"\t2\n",
      "\"info\"\t9\n",
      "\"inform\"\t3\n",
      "\"information\"\t71\n",
      "\"informative\"\t1\n",
      "\"informed\"\t4\n",
      "\"infrastructure\"\t1\n",
      "\"inherently\"\t1\n",
      "\"initial\"\t7\n",
      "\"initializes\"\t1\n",
      "\"initially\"\t4\n",
      "\"initiative\"\t3\n",
      "\"inject\"\t1\n",
      "\"injunction\"\t1\n",
      "\"inlcuding\"\t1\n",
      "\"inlet\"\t4\n",
      "\"innovation\"\t4\n",
      "\"innovative\"\t2\n",
      "\"innovatus\"\t1\n",
      "\"input\"\t6\n",
      "\"inputs\"\t1\n",
      "\"insane\"\t2\n",
      "\"inseminate\"\t1\n",
      "\"inside\"\t2\n",
      "\"insider\"\t2\n",
      "\"insomnia\"\t1\n",
      "\"inspection\"\t1\n",
      "\"instantaneous\"\t1\n",
      "\"instantly\"\t2\n",
      "\"instead\"\t3\n",
      "\"institutions\"\t1\n",
      "\"instruct\"\t1\n",
      "\"instructed\"\t3\n",
      "\"instructions\"\t4\n",
      "\"instructs\"\t1\n",
      "\"instrument\"\t1\n",
      "\"instruments\"\t1\n",
      "\"insufficient\"\t1\n",
      "\"insults\"\t1\n",
      "\"insurance\"\t6\n",
      "\"insure\"\t7\n",
      "\"integrated\"\t2\n",
      "\"integrity\"\t2\n",
      "\"intelligence\"\t1\n",
      "\"intelt\"\t1\n",
      "\"intend\"\t3\n",
      "\"intended\"\t1\n",
      "\"intends\"\t2\n",
      "\"intense\"\t1\n",
      "\"intercreditor\"\t1\n",
      "\"interest\"\t12\n",
      "\"interested\"\t10\n",
      "\"interesting\"\t3\n",
      "\"interests\"\t7\n",
      "\"interfering\"\t1\n",
      "\"intermediary\"\t2\n",
      "\"internal\"\t9\n",
      "\"internally\"\t2\n",
      "\"international\"\t7\n",
      "\"interne\"\t1\n",
      "\"internet\"\t30\n",
      "\"interrupted\"\t1\n",
      "\"interstate\"\t1\n",
      "\"intervened\"\t2\n",
      "\"intl\"\t2\n",
      "\"into\"\t36\n",
      "\"intra\"\t1\n",
      "\"intranet\"\t3\n",
      "\"introduce\"\t1\n",
      "\"introduced\"\t3\n",
      "\"introducing\"\t1\n",
      "\"invest\"\t4\n",
      "\"invested\"\t1\n",
      "\"investigations\"\t1\n",
      "\"investment\"\t18\n",
      "\"investor\"\t1\n",
      "\"investors\"\t1\n",
      "\"invitation\"\t1\n",
      "\"invite\"\t6\n",
      "\"invoices\"\t1\n",
      "\"involuntary\"\t8\n",
      "\"involved\"\t7\n",
      "\"involvement\"\t1\n",
      "\"involves\"\t1\n",
      "\"involving\"\t2\n",
      "\"invovled\"\t2\n",
      "\"ion\"\t1\n",
      "\"iowa\"\t1\n",
      "\"ipos\"\t1\n",
      "\"ipp\"\t2\n",
      "\"ipps\"\t6\n",
      "\"irish\"\t1\n",
      "\"iron\"\t2\n",
      "\"is\"\t249\n",
      "\"isalso\"\t1\n",
      "\"island\"\t2\n",
      "\"isn\"\t3\n",
      "\"iso\"\t10\n",
      "\"isp\"\t8\n",
      "\"isps\"\t3\n",
      "\"issler\"\t5\n",
      "\"issue\"\t21\n",
      "\"issued\"\t4\n",
      "\"issues\"\t19\n",
      "\"it\"\t192\n",
      "\"iteam\"\t1\n",
      "\"item\"\t3\n",
      "\"items\"\t15\n",
      "\"its\"\t27\n",
      "\"itself\"\t3\n",
      "\"ium\"\t2\n",
      "\"ivan\"\t2\n",
      "\"ivernia\"\t2\n",
      "\"ivoire\"\t3\n",
      "\"ja\"\t1\n",
      "\"jackie\"\t1\n",
      "\"jan\"\t4\n",
      "\"jana\"\t3\n",
      "\"jane\"\t1\n",
      "\"janet\"\t1\n",
      "\"janice\"\t1\n",
      "\"janie\"\t1\n",
      "\"january\"\t2\n",
      "\"japan\"\t3\n",
      "\"jason\"\t5\n",
      "\"jauregui\"\t1\n",
      "\"jeff\"\t7\n",
      "\"jersey\"\t1\n",
      "\"jim\"\t3\n",
      "\"jimmy\"\t2\n",
      "\"jirapliegao\"\t1\n",
      "\"jlopes\"\t1\n",
      "\"jm\"\t6\n",
      "\"jnexon\"\t1\n",
      "\"jo\"\t1\n",
      "\"joao\"\t2\n",
      "\"job\"\t3\n",
      "\"joe\"\t1\n",
      "\"joel\"\t6\n",
      "\"johannesburg\"\t2\n",
      "\"john\"\t22\n",
      "\"johnny\"\t2\n",
      "\"johnston\"\t2\n",
      "\"join\"\t10\n",
      "\"joinder\"\t1\n",
      "\"joined\"\t3\n",
      "\"joining\"\t4\n",
      "\"joint\"\t1\n",
      "\"jon\"\t1\n",
      "\"jonathon\"\t1\n",
      "\"jones\"\t3\n",
      "\"jonesg\"\t1\n",
      "\"jose\"\t1\n",
      "\"joseph\"\t7\n",
      "\"josey\"\t7\n",
      "\"journey\"\t1\n",
      "\"journeys\"\t1\n",
      "\"joyce\"\t1\n",
      "\"jpxdltmuk\"\t1\n",
      "\"jshorter\"\t1\n",
      "\"jsp\"\t3\n",
      "\"jturco\"\t2\n",
      "\"jubilar\"\t1\n",
      "\"judge\"\t3\n",
      "\"judgment\"\t1\n",
      "\"judgments\"\t1\n",
      "\"julie\"\t5\n",
      "\"july\"\t2\n",
      "\"june\"\t11\n",
      "\"junk\"\t2\n",
      "\"just\"\t47\n",
      "\"justperform\"\t1\n",
      "\"jvbe\"\t1\n",
      "\"kainantu\"\t2\n",
      "\"kaminski\"\t11\n",
      "\"kaolin\"\t1\n",
      "\"karen\"\t1\n",
      "\"kaskaskia\"\t1\n",
      "\"katamail\"\t1\n",
      "\"kathryn\"\t3\n",
      "\"kathy\"\t1\n",
      "\"kay\"\t5\n",
      "\"kcs\"\t2\n",
      "\"keeley\"\t5\n",
      "\"keen\"\t1\n",
      "\"keep\"\t21\n",
      "\"keeping\"\t4\n",
      "\"kelly\"\t1\n",
      "\"kenny\"\t1\n",
      "\"kept\"\t2\n",
      "\"kerb\"\t1\n",
      "\"kevin\"\t48\n",
      "\"key\"\t10\n",
      "\"keyboard\"\t2\n",
      "\"keyes\"\t1\n",
      "\"keys\"\t1\n",
      "\"keyword\"\t4\n",
      "\"keywordcount\"\t1\n",
      "\"keywords\"\t2\n",
      "\"kfbtyra\"\t1\n",
      "\"kg\"\t3\n",
      "\"khanna\"\t1\n",
      "\"kick\"\t1\n",
      "\"kickoff\"\t2\n",
      "\"kid\"\t1\n",
      "\"killed\"\t2\n",
      "\"killer\"\t1\n",
      "\"killings\"\t2\n",
      "\"kim\"\t3\n",
      "\"kimberley\"\t3\n",
      "\"kimberly\"\t5\n",
      "\"kincaid\"\t2\n",
      "\"kind\"\t7\n",
      "\"kinda\"\t2\n",
      "\"kindall\"\t4\n",
      "\"kindly\"\t1\n",
      "\"kinds\"\t2\n",
      "\"king\"\t5\n",
      "\"kish\"\t1\n",
      "\"kistler\"\t1\n",
      "\"kitchen\"\t3\n",
      "\"kk\"\t1\n",
      "\"klei\"\t1\n",
      "\"knave\"\t3\n",
      "\"knelt\"\t1\n",
      "\"knew\"\t3\n",
      "\"knights\"\t1\n",
      "\"knives\"\t1\n",
      "\"know\"\t42\n",
      "\"knowledge\"\t4\n",
      "\"knowlton\"\t1\n",
      "\"known\"\t4\n",
      "\"knows\"\t2\n",
      "\"knudsen\"\t1\n",
      "\"kokas\"\t1\n",
      "\"kollaros\"\t1\n",
      "\"korea\"\t1\n",
      "\"koromah\"\t2\n",
      "\"krgp\"\t2\n",
      "\"kri\"\t2\n",
      "\"krill\"\t1\n",
      "\"krishna\"\t1\n",
      "\"krishnarao\"\t5\n",
      "\"kristin\"\t2\n",
      "\"kvie\"\t1\n",
      "\"kwh\"\t2\n",
      "\"kyle\"\t1\n",
      "\"label\"\t2\n",
      "\"labor\"\t2\n",
      "\"laborious\"\t1\n",
      "\"lack\"\t1\n",
      "\"lacrecia\"\t1\n",
      "\"lagars\"\t1\n",
      "\"lagrasta\"\t1\n",
      "\"lamb\"\t1\n",
      "\"lamproite\"\t2\n",
      "\"lamps\"\t1\n",
      "\"land\"\t1\n",
      "\"language\"\t3\n",
      "\"lanterns\"\t1\n",
      "\"large\"\t8\n",
      "\"larger\"\t3\n",
      "\"largest\"\t2\n",
      "\"larry\"\t1\n",
      "\"last\"\t18\n",
      "\"lasts\"\t1\n",
      "\"late\"\t5\n",
      "\"later\"\t12\n",
      "\"latin\"\t1\n",
      "\"laughed\"\t1\n",
      "\"launch\"\t2\n",
      "\"lauri\"\t4\n",
      "\"lavorato\"\t6\n",
      "\"law\"\t5\n",
      "\"lawn\"\t3\n",
      "\"layout\"\t3\n",
      "\"layouts\"\t1\n",
      "\"lcd\"\t1\n",
      "\"lead\"\t10\n",
      "\"leaders\"\t1\n",
      "\"leadership\"\t13\n",
      "\"leads\"\t11\n",
      "\"leap\"\t1\n",
      "\"learn\"\t4\n",
      "\"learned\"\t2\n",
      "\"learning\"\t3\n",
      "\"learns\"\t2\n",
      "\"lease\"\t1\n",
      "\"least\"\t12\n",
      "\"leave\"\t4\n",
      "\"leaving\"\t2\n",
      "\"lee\"\t1\n",
      "\"leederville\"\t1\n",
      "\"left\"\t5\n",
      "\"legal\"\t3\n",
      "\"legislative\"\t1\n",
      "\"legislator\"\t1\n",
      "\"legislators\"\t2\n",
      "\"legislature\"\t9\n",
      "\"legs\"\t3\n",
      "\"lehr\"\t1\n",
      "\"lemelman\"\t1\n",
      "\"lend\"\t2\n",
      "\"lender\"\t2\n",
      "\"lenders\"\t4\n",
      "\"length\"\t1\n",
      "\"lengthen\"\t1\n",
      "\"leone\"\t5\n",
      "\"less\"\t20\n",
      "\"lesson\"\t5\n",
      "\"let\"\t35\n",
      "\"lets\"\t1\n",
      "\"letter\"\t27\n",
      "\"letters\"\t11\n",
      "\"level\"\t4\n",
      "\"levels\"\t2\n",
      "\"leverage\"\t1\n",
      "\"liar\"\t2\n",
      "\"licence\"\t1\n",
      "\"licensing\"\t1\n",
      "\"life\"\t12\n",
      "\"lifetime\"\t1\n",
      "\"lift\"\t1\n",
      "\"lifted\"\t1\n",
      "\"lifts\"\t1\n",
      "\"light\"\t1\n",
      "\"like\"\t54\n",
      "\"liked\"\t1\n",
      "\"likelihood\"\t2\n",
      "\"likely\"\t7\n",
      "\"likes\"\t1\n",
      "\"lilly\"\t1\n",
      "\"limitations\"\t1\n",
      "\"limited\"\t14\n",
      "\"limitless\"\t2\n",
      "\"lin\"\t6\n",
      "\"linda\"\t5\n",
      "\"lindiwe\"\t2\n",
      "\"line\"\t21\n",
      "\"lineal\"\t1\n",
      "\"lines\"\t1\n",
      "\"lingerie\"\t2\n",
      "\"link\"\t6\n",
      "\"linkpaks\"\t4\n",
      "\"links\"\t30\n",
      "\"linktocash\"\t1\n",
      "\"linux\"\t4\n",
      "\"lips\"\t1\n",
      "\"liquid\"\t1\n",
      "\"liquids\"\t1\n",
      "\"lisa\"\t2\n",
      "\"list\"\t18\n",
      "\"listed\"\t7\n",
      "\"listen\"\t2\n",
      "\"listened\"\t1\n",
      "\"listinfo\"\t3\n",
      "\"listmaster\"\t1\n",
      "\"lists\"\t2\n",
      "\"lit\"\t1\n",
      "\"literally\"\t1\n",
      "\"literature\"\t1\n",
      "\"litteneker\"\t1\n",
      "\"litterbug\"\t1\n",
      "\"little\"\t9\n",
      "\"live\"\t1\n",
      "\"living\"\t3\n",
      "\"liz\"\t3\n",
      "\"ll\"\t23\n",
      "\"llc\"\t2\n",
      "\"llittle\"\t1\n",
      "\"loads\"\t1\n",
      "\"loan\"\t4\n",
      "\"lobby\"\t1\n",
      "\"lobster\"\t1\n",
      "\"local\"\t6\n",
      "\"locally\"\t2\n",
      "\"locals\"\t1\n",
      "\"located\"\t4\n",
      "\"location\"\t11\n",
      "\"lock\"\t2\n",
      "\"locomotive\"\t1\n",
      "\"loczk\"\t1\n",
      "\"loft\"\t2\n",
      "\"lollipops\"\t1\n",
      "\"london\"\t4\n",
      "\"long\"\t18\n",
      "\"longer\"\t4\n",
      "\"look\"\t14\n",
      "\"looked\"\t1\n",
      "\"looking\"\t4\n",
      "\"looks\"\t5\n",
      "\"loosening\"\t1\n",
      "\"lose\"\t2\n",
      "\"loses\"\t2\n",
      "\"losing\"\t2\n",
      "\"loss\"\t1\n",
      "\"lot\"\t10\n",
      "\"lots\"\t2\n",
      "\"lottery\"\t6\n",
      "\"louise\"\t8\n",
      "\"lounsbury\"\t1\n",
      "\"love\"\t2\n",
      "\"low\"\t10\n",
      "\"lower\"\t1\n",
      "\"lowest\"\t1\n",
      "\"loyal\"\t2\n",
      "\"loyalty\"\t1\n",
      "\"lsc\"\t1\n",
      "\"lst\"\t2\n",
      "\"ltd\"\t2\n",
      "\"lu\"\t5\n",
      "\"luck\"\t2\n",
      "\"lucky\"\t2\n",
      "\"lump\"\t1\n",
      "\"lunch\"\t2\n",
      "\"luo\"\t1\n",
      "\"luong\"\t1\n",
      "\"lx\"\t1\n",
      "\"lycopodium\"\t1\n",
      "\"lyn\"\t7\n",
      "\"lynch\"\t1\n",
      "\"lynda\"\t1\n",
      "\"ma\"\t2\n",
      "\"macarthur\"\t1\n",
      "\"machine\"\t1\n",
      "\"mackey\"\t1\n",
      "\"macquarie\"\t2\n",
      "\"macromedia\"\t6\n",
      "\"madam\"\t2\n",
      "\"made\"\t15\n",
      "\"magellan\"\t1\n",
      "\"magnesium\"\t1\n",
      "\"magnum\"\t1\n",
      "\"magnumo\"\t1\n",
      "\"maidens\"\t1\n",
      "\"mail\"\t32\n",
      "\"mailing\"\t3\n",
      "\"mailings\"\t2\n",
      "\"mailman\"\t3\n",
      "\"mailto\"\t11\n",
      "\"main\"\t1\n",
      "\"maine\"\t1\n",
      "\"maintain\"\t2\n",
      "\"maintainer\"\t1\n",
      "\"major\"\t5\n",
      "\"make\"\t35\n",
      "\"makecashonline\"\t1\n",
      "\"makes\"\t5\n",
      "\"making\"\t17\n",
      "\"male\"\t3\n",
      "\"malina\"\t4\n",
      "\"man\"\t5\n",
      "\"manage\"\t3\n",
      "\"managed\"\t7\n",
      "\"management\"\t54\n",
      "\"manager\"\t8\n",
      "\"managerial\"\t2\n",
      "\"managers\"\t1\n",
      "\"manages\"\t3\n",
      "\"managing\"\t1\n",
      "\"managment\"\t4\n",
      "\"mandated\"\t1\n",
      "\"manganese\"\t1\n",
      "\"manitoba\"\t1\n",
      "\"manual\"\t2\n",
      "\"manufacturers\"\t1\n",
      "\"many\"\t24\n",
      "\"mark\"\t8\n",
      "\"market\"\t12\n",
      "\"marketability\"\t2\n",
      "\"marketer\"\t1\n",
      "\"marketers\"\t1\n",
      "\"marketing\"\t28\n",
      "\"markets\"\t5\n",
      "\"marks\"\t2\n",
      "\"marla\"\t1\n",
      "\"martensite\"\t1\n",
      "\"martin\"\t7\n",
      "\"martina\"\t4\n",
      "\"martinez\"\t1\n",
      "\"mary\"\t7\n",
      "\"maryam\"\t1\n",
      "\"mass\"\t3\n",
      "\"massey\"\t1\n",
      "\"masson\"\t5\n",
      "\"master\"\t3\n",
      "\"match\"\t2\n",
      "\"matches\"\t4\n",
      "\"material\"\t1\n",
      "\"materials\"\t2\n",
      "\"matt\"\t1\n",
      "\"matter\"\t6\n",
      "\"maureen\"\t5\n",
      "\"mauricio\"\t1\n",
      "\"may\"\t27\n",
      "\"maybe\"\t4\n",
      "\"mayerbrown\"\t1\n",
      "\"mayes\"\t1\n",
      "\"mb\"\t1\n",
      "\"mc\"\t1\n",
      "\"mcbeal\"\t1\n",
      "\"mcclankg\"\t1\n",
      "\"mccullough\"\t1\n",
      "\"mcf\"\t2\n",
      "\"mclafferty\"\t1\n",
      "\"mclarney\"\t2\n",
      "\"mclean\"\t1\n",
      "\"mcmullen\"\t2\n",
      "\"mcosta\"\t1\n",
      "\"mcsherry\"\t1\n",
      "\"me\"\t75\n",
      "\"mean\"\t1\n",
      "\"means\"\t6\n",
      "\"meant\"\t1\n",
      "\"meanwhile\"\t3\n",
      "\"measure\"\t1\n",
      "\"measuring\"\t3\n",
      "\"mechanism\"\t1\n",
      "\"media\"\t3\n",
      "\"medical\"\t1\n",
      "\"medication\"\t1\n",
      "\"medications\"\t1\n",
      "\"mediums\"\t1\n",
      "\"meet\"\t9\n",
      "\"meeting\"\t19\n",
      "\"meetings\"\t7\n",
      "\"mega\"\t2\n",
      "\"melissa\"\t3\n",
      "\"melodick\"\t1\n",
      "\"member\"\t21\n",
      "\"members\"\t14\n",
      "\"membership\"\t19\n",
      "\"memo\"\t4\n",
      "\"memory\"\t3\n",
      "\"men\"\t5\n",
      "\"mental\"\t2\n",
      "\"mention\"\t3\n",
      "\"mentioned\"\t5\n",
      "\"merchandise\"\t3\n",
      "\"merchandisethat\"\t1\n",
      "\"merchant\"\t5\n",
      "\"merchants\"\t1\n",
      "\"merely\"\t1\n",
      "\"merry\"\t2\n",
      "\"mesopotamia\"\t1\n",
      "\"message\"\t20\n",
      "\"metal\"\t1\n",
      "\"metaphors\"\t1\n",
      "\"meter\"\t13\n",
      "\"meters\"\t3\n",
      "\"method\"\t1\n",
      "\"methods\"\t1\n",
      "\"mexico\"\t1\n",
      "\"meyers\"\t1\n",
      "\"mg\"\t2\n",
      "\"miami\"\t1\n",
      "\"michael\"\t9\n",
      "\"michelago\"\t2\n",
      "\"michele\"\t1\n",
      "\"micros\"\t2\n",
      "\"microsale\"\t8\n",
      "\"microsoft\"\t6\n",
      "\"mid\"\t3\n",
      "\"midwestern\"\t1\n",
      "\"might\"\t12\n",
      "\"mighty\"\t1\n",
      "\"migraine\"\t1\n",
      "\"miguel\"\t1\n",
      "\"mike\"\t11\n",
      "\"mild\"\t2\n",
      "\"milestone\"\t1\n",
      "\"militarism\"\t1\n",
      "\"millenium\"\t1\n",
      "\"miller\"\t1\n",
      "\"million\"\t17\n",
      "\"millions\"\t2\n",
      "\"mime\"\t1\n",
      "\"min\"\t2\n",
      "\"mind\"\t16\n",
      "\"minds\"\t1\n",
      "\"mine\"\t7\n",
      "\"mineral\"\t2\n",
      "\"minerals\"\t4\n",
      "\"mines\"\t1\n",
      "\"mini\"\t1\n",
      "\"minimal\"\t1\n",
      "\"minimize\"\t1\n",
      "\"minimum\"\t2\n",
      "\"mining\"\t7\n",
      "\"miningnews\"\t9\n",
      "\"minor\"\t1\n",
      "\"minute\"\t4\n",
      "\"minutes\"\t5\n",
      "\"mirant\"\t1\n",
      "\"mircosoft\"\t1\n",
      "\"mirror\"\t3\n",
      "\"miserable\"\t1\n",
      "\"mislead\"\t1\n",
      "\"miss\"\t2\n",
      "\"missed\"\t2\n",
      "\"missing\"\t1\n",
      "\"missouri\"\t1\n",
      "\"misspelled\"\t1\n",
      "\"missss\"\t1\n",
      "\"mitral\"\t1\n",
      "\"mix\"\t2\n",
      "\"mixture\"\t1\n",
      "\"mm\"\t1\n",
      "\"mmbtu\"\t6\n",
      "\"mmce\"\t1\n",
      "\"mo\"\t1\n",
      "\"moates\"\t1\n",
      "\"mobil\"\t1\n",
      "\"mobile\"\t1\n",
      "\"mode\"\t1\n",
      "\"modem\"\t1\n",
      "\"moderate\"\t2\n",
      "\"moderates\"\t2\n",
      "\"moderator\"\t4\n",
      "\"modification\"\t1\n",
      "\"module\"\t1\n",
      "\"modules\"\t4\n",
      "\"moment\"\t3\n",
      "\"moments\"\t1\n",
      "\"monadic\"\t1\n",
      "\"monday\"\t16\n",
      "\"money\"\t35\n",
      "\"mongolia\"\t1\n",
      "\"monies\"\t1\n",
      "\"monitor\"\t1\n",
      "\"montana\"\t1\n",
      "\"month\"\t17\n",
      "\"monthly\"\t2\n",
      "\"months\"\t10\n",
      "\"mood\"\t1\n",
      "\"moore\"\t39\n",
      "\"morality\"\t1\n",
      "\"morayt\"\t1\n",
      "\"more\"\t65\n",
      "\"morne\"\t1\n",
      "\"morning\"\t12\n",
      "\"morris\"\t3\n",
      "\"mortgage\"\t3\n",
      "\"mossel\"\t1\n",
      "\"most\"\t31\n",
      "\"mostly\"\t1\n",
      "\"motero\"\t1\n",
      "\"motivating\"\t1\n",
      "\"mounted\"\t1\n",
      "\"mouse\"\t5\n",
      "\"move\"\t8\n",
      "\"moved\"\t2\n",
      "\"movement\"\t2\n",
      "\"moves\"\t1\n",
      "\"moviebuff\"\t2\n",
      "\"moving\"\t5\n",
      "\"mower\"\t1\n",
      "\"mp\"\t1\n",
      "\"mperkins\"\t1\n",
      "\"mpkemyrxlpq\"\t1\n",
      "\"mr\"\t10\n",
      "\"mrs\"\t8\n",
      "\"ms\"\t10\n",
      "\"mscf\"\t1\n",
      "\"msessa\"\t1\n",
      "\"mst\"\t1\n",
      "\"much\"\t25\n",
      "\"multilanguage\"\t1\n",
      "\"multipart\"\t1\n",
      "\"multiple\"\t7\n",
      "\"murmur\"\t1\n",
      "\"murphy\"\t1\n",
      "\"muscle\"\t2\n",
      "\"music\"\t1\n",
      "\"musically\"\t1\n",
      "\"must\"\t21\n",
      "\"mustard\"\t1\n",
      "\"mutual\"\t1\n",
      "\"mw\"\t3\n",
      "\"mx\"\t6\n",
      "\"my\"\t102\n",
      "\"myers\"\t1\n",
      "\"myinput\"\t4\n",
      "\"myinputare\"\t1\n",
      "\"myself\"\t1\n",
      "\"myshoppingplace\"\t4\n",
      "\"mysiteinc\"\t4\n",
      "\"na\"\t5\n",
      "\"naked\"\t1\n",
      "\"name\"\t22\n",
      "\"names\"\t7\n",
      "\"nas\"\t1\n",
      "\"nation\"\t1\n",
      "\"natives\"\t1\n",
      "\"natural\"\t7\n",
      "\"nature\"\t2\n",
      "\"nbi\"\t1\n",
      "\"ncaa\"\t1\n",
      "\"nd\"\t4\n",
      "\"neaarby\"\t1\n",
      "\"neal\"\t1\n",
      "\"near\"\t6\n",
      "\"nearby\"\t1\n",
      "\"nearly\"\t1\n",
      "\"neat\"\t1\n",
      "\"nebulous\"\t1\n",
      "\"necessary\"\t8\n",
      "\"necessities\"\t1\n",
      "\"neck\"\t1\n",
      "\"need\"\t54\n",
      "\"needed\"\t9\n",
      "\"needs\"\t9\n",
      "\"negative\"\t1\n",
      "\"negotiating\"\t3\n",
      "\"negotiation\"\t1\n",
      "\"neighbor\"\t1\n",
      "\"neighboring\"\t2\n",
      "\"nepco\"\t1\n",
      "\"nero\"\t1\n",
      "\"net\"\t36\n",
      "\"netherland\"\t1\n",
      "\"netherlands\"\t2\n",
      "\"netnoteinc\"\t6\n",
      "\"netrepreneur\"\t1\n",
      "\"netsbestinfo\"\t2\n",
      "\"network\"\t1\n",
      "\"networks\"\t6\n",
      "\"netwww\"\t1\n",
      "\"neuweiler\"\t2\n",
      "\"never\"\t7\n",
      "\"new\"\t66\n",
      "\"newcomers\"\t2\n",
      "\"news\"\t7\n",
      "\"newsboy\"\t2\n",
      "\"newsletter\"\t24\n",
      "\"newsletters\"\t4\n",
      "\"next\"\t27\n",
      "\"nextpart\"\t1\n",
      "\"neyeded\"\t1\n",
      "\"ngo\"\t2\n",
      "\"nguyen\"\t3\n",
      "\"ngx\"\t1\n",
      "\"nice\"\t3\n",
      "\"nickel\"\t4\n",
      "\"nicki\"\t1\n",
      "\"nickname\"\t1\n",
      "\"nicolay\"\t1\n",
      "\"niestrath\"\t1\n",
      "\"nigel\"\t1\n",
      "\"night\"\t4\n",
      "\"nightgear\"\t1\n",
      "\"nighttime\"\t2\n",
      "\"niles\"\t3\n",
      "\"nim\"\t2\n",
      "\"nine\"\t1\n",
      "\"njwa\"\t1\n",
      "\"no\"\t52\n",
      "\"noah\"\t1\n",
      "\"nodded\"\t1\n",
      "\"nom\"\t8\n",
      "\"nominated\"\t4\n",
      "\"nomination\"\t4\n",
      "\"nominations\"\t1\n",
      "\"nommensen\"\t1\n",
      "\"non\"\t5\n",
      "\"none\"\t2\n",
      "\"noon\"\t1\n",
      "\"norma\"\t1\n",
      "\"normal\"\t8\n",
      "\"normally\"\t1\n",
      "\"normet\"\t2\n",
      "\"north\"\t12\n",
      "\"northern\"\t3\n",
      "\"norton\"\t3\n",
      "\"nospam\"\t1\n",
      "\"nostalgia\"\t1\n",
      "\"not\"\t126\n",
      "\"note\"\t9\n",
      "\"noted\"\t4\n",
      "\"notes\"\t1\n",
      "\"nothing\"\t5\n",
      "\"notice\"\t4\n",
      "\"noticed\"\t1\n",
      "\"notiffiyved\"\t1\n",
      "\"notification\"\t1\n",
      "\"notify\"\t2\n",
      "\"notis\"\t2\n",
      "\"nov\"\t5\n",
      "\"novak\"\t1\n",
      "\"novel\"\t1\n",
      "\"novelties\"\t1\n",
      "\"november\"\t3\n",
      "\"now\"\t29\n",
      "\"nowbetterthis\"\t2\n",
      "\"nowthe\"\t1\n",
      "\"nox\"\t2\n",
      "\"nrg\"\t1\n",
      "\"nrw\"\t1\n",
      "\"ns\"\t1\n",
      "\"nt\"\t1\n",
      "\"num\"\t1\n",
      "\"number\"\t17\n",
      "\"numbers\"\t9\n",
      "\"numerous\"\t1\n",
      "\"oak\"\t1\n",
      "\"oblibgat\"\t1\n",
      "\"obligation\"\t2\n",
      "\"obligationin\"\t1\n",
      "\"obligations\"\t2\n",
      "\"observations\"\t2\n",
      "\"obtain\"\t4\n",
      "\"obtained\"\t1\n",
      "\"obviously\"\t4\n",
      "\"occasion\"\t1\n",
      "\"occur\"\t1\n",
      "\"occurs\"\t1\n",
      "\"ocd\"\t1\n",
      "\"oceania\"\t1\n",
      "\"oconan\"\t2\n",
      "\"odin\"\t2\n",
      "\"odlx\"\t1\n",
      "\"oem\"\t3\n",
      "\"of\"\t566\n",
      "\"off\"\t8\n",
      "\"offer\"\t26\n",
      "\"offered\"\t3\n",
      "\"offering\"\t7\n",
      "\"offers\"\t2\n",
      "\"office\"\t26\n",
      "\"officer\"\t3\n",
      "\"offices\"\t3\n",
      "\"official\"\t1\n",
      "\"officially\"\t3\n",
      "\"officials\"\t1\n",
      "\"offsite\"\t2\n",
      "\"often\"\t9\n",
      "\"oh\"\t2\n",
      "\"oil\"\t1\n",
      "\"oilshale\"\t1\n",
      "\"ok\"\t4\n",
      "\"old\"\t7\n",
      "\"olson\"\t2\n",
      "\"omaha\"\t1\n",
      "\"omission\"\t1\n",
      "\"on\"\t271\n",
      "\"once\"\t8\n",
      "\"ondarza\"\t1\n",
      "\"one\"\t68\n",
      "\"onerous\"\t1\n",
      "\"ongoing\"\t2\n",
      "\"online\"\t20\n",
      "\"only\"\t32\n",
      "\"ontacted\"\t1\n",
      "\"oo\"\t6\n",
      "\"op\"\t4\n",
      "\"open\"\t7\n",
      "\"opening\"\t4\n",
      "\"openpage\"\t1\n",
      "\"operate\"\t1\n",
      "\"operation\"\t2\n",
      "\"operational\"\t6\n",
      "\"operations\"\t41\n",
      "\"operators\"\t3\n",
      "\"opinion\"\t5\n",
      "\"opportunities\"\t7\n",
      "\"opportunity\"\t9\n",
      "\"oppose\"\t1\n",
      "\"opposite\"\t1\n",
      "\"opposition\"\t2\n",
      "\"opt\"\t2\n",
      "\"optimistic\"\t1\n",
      "\"option\"\t1\n",
      "\"options\"\t2\n",
      "\"optionscontrol\"\t1\n",
      "\"or\"\t166\n",
      "\"orange\"\t1\n",
      "\"order\"\t44\n",
      "\"ordered\"\t6\n",
      "\"orders\"\t1\n",
      "\"ore\"\t3\n",
      "\"org\"\t4\n",
      "\"organisation\"\t1\n",
      "\"organization\"\t6\n",
      "\"organizational\"\t1\n",
      "\"organize\"\t2\n",
      "\"orgoto\"\t1\n",
      "\"orgtrade\"\t1\n",
      "\"oriental\"\t1\n",
      "\"original\"\t3\n",
      "\"originality\"\t1\n",
      "\"originally\"\t1\n",
      "\"origination\"\t1\n",
      "\"originator\"\t2\n",
      "\"orleantraders\"\t1\n",
      "\"orrick\"\t1\n",
      "\"osman\"\t4\n",
      "\"otc\"\t1\n",
      "\"other\"\t43\n",
      "\"others\"\t4\n",
      "\"otherwise\"\t1\n",
      "\"ounces\"\t1\n",
      "\"our\"\t119\n",
      "\"ourselves\"\t1\n",
      "\"out\"\t70\n",
      "\"outback\"\t1\n",
      "\"outdated\"\t1\n",
      "\"outline\"\t2\n",
      "\"outlined\"\t1\n",
      "\"outlook\"\t3\n",
      "\"outpacing\"\t1\n",
      "\"outrageous\"\t1\n",
      "\"outside\"\t3\n",
      "\"outstanding\"\t4\n",
      "\"over\"\t50\n",
      "\"overall\"\t2\n",
      "\"overgaard\"\t1\n",
      "\"overnight\"\t2\n",
      "\"overpaying\"\t1\n",
      "\"oversee\"\t3\n",
      "\"overseer\"\t1\n",
      "\"overuse\"\t1\n",
      "\"overwhelm\"\t1\n",
      "\"owe\"\t1\n",
      "\"own\"\t15\n",
      "\"owned\"\t5\n",
      "\"owner\"\t2\n",
      "\"owners\"\t2\n",
      "\"ownership\"\t2\n",
      "\"owning\"\t2\n",
      "\"owns\"\t1\n",
      "\"oxidation\"\t1\n",
      "\"oxley\"\t3\n",
      "\"oxx\"\t2\n",
      "\"oxymoron\"\t1\n",
      "\"ozarka\"\t1\n",
      "\"paces\"\t1\n",
      "\"pacific\"\t3\n",
      "\"package\"\t4\n",
      "\"padron\"\t1\n",
      "\"page\"\t23\n",
      "\"pagemaker\"\t2\n",
      "\"pages\"\t9\n",
      "\"paid\"\t5\n",
      "\"paidtosurf\"\t2\n",
      "\"pain\"\t2\n",
      "\"painter\"\t1\n",
      "\"palaeo\"\t1\n",
      "\"pamela\"\t2\n",
      "\"panel\"\t1\n",
      "\"pangs\"\t1\n",
      "\"paper\"\t3\n",
      "\"papers\"\t2\n",
      "\"papua\"\t1\n",
      "\"par\"\t2\n",
      "\"paragraph\"\t6\n",
      "\"paragraphs\"\t8\n",
      "\"parallel\"\t1\n",
      "\"parents\"\t1\n",
      "\"part\"\t9\n",
      "\"participants\"\t2\n",
      "\"participate\"\t4\n",
      "\"participating\"\t1\n",
      "\"participation\"\t1\n",
      "\"particular\"\t2\n",
      "\"particularly\"\t3\n",
      "\"parties\"\t4\n",
      "\"partner\"\t4\n",
      "\"partners\"\t4\n",
      "\"partnership\"\t1\n",
      "\"parts\"\t1\n",
      "\"party\"\t3\n",
      "\"paso\"\t2\n",
      "\"pass\"\t2\n",
      "\"passed\"\t1\n",
      "\"passport\"\t1\n",
      "\"password\"\t5\n",
      "\"past\"\t3\n",
      "\"path\"\t2\n",
      "\"pathetic\"\t1\n",
      "\"pathos\"\t1\n",
      "\"patricia\"\t4\n",
      "\"paul\"\t2\n",
      "\"paulo\"\t5\n",
      "\"pause\"\t1\n",
      "\"pavluk\"\t1\n",
      "\"pay\"\t5\n",
      "\"payback\"\t1\n",
      "\"payers\"\t1\n",
      "\"paying\"\t3\n",
      "\"payment\"\t1\n",
      "\"payments\"\t8\n",
      "\"payne\"\t2\n",
      "\"payroll\"\t5\n",
      "\"pbem\"\t1\n",
      "\"pc\"\t5\n",
      "\"pcenergy\"\t3\n",
      "\"pcp\"\t1\n",
      "\"pdx\"\t1\n",
      "\"peace\"\t4\n",
      "\"peaking\"\t1\n",
      "\"peel\"\t2\n",
      "\"peers\"\t1\n",
      "\"penance\"\t1\n",
      "\"pennsylvania\"\t3\n",
      "\"pentium\"\t1\n",
      "\"people\"\t38\n",
      "\"per\"\t11\n",
      "\"perceived\"\t1\n",
      "\"percent\"\t1\n",
      "\"percentage\"\t2\n",
      "\"perfect\"\t3\n",
      "\"perform\"\t1\n",
      "\"performance\"\t7\n",
      "\"performer\"\t2\n",
      "\"perhaps\"\t3\n",
      "\"period\"\t8\n",
      "\"persist\"\t1\n",
      "\"persistence\"\t2\n",
      "\"persists\"\t1\n",
      "\"person\"\t16\n",
      "\"personage\"\t1\n",
      "\"personal\"\t12\n",
      "\"personality\"\t4\n",
      "\"personally\"\t1\n",
      "\"personnel\"\t7\n",
      "\"persons\"\t1\n",
      "\"perspective\"\t7\n",
      "\"perth\"\t1\n",
      "\"pest\"\t1\n",
      "\"pet\"\t1\n",
      "\"pete\"\t1\n",
      "\"peter\"\t3\n",
      "\"petteway\"\t1\n",
      "\"pg\"\t7\n",
      "\"pgm\"\t1\n",
      "\"ph\"\t3\n",
      "\"phases\"\t2\n",
      "\"phentermine\"\t3\n",
      "\"philadelphia\"\t1\n",
      "\"philip\"\t1\n",
      "\"phillip\"\t1\n",
      "\"phone\"\t15\n",
      "\"phonetic\"\t1\n",
      "\"photo\"\t1\n",
      "\"photoshop\"\t3\n",
      "\"php\"\t3\n",
      "\"phrasemake\"\t1\n",
      "\"phrases\"\t3\n",
      "\"physical\"\t6\n",
      "\"physicians\"\t1\n",
      "\"pibrochs\"\t1\n",
      "\"pick\"\t3\n",
      "\"picture\"\t4\n",
      "\"pictures\"\t8\n",
      "\"piece\"\t1\n",
      "\"pierre\"\t1\n",
      "\"pike\"\t1\n",
      "\"pilkington\"\t1\n",
      "\"pillsburywinthrop\"\t2\n",
      "\"pilocystic\"\t1\n",
      "\"pilot\"\t6\n",
      "\"pinion\"\t1\n",
      "\"pinnacle\"\t1\n",
      "\"pinnamaneni\"\t4\n",
      "\"pipe\"\t1\n",
      "\"pipeline\"\t3\n",
      "\"pipes\"\t2\n",
      "\"pitchers\"\t1\n",
      "\"pitifully\"\t1\n",
      "\"pl\"\t1\n",
      "\"place\"\t20\n",
      "\"placed\"\t1\n",
      "\"placement\"\t2\n",
      "\"places\"\t1\n",
      "\"plain\"\t4\n",
      "\"plan\"\t17\n",
      "\"plans\"\t2\n",
      "\"plant\"\t2\n",
      "\"planted\"\t1\n",
      "\"plants\"\t2\n",
      "\"platform\"\t2\n",
      "\"platitudes\"\t1\n",
      "\"platte\"\t1\n",
      "\"played\"\t1\n",
      "\"player\"\t2\n",
      "\"pleas\"\t1\n",
      "\"pleasant\"\t1\n",
      "\"please\"\t84\n",
      "\"pleased\"\t3\n",
      "\"pleasure\"\t1\n",
      "\"plentiful\"\t1\n",
      "\"plus\"\t4\n",
      "\"plushy\"\t1\n",
      "\"pm\"\t37\n",
      "\"po\"\t1\n",
      "\"point\"\t15\n",
      "\"points\"\t3\n",
      "\"policy\"\t6\n",
      "\"political\"\t3\n",
      "\"politically\"\t1\n",
      "\"politicians\"\t1\n",
      "\"pompey\"\t1\n",
      "\"poor\"\t3\n",
      "\"poors\"\t1\n",
      "\"pops\"\t2\n",
      "\"popular\"\t2\n",
      "\"portion\"\t1\n",
      "\"ports\"\t1\n",
      "\"position\"\t7\n",
      "\"positions\"\t1\n",
      "\"possesses\"\t1\n",
      "\"possibilities\"\t1\n",
      "\"possibility\"\t4\n",
      "\"possible\"\t17\n",
      "\"possibly\"\t2\n",
      "\"post\"\t9\n",
      "\"postal\"\t1\n",
      "\"posting\"\t1\n",
      "\"posts\"\t1\n",
      "\"potency\"\t1\n",
      "\"potential\"\t8\n",
      "\"pound\"\t2\n",
      "\"pounds\"\t1\n",
      "\"power\"\t24\n",
      "\"powered\"\t3\n",
      "\"powerful\"\t7\n",
      "\"powerquest\"\t1\n",
      "\"ppmfztdtet\"\t1\n",
      "\"practices\"\t3\n",
      "\"prager\"\t1\n",
      "\"pray\"\t1\n",
      "\"prbolem\"\t1\n",
      "\"pre\"\t3\n",
      "\"precedent\"\t1\n",
      "\"precious\"\t1\n",
      "\"precluded\"\t1\n",
      "\"preferences\"\t2\n",
      "\"preferred\"\t2\n",
      "\"prefix\"\t1\n",
      "\"premature\"\t1\n",
      "\"premiere\"\t2\n",
      "\"premium\"\t3\n",
      "\"premiums\"\t2\n",
      "\"preneur\"\t2\n",
      "\"prepared\"\t2\n",
      "\"preposition\"\t1\n",
      "\"presas\"\t2\n",
      "\"presccription\"\t1\n",
      "\"prescriptions\"\t1\n",
      "\"presence\"\t3\n",
      "\"present\"\t2\n",
      "\"presentation\"\t1\n",
      "\"presented\"\t1\n",
      "\"president\"\t9\n",
      "\"presidential\"\t1\n",
      "\"press\"\t4\n",
      "\"pressure\"\t5\n",
      "\"pressured\"\t2\n",
      "\"prestigious\"\t1\n",
      "\"presumably\"\t1\n",
      "\"presumed\"\t1\n",
      "\"pretty\"\t4\n",
      "\"prevatt\"\t4\n",
      "\"prevent\"\t1\n",
      "\"previous\"\t9\n",
      "\"previously\"\t2\n",
      "\"prez\"\t1\n",
      "\"price\"\t27\n",
      "\"prices\"\t8\n",
      "\"pricing\"\t4\n",
      "\"pricked\"\t1\n",
      "\"pride\"\t1\n",
      "\"priicce\"\t1\n",
      "\"priice\"\t1\n",
      "\"priices\"\t1\n",
      "\"prilosec\"\t1\n",
      "\"primary\"\t3\n",
      "\"principal\"\t3\n",
      "\"principle\"\t1\n",
      "\"print\"\t1\n",
      "\"printable\"\t2\n",
      "\"printer\"\t23\n",
      "\"prior\"\t8\n",
      "\"priority\"\t2\n",
      "\"priscilla\"\t1\n",
      "\"privacy\"\t6\n",
      "\"private\"\t5\n",
      "\"privileged\"\t1\n",
      "\"prize\"\t1\n",
      "\"pro\"\t2\n",
      "\"probably\"\t7\n",
      "\"problem\"\t5\n",
      "\"problematic\"\t1\n",
      "\"problems\"\t5\n",
      "\"procedures\"\t3\n",
      "\"proceed\"\t2\n",
      "\"proceeds\"\t1\n",
      "\"process\"\t13\n",
      "\"processed\"\t2\n",
      "\"processes\"\t2\n",
      "\"processing\"\t8\n",
      "\"processor\"\t1\n",
      "\"procrustes\"\t1\n",
      "\"procurement\"\t2\n",
      "\"produce\"\t2\n",
      "\"producer\"\t1\n",
      "\"producers\"\t3\n",
      "\"producing\"\t1\n",
      "\"product\"\t36\n",
      "\"production\"\t8\n",
      "\"products\"\t23\n",
      "\"professional\"\t14\n",
      "\"professionals\"\t3\n",
      "\"professor\"\t1\n",
      "\"profile\"\t3\n",
      "\"profit\"\t6\n",
      "\"profitable\"\t1\n",
      "\"profitbanners\"\t4\n",
      "\"profits\"\t1\n",
      "\"program\"\t7\n",
      "\"programs\"\t14\n",
      "\"progress\"\t2\n",
      "\"prohibited\"\t1\n",
      "\"project\"\t18\n",
      "\"projects\"\t2\n",
      "\"proliferation\"\t3\n",
      "\"prominent\"\t2\n",
      "\"promise\"\t1\n",
      "\"promised\"\t1\n",
      "\"promising\"\t1\n",
      "\"promote\"\t2\n",
      "\"promoted\"\t1\n",
      "\"promoting\"\t2\n",
      "\"promotion\"\t1\n",
      "\"promotional\"\t2\n",
      "\"prompt\"\t1\n",
      "\"properly\"\t2\n",
      "\"property\"\t2\n",
      "\"proposal\"\t9\n",
      "\"proposed\"\t3\n",
      "\"prospects\"\t1\n",
      "\"prosper\"\t3\n",
      "\"prostaff\"\t1\n",
      "\"protest\"\t2\n",
      "\"protesting\"\t1\n",
      "\"protocol\"\t1\n",
      "\"prove\"\t2\n",
      "\"proven\"\t1\n",
      "\"provide\"\t21\n",
      "\"provided\"\t3\n",
      "\"provider\"\t3\n",
      "\"providers\"\t2\n",
      "\"provides\"\t2\n",
      "\"providing\"\t6\n",
      "\"province\"\t1\n",
      "\"proxy\"\t7\n",
      "\"prozac\"\t1\n",
      "\"prriicegreat\"\t1\n",
      "\"ps\"\t1\n",
      "\"pst\"\t1\n",
      "\"psychotic\"\t1\n",
      "\"pting\"\t1\n",
      "\"pts\"\t1\n",
      "\"public\"\t2\n",
      "\"publicity\"\t1\n",
      "\"published\"\t5\n",
      "\"publishes\"\t1\n",
      "\"publishing\"\t2\n",
      "\"puc\"\t3\n",
      "\"pull\"\t5\n",
      "\"pulled\"\t1\n",
      "\"pulling\"\t1\n",
      "\"pulp\"\t1\n",
      "\"pun\"\t1\n",
      "\"purchase\"\t11\n",
      "\"purchased\"\t1\n",
      "\"purchases\"\t3\n",
      "\"purchasing\"\t2\n",
      "\"pure\"\t1\n",
      "\"purpose\"\t6\n",
      "\"purposefully\"\t1\n",
      "\"pursuing\"\t1\n",
      "\"pushed\"\t1\n",
      "\"pushes\"\t1\n",
      "\"pushing\"\t1\n",
      "\"put\"\t12\n",
      "\"putpeel\"\t8\n",
      "\"puts\"\t1\n",
      "\"pwarden\"\t1\n",
      "\"quadrangular\"\t1\n",
      "\"qualification\"\t3\n",
      "\"qualified\"\t1\n",
      "\"qualities\"\t1\n",
      "\"quality\"\t15\n",
      "\"qualityproducts\"\t1\n",
      "\"quark\"\t1\n",
      "\"quarter\"\t1\n",
      "\"quasi\"\t1\n",
      "\"queensland\"\t2\n",
      "\"question\"\t11\n",
      "\"questions\"\t36\n",
      "\"quick\"\t3\n",
      "\"quickens\"\t1\n",
      "\"quickly\"\t7\n",
      "\"quite\"\t4\n",
      "\"quitting\"\t1\n",
      "\"quote\"\t1\n",
      "\"quoted\"\t4\n",
      "\"quotes\"\t3\n",
      "\"rabey\"\t1\n",
      "\"rac\"\t1\n",
      "\"race\"\t1\n",
      "\"rail\"\t3\n",
      "\"railing\"\t1\n",
      "\"raise\"\t2\n",
      "\"raised\"\t2\n",
      "\"raises\"\t2\n",
      "\"raising\"\t1\n",
      "\"ram\"\t2\n",
      "\"ramupgradeable\"\t1\n",
      "\"ran\"\t2\n",
      "\"ranch\"\t10\n",
      "\"randall\"\t2\n",
      "\"randle\"\t1\n",
      "\"randomly\"\t1\n",
      "\"randy\"\t1\n",
      "\"ranen\"\t1\n",
      "\"range\"\t2\n",
      "\"rankings\"\t1\n",
      "\"ranks\"\t2\n",
      "\"rapidly\"\t1\n",
      "\"rare\"\t1\n",
      "\"rat\"\t2\n",
      "\"rate\"\t33\n",
      "\"rated\"\t3\n",
      "\"rates\"\t7\n",
      "\"rather\"\t6\n",
      "\"rating\"\t2\n",
      "\"ratio\"\t1\n",
      "\"ravi\"\t6\n",
      "\"ray\"\t4\n",
      "\"raymond\"\t7\n",
      "\"rd\"\t1\n",
      "\"re\"\t33\n",
      "\"rea\"\t1\n",
      "\"reach\"\t7\n",
      "\"reached\"\t3\n",
      "\"reaching\"\t1\n",
      "\"read\"\t18\n",
      "\"reader\"\t23\n",
      "\"readers\"\t3\n",
      "\"readies\"\t1\n",
      "\"reading\"\t1\n",
      "\"reado\"\t1\n",
      "\"reads\"\t2\n",
      "\"ready\"\t5\n",
      "\"real\"\t14\n",
      "\"realize\"\t3\n",
      "\"really\"\t7\n",
      "\"rear\"\t1\n",
      "\"reason\"\t7\n",
      "\"reasonable\"\t2\n",
      "\"reasons\"\t1\n",
      "\"reassigned\"\t1\n",
      "\"rebecca\"\t2\n",
      "\"rebel\"\t2\n",
      "\"rebels\"\t2\n",
      "\"recap\"\t3\n",
      "\"receipt\"\t6\n",
      "\"receipts\"\t1\n",
      "\"receivable\"\t1\n",
      "\"receive\"\t12\n",
      "\"received\"\t5\n",
      "\"receives\"\t4\n",
      "\"receiving\"\t5\n",
      "\"recent\"\t3\n",
      "\"recently\"\t5\n",
      "\"reception\"\t1\n",
      "\"recieved\"\t2\n",
      "\"recipient\"\t2\n",
      "\"reclaimers\"\t1\n",
      "\"recognition\"\t1\n",
      "\"recognizing\"\t4\n",
      "\"recommend\"\t1\n",
      "\"recommendation\"\t1\n",
      "\"recommendations\"\t4\n",
      "\"record\"\t2\n",
      "\"recorded\"\t1\n",
      "\"recover\"\t2\n",
      "\"recovery\"\t2\n",
      "\"recruiting\"\t3\n",
      "\"red\"\t2\n",
      "\"redesign\"\t2\n",
      "\"redesigns\"\t1\n",
      "\"redhat\"\t1\n",
      "\"reduce\"\t1\n",
      "\"reduced\"\t1\n",
      "\"reduces\"\t2\n",
      "\"reduction\"\t4\n",
      "\"ref\"\t2\n",
      "\"refer\"\t2\n",
      "\"reference\"\t2\n",
      "\"references\"\t1\n",
      "\"referendum\"\t6\n",
      "\"referral\"\t2\n",
      "\"referred\"\t2\n",
      "\"refinances\"\t2\n",
      "\"reflect\"\t1\n",
      "\"reflected\"\t1\n",
      "\"reflections\"\t1\n",
      "\"reflux\"\t1\n",
      "\"refugee\"\t3\n",
      "\"refusals\"\t1\n",
      "\"refuse\"\t1\n",
      "\"regard\"\t9\n",
      "\"regarding\"\t2\n",
      "\"regardless\"\t4\n",
      "\"regards\"\t7\n",
      "\"regina\"\t6\n",
      "\"region\"\t6\n",
      "\"regional\"\t11\n",
      "\"regions\"\t6\n",
      "\"registered\"\t4\n",
      "\"regretful\"\t1\n",
      "\"regulations\"\t3\n",
      "\"reins\"\t1\n",
      "\"reiterate\"\t1\n",
      "\"rejoice\"\t1\n",
      "\"related\"\t2\n",
      "\"relates\"\t1\n",
      "\"relating\"\t2\n",
      "\"relation\"\t1\n",
      "\"relations\"\t3\n",
      "\"relationship\"\t6\n",
      "\"relative\"\t2\n",
      "\"release\"\t1\n",
      "\"released\"\t4\n",
      "\"releases\"\t2\n",
      "\"relegated\"\t1\n",
      "\"reliant\"\t4\n",
      "\"reliantenergy\"\t3\n",
      "\"relieved\"\t1\n",
      "\"relieves\"\t1\n",
      "\"remain\"\t1\n",
      "\"remainder\"\t2\n",
      "\"remaining\"\t3\n",
      "\"remember\"\t13\n",
      "\"remind\"\t2\n",
      "\"reminder\"\t1\n",
      "\"remitted\"\t1\n",
      "\"removal\"\t1\n",
      "\"remove\"\t6\n",
      "\"removed\"\t4\n",
      "\"removes\"\t1\n",
      "\"removing\"\t1\n",
      "\"remunerate\"\t1\n",
      "\"renewable\"\t2\n",
      "\"rennie\"\t1\n",
      "\"rental\"\t1\n",
      "\"repeal\"\t1\n",
      "\"repeatedly\"\t2\n",
      "\"replace\"\t2\n",
      "\"replay\"\t2\n",
      "\"replies\"\t3\n",
      "\"repling\"\t1\n",
      "\"reply\"\t5\n",
      "\"replying\"\t1\n",
      "\"report\"\t14\n",
      "\"reportedly\"\t2\n",
      "\"reporting\"\t10\n",
      "\"reports\"\t1\n",
      "\"representatives\"\t2\n",
      "\"republicans\"\t2\n",
      "\"reputation\"\t2\n",
      "\"request\"\t14\n",
      "\"requesting\"\t1\n",
      "\"require\"\t3\n",
      "\"required\"\t2\n",
      "\"requirement\"\t1\n",
      "\"requirements\"\t5\n",
      "\"requires\"\t1\n",
      "\"requiring\"\t1\n",
      "\"reread\"\t1\n",
      "\"research\"\t5\n",
      "\"resell\"\t1\n",
      "\"reseller\"\t1\n",
      "\"reservation\"\t1\n",
      "\"reserve\"\t2\n",
      "\"reserved\"\t3\n",
      "\"residents\"\t1\n",
      "\"residue\"\t1\n",
      "\"resistance\"\t1\n",
      "\"resolve\"\t4\n",
      "\"resolved\"\t1\n",
      "\"resort\"\t2\n",
      "\"resource\"\t5\n",
      "\"resourceful\"\t1\n",
      "\"resources\"\t23\n",
      "\"resourcestocks\"\t1\n",
      "\"respect\"\t4\n",
      "\"respectable\"\t1\n",
      "\"respected\"\t1\n",
      "\"respective\"\t2\n",
      "\"respond\"\t8\n",
      "\"response\"\t4\n",
      "\"responses\"\t8\n",
      "\"responsibilites\"\t2\n",
      "\"responsibilities\"\t7\n",
      "\"responsibility\"\t10\n",
      "\"responsible\"\t4\n",
      "\"rest\"\t5\n",
      "\"restate\"\t1\n",
      "\"restless\"\t1\n",
      "\"restore\"\t1\n",
      "\"restrictions\"\t1\n",
      "\"result\"\t2\n",
      "\"resulted\"\t2\n",
      "\"results\"\t6\n",
      "\"resume\"\t3\n",
      "\"retail\"\t4\n",
      "\"retains\"\t3\n",
      "\"retarding\"\t1\n",
      "\"retentive\"\t1\n",
      "\"retire\"\t3\n",
      "\"retired\"\t2\n",
      "\"retirement\"\t1\n",
      "\"return\"\t8\n",
      "\"returned\"\t2\n",
      "\"rev\"\t4\n",
      "\"revenue\"\t2\n",
      "\"reversed\"\t2\n",
      "\"review\"\t12\n",
      "\"reviewed\"\t4\n",
      "\"reviewing\"\t1\n",
      "\"reviews\"\t6\n",
      "\"revised\"\t2\n",
      "\"revolution\"\t2\n",
      "\"revolutionary\"\t1\n",
      "\"rewarding\"\t2\n",
      "\"rewrite\"\t2\n",
      "\"rge\"\t1\n",
      "\"rhine\"\t1\n",
      "\"rhinopez\"\t1\n",
      "\"rich\"\t1\n",
      "\"richard\"\t3\n",
      "\"richarddaniel\"\t1\n",
      "\"riches\"\t1\n",
      "\"rick\"\t11\n",
      "\"rid\"\t1\n",
      "\"ride\"\t2\n",
      "\"ridiculous\"\t1\n",
      "\"riding\"\t1\n",
      "\"riedel\"\t1\n",
      "\"right\"\t17\n",
      "\"rightly\"\t1\n",
      "\"rights\"\t4\n",
      "\"rise\"\t1\n",
      "\"rising\"\t1\n",
      "\"risk\"\t49\n",
      "\"rita\"\t3\n",
      "\"river\"\t2\n",
      "\"riverdeep\"\t1\n",
      "\"rizzi\"\t2\n",
      "\"rm\"\t1\n",
      "\"rmation\"\t1\n",
      "\"road\"\t2\n",
      "\"roared\"\t1\n",
      "\"rob\"\t3\n",
      "\"robert\"\t7\n",
      "\"roberts\"\t9\n",
      "\"rock\"\t2\n",
      "\"rodgers\"\t1\n",
      "\"rodney\"\t1\n",
      "\"rodriguez\"\t2\n",
      "\"rogram\"\t1\n",
      "\"rohan\"\t1\n",
      "\"roibot\"\t3\n",
      "\"role\"\t18\n",
      "\"roll\"\t1\n",
      "\"roman\"\t4\n",
      "\"romantic\"\t1\n",
      "\"romeo\"\t1\n",
      "\"roof\"\t2\n",
      "\"rook\"\t1\n",
      "\"room\"\t3\n",
      "\"rosalie\"\t1\n",
      "\"rosel\"\t2\n",
      "\"rosenfield\"\t6\n",
      "\"ross\"\t4\n",
      "\"rossman\"\t12\n",
      "\"round\"\t1\n",
      "\"routes\"\t1\n",
      "\"roving\"\t6\n",
      "\"roxio\"\t1\n",
      "\"rsa\"\t1\n",
      "\"rsbaker\"\t1\n",
      "\"rto\"\t1\n",
      "\"rtol\"\t1\n",
      "\"ruanda\"\t1\n",
      "\"rub\"\t1\n",
      "\"rudl\"\t2\n",
      "\"ruin\"\t1\n",
      "\"rule\"\t2\n",
      "\"rules\"\t1\n",
      "\"ruling\"\t2\n",
      "\"run\"\t2\n",
      "\"runkel\"\t1\n",
      "\"running\"\t7\n",
      "\"rush\"\t1\n",
      "\"rushed\"\t1\n",
      "\"russell\"\t1\n",
      "\"ruzika\"\t1\n",
      "\"rvsq\"\t1\n",
      "\"rw\"\t1\n",
      "\"rx\"\t1\n",
      "\"ryanmcgeachie\"\t1\n",
      "\"sa\"\t4\n",
      "\"saa\"\t1\n",
      "\"saave\"\t7\n",
      "\"safe\"\t5\n",
      "\"safely\"\t2\n",
      "\"safety\"\t2\n",
      "\"said\"\t3\n",
      "\"salaried\"\t1\n",
      "\"sale\"\t10\n",
      "\"sales\"\t43\n",
      "\"sallen\"\t1\n",
      "\"sally\"\t34\n",
      "\"salomon\"\t2\n",
      "\"salt\"\t1\n",
      "\"sam\"\t3\n",
      "\"samarium\"\t1\n",
      "\"same\"\t13\n",
      "\"samer\"\t5\n",
      "\"sample\"\t6\n",
      "\"sampling\"\t1\n",
      "\"samuel\"\t1\n",
      "\"san\"\t4\n",
      "\"sand\"\t1\n",
      "\"sandton\"\t2\n",
      "\"sang\"\t1\n",
      "\"sanibel\"\t1\n",
      "\"sankoh\"\t3\n",
      "\"sap\"\t17\n",
      "\"sapphire\"\t1\n",
      "\"sat\"\t1\n",
      "\"satisfied\"\t4\n",
      "\"saturday\"\t1\n",
      "\"save\"\t8\n",
      "\"saving\"\t2\n",
      "\"savings\"\t1\n",
      "\"savvy\"\t1\n",
      "\"saw\"\t1\n",
      "\"say\"\t6\n",
      "\"saying\"\t4\n",
      "\"says\"\t3\n",
      "\"sc\"\t5\n",
      "\"scampbell\"\t1\n",
      "\"scams\"\t1\n",
      "\"scenario\"\t1\n",
      "\"schafer\"\t1\n",
      "\"schaffer\"\t1\n",
      "\"schedule\"\t8\n",
      "\"scheduled\"\t3\n",
      "\"scheduling\"\t4\n",
      "\"schmidt\"\t4\n",
      "\"school\"\t2\n",
      "\"schott\"\t1\n",
      "\"schumack\"\t3\n",
      "\"science\"\t1\n",
      "\"scientific\"\t1\n",
      "\"scope\"\t2\n",
      "\"score\"\t1\n",
      "\"scott\"\t2\n",
      "\"scotty\"\t1\n",
      "\"scout\"\t1\n",
      "\"scratch\"\t1\n",
      "\"screamed\"\t1\n",
      "\"screaming\"\t1\n",
      "\"screen\"\t1\n",
      "\"screening\"\t1\n",
      "\"screwball\"\t1\n",
      "\"script\"\t3\n",
      "\"scroll\"\t3\n",
      "\"scuttle\"\t1\n",
      "\"sdba\"\t1\n",
      "\"sds\"\t1\n",
      "\"search\"\t4\n",
      "\"searching\"\t2\n",
      "\"season\"\t1\n",
      "\"second\"\t4\n",
      "\"secret\"\t8\n",
      "\"secrets\"\t5\n",
      "\"section\"\t4\n",
      "\"sector\"\t3\n",
      "\"secure\"\t3\n",
      "\"secured\"\t1\n",
      "\"securities\"\t5\n",
      "\"securitization\"\t3\n",
      "\"security\"\t10\n",
      "\"see\"\t34\n",
      "\"seeded\"\t1\n",
      "\"seeing\"\t1\n",
      "\"seem\"\t3\n",
      "\"seemed\"\t2\n",
      "\"seems\"\t4\n",
      "\"seen\"\t4\n",
      "\"seize\"\t2\n",
      "\"selected\"\t1\n",
      "\"selection\"\t4\n",
      "\"self\"\t4\n",
      "\"sell\"\t8\n",
      "\"sellens\"\t1\n",
      "\"selling\"\t11\n",
      "\"sellinternetaccess\"\t5\n",
      "\"sells\"\t2\n",
      "\"semester\"\t1\n",
      "\"sempra\"\t1\n",
      "\"sempratrading\"\t1\n",
      "\"sen\"\t1\n",
      "\"senate\"\t2\n",
      "\"senator\"\t5\n",
      "\"send\"\t23\n",
      "\"sending\"\t1\n",
      "\"sengupta\"\t1\n",
      "\"senior\"\t11\n",
      "\"sense\"\t3\n",
      "\"sensitive\"\t2\n",
      "\"sent\"\t16\n",
      "\"sentence\"\t2\n",
      "\"sentences\"\t4\n",
      "\"sentiment\"\t1\n",
      "\"separate\"\t7\n",
      "\"sera\"\t2\n",
      "\"sergeev\"\t5\n",
      "\"serial\"\t2\n",
      "\"serious\"\t1\n",
      "\"serve\"\t6\n",
      "\"served\"\t1\n",
      "\"server\"\t5\n",
      "\"servers\"\t2\n",
      "\"service\"\t48\n",
      "\"services\"\t16\n",
      "\"session\"\t1\n",
      "\"sessions\"\t2\n",
      "\"set\"\t15\n",
      "\"setbacks\"\t1\n",
      "\"settanni\"\t1\n",
      "\"setting\"\t3\n",
      "\"settingt\"\t1\n",
      "\"settled\"\t3\n",
      "\"settlement\"\t2\n",
      "\"settlements\"\t2\n",
      "\"setup\"\t5\n",
      "\"seven\"\t5\n",
      "\"seventhpower\"\t4\n",
      "\"several\"\t17\n",
      "\"severe\"\t1\n",
      "\"seward\"\t1\n",
      "\"sex\"\t1\n",
      "\"sexual\"\t2\n",
      "\"sezgen\"\t4\n",
      "\"shakespeare\"\t3\n",
      "\"shall\"\t9\n",
      "\"shanbhogue\"\t5\n",
      "\"shandong\"\t1\n",
      "\"share\"\t8\n",
      "\"shared\"\t4\n",
      "\"shares\"\t1\n",
      "\"sharing\"\t3\n",
      "\"sharpens\"\t1\n",
      "\"sharply\"\t1\n",
      "\"she\"\t18\n",
      "\"sheila\"\t4\n",
      "\"shenkman\"\t1\n",
      "\"sherlyn\"\t3\n",
      "\"sherri\"\t2\n",
      "\"shift\"\t2\n",
      "\"shiip\"\t2\n",
      "\"shipped\"\t1\n",
      "\"shipping\"\t1\n",
      "\"shirley\"\t18\n",
      "\"shoot\"\t1\n",
      "\"shop\"\t3\n",
      "\"shopping\"\t5\n",
      "\"short\"\t8\n",
      "\"shorter\"\t1\n",
      "\"shortly\"\t1\n",
      "\"shot\"\t1\n",
      "\"should\"\t27\n",
      "\"shoulder\"\t1\n",
      "\"show\"\t7\n",
      "\"showcase\"\t20\n",
      "\"showcases\"\t6\n",
      "\"shown\"\t2\n",
      "\"shows\"\t1\n",
      "\"shults\"\t1\n",
      "\"shut\"\t1\n",
      "\"shutdown\"\t1\n",
      "\"shwc\"\t1\n",
      "\"shy\"\t1\n",
      "\"siberia\"\t1\n",
      "\"sibilant\"\t1\n",
      "\"sick\"\t1\n",
      "\"side\"\t2\n",
      "\"sides\"\t1\n",
      "\"sierra\"\t5\n",
      "\"sight\"\t1\n",
      "\"sign\"\t4\n",
      "\"signature\"\t1\n",
      "\"signed\"\t4\n",
      "\"significance\"\t1\n",
      "\"significant\"\t4\n",
      "\"signing\"\t1\n",
      "\"signups\"\t1\n",
      "\"sillily\"\t1\n",
      "\"silver\"\t1\n",
      "\"similes\"\t1\n",
      "\"simple\"\t10\n",
      "\"simplicity\"\t4\n",
      "\"simply\"\t5\n",
      "\"since\"\t13\n",
      "\"sincerely\"\t4\n",
      "\"singing\"\t1\n",
      "\"single\"\t4\n",
      "\"singleton\"\t1\n",
      "\"sink\"\t1\n",
      "\"sir\"\t2\n",
      "\"sit\"\t1\n",
      "\"sitara\"\t3\n",
      "\"site\"\t60\n",
      "\"sites\"\t31\n",
      "\"situation\"\t4\n",
      "\"six\"\t3\n",
      "\"size\"\t5\n",
      "\"skilling\"\t7\n",
      "\"skills\"\t2\n",
      "\"skin\"\t1\n",
      "\"skinner\"\t3\n",
      "\"slash\"\t1\n",
      "\"slaver\"\t1\n",
      "\"sleep\"\t2\n",
      "\"slgavjmoqq\"\t1\n",
      "\"slightly\"\t1\n",
      "\"slipped\"\t1\n",
      "\"slots\"\t1\n",
      "\"slotting\"\t1\n",
      "\"slow\"\t3\n",
      "\"slower\"\t1\n",
      "\"slowly\"\t1\n",
      "\"small\"\t3\n",
      "\"smaller\"\t7\n",
      "\"smith\"\t7\n",
      "\"smithc\"\t1\n",
      "\"smoker\"\t1\n",
      "\"smoking\"\t7\n",
      "\"sneak\"\t2\n",
      "\"snhezkjzhisbpjhgx\"\t1\n",
      "\"snooping\"\t1\n",
      "\"snowboard\"\t1\n",
      "\"so\"\t60\n",
      "\"soap\"\t2\n",
      "\"socal\"\t4\n",
      "\"softtwares\"\t2\n",
      "\"software\"\t13\n",
      "\"softwares\"\t1\n",
      "\"sokolov\"\t4\n",
      "\"sold\"\t2\n",
      "\"solely\"\t1\n",
      "\"solicit\"\t1\n",
      "\"solicitation\"\t2\n",
      "\"solid\"\t1\n",
      "\"solmonson\"\t1\n",
      "\"solution\"\t2\n",
      "\"solved\"\t1\n",
      "\"soma\"\t1\n",
      "\"some\"\t68\n",
      "\"somehow\"\t1\n",
      "\"someone\"\t11\n",
      "\"something\"\t8\n",
      "\"sometime\"\t2\n",
      "\"sometimes\"\t1\n",
      "\"somewhat\"\t1\n",
      "\"son\"\t10\n",
      "\"songs\"\t1\n",
      "\"soon\"\t9\n",
      "\"sorry\"\t2\n",
      "\"sos\"\t1\n",
      "\"sotware\"\t1\n",
      "\"sound\"\t3\n",
      "\"soundmax\"\t1\n",
      "\"sounds\"\t1\n",
      "\"source\"\t5\n",
      "\"sources\"\t7\n",
      "\"south\"\t15\n",
      "\"southern\"\t1\n",
      "\"southernenergy\"\t2\n",
      "\"southwest\"\t1\n",
      "\"souza\"\t1\n",
      "\"sp\"\t1\n",
      "\"space\"\t7\n",
      "\"spam\"\t7\n",
      "\"spare\"\t1\n",
      "\"spark\"\t2\n",
      "\"speak\"\t8\n",
      "\"speaking\"\t1\n",
      "\"special\"\t14\n",
      "\"specials\"\t4\n",
      "\"specific\"\t7\n",
      "\"specifically\"\t4\n",
      "\"speed\"\t2\n",
      "\"speeding\"\t1\n",
      "\"speeds\"\t1\n",
      "\"spell\"\t2\n",
      "\"spelling\"\t3\n",
      "\"spend\"\t8\n",
      "\"spending\"\t1\n",
      "\"spent\"\t4\n",
      "\"spigot\"\t1\n",
      "\"spirit\"\t2\n",
      "\"split\"\t2\n",
      "\"splitting\"\t1\n",
      "\"spoke\"\t2\n",
      "\"spoken\"\t2\n",
      "\"sponsor\"\t4\n",
      "\"sponsored\"\t1\n",
      "\"sponsoring\"\t1\n",
      "\"sponsorship\"\t9\n",
      "\"sportsbetting\"\t2\n",
      "\"spot\"\t5\n",
      "\"spotlight\"\t1\n",
      "\"spp\"\t1\n",
      "\"spread\"\t1\n",
      "\"spreads\"\t1\n",
      "\"spring\"\t1\n",
      "\"sql\"\t1\n",
      "\"squeeze\"\t1\n",
      "\"squill\"\t1\n",
      "\"sr\"\t1\n",
      "\"srs\"\t1\n",
      "\"ss\"\t1\n",
      "\"ssb\"\t1\n",
      "\"ssmb\"\t1\n",
      "\"st\"\t3\n",
      "\"stability\"\t3\n",
      "\"stable\"\t1\n",
      "\"stacey\"\t4\n",
      "\"stacy\"\t1\n",
      "\"stad\"\t1\n",
      "\"staff\"\t5\n",
      "\"stage\"\t2\n",
      "\"stake\"\t2\n",
      "\"stalling\"\t1\n",
      "\"stand\"\t2\n",
      "\"standard\"\t3\n",
      "\"standing\"\t6\n",
      "\"stands\"\t1\n",
      "\"star\"\t2\n",
      "\"stars\"\t1\n",
      "\"start\"\t9\n",
      "\"startbgmlmezine\"\t2\n",
      "\"started\"\t3\n",
      "\"starting\"\t1\n",
      "\"state\"\t30\n",
      "\"stated\"\t2\n",
      "\"statement\"\t1\n",
      "\"statements\"\t1\n",
      "\"states\"\t5\n",
      "\"station\"\t2\n",
      "\"stats\"\t2\n",
      "\"status\"\t1\n",
      "\"stay\"\t2\n",
      "\"stayed\"\t1\n",
      "\"steadily\"\t1\n",
      "\"steak\"\t1\n",
      "\"stearns\"\t2\n",
      "\"steeves\"\t2\n",
      "\"stefkatz\"\t1\n",
      "\"stella\"\t6\n",
      "\"stelly\"\t1\n",
      "\"stentofon\"\t2\n",
      "\"step\"\t2\n",
      "\"stephanie\"\t1\n",
      "\"steps\"\t1\n",
      "\"stern\"\t1\n",
      "\"steve\"\t3\n",
      "\"stick\"\t2\n",
      "\"stil\"\t2\n",
      "\"still\"\t12\n",
      "\"stilled\"\t1\n",
      "\"stinson\"\t8\n",
      "\"stock\"\t5\n",
      "\"stocker\"\t1\n",
      "\"stockhouse\"\t1\n",
      "\"stomaching\"\t1\n",
      "\"stood\"\t1\n",
      "\"stop\"\t15\n",
      "\"stopping\"\t3\n",
      "\"store\"\t2\n",
      "\"stores\"\t6\n",
      "\"stories\"\t4\n",
      "\"story\"\t17\n",
      "\"stove\"\t1\n",
      "\"straight\"\t4\n",
      "\"strain\"\t1\n",
      "\"strangas\"\t1\n",
      "\"strange\"\t2\n",
      "\"strangulate\"\t1\n",
      "\"stratagem\"\t1\n",
      "\"strategic\"\t3\n",
      "\"strategies\"\t5\n",
      "\"strategist\"\t2\n",
      "\"strategy\"\t2\n",
      "\"stratton\"\t1\n",
      "\"streams\"\t2\n",
      "\"street\"\t1\n",
      "\"streets\"\t1\n",
      "\"strength\"\t1\n",
      "\"strengthened\"\t1\n",
      "\"strengthening\"\t1\n",
      "\"strengths\"\t2\n",
      "\"stress\"\t5\n",
      "\"stretch\"\t3\n",
      "\"strictly\"\t1\n",
      "\"strides\"\t2\n",
      "\"striking\"\t1\n",
      "\"strong\"\t2\n",
      "\"stronger\"\t2\n",
      "\"stroock\"\t1\n",
      "\"struck\"\t2\n",
      "\"structure\"\t5\n",
      "\"students\"\t4\n",
      "\"studio\"\t2\n",
      "\"stuff\"\t4\n",
      "\"stukm\"\t1\n",
      "\"stupid\"\t1\n",
      "\"stupidity\"\t1\n",
      "\"style\"\t1\n",
      "\"styles\"\t1\n",
      "\"subconsciously\"\t1\n",
      "\"subject\"\t53\n",
      "\"submissions\"\t4\n",
      "\"submit\"\t10\n",
      "\"submitted\"\t1\n",
      "\"subscribe\"\t7\n",
      "\"subscribed\"\t4\n",
      "\"subscribers\"\t1\n",
      "\"subscribing\"\t1\n",
      "\"subscription\"\t10\n",
      "\"subscriptions\"\t1\n",
      "\"subsequently\"\t1\n",
      "\"substantial\"\t2\n",
      "\"succeed\"\t3\n",
      "\"succeeded\"\t1\n",
      "\"succeeding\"\t1\n",
      "\"succeeds\"\t1\n",
      "\"success\"\t25\n",
      "\"successes\"\t3\n",
      "\"successful\"\t17\n",
      "\"successfully\"\t1\n",
      "\"such\"\t9\n",
      "\"sue\"\t3\n",
      "\"sugar\"\t3\n",
      "\"suggest\"\t2\n",
      "\"suggested\"\t1\n",
      "\"suggestions\"\t5\n",
      "\"suite\"\t5\n",
      "\"sum\"\t3\n",
      "\"summary\"\t5\n",
      "\"summer\"\t5\n",
      "\"summit\"\t1\n",
      "\"sunrise\"\t1\n",
      "\"sup\"\t1\n",
      "\"super\"\t5\n",
      "\"superb\"\t1\n",
      "\"superman\"\t1\n",
      "\"supervisor\"\t4\n",
      "\"supervisors\"\t5\n",
      "\"supplier\"\t2\n",
      "\"suppliers\"\t6\n",
      "\"supply\"\t4\n",
      "\"support\"\t16\n",
      "\"supported\"\t1\n",
      "\"supporting\"\t6\n",
      "\"supportive\"\t1\n",
      "\"supports\"\t3\n",
      "\"supposedly\"\t1\n",
      "\"suppressant\"\t1\n",
      "\"suprervisagra\"\t1\n",
      "\"sure\"\t11\n",
      "\"surf\"\t5\n",
      "\"surfing\"\t1\n",
      "\"surfola\"\t4\n",
      "\"surged\"\t1\n",
      "\"surgery\"\t1\n",
      "\"surrounding\"\t1\n",
      "\"survey\"\t3\n",
      "\"susan\"\t9\n",
      "\"suspicion\"\t1\n",
      "\"sustainability\"\t1\n",
      "\"suzms\"\t1\n",
      "\"swap\"\t2\n",
      "\"swbe\"\t1\n",
      "\"sweet\"\t3\n",
      "\"swidner\"\t1\n",
      "\"swift\"\t2\n",
      "\"swings\"\t1\n",
      "\"swiss\"\t2\n",
      "\"switch\"\t1\n",
      "\"switchman\"\t1\n",
      "\"sydney\"\t2\n",
      "\"sylg\"\t1\n",
      "\"symaantec\"\t1\n",
      "\"syndicate\"\t1\n",
      "\"system\"\t13\n",
      "\"systems\"\t6\n",
      "\"systemslogical\"\t1\n",
      "\"table\"\t2\n",
      "\"tablet\"\t1\n",
      "\"tablets\"\t1\n",
      "\"tactically\"\t1\n",
      "\"tag\"\t1\n",
      "\"take\"\t19\n",
      "\"takegreat\"\t1\n",
      "\"taken\"\t2\n",
      "\"takeover\"\t2\n",
      "\"takes\"\t7\n",
      "\"taking\"\t4\n",
      "\"takriti\"\t5\n",
      "\"talent\"\t2\n",
      "\"talk\"\t7\n",
      "\"talked\"\t1\n",
      "\"talking\"\t2\n",
      "\"talks\"\t3\n",
      "\"tall\"\t1\n",
      "\"tamarchenko\"\t4\n",
      "\"tang\"\t5\n",
      "\"tangible\"\t1\n",
      "\"tantalum\"\t1\n",
      "\"tanya\"\t4\n",
      "\"target\"\t9\n",
      "\"targeted\"\t11\n",
      "\"targeting\"\t1\n",
      "\"tarrif\"\t2\n",
      "\"tarrin\"\t1\n",
      "\"task\"\t2\n",
      "\"taught\"\t1\n",
      "\"tax\"\t1\n",
      "\"taxation\"\t1\n",
      "\"taylor\"\t4\n",
      "\"taylorja\"\t1\n",
      "\"tea\"\t2\n",
      "\"teach\"\t1\n",
      "\"teacher\"\t1\n",
      "\"teachers\"\t1\n",
      "\"team\"\t19\n",
      "\"tear\"\t1\n",
      "\"tears\"\t1\n",
      "\"technical\"\t3\n",
      "\"technicalities\"\t1\n",
      "\"techniques\"\t5\n",
      "\"technology\"\t3\n",
      "\"teco\"\t2\n",
      "\"teddy\"\t3\n",
      "\"tejones\"\t2\n",
      "\"tel\"\t3\n",
      "\"tele\"\t1\n",
      "\"telephone\"\t3\n",
      "\"teleseminar\"\t2\n",
      "\"television\"\t1\n",
      "\"tell\"\t13\n",
      "\"telling\"\t1\n",
      "\"tells\"\t1\n",
      "\"tempted\"\t1\n",
      "\"tenacity\"\t1\n",
      "\"tenderer\"\t1\n",
      "\"tendererlycopodium\"\t1\n",
      "\"teosrest\"\t1\n",
      "\"terence\"\t1\n",
      "\"term\"\t8\n",
      "\"terminate\"\t1\n",
      "\"terms\"\t5\n",
      "\"terrible\"\t1\n",
      "\"terrific\"\t1\n",
      "\"terrorist\"\t1\n",
      "\"terry\"\t1\n",
      "\"test\"\t1\n",
      "\"testimonials\"\t2\n",
      "\"texaco\"\t6\n",
      "\"texas\"\t1\n",
      "\"text\"\t15\n",
      "\"texts\"\t2\n",
      "\"textual\"\t1\n",
      "\"texture\"\t1\n",
      "\"textures\"\t1\n",
      "\"tgary\"\t1\n",
      "\"th\"\t14\n",
      "\"than\"\t32\n",
      "\"thank\"\t9\n",
      "\"thanking\"\t3\n",
      "\"thanks\"\t34\n",
      "\"that\"\t227\n",
      "\"the\"\t1247\n",
      "\"theinvestment\"\t1\n",
      "\"their\"\t40\n",
      "\"them\"\t56\n",
      "\"themselves\"\t4\n",
      "\"then\"\t28\n",
      "\"theqgrefor\"\t1\n",
      "\"there\"\t56\n",
      "\"thereafter\"\t2\n",
      "\"therefore\"\t7\n",
      "\"thereof\"\t1\n",
      "\"these\"\t50\n",
      "\"they\"\t63\n",
      "\"thickness\"\t1\n",
      "\"thimble\"\t1\n",
      "\"thing\"\t13\n",
      "\"things\"\t8\n",
      "\"think\"\t11\n",
      "\"thinking\"\t1\n",
      "\"third\"\t3\n",
      "\"thirteen\"\t1\n",
      "\"thirty\"\t3\n",
      "\"this\"\t262\n",
      "\"thompson\"\t1\n",
      "\"thorns\"\t1\n",
      "\"thoroughly\"\t1\n",
      "\"those\"\t15\n",
      "\"though\"\t6\n",
      "\"thought\"\t2\n",
      "\"thoughts\"\t2\n",
      "\"thousainds\"\t1\n",
      "\"thousand\"\t2\n",
      "\"thousands\"\t3\n",
      "\"threat\"\t4\n",
      "\"threats\"\t2\n",
      "\"three\"\t17\n",
      "\"thrid\"\t1\n",
      "\"thronged\"\t1\n",
      "\"through\"\t18\n",
      "\"throughout\"\t4\n",
      "\"throw\"\t1\n",
      "\"thu\"\t10\n",
      "\"thunder\"\t1\n",
      "\"thuraisingham\"\t6\n",
      "\"thursday\"\t11\n",
      "\"thus\"\t1\n",
      "\"ticket\"\t2\n",
      "\"tidbits\"\t1\n",
      "\"till\"\t1\n",
      "\"tilts\"\t1\n",
      "\"time\"\t44\n",
      "\"timekeeping\"\t2\n",
      "\"timely\"\t2\n",
      "\"times\"\t5\n",
      "\"timesheets\"\t1\n",
      "\"timing\"\t1\n",
      "\"timotheus\"\t1\n",
      "\"timshometownstories\"\t3\n",
      "\"tin\"\t5\n",
      "\"tinned\"\t1\n",
      "\"tips\"\t4\n",
      "\"tire\"\t1\n",
      "\"tired\"\t2\n",
      "\"tires\"\t3\n",
      "\"tithable\"\t1\n",
      "\"title\"\t4\n",
      "\"titles\"\t3\n",
      "\"tlapek\"\t5\n",
      "\"tm\"\t1\n",
      "\"to\"\t964\n",
      "\"tobacco\"\t2\n",
      "\"today\"\t34\n",
      "\"todd\"\t1\n",
      "\"together\"\t7\n",
      "\"toilet\"\t1\n",
      "\"tokyo\"\t1\n",
      "\"told\"\t6\n",
      "\"toll\"\t3\n",
      "\"tommy\"\t1\n",
      "\"tomorrow\"\t5\n",
      "\"tonai\"\t1\n",
      "\"tone\"\t1\n",
      "\"tonne\"\t1\n",
      "\"too\"\t12\n",
      "\"took\"\t3\n",
      "\"tool\"\t2\n",
      "\"toolbar\"\t7\n",
      "\"top\"\t9\n",
      "\"topic\"\t2\n",
      "\"topics\"\t1\n",
      "\"toronto\"\t1\n",
      "\"tortoises\"\t1\n",
      "\"total\"\t8\n",
      "\"touched\"\t1\n",
      "\"toward\"\t1\n",
      "\"towards\"\t4\n",
      "\"towel\"\t1\n",
      "\"towels\"\t1\n",
      "\"tower\"\t2\n",
      "\"town\"\t4\n",
      "\"toy\"\t2\n",
      "\"tr\"\t2\n",
      "\"track\"\t3\n",
      "\"tracked\"\t1\n",
      "\"tracks\"\t2\n",
      "\"trade\"\t25\n",
      "\"trademarked\"\t2\n",
      "\"trader\"\t4\n",
      "\"traders\"\t1\n",
      "\"trading\"\t29\n",
      "\"tradition\"\t1\n",
      "\"traditional\"\t2\n",
      "\"traffic\"\t10\n",
      "\"trafficmultipliers\"\t1\n",
      "\"train\"\t7\n",
      "\"training\"\t9\n",
      "\"tramadol\"\t2\n",
      "\"trans\"\t1\n",
      "\"transact\"\t1\n",
      "\"transaction\"\t5\n",
      "\"transalta\"\t1\n",
      "\"transcanada\"\t2\n",
      "\"transco\"\t2\n",
      "\"transfer\"\t12\n",
      "\"transferred\"\t3\n",
      "\"transferring\"\t2\n",
      "\"transistion\"\t5\n",
      "\"transition\"\t4\n",
      "\"transmission\"\t12\n",
      "\"transmissions\"\t1\n",
      "\"transport\"\t3\n",
      "\"transportation\"\t2\n",
      "\"transporting\"\t1\n",
      "\"trash\"\t1\n",
      "\"travel\"\t3\n",
      "\"traveling\"\t1\n",
      "\"travelling\"\t1\n",
      "\"travis\"\t1\n",
      "\"treasonous\"\t1\n",
      "\"treasurer\"\t1\n",
      "\"treat\"\t1\n",
      "\"treatment\"\t1\n",
      "\"treats\"\t1\n",
      "\"tree\"\t2\n",
      "\"trevino\"\t4\n",
      "\"trial\"\t3\n",
      "\"trials\"\t1\n",
      "\"triassic\"\t1\n",
      "\"tricky\"\t1\n",
      "\"tried\"\t5\n",
      "\"trigger\"\t2\n",
      "\"trina\"\t1\n",
      "\"trip\"\t2\n",
      "\"triple\"\t1\n",
      "\"trips\"\t1\n",
      "\"trisha\"\t1\n",
      "\"trista\"\t2\n",
      "\"troubled\"\t1\n",
      "\"true\"\t9\n",
      "\"truly\"\t1\n",
      "\"trunk\"\t2\n",
      "\"trust\"\t8\n",
      "\"trusted\"\t2\n",
      "\"truth\"\t2\n",
      "\"try\"\t10\n",
      "\"trying\"\t3\n",
      "\"tuesday\"\t4\n",
      "\"tuned\"\t1\n",
      "\"tuneful\"\t1\n",
      "\"tungsten\"\t1\n",
      "\"tuning\"\t1\n",
      "\"turk\"\t3\n",
      "\"turn\"\t3\n",
      "\"turned\"\t1\n",
      "\"turner\"\t3\n",
      "\"tw\"\t1\n",
      "\"twain\"\t1\n",
      "\"twenty\"\t4\n",
      "\"twice\"\t2\n",
      "\"two\"\t24\n",
      "\"tx\"\t3\n",
      "\"txu\"\t2\n",
      "\"txuelectric\"\t1\n",
      "\"txuenergy\"\t3\n",
      "\"tyone\"\t1\n",
      "\"type\"\t12\n",
      "\"uafn\"\t1\n",
      "\"ugh\"\t1\n",
      "\"uk\"\t4\n",
      "\"ult\"\t2\n",
      "\"ultimate\"\t1\n",
      "\"un\"\t1\n",
      "\"unable\"\t3\n",
      "\"unattainable\"\t2\n",
      "\"unavoidable\"\t1\n",
      "\"unbelievably\"\t1\n",
      "\"unblock\"\t1\n",
      "\"unblocking\"\t4\n",
      "\"unclaimed\"\t1\n",
      "\"unclear\"\t1\n",
      "\"uncollected\"\t1\n",
      "\"uncomfortable\"\t1\n",
      "\"uncover\"\t1\n",
      "\"under\"\t23\n",
      "\"undercollected\"\t1\n",
      "\"undercollection\"\t4\n",
      "\"underga\"\t1\n",
      "\"underground\"\t1\n",
      "\"underneath\"\t1\n",
      "\"understand\"\t7\n",
      "\"understanding\"\t9\n",
      "\"underwrite\"\t1\n",
      "\"undeveloped\"\t1\n",
      "\"unify\"\t3\n",
      "\"union\"\t2\n",
      "\"unions\"\t2\n",
      "\"unique\"\t2\n",
      "\"unit\"\t7\n",
      "\"united\"\t5\n",
      "\"units\"\t4\n",
      "\"universal\"\t1\n",
      "\"university\"\t1\n",
      "\"unknown\"\t6\n",
      "\"unless\"\t5\n",
      "\"unlike\"\t1\n",
      "\"unlimited\"\t4\n",
      "\"unmanly\"\t1\n",
      "\"unnecessarily\"\t2\n",
      "\"unnecessary\"\t1\n",
      "\"unocal\"\t1\n",
      "\"unprofessional\"\t1\n",
      "\"unrealistic\"\t2\n",
      "\"unsubscribe\"\t16\n",
      "\"unsubscribed\"\t1\n",
      "\"until\"\t17\n",
      "\"untouchable\"\t1\n",
      "\"unwarranted\"\t1\n",
      "\"up\"\t47\n",
      "\"upcoming\"\t1\n",
      "\"update\"\t13\n",
      "\"updated\"\t1\n",
      "\"upgradeable\"\t3\n",
      "\"upgraded\"\t1\n",
      "\"upgrades\"\t2\n",
      "\"upload\"\t1\n",
      "\"uploaded\"\t1\n",
      "\"upon\"\t9\n",
      "\"upping\"\t1\n",
      "\"upward\"\t1\n",
      "\"ur\"\t1\n",
      "\"uranium\"\t1\n",
      "\"urg\"\t2\n",
      "\"urgency\"\t1\n",
      "\"urgent\"\t7\n",
      "\"urgently\"\t1\n",
      "\"url\"\t3\n",
      "\"us\"\t50\n",
      "\"usage\"\t4\n",
      "\"usavity\"\t1\n",
      "\"usb\"\t1\n",
      "\"usd\"\t2\n",
      "\"use\"\t43\n",
      "\"used\"\t11\n",
      "\"useful\"\t4\n",
      "\"user\"\t8\n",
      "\"userconf\"\t1\n",
      "\"users\"\t7\n",
      "\"uses\"\t1\n",
      "\"using\"\t18\n",
      "\"utilities\"\t22\n",
      "\"utility\"\t8\n",
      "\"uuz\"\t1\n",
      "\"uvd\"\t1\n",
      "\"uwe\"\t4\n",
      "\"uz\"\t1\n",
      "\"vacation\"\t2\n",
      "\"val\"\t3\n",
      "\"valeria\"\t1\n",
      "\"valid\"\t4\n",
      "\"validate\"\t1\n",
      "\"valium\"\t3\n",
      "\"valley\"\t3\n",
      "\"valuable\"\t9\n",
      "\"valuables\"\t2\n",
      "\"value\"\t11\n",
      "\"valued\"\t1\n",
      "\"van\"\t3\n",
      "\"vanadium\"\t1\n",
      "\"vance\"\t2\n",
      "\"var\"\t1\n",
      "\"variety\"\t1\n",
      "\"vary\"\t1\n",
      "\"vasant\"\t5\n",
      "\"vastar\"\t8\n",
      "\"vaughn\"\t3\n",
      "\"vault\"\t1\n",
      "\"ve\"\t21\n",
      "\"vein\"\t1\n",
      "\"vendor\"\t2\n",
      "\"vendors\"\t1\n",
      "\"venture\"\t5\n",
      "\"verbry\"\t1\n",
      "\"verification\"\t2\n",
      "\"verify\"\t1\n",
      "\"version\"\t9\n",
      "\"versus\"\t2\n",
      "\"very\"\t31\n",
      "\"verypowerful\"\t1\n",
      "\"veteran\"\t1\n",
      "\"vi\"\t2\n",
      "\"via\"\t13\n",
      "\"viag\"\t1\n",
      "\"viagra\"\t5\n",
      "\"vic\"\t2\n",
      "\"vice\"\t9\n",
      "\"vicodin\"\t2\n",
      "\"vicqodin\"\t1\n",
      "\"victor\"\t2\n",
      "\"view\"\t11\n",
      "\"viewer\"\t1\n",
      "\"villarreal\"\t1\n",
      "\"vince\"\t17\n",
      "\"vincent\"\t5\n",
      "\"vintage\"\t2\n",
      "\"virtues\"\t1\n",
      "\"vision\"\t1\n",
      "\"visit\"\t30\n",
      "\"visited\"\t1\n",
      "\"visitor\"\t3\n",
      "\"visitors\"\t2\n",
      "\"visits\"\t1\n",
      "\"visual\"\t1\n",
      "\"visually\"\t1\n",
      "\"voice\"\t6\n",
      "\"voices\"\t1\n",
      "\"volatility\"\t4\n",
      "\"volume\"\t9\n",
      "\"volumes\"\t1\n",
      "\"voluntary\"\t1\n",
      "\"vote\"\t7\n",
      "\"voted\"\t1\n",
      "\"voting\"\t2\n",
      "\"vp\"\t1\n",
      "\"vs\"\t2\n",
      "\"vzxoaxqhg\"\t1\n",
      "\"wa\"\t2\n",
      "\"wacked\"\t1\n",
      "\"waggons\"\t1\n",
      "\"wait\"\t2\n",
      "\"walked\"\t1\n",
      "\"wall\"\t6\n",
      "\"wallis\"\t1\n",
      "\"wallow\"\t1\n",
      "\"walpole\"\t1\n",
      "\"walsh\"\t2\n",
      "\"walton\"\t2\n",
      "\"want\"\t36\n",
      "\"wanted\"\t6\n",
      "\"wanting\"\t4\n",
      "\"wants\"\t2\n",
      "\"war\"\t2\n",
      "\"ward\"\t1\n",
      "\"wardsgiftshop\"\t1\n",
      "\"warrant\"\t1\n",
      "\"warrants\"\t2\n",
      "\"warranty\"\t1\n",
      "\"was\"\t68\n",
      "\"wash\"\t1\n",
      "\"washing\"\t4\n",
      "\"washington\"\t1\n",
      "\"waste\"\t1\n",
      "\"watched\"\t1\n",
      "\"watchfully\"\t1\n",
      "\"water\"\t2\n",
      "\"watson\"\t2\n",
      "\"way\"\t10\n",
      "\"ways\"\t10\n",
      "\"wbom\"\t1\n",
      "\"we\"\t182\n",
      "\"weakness\"\t4\n",
      "\"wealth\"\t2\n",
      "\"weather\"\t2\n",
      "\"web\"\t23\n",
      "\"webmail\"\t1\n",
      "\"webmaster\"\t1\n",
      "\"webpage\"\t4\n",
      "\"website\"\t28\n",
      "\"websites\"\t2\n",
      "\"wedeliverparties\"\t1\n",
      "\"wednesday\"\t6\n",
      "\"weed\"\t1\n",
      "\"week\"\t38\n",
      "\"weekend\"\t3\n",
      "\"weekly\"\t4\n",
      "\"weeks\"\t8\n",
      "\"weep\"\t1\n",
      "\"weight\"\t2\n",
      "\"weightwheezy\"\t1\n",
      "\"weissman\"\t5\n",
      "\"welch\"\t1\n",
      "\"welcome\"\t2\n",
      "\"well\"\t25\n",
      "\"went\"\t3\n",
      "\"were\"\t26\n",
      "\"west\"\t5\n",
      "\"western\"\t6\n",
      "\"westerngas\"\t1\n",
      "\"westward\"\t1\n",
      "\"wfxu\"\t1\n",
      "\"whalley\"\t3\n",
      "\"what\"\t68\n",
      "\"whatever\"\t4\n",
      "\"whats\"\t1\n",
      "\"whatsoever\"\t3\n",
      "\"whelan\"\t1\n",
      "\"when\"\t33\n",
      "\"where\"\t13\n",
      "\"whereby\"\t2\n",
      "\"whether\"\t4\n",
      "\"which\"\t47\n",
      "\"while\"\t14\n",
      "\"whiskey\"\t1\n",
      "\"whitehorse\"\t1\n",
      "\"who\"\t27\n",
      "\"whole\"\t2\n",
      "\"wholesale\"\t15\n",
      "\"whom\"\t1\n",
      "\"whooping\"\t1\n",
      "\"whose\"\t2\n",
      "\"why\"\t11\n",
      "\"wide\"\t1\n",
      "\"widow\"\t2\n",
      "\"wife\"\t3\n",
      "\"wijsman\"\t1\n",
      "\"will\"\t234\n",
      "\"willbe\"\t1\n",
      "\"william\"\t1\n",
      "\"williams\"\t7\n",
      "\"willie\"\t1\n",
      "\"willing\"\t1\n",
      "\"wilson\"\t2\n",
      "\"win\"\t18\n",
      "\"wind\"\t1\n",
      "\"window\"\t1\n",
      "\"windows\"\t12\n",
      "\"windowsentities\"\t1\n",
      "\"windred\"\t1\n",
      "\"wing\"\t1\n",
      "\"winner\"\t3\n",
      "\"winners\"\t2\n",
      "\"winning\"\t4\n",
      "\"wisely\"\t2\n",
      "\"wisew\"\t1\n",
      "\"wish\"\t7\n",
      "\"wishes\"\t1\n",
      "\"wishing\"\t1\n",
      "\"with\"\t201\n",
      "\"withers\"\t4\n",
      "\"within\"\t25\n",
      "\"without\"\t10\n",
      "\"wives\"\t1\n",
      "\"women\"\t3\n",
      "\"won\"\t6\n",
      "\"wonder\"\t2\n",
      "\"wonderful\"\t1\n",
      "\"wondering\"\t1\n",
      "\"woo\"\t1\n",
      "\"wood\"\t1\n",
      "\"woodwork\"\t1\n",
      "\"woolgar\"\t1\n",
      "\"word\"\t9\n",
      "\"wording\"\t1\n",
      "\"words\"\t8\n",
      "\"work\"\t32\n",
      "\"workable\"\t1\n",
      "\"worked\"\t3\n",
      "\"workforce\"\t1\n",
      "\"working\"\t10\n",
      "\"workout\"\t1\n",
      "\"works\"\t11\n",
      "\"workstation\"\t1\n",
      "\"world\"\t10\n",
      "\"worldwide\"\t11\n",
      "\"worry\"\t2\n",
      "\"worrying\"\t1\n",
      "\"worse\"\t1\n",
      "\"worst\"\t1\n",
      "\"worth\"\t1\n",
      "\"worthless\"\t1\n",
      "\"worthwhile\"\t1\n",
      "\"would\"\t73\n",
      "\"wouldn\"\t4\n",
      "\"wound\"\t1\n",
      "\"wpd\"\t2\n",
      "\"wr\"\t1\n",
      "\"wrinkle\"\t1\n",
      "\"write\"\t13\n",
      "\"writing\"\t7\n",
      "\"written\"\t6\n",
      "\"wrong\"\t3\n",
      "\"wrote\"\t3\n",
      "\"ws\"\t1\n",
      "\"wsc\"\t1\n",
      "\"wugn\"\t1\n",
      "\"www\"\t46\n",
      "\"wyn\"\t2\n",
      "\"wynne\"\t2\n",
      "\"wynpublishing\"\t1\n",
      "\"xacnax\"\t1\n",
      "\"xan\"\t2\n",
      "\"xanax\"\t3\n",
      "\"xeni\"\t2\n",
      "\"xent\"\t2\n",
      "\"xes\"\t1\n",
      "\"xm\"\t1\n",
      "\"xp\"\t6\n",
      "\"xpress\"\t1\n",
      "\"xqirzd\"\t1\n",
      "\"yahoo\"\t7\n",
      "\"yanowski\"\t1\n",
      "\"yard\"\t2\n",
      "\"ycon\"\t2\n",
      "\"yeah\"\t2\n",
      "\"year\"\t25\n",
      "\"yearno\"\t1\n",
      "\"years\"\t22\n",
      "\"yellow\"\t1\n",
      "\"yes\"\t7\n",
      "\"yesterday\"\t7\n",
      "\"yesterdays\"\t1\n",
      "\"yet\"\t5\n",
      "\"yjoou\"\t1\n",
      "\"you\"\t445\n",
      "\"youcan\"\t1\n",
      "\"young\"\t2\n",
      "\"your\"\t395\n",
      "\"yourmembership\"\t2\n",
      "\"yours\"\t3\n",
      "\"yourself\"\t11\n",
      "\"yoursuccess\"\t2\n",
      "\"yowman\"\t1\n",
      "\"ypfpb\"\t1\n",
      "\"zaak\"\t2\n",
      "\"zaako\"\t1\n",
      "\"zac\"\t2\n",
      "\"zadorozhny\"\t4\n",
      "\"zero\"\t4\n",
      "\"zesto\"\t10\n",
      "\"zimin\"\t5\n",
      "\"zinc\"\t1\n",
      "\"zk\"\t1\n",
      "\"zo\"\t2\n",
      "\"zolam\"\t2\n",
      "\"zxs\"\t1\n",
      "Removing temp directory /var/folders/0r/78q4n41j3dgdb6ndrr46gw3430x2wk/T/WordCountHW12.z086769.20160628.084016.846168...\n"
     ]
    }
   ],
   "source": [
    "!python WordCountHW12.py  enronemail_1h.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The below will count the overall frequency of the word \"assistance.\"  This is a modification of the code provided, which will validate the mapreduce wordcount job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      10\r\n"
     ]
    }
   ],
   "source": [
    "!grep -o assistance enronemail_1h.txt | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The below will count the number of lines where the word \"assistance\" occurs.   This is exactly the code provided above.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       8\r\n"
     ]
    }
   ],
   "source": [
    "!grep assistance enronemail_1h.txt|cut -d$'\\t' -f4| grep assistance|wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW1.2.1 \n",
    "\n",
    "Using Hadoop MapReduce (or MRJob) and your wordcount job (from HW1.2) determine the top-10 occurring tokens (most frequent tokens) using a single reducer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The below code will read in data from enronemail_1h.txt, create a text file called hw121.txt in the format of (word, wordfrequency).  This is an intermediate step in the solution of printing the top-10 occurring tokens.  The file WordCountHW12 has a single reducer and is provided above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from WordCountHW12 import MRJobWordCount \n",
    "     \n",
    "inputData = 'enronemail_1h.txt'\n",
    "\n",
    "mr_job = MRJobWordCount(args=[inputData])\n",
    "results={}\n",
    "with mr_job.make_runner() as runner: \n",
    "    runner.run()\n",
    "\n",
    "    for line in runner.stream_output():\n",
    "        key,value =  mr_job.parse_output_line(line)\n",
    "        results[key] = value            \n",
    "\n",
    "    with open('hw121.txt', 'w') as f:\n",
    "        for k in results.keys():\n",
    "            f.writelines( k + \"\\t\"+ str(results[k]) +\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW1.2.1 \n",
    "\n",
    "Using Hadoop MapReduce (or MRJob) and your wordcount job (from HW1.2) determine the top-10 occurring tokens (most frequent tokens) using a single reducer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now that the hw121.txt file has been created and contains the data from enronemail_1h.txt in the (word, wordfrequency) format, the below will read the file back into Python as a dictionary, sort the dictionary by descending wordfrequency, and print the top 10 most frequently occurring words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'to', 'and', 'of', 'you', 'in', 'your', 'ect', 'for', 'on']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prevresults = {}\n",
    "resultdict = [s.split('\\n')[0].split('\\t') for s in open(\"hw121.txt\").readlines()]\n",
    "for word, count in resultdict:\n",
    "    prevresults[word] =  map(int, count.split(\",\"))\n",
    "sorted(prevresults, key=prevresults.get, reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### If the desire was to have both word and frequency..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', [1247]),\n",
       " ('to', [964]),\n",
       " ('and', [670]),\n",
       " ('of', [566]),\n",
       " ('you', [445]),\n",
       " ('in', [418]),\n",
       " ('your', [395]),\n",
       " ('ect', [382]),\n",
       " ('for', [374]),\n",
       " ('on', [271])]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "prevresultscounts = {}\n",
    "resultdict = [s.split('\\n')[0].split('\\t') for s in open(\"hw121.txt\").readlines()]\n",
    "for word, statsStr in resultdict:\n",
    "    prevresultscounts[word] =  map(int, statsStr.split(\",\"))\n",
    "\n",
    "Counter(prevresultscounts).most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW1.3: Multinomial NAIVE BAYES with NO Smoothing using a single reducer\n",
    "\n",
    "Using the Enron data from HW1 and Hadoop MapReduce (or MRJob), write  a mapper/reducer job(s) that\n",
    "   will both learn  Naive Bayes classifier and classify the Enron email messages using the learnt Naive Bayes classifier. Use all white-space delimitted tokens as independent input variables (assume spaces, fullstops, commas as delimiters). Note: for multinomial Naive Bayes, the Pr(X=“assistance”|Y=SPAM) is calculated as follows:\n",
    "\n",
    "   the number of times “assistance” occurs in SPAM labeled documents / the number of words in documents labeled SPAM \n",
    "\n",
    "   E.g.,   “assistance” occurs 5 times in all of the documents Labeled SPAM, and the length in terms of the number of words in all documents labeled as SPAM (when concatenated) is 1,000. Then Pr(X=“assistance”|Y=SPAM) = 5/1000. Note this is a multinomial estimation of the class conditional for a Naive Bayes Classifier. No smoothing is needed in this HW. Multiplying lots of probabilities, which are between 0 and 1, can result in floating-point underflow. Since log(xy) = log(x) + log(y), it is better to perform all computations by summing logs of probabilities rather than multiplying probabilities. Please pay attention to probabilites that are zero! They will need special attention. Count up how many times you need to process a zero probabilty for each class and report. \n",
    "\n",
    "   Report the performance of your learnt classifier in terms of misclassifcation error rate of your multinomial Naive Bayes Classifier. Plot a histogram of the  posterior probabilities (i.e., Pr(Class|Doc)) for each class over the training set. Summarize what you see. \n",
    "\n",
    "   Error Rate = misclassification rate with respect to a provided set (say training set in this case). It is more formally defined here:\n",
    "\n",
    "Let DF represent the evalution set in the following:\n",
    "Err(Model, DF) = |{(X, c(X)) ∈ DF : c(X) != Model(x)}|   / |DF|\n",
    "\n",
    "Where || denotes set cardinality; c(X) denotes the class of the tuple X in DF; and Model(X) denotes the class inferred by the Model “Model”\n",
    "\n",
    "NOTE: please assume one reducer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting NaiveBayesTrainerHW1.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile NaiveBayesTrainerHW1.py\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    " \n",
    "from collections import defaultdict\n",
    " \n",
    "from mrjob.job import MRJob\n",
    "from mrjob.job import MRStep\n",
    "\n",
    "import re, string\n",
    "\n",
    "line_counts = dict()\n",
    "word_counts = dict()\n",
    "\n",
    "class NaiveBayesTrainer(MRJob):\n",
    " \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(NaiveBayesTrainer, self).__init__(*args, **kwargs)\n",
    "        \n",
    "    def jobconf(self):\n",
    "        orig_jobconf = super(NaiveBayesTrainer, self).jobconf()        \n",
    "        custom_jobconf = {\n",
    "            'mapred.reduce.tasks': '1',\n",
    "        }\n",
    "        combined_jobconf = orig_jobconf\n",
    "        combined_jobconf.update(custom_jobconf)\n",
    "        self.jobconf = combined_jobconf\n",
    "        return combined_jobconf\n",
    "    \n",
    "     \n",
    "    def configure_options(self):\n",
    "        super(NaiveBayesTrainer, self).configure_options()\n",
    "        self.add_passthrough_option(\n",
    "            '--smoothmethod', default='nosmooth', choices=['nosmooth', 'laplace', 'jelinekmercer']\n",
    "        )\n",
    "        \n",
    "        self.add_passthrough_option(\n",
    "            '--jmlambda', default=0.3, dest='jmlambda', type='float'\n",
    "        )\n",
    "        \n",
    "    def steps(self):\n",
    "        out = [\n",
    "            MRStep(\n",
    "                mapper = self.mapper,\n",
    "                combiner = self.combiner,\n",
    "                reducer = self.reducer_pre\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        if self.options.smoothmethod == 'laplace': \n",
    "            out.append(MRStep(\n",
    "                reducer = self.reducer_laplace\n",
    "            ))\n",
    "        \n",
    "        elif self.options.smoothmethod == 'jelinekmercer':\n",
    "            out.append(MRStep(\n",
    "                reducer = self.reducer_jelinekmercer\n",
    "            ))\n",
    "            \n",
    "        else:\n",
    "            out.append(MRStep(\n",
    "                reducer = self.reducer_nosmooth\n",
    "            ))\n",
    "        \n",
    "        return out\n",
    " \n",
    "    def mapper(self, _, line):\n",
    "        regex = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "        _, classifier, token = line.strip().split('\\t', 2)\n",
    "        token = regex.sub(' ', token.lower())\n",
    "        token = re.sub( '\\s+', ' ', token )\n",
    "        words = token.split()\n",
    "        yield (('line', classifier), 1)\n",
    " \n",
    "        for word in set(words):                \n",
    "            yield ((word, classifier), words.count(word))\n",
    "            yield (('word', classifier), words.count(word))\n",
    " \n",
    " \n",
    "    def combiner(self, word_classifier, counts):\n",
    "        yield (word_classifier, sum(counts))\n",
    " \n",
    "    def reducer_pre(self, word_classifier, counts):\n",
    "        total_count = sum(counts)\n",
    "        word, classifier = word_classifier\n",
    "\n",
    "        if word == 'word':\n",
    "            if classifier not in word_counts:\n",
    "                word_counts[classifier] = 0\n",
    "                \n",
    "            word_counts[classifier] += total_count\n",
    "            return\n",
    "\n",
    "        if word == 'line':\n",
    "            line_counts[classifier] = total_count\n",
    "            word = 'PriorProb'\n",
    "\n",
    "        if classifier not in word_counts:\n",
    "            word_counts[classifier] = 0\n",
    "            word_counts[classifier] -= total_count\n",
    "        else:\n",
    "            yield (word, {classifier: total_count})\n",
    "            \n",
    "    def reducer_nosmooth(self, word, classified_counts):\n",
    "        combined = defaultdict(lambda: 0)\n",
    "\n",
    "        for entry in classified_counts:\n",
    "            for classifier, count in entry.items():\n",
    "                combined[classifier] += count\n",
    "\n",
    "        for classifier in line_counts.keys():\n",
    "            count = combined.get(classifier, 0)\n",
    " \n",
    "            if word == 'PriorProb':\n",
    "                probability = count / sum(line_counts.values())\n",
    "            else:\n",
    "                probability = count / word_counts[classifier]\n",
    " \n",
    "            yield (word, classifier), probability\n",
    "    \n",
    "    def reducer_laplace(self, word, classified_counts):\n",
    "        combined = defaultdict(lambda: 0)\n",
    "        for entry in classified_counts:\n",
    "            for classifier, count in entry.items():\n",
    "                combined[classifier] += count\n",
    " \n",
    "        for classifier in line_counts.keys():\n",
    "            count = combined.get(classifier, 0)\n",
    " \n",
    "            if word == 'PriorProb':\n",
    "                probability = count / sum(line_counts.values())\n",
    "            else:\n",
    "                probability = (count + 1) / (word_counts[classifier]+ 1)\n",
    " \n",
    "            yield (word, classifier), probability\n",
    "    \n",
    "    def reducer_jelinekmercer(self, word, classified_counts):\n",
    "        combined = defaultdict(lambda: 0)\n",
    "        \n",
    "        for entry in classified_counts:\n",
    "            for classifier, count in entry.items():\n",
    "                combined[classifier] += count\n",
    " \n",
    "        for classifier in line_counts.keys():\n",
    "            count = combined.get(classifier, 0)\n",
    "\n",
    "        for classifier in line_counts.keys():\n",
    "            count = combined.get(classifier, 0)\n",
    "            jmlambda = self.options.jmlambda\n",
    "        \n",
    "            if word == 'PriorProb':\n",
    "                probability = count / sum(line_counts.values())\n",
    "            else:\n",
    "                probability = (\n",
    "                    (1 - jmlambda) * (count / word_counts[classifier]) +\n",
    "                    (jmlambda * sum(combined.values()) / sum(word_counts.values()))\n",
    "                )\n",
    "                \n",
    "            yield (word, classifier), probability \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    NaiveBayesTrainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import NaiveBayesTrainerHW1 as nbTrainer \n",
    "\n",
    "def model(trainer, modelfile, smoothing_type='none', jmlambda=0.3):\n",
    "    nbTrainer.word_counts = dict()\n",
    "    nbTrainer.line_counts = dict()\n",
    "    mr_job = nbTrainer.NaiveBayesTrainer(\n",
    "        args=[\n",
    "            trainer,\n",
    "            '--smoothmethod={}'.format(smoothing_type),\n",
    "            '--jmlambda={}'.format(jmlambda)\n",
    "        ]\n",
    "    )\n",
    "    modelStats = dict()\n",
    "    \n",
    "    with mr_job.make_runner() as runner: \n",
    "        runner.run()\n",
    "        \n",
    "        for line in runner.stream_output():\n",
    "            key, value =  mr_job.parse_output_line(line)\n",
    "            word = key[0]\n",
    "            classifier = int(key[1])\n",
    "\n",
    "            if word not in modelStats:\n",
    "                probs = ['0', '0']\n",
    "                probs[classifier] = str(value)\n",
    "                modelStats[word] = probs                        \n",
    "            else:\n",
    "                modelStats[word][classifier] = str(value)\n",
    "\n",
    "        # Store model locally\n",
    "        with open(modelfile, 'w') as f:\n",
    "            for word, probs in modelStats.items():\n",
    "                f.writelines(word + \"\\t\" + \"\\t\".join(probs) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model(    \n",
    "    trainer='enronemail_1h.txt',\n",
    "    smoothing_type='nosmooth',\n",
    "    modelfile='enron_model_unsmoothed.txt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting NaiveBayesClassifierHW13.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile NaiveBayesClassifierHW13.py\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "import os, re, string, math\n",
    "\n",
    "counts = []\n",
    "\n",
    "class NaiveBayesClassifier(MRJob):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(NaiveBayesClassifier, self).__init__(*args, **kwargs)\n",
    "        \n",
    "    def steps(self):\n",
    "        return [\n",
    "            MRStep(\n",
    "                mapper_init=self.mapper_init, \n",
    "                mapper=self.mapper,\n",
    "                combiner=self.combiner,\n",
    "                reducer=self.reducer  \n",
    "            ),\n",
    "            MRStep(reducer=self.reducer_final)\n",
    "        ]\n",
    "\n",
    "    def configure_options(self):\n",
    "        super(NaiveBayesClassifier, self).configure_options()\n",
    "        \n",
    "        self.add_file_option('--model')\n",
    "        \n",
    "    def mapper_init(self): \n",
    "        self.model_stats = {}\n",
    "\n",
    "        with open(self.options.model, \"r\") as f:\n",
    "            lines = f.read().split('\\n')\n",
    "        \n",
    "        split_lines = [line.split('\\t') for line in lines]\n",
    "        \n",
    "        for entry in split_lines:\n",
    "            word = entry[0]\n",
    "            probs = [float(p) for p in entry[1:]]\n",
    "            self.model_stats[word] = probs\n",
    "    \n",
    "    def mapper(self, _, line):\n",
    "        regex = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "        _, classifier, token = line.strip().split('\\t', 2)\n",
    "        token = regex.sub(' ', token.lower())\n",
    "        token = re.sub( '\\s+', ' ', token )\n",
    "\n",
    "        p0 = math.log10(self.model_stats['PriorProb'][0])\n",
    "        p1 = math.log10(self.model_stats['PriorProb'][1])\n",
    "        \n",
    "        for word in token.split():\n",
    "\n",
    "            probs = self.model_stats.get(word, [0, 0]) \n",
    "            probs = [p if p > 0 else 1 for p in probs] \n",
    "           \n",
    "            p0 += math.log10(probs[0])\n",
    "            p1 += math.log10(probs[1])\n",
    "\n",
    "        if p0 > p1:\n",
    "            prediction = 0\n",
    "        elif p1 > p0:\n",
    "            prediction = 1\n",
    "        else:\n",
    "            prediction = -1 \n",
    "\n",
    "        if prediction == int(classifier):\n",
    "            key = 'correct'\n",
    "        else:\n",
    "            key = 'incorrect'\n",
    "            \n",
    "        yield (key, 1)\n",
    "\n",
    "    def combiner(self, key, values):\n",
    "        yield (key, sum(values))\n",
    "        \n",
    "    def reducer(self, key, values):\n",
    "        values = list(values)\n",
    "        count = sum(values)\n",
    "        counts.append(count)\n",
    "        yield (key, count)\n",
    "      \n",
    "    def reducer_final(self, key, values):\n",
    "        values = list(values)\n",
    "\n",
    "        rate = sum(values) / sum(counts)\n",
    "        output = 'Inaccuracy Rate' if key == 'incorrect' else 'Accuracy Rate'\n",
    "        \n",
    "        yield (output, rate)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    NaiveBayesClassifier.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import NaiveBayesClassifierHW13 as nbClassifier\n",
    "\n",
    "\n",
    "def classify(smoothtype, valer, modelfile):\n",
    "    model_path = os.path.join(\n",
    "        os.path.abspath(os.path.curdir), \n",
    "        modelfile\n",
    "    )\n",
    "    nbClassifier.counts = []\n",
    "    mr_job = nbClassifier.NaiveBayesClassifier(\n",
    "        args=[\n",
    "            valer,\n",
    "            '--model={}'.format(modelfile)\n",
    "        ]\n",
    "    )\n",
    "    out = {'Smooth Method': smoothtype, 'Inaccuracy Rate': 0, 'Accuracy Rate': 0}\n",
    "    \n",
    "    with mr_job.make_runner() as runner: \n",
    "        runner.run()\n",
    "        for line in runner.stream_output():\n",
    "            key, value =  mr_job.parse_output_line(line)\n",
    "            out[key] = value\n",
    "                \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy Rate': 0, 'Inaccuracy Rate': 1.0, 'Smooth Method': 'Unsmoothed'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify('Unsmoothed', 'enronemail_1h.txt', 'enron_model_unsmoothed.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW1.4:  Multinomial Naive Bayes with Smoothing \n",
    "\n",
    "### HW1.4.0: Repeat HW1.3 with the following modification: use Laplace plus-one smoothing. Compare the misclassifcation error rates for HW1.3 versus HW1.4 and explain the differences.\n",
    "\n",
    "For a quick reference on the construction of the Multinomial NAIVE BAYES classifier that you will code,\n",
    "please consult the \"Document Classification\" section of the following wikipedia page:\n",
    "\n",
    "https://en.wikipedia.org/wiki/Naive_Bayes_classifier#Document_classification\n",
    "\n",
    "OR the original paper by the curators of the Enron email data:\n",
    "\n",
    "http://www.aueb.gr/users/ion/docs/ceas2006_paper.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model(    \n",
    "    trainer='enron_trainer.txt',\n",
    "    smoothing_type='laplace',\n",
    "    modelfile='enron_model_laplace.txt'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _You can see a huge improvement in adding the Laplace smoothing to the Naive Bayes algorithm.  One major reason for why is that the Laplace smoother eliminates nonzero probabilities, so multiplication is less impactful.  As you can see, the accuracy rate for Laplace is 96%, while the accuracy rate for the Unsmoothed method is 0%.  This is a huge increase with minimal additional work._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy Rate': 0.96, 'Inaccuracy Rate': 0.04, 'Smooth Method': 'Laplace'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify('Laplace', 'enronemail_1h.txt', 'enron_model_laplace.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy Rate': 0, 'Inaccuracy Rate': 1.0, 'Smooth Method': 'Unsmoothed'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify('Unsmoothed', 'enronemail_1h.txt', 'enron_model_unsmoothed.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW 1.4.1 Jelinek-Mercer (JM) smoothing* \n",
    "\n",
    "HW 1.4.1 Jelinek-Mercer (JM) smoothing* \n",
    "\n",
    "With different smoothing methods, p(wk|ci) (i.e., the word class conditionals) will be computed\n",
    "differently. We consider Jelinek-Mercer (JM) smoothing as an alternative to Laplace  Let c(w, ci) denote\n",
    "the frequency of word w in category ci,  p(w|C) be the maximum likelihood estimation of word w in \n",
    "collection C (relative frequency) and let |C for classi| denote the length of the classi. Then:\n",
    "\n",
    "1) Jelinek-Mercer (JM) smoothing:\n",
    "\n",
    "λp(w|ci) = (1 − λ) * c(w, ci)/sum_over_wJ_in_V(c(wJ, ci))    +  λ p(w|C)\n",
    "\n",
    "Where c(w, ci)/sum_over_wJ_in_V(c(wJ, ci)) essential denotes the relative frequency of word w in class ci, i.e., Pr(w|ci)\n",
    "and one can set λ = 0.3  by default. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model(    \n",
    "    trainer='enron_trainer.txt',\n",
    "    smoothing_type='jelinekmercer',\n",
    "    modelfile='enron_model_jm.txt',\n",
    "    jmlambda=.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy Rate': 0.97,\n",
       " 'Inaccuracy Rate': 0.03,\n",
       " 'Smooth Method': 'jm lambda=.3'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify('jm lambda=.3', 'enronemail_1h.txt', 'enron_model_jm.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW1.4.2 Split data in to training, validation and testing data subsets\n",
    "\n",
    "Split the data using MRJob into three subsets in the following proportions (70% for training, 15% for valdiation, and 15% for testing). Train Multinomial Naive Bayes classifiers using Laplace plus-one smoothing and using  Jelinek-Mercer (JM) smoothing where you consider different hyperparameter values for λ. Please consider λ in {0.0, 0.1, 0.3, 0.5, 0.7, 1}. Present  a table compare the  results of the different approaches: each  row is the approach taken (e.g., Multinomial Naive Bayes with Laplace+1, or Multinomial Naive Bayes with  with JM= 0.3 for λ =0.3) and a column for  error rate on the training, validation and test data sets. Present a graph also (in python) consisting of three curves (where the x-axis represents the approach taken and the y-axis represents the error rate). Dont forget to put a good title on your graph!\n",
    "\n",
    "Looking the validation curve select the best model. How does it perform on the unseen test set? Comment.\n",
    "\n",
    "\n",
    "* REFERENCES \n",
    "   + http://www.ntu.edu.sg/home/gaocong/papers/wpp095-yuan.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "with open(\"enronemail_1h.txt\", \"r\") as f:\n",
    "    fullfile = f.read().split('\\n')\n",
    "\n",
    "linecount = len(fullfile)\n",
    "linecount_70pct = int(.7*linecount)\n",
    "linecount_85pct = int(.85*linecount)\n",
    "\n",
    "\n",
    "trainer_data = fullfile[:linecount_70pct]\n",
    "validation_data = fullfile[linecount_70pct:linecount_85pct]\n",
    "tester_data = fullfile[linecount_85pct:]\n",
    "\n",
    "with open(\"enron_trainer.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(trainer_data))\n",
    "with open(\"enron_valer.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(validation_data))\n",
    "with open(\"enron_tester.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(tester_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "testing_filename = 'enron_tester.txt'\n",
    "validation_filename = 'enron_valer.txt'\n",
    "model_filename = 'enron_model_trial.txt'\n",
    "results = []\n",
    "\n",
    "def modelcompare(smoothtype, smoothing_type, jmlambda=0.3):\n",
    "\n",
    "    model(    \n",
    "        trainer='enron_trainer.txt',\n",
    "        smoothing_type=smoothing_type,\n",
    "        modelfile=model_filename,\n",
    "        jmlambda=jmlambda\n",
    "    )\n",
    "    \n",
    "    out = {'name': smoothtype}\n",
    "    \n",
    "    results = classify(smoothtype, testing_filename, model_filename)\n",
    "    out['error_train'] = results['Inaccuracy Rate']\n",
    "    \n",
    "    results = classify(smoothtype, testing_filename, model_filename)\n",
    "    out['error_test'] = results['Inaccuracy Rate']\n",
    "    \n",
    "    results = classify(smoothtype, validation_filename, model_filename)\n",
    "    out['error_validate'] = results['Inaccuracy Rate']\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   error_test  error_train  error_validate                         name\n",
      "0    0.800000     0.800000        0.866667                   Unsmoothed\n",
      "1    0.200000     0.200000        0.066667                      LaPlace\n",
      "2    0.800000     0.800000        0.866667  Jelinek-Mercer lambda = 0.0\n",
      "3    0.133333     0.133333        0.000000  Jelinek-Mercer lambda = 0.1\n",
      "4    0.200000     0.200000        0.000000  Jelinek-Mercer lambda = 0.3\n",
      "5    0.200000     0.200000        0.066667  Jelinek-Mercer lambda = 0.5\n",
      "6    0.200000     0.200000        0.066667  Jelinek-Mercer lambda = 0.7\n",
      "7    0.600000     0.600000        0.466667  Jelinek-Mercer lambda = 1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results.append(modelcompare('Unsmoothed', 'nosmooth'))\n",
    "results.append(modelcompare('LaPlace', 'laplace'))\n",
    "results.append(modelcompare('Jelinek-Mercer lambda = 0.0', 'jelinekmercer', jmlambda=0.0))\n",
    "results.append(modelcompare('Jelinek-Mercer lambda = 0.1', 'jelinekmercer', jmlambda=0.1))\n",
    "results.append(modelcompare('Jelinek-Mercer lambda = 0.3', 'jelinekmercer', jmlambda=0.3))\n",
    "results.append(modelcompare('Jelinek-Mercer lambda = 0.5', 'jelinekmercer', jmlambda=0.5))\n",
    "results.append(modelcompare('Jelinek-Mercer lambda = 0.7', 'jelinekmercer', jmlambda=0.7))\n",
    "results.append(modelcompare('Jelinek-Mercer lambda = 1.0', 'jelinekmercer', jmlambda=1.0))\n",
    "\n",
    "resultsout = pandas.DataFrame(results)\n",
    "print resultsout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x1151b5290>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAGlCAYAAAACrXq3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x113fd9d50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import pyplot\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "indices = 10 * resultsout.index\n",
    "\n",
    "fig = pyplot.figure()\n",
    "ax = pyplot.subplot(111)\n",
    "\n",
    "x = ax.scatter(indices, resultsout.error_test,color='y', marker = '*', s=100)\n",
    "y = ax.scatter(indices, resultsout.error_validate,color='r', marker = '.', s=100)\n",
    "z = ax.scatter(indices, resultsout.error_train,color='b', marker='+', s=100)\n",
    "pyplot.xticks(indices, resultsout.name, rotation=90)\n",
    "pyplot.ylabel('Error Rate')\n",
    "pyplot.xlabel('Smoothing Method')\n",
    "pyplot.title('Error Rate vs NaiveBayes Smoothing Method')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Based on the graph above, when given the validation data set, the Jelinek-Mercer lambda = .1 or lambda = .3 work equally as well (this is confirmed by looking at the data table).  When applied to the unseen test set, the lamdba = .1 worked the best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW1.5: Remove words with frequency of less than three (3) in the training set\n",
    "\n",
    "Repeat HW1.4. This time when modeling and classification ignore tokens with a frequency of less than three (3) in the training set. How does it affect the misclassifcation error of learnt naive multinomial Bayesian Classifier on the training dataset. Report the error and the change in error. HINT: ignore tokens with a frequency of less than three (3). Think of this as a preprocessing step. How many new mapreduce jobs do you need to solve thus homework? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting NaiveBayesTrainerLess3HW1.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile NaiveBayesTrainerLess3HW1.py\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    " \n",
    "from collections import defaultdict\n",
    " \n",
    "from mrjob.job import MRJob\n",
    "from mrjob.job import MRStep\n",
    "\n",
    "import re, string\n",
    "\n",
    "line_counts = dict()\n",
    "word_counts = dict()\n",
    "\n",
    "class NaiveBayesTrainerLess3(MRJob):\n",
    " \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(NaiveBayesTrainerLess3, self).__init__(*args, **kwargs)\n",
    "        \n",
    "    def jobconf(self):\n",
    "        orig_jobconf = super(NaiveBayesTrainerLess3, self).jobconf()        \n",
    "        custom_jobconf = {\n",
    "            'mapred.reduce.tasks': '1',\n",
    "        }\n",
    "        combined_jobconf = orig_jobconf\n",
    "        combined_jobconf.update(custom_jobconf)\n",
    "        self.jobconf = combined_jobconf\n",
    "        return combined_jobconf\n",
    "    \n",
    "     \n",
    "    def configure_options(self):\n",
    "        super(NaiveBayesTrainerLess3, self).configure_options()\n",
    "        self.add_passthrough_option(\n",
    "            '--smoothmethod', default='nosmooth', choices=['nosmooth', 'laplace', 'jelinekmercer']\n",
    "        )\n",
    "        \n",
    "        self.add_passthrough_option(\n",
    "            '--jmlambda', default=0.3, dest='jmlambda', type='float'\n",
    "        )\n",
    "        \n",
    "    def steps(self):\n",
    "        out = [\n",
    "            MRStep(\n",
    "                mapper = self.mapper,\n",
    "                combiner = self.combiner,\n",
    "                reducer = self.reducer_pre\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        if self.options.smoothmethod == 'laplace': \n",
    "            out.append(MRStep(\n",
    "                reducer = self.reducer_laplace\n",
    "            ))\n",
    "        \n",
    "        elif self.options.smoothmethod == 'jelinekmercer':\n",
    "            out.append(MRStep(\n",
    "                reducer = self.reducer_jelinekmercer\n",
    "            ))\n",
    "            \n",
    "        else:\n",
    "            out.append(MRStep(\n",
    "                reducer = self.reducer_nosmooth\n",
    "            ))\n",
    "        \n",
    "        return out\n",
    " \n",
    "    def mapper(self, _, line):\n",
    "        regex = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "        _, classifier, token = line.strip().split('\\t', 2)\n",
    "        token = regex.sub(' ', token.lower())\n",
    "        token = re.sub( '\\s+', ' ', token )\n",
    "        words = token.split()\n",
    "        yield (('line', classifier), 1)\n",
    " \n",
    "        for word in set(words):                \n",
    "            yield ((word, classifier), words.count(word))\n",
    "            yield (('word', classifier), words.count(word))\n",
    " \n",
    " \n",
    "    def combiner(self, word_classifier, counts):\n",
    "        yield (word_classifier, sum(counts))\n",
    " \n",
    "    def reducer_pre(self, word_classifier, counts):\n",
    "        total_count = sum(counts)\n",
    "        word, classifier = word_classifier\n",
    "\n",
    "        if word == 'word':\n",
    "            if classifier not in word_counts:\n",
    "                word_counts[classifier] = 0\n",
    "                \n",
    "            word_counts[classifier] += total_count\n",
    "            return\n",
    "\n",
    "        if word == 'line':\n",
    "            line_counts[classifier] = total_count\n",
    "            word = 'PriorProb'\n",
    "\n",
    "        if total_count <= 3:\n",
    "\n",
    "            if classifier not in word_counts:\n",
    "                word_counts[classifier] = 0\n",
    "            word_counts[classifier] -= total_count\n",
    "        else:\n",
    "            yield (word, {classifier: total_count})\n",
    "            \n",
    "    def reducer_nosmooth(self, word, classified_counts):\n",
    "        combined = defaultdict(lambda: 0)\n",
    "\n",
    "        for entry in classified_counts:\n",
    "            for classifier, count in entry.items():\n",
    "                combined[classifier] += count\n",
    "\n",
    "        for classifier in line_counts.keys():\n",
    "            count = combined.get(classifier, 0)\n",
    " \n",
    "            if word == 'PriorProb':\n",
    "                probability = count / sum(line_counts.values())\n",
    "            else:\n",
    "                probability = count / word_counts[classifier]\n",
    " \n",
    "            yield (word, classifier), probability\n",
    "    \n",
    "    def reducer_laplace(self, word, classified_counts):\n",
    "        combined = defaultdict(lambda: 0)\n",
    "        for entry in classified_counts:\n",
    "            for classifier, count in entry.items():\n",
    "                combined[classifier] += count\n",
    " \n",
    "        for classifier in line_counts.keys():\n",
    "            count = combined.get(classifier, 0)\n",
    " \n",
    "            if word == 'PriorProb':\n",
    "                probability = count / sum(line_counts.values())\n",
    "            else:\n",
    "                probability = (count + 1) / (word_counts[classifier]+ 1)\n",
    " \n",
    "            yield (word, classifier), probability\n",
    "    \n",
    "    def reducer_jelinekmercer(self, word, classified_counts):\n",
    "        combined = defaultdict(lambda: 0)\n",
    "        \n",
    "        for entry in classified_counts:\n",
    "            for classifier, count in entry.items():\n",
    "                combined[classifier] += count\n",
    " \n",
    "        for classifier in line_counts.keys():\n",
    "            count = combined.get(classifier, 0)\n",
    "\n",
    "        for classifier in line_counts.keys():\n",
    "            count = combined.get(classifier, 0)\n",
    "            jmlambda = self.options.jmlambda\n",
    "        \n",
    "            if word == 'PriorProb':\n",
    "                probability = count / sum(line_counts.values())\n",
    "            else:\n",
    "                probability = (\n",
    "                    (1 - jmlambda) * (count / word_counts[classifier]) +\n",
    "                    (jmlambda * sum(combined.values()) / sum(word_counts.values()))\n",
    "                )\n",
    "                \n",
    "            yield (word, classifier), probability \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    NaiveBayesTrainerLess3.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import NaiveBayesTrainerLess3HW1 as nbTrainerL3 \n",
    "\n",
    "def model(trainer, modelfile, smoothing_type='none', jmlambda=0.3):\n",
    "    nbTrainerL3.word_counts = dict()\n",
    "    nbTrainerL3.line_counts = dict()\n",
    "    mr_job = nbTrainerL3.NaiveBayesTrainerLess3(\n",
    "        args=[\n",
    "            trainer,\n",
    "            '--smoothmethod={}'.format(smoothing_type),\n",
    "            '--jmlambda={}'.format(jmlambda)\n",
    "        ]\n",
    "    )\n",
    "    modelStats = dict()\n",
    "    \n",
    "    with mr_job.make_runner() as runner: \n",
    "        runner.run()\n",
    "        \n",
    "        for line in runner.stream_output():\n",
    "            key, value =  mr_job.parse_output_line(line)\n",
    "            word = key[0]\n",
    "            classifier = int(key[1])\n",
    "\n",
    "            if word not in modelStats:\n",
    "                probs = ['0', '0']\n",
    "                probs[classifier] = str(value)\n",
    "                modelStats[word] = probs                        \n",
    "            else:\n",
    "                modelStats[word][classifier] = str(value)\n",
    "\n",
    "        # Store model locally\n",
    "        with open(modelfile, 'w') as f:\n",
    "            for word, probs in modelStats.items():\n",
    "                f.writelines(word + \"\\t\" + \"\\t\".join(probs) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model(    \n",
    "    trainer='enronemail_1h.txt',\n",
    "    smoothing_type='nosmooth',\n",
    "    modelfile='enron_model_unsmoothed.txt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting NaiveBayesClassifierLess3HW1.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile NaiveBayesClassifierLess3HW1.py\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "import os, re, string, math\n",
    "\n",
    "counts = []\n",
    "\n",
    "class NaiveBayesClassifierL3(MRJob):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(NaiveBayesClassifierL3, self).__init__(*args, **kwargs)\n",
    "        \n",
    "    def steps(self):\n",
    "        return [\n",
    "            MRStep(\n",
    "                mapper_init=self.mapper_init, \n",
    "                mapper=self.mapper,\n",
    "                combiner=self.combiner,\n",
    "                reducer=self.reducer  \n",
    "            ),\n",
    "            MRStep(reducer=self.reducer_final)\n",
    "        ]\n",
    "\n",
    "    def configure_options(self):\n",
    "        super(NaiveBayesClassifierL3, self).configure_options()\n",
    "        \n",
    "        self.add_file_option('--model')\n",
    "        \n",
    "    def mapper_init(self): \n",
    "        self.model_stats = {}\n",
    "\n",
    "        with open(self.options.model, \"r\") as f:\n",
    "            lines = f.read().split('\\n')\n",
    "        \n",
    "        split_lines = [line.split('\\t') for line in lines]\n",
    "        \n",
    "        for entry in split_lines:\n",
    "            word = entry[0]\n",
    "            probs = [float(p) for p in entry[1:]]\n",
    "            self.model_stats[word] = probs\n",
    "    \n",
    "    def mapper(self, _, line):\n",
    "        regex = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "        _, classifier, token = line.strip().split('\\t', 2)\n",
    "        token = regex.sub(' ', token.lower())\n",
    "        token = re.sub( '\\s+', ' ', token )\n",
    "\n",
    "        p0 = math.log10(self.model_stats['PriorProb'][0])\n",
    "        p1 = math.log10(self.model_stats['PriorProb'][1])\n",
    "        \n",
    "        for word in token.split():\n",
    "\n",
    "            probs = self.model_stats.get(word, [0, 0]) \n",
    "            probs = [p if p > 0 else 1 for p in probs] \n",
    "           \n",
    "            p0 += math.log10(probs[0])\n",
    "            p1 += math.log10(probs[1])\n",
    "\n",
    "        if p0 > p1:\n",
    "            prediction = 0\n",
    "        elif p1 > p0:\n",
    "            prediction = 1\n",
    "        else:\n",
    "            prediction = -1 \n",
    "\n",
    "        if prediction == int(classifier):\n",
    "            key = 'correct'\n",
    "        else:\n",
    "            key = 'incorrect'\n",
    "            \n",
    "        yield (key, 1)\n",
    "\n",
    "    def combiner(self, key, values):\n",
    "        yield (key, sum(values))\n",
    "        \n",
    "    def reducer(self, key, values):\n",
    "        values = list(values)\n",
    "        count = sum(values)\n",
    "        counts.append(count)\n",
    "        yield (key, count)\n",
    "      \n",
    "    def reducer_final(self, key, values):\n",
    "        values = list(values)\n",
    "\n",
    "        rate = sum(values) / sum(counts)\n",
    "        output = 'Inaccuracy Rate' if key == 'incorrect' else 'Accuracy Rate'\n",
    "        \n",
    "        yield (output, rate)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    NaiveBayesClassifierL3.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import NaiveBayesClassifierLess3HW1 as nbClassifier\n",
    "\n",
    "\n",
    "def classifyL3(smoothtype, valer, modelfile):\n",
    "    model_path = os.path.join(\n",
    "        os.path.abspath(os.path.curdir), \n",
    "        modelfile\n",
    "    )\n",
    "    nbClassifier.counts = []\n",
    "    mr_job = nbClassifier.NaiveBayesClassifierL3(\n",
    "        args=[\n",
    "            valer,\n",
    "            '--model={}'.format(modelfile)\n",
    "        ]\n",
    "    )\n",
    "    out = {'Smooth Method': smoothtype, 'Inaccuracy Rate': 0, 'Accuracy Rate': 0}\n",
    "    \n",
    "    with mr_job.make_runner() as runner: \n",
    "        runner.run()\n",
    "        for line in runner.stream_output():\n",
    "            key, value =  mr_job.parse_output_line(line)\n",
    "            out[key] = value\n",
    "                \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   error_change_train  error_train_all  error_train_less3freq             name\n",
      "0                 0.0         0.733333               0.733333       Unsmoothed\n",
      "1                 0.0         0.200000               0.200000          LaPlace\n",
      "2                 0.0         0.733333               0.733333  JM lambda = 0.0\n",
      "3                 0.0         0.200000               0.200000  JM lambda = 0.1\n",
      "4                 0.0         0.200000               0.200000  JM lambda = 0.3\n",
      "5                 0.0         0.200000               0.200000  JM lambda = 0.5\n",
      "6                 0.0         0.200000               0.200000  JM lambda = 0.7\n",
      "7                 0.0         0.600000               0.600000  JM lambda = 1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "L3results.append(modelcompareL3('Unsmoothed', 'nosmooth'))\n",
    "L3results.append(modelcompareL3('LaPlace', 'laplace'))\n",
    "L3results.append(modelcompareL3('JM lambda = 0.0', 'jelinekmercer', jmlambda=0.0))\n",
    "L3results.append(modelcompareL3('JM lambda = 0.1', 'jelinekmercer', jmlambda=0.1))\n",
    "L3results.append(modelcompareL3('JM lambda = 0.3', 'jelinekmercer', jmlambda=0.3))\n",
    "L3results.append(modelcompareL3('JM lambda = 0.5', 'jelinekmercer', jmlambda=0.5))\n",
    "L3results.append(modelcompareL3('JM lambda = 0.7', 'jelinekmercer', jmlambda=0.7))\n",
    "L3results.append(modelcompareL3('JM lambda = 1.0', 'jelinekmercer', jmlambda=1.0))\n",
    "\n",
    "L3resultsout = pandas.DataFrame(L3results)\n",
    "print L3resultsout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the data above, I did not actualy see any change in performance on the trainer data set.  This was surprising."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# HW1.6 Benchmark your code with the Python SciKit-Learn implementation of the multinomial Naive Bayes algorithm\n",
    "\n",
    "## HW1.6.0: Multinomial Naive Bayes using SciKit-Learn\n",
    "\n",
    "It always a good idea to benchmark your solutions against publicly available libraries such as SciKit-Learn, The Machine Learning toolkit available in Python. In this exercise, we benchmark ourselves against the SciKit-Learn implementation of multinomial Naive Bayes.  For more information on this implementation see: http://scikit-learn.org/stable/modules/naive_bayes.html more  \n",
    "\n",
    "In this exercise, please complete the following:\n",
    "\n",
    "— Run the Multinomial Naive Bayes algorithm (using default settings) from SciKit-Learn over the same training data used in HW1.4.2 and report the misclassification error (please note some data preparation might be needed to get the Multinomial Naive Bayes algorithm from SkiKit-Learn to run over this dataset)\n",
    "- Prepare a table to present your results, where rows correspond to approach used (SkiKit-Learn versus your Hadoop implementation) and the column presents the  misclassification error rates (train, validation, testing)\n",
    "— Explain/justify any differences in terms of training error rates over the dataset in HW1.5 between your Multinomial Naive Bayes implementation (in Map Reduce) versus the Multinomial Naive Bayes implementation in SciKit-Learn \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SK- multinomial NB training error: 0.0000\n",
      "SK- Bernoulli   NB training error: 0.1571\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import *\n",
    "\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "with open('enron_trainer.txt', 'r') as f:\n",
    "    reader = csv.reader(f, delimiter=\"\\t\")\n",
    "    emails = list(reader)\n",
    "train_label = [msg[1] for msg in emails]\n",
    "train_data = [msg[2] + msg[3] if len(msg) == 4 else msg[2] for msg in emails]\n",
    "msg_id = [msg[0].lower() for msg in emails]\n",
    "# print(train_label, train_data, msg_id)\n",
    "\n",
    "# feature vectorization\n",
    "uniVectorizer = CountVectorizer()\n",
    "dtmTrain = uniVectorizer.fit_transform(train_data) \n",
    "# print(uniVectorizer, dtmTrain)\n",
    "\n",
    "# multinomial Naive Bayes Classifier from sklearn\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(dtmTrain, train_label)\n",
    "pred_mnb = mnb.predict(dtmTrain)\n",
    "training_error_mnb = 1.0 * sum(pred_mnb != train_label) / len(train_label)\n",
    "\n",
    "# Bernoulli Naive Bayes Classifier from sklearn\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(dtmTrain, train_label)\n",
    "pred_bnb = bnb.predict(dtmTrain)\n",
    "training_error_bnb = 1.0*sum(pred_bnb != train_label) / len(train_label)\n",
    "\n",
    "print 'SK- multinomial NB training error: %.4f' %training_error_mnb\n",
    "print 'SK- Bernoulli   NB training error: %.4f' %training_error_bnb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
