{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# <center> Scott Zuehlke Homework 1 </center>\n",
    "#### <center> This homework assignment was done in large partnership with Renee Murray, who was a significant help in the Python coding of the homework assignments.</center>\n",
    "\n",
    "## <center>  Written on a Mac, for a Mac </center>\n",
    "\n",
    "\n",
    "## HW1.0.0. \n",
    "### Define big data. Provide an example of a big data problem in your domain of expertise. \n",
    "\n",
    "#### _Big data is a generic term to represent data sets that are so large, or possibly so complex, that traditional methods of processing and analysis are inadequate.  While the cutoff of what represents \"big data\" is relative to a company and its technological capabilities, there is a tipping point where basic methods (SQL, for example) cannot process the large amounts of data in a sufficient amount of time.  The other side of that tipping point is what is referred to as \"big data.\"_\n",
    "\n",
    "#### _In my domain of retail and e-commerce, a perfect example of \"big data\" would be the data generated by our Target.com website.  A specific use case for this data is the Target.com Personalization Engine.  The Personalization Engine runs in a fraction of a second and pulls data from a Hadoop environment to create a \"people with similar purchase history have also bought...\" type recommendation.  The amount of data to process would take days with a traditional processing technique, but through Hadoop and Spark algorithms, millions of records can be processed almost instantaneously._\n",
    "\n",
    "\n",
    "### What is a race condition in the context of parallel computation? Give an example.\n",
    "\n",
    "#### _A race condition, in the context of parallel computation, is a situation where more than one process reaches the same variable, file, or data set concurrently and alters the final result._\n",
    "\n",
    "#### _A real world example would be a deposit/withdrawal at a bank.  If a customer has 10 dollars in their account on Monday, deposits 25 on Tuesday and tries to withdraw 20 on Wednesday, the withdrawal's success would depend on the deposit happeing BEFORE the withdrawal processes.  Below is some pseudocode to illustrate._\n",
    "```\n",
    "class BankAccount:\n",
    "    \n",
    "    def __init__(self, balance, deposit, withdraw):    \n",
    "        self.balance = balance\n",
    "        self.deposit = deposit\n",
    "        self.withdraw = withdraw\n",
    "    \n",
    "    def ProcessDeposit(balance, deposit):\n",
    "        new_balance = balance + deposit_amt\n",
    "        yield new_balance\n",
    "        \n",
    "        \n",
    "    def ProcessWithdrawal(balance, withdraw):\n",
    "        \n",
    "        if new_balance >= withdraw then:\n",
    "            new_balance = balance + deposit_amt\n",
    "            yield new_balance \n",
    "        else:\n",
    "            yield \"Withdrawal would cause overdraft.\"\n",
    "```\n",
    "            \n",
    "####  _Ideally, if a person were to start with an initial balance of 10 dollars, deposits 25 and then withdraws 20, the ending balance should be 10+25-20 = 15.  However, if the withdrawal were to post first, then balance would actually go negative, i.e. 10 - 20 + 25._ Mathematically, this would yield the same result of 15, but in the example above, since the new_balance would be less than the withdrawal, it would fail to post and yield outcome,\"Withdrawal would cause overdraft.\"_\n",
    "        \n",
    "\n",
    "\n",
    "## What is MapReduce?\n",
    "\n",
    "#### _MapReduce is a programming algorithm for processing, and generating, large data sets.  A mapper is created to apply a specific algorithm to each of a smaller piece of the original data spread out across multiple computers or nodes, creates a key-value pair with the resulting output from each defined key, and then a reducer will merge the key value pairs to create a single output, which is the desired result of analysis on the larger, initial data set._\n",
    "\n",
    "\n",
    "\n",
    "## How does it differ from Hadoop?\n",
    "\n",
    "#### _MapReduce is a \"divide and conquer\" algorithm that allows for processing of \"big data\" by splitting chunks across multiple nodes or clusters.  Hadoop is an infrastructure that utilizes MapReduce to process large, or unstructured/complex, data sets._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW1.0.1 \n",
    "\n",
    "## Which programming paradigm is Hadoop based on? Explain and give a simple example of functional programming in raw python code and show the code running. E.g., in raw python find the average length of a string in and of strings using a python \"map-reduce\" (functional programming) job. Alternatively, you can do this in python Hadoop Streaming.   \n",
    "\n",
    "#### _Hadoop is based on the MapReduce programming paradigm, which is based on functional programming.  So, by extension, it could be said that Hadoop is, actually, based on the functional programming._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **_The below code calculates the average string length in a string of strings.  The provided string was provided in the original homework assignment._**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input string  ['str1', 'string2', 'w261', 'MAchine learning at SCALE'] has an average length of "
     ]
    },
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def stringlength(string):\n",
    "    return len(string)\n",
    "\n",
    "def numelements(string):\n",
    "    return len(string.split())\n",
    " \n",
    "strings = [\"str1\", \"string2\", \"w261\", \"MAchine learning at SCALE\"]\n",
    "stringlengthmap = map(stringlength, strings)\n",
    "\n",
    "import functools\n",
    "print \"The input string \", strings, \"has an average length of \", \n",
    "functools.reduce(lambda x, y: x + y / float(len(stringlengthmap)), stringlengthmap, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **_The below code is now to prove that the code does work, by providing a different, custom string with different string lengths.  _**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input string  ['Really hope', 'this assignment', 'ends better than', 'it started!'] has an average length of "
     ]
    },
    {
     "data": {
      "text/plain": [
       "13.25"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def stringlength(string):\n",
    "    return len(string)\n",
    "\n",
    "def numelements(string):\n",
    "    return len(string.split())\n",
    " \n",
    "strings = [\"Really hope\", \"this assignment\", \"ends better than\", \"it started!\"]\n",
    "stringlengthmap = map(stringlength, strings)\n",
    "\n",
    "import functools\n",
    "print \"The input string \", strings, \"has an average length of \", \n",
    "functools.reduce(lambda x, y: x + y / float(len(stringlengthmap)), stringlengthmap, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW1.1 Cross fold validation \n",
    "\n",
    "## What is cross validation (in partiticular 10-fold cross validation)?\n",
    "\n",
    "#### _Cross-validation is a technique to evaluate predictive models by partitioning the original sample into a training set to train the model, and a test set to evaluate it.  10-fold cross validation is partitioning the original sample into 10 partitions; 9 to train and one to test.  Here's a basic outline of a 10 fold cross validation on a modeling data set:_\n",
    "\n",
    "   * Partition data into, approximately, n/10 where n is the size of the data set.  (If the data set has 1000 records, there would be roughly 1000/10 = 100 data points in each partition).\n",
    "\n",
    "   * Train a model on 9 of the 10 partitions, holding the last for validation.\n",
    "\n",
    "   * Repeat 9 times, with each iteration a different holding partition for validation.\n",
    "\n",
    "   * Calculate a desired metric for the 10 validations (MSE, RMSE, MAPE, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Info for the rest of the assignment: \n",
    "\n",
    "===== SPAM Dataset \n",
    "In the remainder of this assignment you will produce a spam filter\n",
    "that is backed by a multinomial naive Bayes classifier  (see http://nlp.stanford.edu/IR-book/html/htmledition/properties-of-naive-bayes-1.html).\n",
    "\n",
    "For the sake of this assignment we will focus on the basic construction \n",
    "of the parallelized classifier, and not consider its validation or calibration,\n",
    "and so you will have the classifier operate on its own training data (unlike a \n",
    "field application where one would use non-overlapping subsets for training, validation and testing).\n",
    "\n",
    "The data you will use is a curated subset of the Enron email corpus\n",
    "(whose details you may find in the file enronemail_README.txt  in the directory surrounding these instructions).\n",
    "\n",
    "NOTE: please use the subject field and the body field for all your Naive Bayes modeling. \n",
    "\n",
    "NOTE: This SPAM/HAM dataset for HW1 contains 100 records from the Enron SPAM/HAM corpus. Please limit your study to this unless otherwise instructed. There are about 93,000 emails in the original SPAM/HAM corpus. There are several versions of the SPAM/HAM corpus. Other Enron-Spam datasets are available from http://www.aueb.gr/users/ion/data/enron-spam/index.html and http://www.aueb.gr/users/ion/publications.html in both raw and pre-processed form. \n",
    "\n",
    "Doing some exploratory data analysis you will see (with this very small dataset) the following:\n",
    "> wc -l enronemail_1h.txt  #100 email records\n",
    "     100 enronemail_1h.txt\n",
    "> cut -f2 -d$'\\t' enronemail_1h.txt|wc  #extract second field which is SPAM flag\n",
    "     101     394    3999\n",
    "JAMES-SHANAHANs-Desktop-Pro-2:HW1-Questions jshanahan$ cut -f2 -d$'\\t' enronemail_1h.txt|head\n",
    "0\n",
    "0\n",
    "0\n",
    "0\n",
    "0\n",
    "0\n",
    "0\n",
    "0\n",
    "1\n",
    "1\n",
    "\n",
    "> head -n 100 enronemail_1h.txt|tail -1|less \n",
    "\n",
    "### An example SPAM email record\n",
    "018.2001-07-13.SA_and_HP       1        [ilug] we need your assistance to invest in your country        dear sir/madam,  i am well confident of your capability to assist me in  a transaction for mutual benefit of both parties, ie  (me and you) i am also believing that you will not  expose or betray the trust and confidence i am about  to establish with you. i have decided to contact you  with greatest delight and personal respect.  well, i am victor sankoh, son to mr. foday  sankoh  who was arrested by the ecomog peace keeping force  months ago in my country sierra leone. …."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW1.2 \n",
    "\n",
    "### WORDCOUNT\n",
    "Using the Enron dataset and Hadoop MapReduce streaming (or MRJob), write the mapper/reducer job that  will determine the word count (number of occurrences) of each white-space delimitted token (assume spaces, fullstops, comma as delimiters). Examine the word “assistance” and report its word count results.\n",
    "\n",
    " \n",
    "CROSSCHECK: >grep assistance enronemail_1h.txt|cut -d$'\\t' -f4| grep assistance|wc -l    \n",
    "       8   \n",
    "       \n",
    "NOTE:  \"assistance\" occurs on 8 lines but how many times does the token occur? 10 times! This is the number we are looking for!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting WordCountHW12.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile WordCountHW12.py\n",
    "\n",
    "from mrjob.job import MRJob\n",
    "import re, string\n",
    "\n",
    "class MRJobWordCount(MRJob):\n",
    "\n",
    "    def mapper(self, _, line):\n",
    "        regex = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "        token = line.strip().split('\\t', 2)[-1]\n",
    "        token = regex.sub(' ', token.lower())\n",
    "        token = re.sub( '\\s+', ' ', token )\n",
    "        words = token.split()\n",
    "\n",
    "        for word in words:\n",
    "            if len(word) > 1:\n",
    "                yield (word, 1)\n",
    "\n",
    "    def combiner(self, word, counts):\n",
    "        yield(word, sum(counts))\n",
    "\n",
    "    def reducer(self, word, counts):\n",
    "        yield word, sum(counts)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    MRJobWordCount.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "Creating temp directory /var/folders/0r/78q4n41j3dgdb6ndrr46gw3430x2wk/T/WordCountHW12.z086769.20160701.135730.277857\n",
      "Running step 1 of 1...\n",
      "Streaming final output from /var/folders/0r/78q4n41j3dgdb6ndrr46gw3430x2wk/T/WordCountHW12.z086769.20160701.135730.277857/output...\n",
      "\"00\"\t33\n",
      "\"000\"\t52\n",
      "\"001\"\t3\n",
      "\"0011\"\t1\n",
      "\"00450\"\t1\n",
      "\"0080\"\t1\n",
      "\"01\"\t25\n",
      "\"012\"\t4\n",
      "\"02\"\t19\n",
      "\"028\"\t1\n",
      "\"0281\"\t1\n",
      "\"03\"\t3\n",
      "\"036474336\"\t1\n",
      "\"04\"\t7\n",
      "\"048\"\t1\n",
      "\"05\"\t4\n",
      "\"055\"\t2\n",
      "\"06\"\t21\n",
      "\"0643\"\t1\n",
      "\"07\"\t10\n",
      "\"08\"\t22\n",
      "\"081\"\t2\n",
      "\"088889774\"\t1\n",
      "\"09\"\t21\n",
      "\"10\"\t44\n",
      "\"100\"\t19\n",
      "\"100038\"\t1\n",
      "\"1016\"\t1\n",
      "\"103\"\t1\n",
      "\"107\"\t1\n",
      "\"108\"\t1\n",
      "\"11\"\t15\n",
      "\"114427\"\t1\n",
      "\"12\"\t74\n",
      "\"120\"\t1\n",
      "\"1200\"\t2\n",
      "\"122\"\t1\n",
      "\"123\"\t3\n",
      "\"123395\"\t1\n",
      "\"124\"\t3\n",
      "\"125\"\t2\n",
      "\"126\"\t2\n",
      "\"13\"\t13\n",
      "\"134\"\t1\n",
      "\"14\"\t33\n",
      "\"146907159\"\t1\n",
      "\"148415904\"\t1\n",
      "\"1488230796\"\t1\n",
      "\"149\"\t1\n",
      "\"15\"\t25\n",
      "\"150\"\t1\n",
      "\"1500\"\t1\n",
      "\"151\"\t1\n",
      "\"1517\"\t1\n",
      "\"16\"\t5\n",
      "\"161\"\t1\n",
      "\"1687\"\t1\n",
      "\"1689\"\t1\n",
      "\"17\"\t19\n",
      "\"18\"\t18\n",
      "\"1814\"\t1\n",
      "\"1848\"\t1\n",
      "\"1864\"\t1\n",
      "\"19\"\t9\n",
      "\"1928\"\t1\n",
      "\"1930\"\t1\n",
      "\"1932\"\t1\n",
      "\"1933\"\t1\n",
      "\"1934\"\t1\n",
      "\"1935\"\t1\n",
      "\"1936\"\t1\n",
      "\"1938\"\t1\n",
      "\"1941\"\t1\n",
      "\"1942\"\t1\n",
      "\"1944\"\t1\n",
      "\"1945\"\t1\n",
      "\"1947\"\t1\n",
      "\"1949\"\t1\n",
      "\"1953\"\t1\n",
      "\"1980\"\t2\n",
      "\"1990\"\t2\n",
      "\"1992\"\t3\n",
      "\"1997\"\t3\n",
      "\"1998\"\t2\n",
      "\"1999\"\t10\n",
      "\"20\"\t20\n",
      "\"200\"\t3\n",
      "\"2000\"\t30\n",
      "\"2001\"\t29\n",
      "\"2002\"\t2\n",
      "\"2003\"\t19\n",
      "\"2004\"\t16\n",
      "\"2005\"\t3\n",
      "\"201\"\t2\n",
      "\"2020\"\t1\n",
      "\"2086\"\t1\n",
      "\"209318\"\t1\n",
      "\"21\"\t3\n",
      "\"211075433222\"\t2\n",
      "\"212\"\t3\n",
      "\"213\"\t1\n",
      "\"2152\"\t1\n",
      "\"22\"\t8\n",
      "\"224\"\t1\n",
      "\"229\"\t2\n",
      "\"23\"\t4\n",
      "\"230\"\t1\n",
      "\"234\"\t1\n",
      "\"24\"\t27\n",
      "\"249\"\t2\n",
      "\"2497\"\t1\n",
      "\"25\"\t4\n",
      "\"250\"\t1\n",
      "\"2500\"\t1\n",
      "\"252050406\"\t1\n",
      "\"255326837\"\t1\n",
      "\"256\"\t1\n",
      "\"25711\"\t2\n",
      "\"2575\"\t4\n",
      "\"259\"\t1\n",
      "\"26\"\t5\n",
      "\"260\"\t2\n",
      "\"263\"\t2\n",
      "\"2666\"\t1\n",
      "\"27\"\t6\n",
      "\"27049\"\t2\n",
      "\"2753\"\t1\n",
      "\"28\"\t10\n",
      "\"2807\"\t1\n",
      "\"281\"\t1\n",
      "\"2868\"\t1\n",
      "\"29\"\t10\n",
      "\"29155\"\t1\n",
      "\"2963\"\t1\n",
      "\"299\"\t1\n",
      "\"30\"\t20\n",
      "\"300\"\t9\n",
      "\"3000\"\t2\n",
      "\"3011\"\t1\n",
      "\"306\"\t2\n",
      "\"31\"\t4\n",
      "\"312\"\t1\n",
      "\"3130\"\t1\n",
      "\"31615304791\"\t1\n",
      "\"32\"\t12\n",
      "\"321\"\t1\n",
      "\"3267\"\t1\n",
      "\"3300\"\t1\n",
      "\"33155\"\t1\n",
      "\"332\"\t1\n",
      "\"33282\"\t1\n",
      "\"33465\"\t1\n",
      "\"3359\"\t1\n",
      "\"33597\"\t1\n",
      "\"34\"\t4\n",
      "\"3404\"\t1\n",
      "\"3405\"\t2\n",
      "\"34357\"\t1\n",
      "\"345\"\t1\n",
      "\"34710\"\t1\n",
      "\"349\"\t2\n",
      "\"35\"\t2\n",
      "\"35615\"\t1\n",
      "\"35782\"\t1\n",
      "\"36\"\t2\n",
      "\"37\"\t1\n",
      "\"37159\"\t2\n",
      "\"375\"\t1\n",
      "\"38\"\t5\n",
      "\"39\"\t5\n",
      "\"392\"\t2\n",
      "\"39510\"\t2\n",
      "\"399\"\t1\n",
      "\"39934\"\t2\n",
      "\"40\"\t9\n",
      "\"4073\"\t1\n",
      "\"409055\"\t1\n",
      "\"41\"\t1\n",
      "\"415\"\t4\n",
      "\"418\"\t4\n",
      "\"419\"\t1\n",
      "\"420\"\t1\n",
      "\"422\"\t4\n",
      "\"423\"\t2\n",
      "\"43\"\t2\n",
      "\"431\"\t1\n",
      "\"436425795822\"\t1\n",
      "\"44\"\t6\n",
      "\"449\"\t1\n",
      "\"45\"\t6\n",
      "\"4500\"\t2\n",
      "\"46\"\t2\n",
      "\"47\"\t2\n",
      "\"474\"\t1\n",
      "\"4748\"\t1\n",
      "\"4887\"\t1\n",
      "\"49\"\t1\n",
      "\"499\"\t2\n",
      "\"50\"\t15\n",
      "\"500\"\t8\n",
      "\"5000\"\t3\n",
      "\"5022\"\t1\n",
      "\"51\"\t1\n",
      "\"512517\"\t2\n",
      "\"519\"\t1\n",
      "\"52\"\t3\n",
      "\"521\"\t1\n",
      "\"52109\"\t1\n",
      "\"52477\"\t1\n",
      "\"529\"\t3\n",
      "\"5290\"\t2\n",
      "\"54\"\t4\n",
      "\"54804\"\t1\n",
      "\"549\"\t1\n",
      "\"55\"\t4\n",
      "\"553\"\t1\n",
      "\"5555\"\t2\n",
      "\"56\"\t1\n",
      "\"560\"\t1\n",
      "\"57\"\t1\n",
      "\"58\"\t1\n",
      "\"584\"\t1\n",
      "\"59\"\t2\n",
      "\"599\"\t1\n",
      "\"60\"\t6\n",
      "\"600\"\t1\n",
      "\"602\"\t1\n",
      "\"609\"\t1\n",
      "\"61\"\t2\n",
      "\"6207\"\t1\n",
      "\"62163\"\t1\n",
      "\"62413\"\t1\n",
      "\"630\"\t1\n",
      "\"6396\"\t1\n",
      "\"64\"\t1\n",
      "\"642\"\t1\n",
      "\"645\"\t2\n",
      "\"64610\"\t2\n",
      "\"6484\"\t1\n",
      "\"66\"\t1\n",
      "\"6614102\"\t1\n",
      "\"67\"\t2\n",
      "\"674\"\t1\n",
      "\"6761\"\t1\n",
      "\"68\"\t1\n",
      "\"69\"\t1\n",
      "\"6902\"\t1\n",
      "\"69545\"\t1\n",
      "\"6992\"\t2\n",
      "\"70\"\t1\n",
      "\"700\"\t3\n",
      "\"703\"\t1\n",
      "\"706\"\t2\n",
      "\"71\"\t1\n",
      "\"713\"\t6\n",
      "\"7168\"\t1\n",
      "\"7247\"\t1\n",
      "\"7268\"\t3\n",
      "\"731\"\t1\n",
      "\"735670\"\t1\n",
      "\"7358\"\t2\n",
      "\"738\"\t1\n",
      "\"7394\"\t1\n",
      "\"74949\"\t1\n",
      "\"75\"\t5\n",
      "\"7517\"\t1\n",
      "\"7578\"\t1\n",
      "\"76\"\t1\n",
      "\"763\"\t1\n",
      "\"7675213911\"\t1\n",
      "\"77\"\t1\n",
      "\"77056\"\t2\n",
      "\"78\"\t2\n",
      "\"783019\"\t1\n",
      "\"783518\"\t1\n",
      "\"7877\"\t6\n",
      "\"789118270\"\t1\n",
      "\"793\"\t1\n",
      "\"80\"\t5\n",
      "\"800\"\t3\n",
      "\"802\"\t1\n",
      "\"8038\"\t1\n",
      "\"81\"\t2\n",
      "\"816\"\t2\n",
      "\"82\"\t1\n",
      "\"825854664\"\t1\n",
      "\"840\"\t1\n",
      "\"8434\"\t1\n",
      "\"847\"\t1\n",
      "\"8507\"\t1\n",
      "\"8561513507\"\t1\n",
      "\"869279893\"\t1\n",
      "\"87\"\t3\n",
      "\"877\"\t3\n",
      "\"878\"\t1\n",
      "\"8859\"\t10\n",
      "\"888\"\t5\n",
      "\"89\"\t1\n",
      "\"8901\"\t1\n",
      "\"8919\"\t1\n",
      "\"893\"\t1\n",
      "\"90\"\t3\n",
      "\"900\"\t1\n",
      "\"908\"\t1\n",
      "\"9100\"\t1\n",
      "\"92\"\t1\n",
      "\"9213\"\t1\n",
      "\"9237\"\t1\n",
      "\"925\"\t2\n",
      "\"928976257\"\t1\n",
      "\"9291\"\t1\n",
      "\"932\"\t2\n",
      "\"9381\"\t1\n",
      "\"94105\"\t1\n",
      "\"9434\"\t2\n",
      "\"944\"\t1\n",
      "\"9489\"\t1\n",
      "\"95\"\t15\n",
      "\"95394\"\t1\n",
      "\"96\"\t1\n",
      "\"96006681\"\t1\n",
      "\"9610\"\t1\n",
      "\"964\"\t2\n",
      "\"9643\"\t2\n",
      "\"965\"\t1\n",
      "\"97\"\t1\n",
      "\"973\"\t2\n",
      "\"98\"\t1\n",
      "\"982\"\t1\n",
      "\"986782\"\t1\n",
      "\"99\"\t64\n",
      "\"999\"\t3\n",
      "\"ab\"\t5\n",
      "\"abidjan\"\t2\n",
      "\"ability\"\t2\n",
      "\"able\"\t14\n",
      "\"abn\"\t1\n",
      "\"about\"\t52\n",
      "\"above\"\t11\n",
      "\"absent\"\t1\n",
      "\"absenteeism\"\t1\n",
      "\"absolute\"\t2\n",
      "\"absolutely\"\t1\n",
      "\"absorb\"\t1\n",
      "\"abuse\"\t2\n",
      "\"abused\"\t1\n",
      "\"acce\"\t1\n",
      "\"accelerate\"\t1\n",
      "\"accelerated\"\t1\n",
      "\"accept\"\t3\n",
      "\"acceptable\"\t1\n",
      "\"accepted\"\t1\n",
      "\"accepting\"\t2\n",
      "\"accepts\"\t1\n",
      "\"access\"\t12\n",
      "\"accomodate\"\t4\n",
      "\"accomodates\"\t1\n",
      "\"accompanied\"\t1\n",
      "\"according\"\t2\n",
      "\"accordingly\"\t1\n",
      "\"account\"\t36\n",
      "\"accountability\"\t1\n",
      "\"accounting\"\t5\n",
      "\"accounts\"\t1\n",
      "\"accrual\"\t2\n",
      "\"accurate\"\t1\n",
      "\"aches\"\t1\n",
      "\"achieve\"\t1\n",
      "\"achieved\"\t1\n",
      "\"acid\"\t1\n",
      "\"acquire\"\t1\n",
      "\"acquisition\"\t1\n",
      "\"acrobaat\"\t1\n",
      "\"acrobat\"\t1\n",
      "\"across\"\t10\n",
      "\"act\"\t7\n",
      "\"action\"\t1\n",
      "\"activate\"\t4\n",
      "\"active\"\t1\n",
      "\"activists\"\t1\n",
      "\"activities\"\t10\n",
      "\"actor\"\t1\n",
      "\"actress\"\t1\n",
      "\"actual\"\t4\n",
      "\"actually\"\t2\n",
      "\"ad\"\t31\n",
      "\"adage\"\t1\n",
      "\"adams\"\t1\n",
      "\"adapted\"\t1\n",
      "\"add\"\t12\n",
      "\"added\"\t2\n",
      "\"adding\"\t2\n",
      "\"addition\"\t5\n",
      "\"additional\"\t13\n",
      "\"additionally\"\t2\n",
      "\"address\"\t27\n",
      "\"addressed\"\t1\n",
      "\"addresses\"\t5\n",
      "\"addressing\"\t1\n",
      "\"addtional\"\t1\n",
      "\"adequately\"\t1\n",
      "\"adhesion\"\t1\n",
      "\"adm\"\t1\n",
      "\"admin\"\t1\n",
      "\"adminder\"\t2\n",
      "\"administration\"\t3\n",
      "\"admitted\"\t1\n",
      "\"admixture\"\t1\n",
      "\"adobe\"\t12\n",
      "\"adobee\"\t1\n",
      "\"adolescent\"\t1\n",
      "\"adr\"\t1\n",
      "\"adrianbold\"\t2\n",
      "\"ads\"\t5\n",
      "\"adult\"\t3\n",
      "\"adv\"\t1\n",
      "\"advance\"\t4\n",
      "\"advanced\"\t1\n",
      "\"advantage\"\t1\n",
      "\"advantages\"\t1\n",
      "\"advertise\"\t2\n",
      "\"advertised\"\t1\n",
      "\"advertisement\"\t4\n",
      "\"advertisements\"\t1\n",
      "\"advertising\"\t7\n",
      "\"advertisments\"\t1\n",
      "\"advice\"\t4\n",
      "\"advise\"\t2\n",
      "\"advises\"\t1\n",
      "\"advocate\"\t1\n",
      "\"advocates\"\t1\n",
      "\"advs\"\t1\n",
      "\"aec\"\t2\n",
      "\"aeopublishing\"\t29\n",
      "\"afeee\"\t1\n",
      "\"aff\"\t1\n",
      "\"affairs\"\t1\n",
      "\"affect\"\t2\n",
      "\"affectate\"\t1\n",
      "\"affiliate\"\t2\n",
      "\"affiliates\"\t6\n",
      "\"afford\"\t1\n",
      "\"afirst\"\t1\n",
      "\"afraid\"\t4\n",
      "\"africa\"\t10\n",
      "\"after\"\t19\n",
      "\"afternoon\"\t4\n",
      "\"again\"\t12\n",
      "\"against\"\t6\n",
      "\"age\"\t5\n",
      "\"agendas\"\t1\n",
      "\"agent\"\t3\n",
      "\"aggressive\"\t1\n",
      "\"aggressively\"\t3\n",
      "\"ago\"\t1\n",
      "\"agonizing\"\t1\n",
      "\"agouti\"\t1\n",
      "\"agree\"\t3\n",
      "\"agreed\"\t2\n",
      "\"agreeing\"\t1\n",
      "\"agreement\"\t16\n",
      "\"agreements\"\t3\n",
      "\"ague\"\t1\n",
      "\"ah\"\t1\n",
      "\"ahead\"\t1\n",
      "\"aid\"\t1\n",
      "\"aids\"\t1\n",
      "\"air\"\t6\n",
      "\"airport\"\t2\n",
      "\"airs\"\t1\n",
      "\"aka\"\t1\n",
      "\"akkabay\"\t4\n",
      "\"al\"\t2\n",
      "\"albuquerque\"\t2\n",
      "\"alertness\"\t1\n",
      "\"alex\"\t4\n",
      "\"alexios\"\t1\n",
      "\"alhaji\"\t2\n",
      "\"all\"\t111\n",
      "\"allay\"\t1\n",
      "\"allen\"\t5\n",
      "\"alleviates\"\t1\n",
      "\"alli\"\t1\n",
      "\"allocate\"\t1\n",
      "\"allocated\"\t2\n",
      "\"allocating\"\t2\n",
      "\"allocation\"\t6\n",
      "\"allocations\"\t4\n",
      "\"allow\"\t12\n",
      "\"allows\"\t3\n",
      "\"almost\"\t3\n",
      "\"alone\"\t2\n",
      "\"along\"\t4\n",
      "\"alpra\"\t2\n",
      "\"already\"\t13\n",
      "\"alsdorf\"\t1\n",
      "\"also\"\t56\n",
      "\"alternative\"\t1\n",
      "\"alternatively\"\t1\n",
      "\"although\"\t3\n",
      "\"altra\"\t1\n",
      "\"alum\"\t1\n",
      "\"always\"\t10\n",
      "\"am\"\t86\n",
      "\"amadol\"\t2\n",
      "\"amazed\"\t1\n",
      "\"amb\"\t2\n",
      "\"ambien\"\t2\n",
      "\"ambrose\"\t1\n",
      "\"amended\"\t1\n",
      "\"americ\"\t2\n",
      "\"america\"\t15\n",
      "\"american\"\t2\n",
      "\"amex\"\t1\n",
      "\"ami\"\t1\n",
      "\"amiable\"\t1\n",
      "\"amigo\"\t1\n",
      "\"amitava\"\t4\n",
      "\"among\"\t7\n",
      "\"amortize\"\t4\n",
      "\"amount\"\t7\n",
      "\"amounts\"\t2\n",
      "\"amsterdam\"\t1\n",
      "\"amy\"\t2\n",
      "\"an\"\t77\n",
      "\"anabel\"\t1\n",
      "\"anal\"\t1\n",
      "\"analyses\"\t1\n",
      "\"analysis\"\t3\n",
      "\"analyst\"\t2\n",
      "\"analyze\"\t1\n",
      "\"ancillary\"\t2\n",
      "\"and\"\t670\n",
      "\"andorra\"\t1\n",
      "\"andrea\"\t3\n",
      "\"angelova\"\t4\n",
      "\"angels\"\t2\n",
      "\"angrily\"\t1\n",
      "\"angry\"\t1\n",
      "\"anheuser\"\t1\n",
      "\"anita\"\t2\n",
      "\"annals\"\t1\n",
      "\"annie\"\t2\n",
      "\"announcement\"\t7\n",
      "\"announcements\"\t4\n",
      "\"annoy\"\t1\n",
      "\"annoying\"\t1\n",
      "\"annuallouy\"\t1\n",
      "\"anonymise\"\t1\n",
      "\"anonymizer\"\t1\n",
      "\"anonymously\"\t1\n",
      "\"another\"\t15\n",
      "\"answer\"\t7\n",
      "\"answered\"\t1\n",
      "\"answering\"\t3\n",
      "\"answers\"\t7\n",
      "\"ante\"\t1\n",
      "\"anticipate\"\t1\n",
      "\"antivirus\"\t1\n",
      "\"antoine\"\t1\n",
      "\"any\"\t77\n",
      "\"anyare\"\t1\n",
      "\"anybody\"\t1\n",
      "\"anyhow\"\t5\n",
      "\"anyone\"\t7\n",
      "\"anything\"\t11\n",
      "\"anyway\"\t2\n",
      "\"anywhere\"\t3\n",
      "\"anz\"\t2\n",
      "\"aol\"\t6\n",
      "\"apachi\"\t1\n",
      "\"apart\"\t2\n",
      "\"apex\"\t1\n",
      "\"aphrodite\"\t1\n",
      "\"apoligize\"\t2\n",
      "\"apollo\"\t1\n",
      "\"apologies\"\t2\n",
      "\"apologize\"\t3\n",
      "\"apparently\"\t2\n",
      "\"appeals\"\t4\n",
      "\"appear\"\t7\n",
      "\"appearance\"\t2\n",
      "\"appears\"\t3\n",
      "\"appellate\"\t1\n",
      "\"appetite\"\t2\n",
      "\"application\"\t4\n",
      "\"applied\"\t5\n",
      "\"apply\"\t4\n",
      "\"appreciate\"\t2\n",
      "\"appreciated\"\t1\n",
      "\"appreciation\"\t2\n",
      "\"approach\"\t2\n",
      "\"appropriate\"\t3\n",
      "\"approval\"\t1\n",
      "\"approved\"\t6\n",
      "\"approximately\"\t4\n",
      "\"aqmd\"\t2\n",
      "\"aqoj\"\t1\n",
      "\"arbitrage\"\t4\n",
      "\"architect\"\t1\n",
      "\"archive\"\t1\n",
      "\"arcy\"\t7\n",
      "\"are\"\t169\n",
      "\"area\"\t4\n",
      "\"areas\"\t3\n",
      "\"aren\"\t3\n",
      "\"argentine\"\t4\n",
      "\"argue\"\t1\n",
      "\"argument\"\t2\n",
      "\"arizona\"\t1\n",
      "\"ark\"\t1\n",
      "\"arlene\"\t2\n",
      "\"arm\"\t1\n",
      "\"armstrong\"\t2\n",
      "\"around\"\t6\n",
      "\"arousing\"\t1\n",
      "\"arrange\"\t5\n",
      "\"arranged\"\t1\n",
      "\"arrangement\"\t2\n",
      "\"arrangements\"\t3\n",
      "\"arrest\"\t4\n",
      "\"arrested\"\t1\n",
      "\"arrival\"\t1\n",
      "\"art\"\t2\n",
      "\"arthur\"\t1\n",
      "\"article\"\t3\n",
      "\"articles\"\t2\n",
      "\"as\"\t138\n",
      "\"asap\"\t1\n",
      "\"ascii\"\t1\n",
      "\"ashburton\"\t3\n",
      "\"asia\"\t1\n",
      "\"aside\"\t4\n",
      "\"ask\"\t9\n",
      "\"asked\"\t3\n",
      "\"asking\"\t10\n",
      "\"asks\"\t1\n",
      "\"aspermont\"\t3\n",
      "\"assault\"\t1\n",
      "\"assay\"\t1\n",
      "\"assays\"\t1\n",
      "\"assembly\"\t2\n",
      "\"assemblyman\"\t3\n",
      "\"asset\"\t1\n",
      "\"assets\"\t14\n",
      "\"assignment\"\t1\n",
      "\"assist\"\t7\n",
      "\"assistance\"\t10\n",
      "\"assistant\"\t2\n",
      "\"associate\"\t3\n",
      "\"associated\"\t4\n",
      "\"association\"\t3\n",
      "\"assortment\"\t1\n",
      "\"assume\"\t1\n",
      "\"assuming\"\t1\n",
      "\"assumption\"\t1\n",
      "\"assure\"\t4\n",
      "\"asthma\"\t1\n",
      "\"at\"\t146\n",
      "\"ate\"\t3\n",
      "\"ativan\"\t1\n",
      "\"atop\"\t1\n",
      "\"atreus\"\t1\n",
      "\"attached\"\t8\n",
      "\"attack\"\t1\n",
      "\"attacked\"\t1\n",
      "\"attatched\"\t2\n",
      "\"attempt\"\t2\n",
      "\"attend\"\t7\n",
      "\"attendance\"\t2\n",
      "\"attended\"\t1\n",
      "\"attendees\"\t2\n",
      "\"attending\"\t1\n",
      "\"attention\"\t3\n",
      "\"attest\"\t1\n",
      "\"attitudinal\"\t1\n",
      "\"attl\"\t1\n",
      "\"attn\"\t2\n",
      "\"attractive\"\t2\n",
      "\"attributable\"\t1\n",
      "\"audience\"\t10\n",
      "\"audio\"\t2\n",
      "\"audit\"\t3\n",
      "\"auditor\"\t1\n",
      "\"august\"\t1\n",
      "\"australia\"\t10\n",
      "\"australian\"\t3\n",
      "\"australiasds\"\t1\n",
      "\"authenticity\"\t1\n",
      "\"author\"\t4\n",
      "\"authorities\"\t1\n",
      "\"authority\"\t1\n",
      "\"authorized\"\t1\n",
      "\"authors\"\t1\n",
      "\"automated\"\t2\n",
      "\"automatically\"\t7\n",
      "\"automobile\"\t1\n",
      "\"availability\"\t2\n",
      "\"available\"\t23\n",
      "\"average\"\t4\n",
      "\"aviation\"\t1\n",
      "\"avoid\"\t10\n",
      "\"avoided\"\t1\n",
      "\"await\"\t4\n",
      "\"awaking\"\t1\n",
      "\"award\"\t1\n",
      "\"aware\"\t1\n",
      "\"away\"\t9\n",
      "\"awesome\"\t1\n",
      "\"ax\"\t2\n",
      "\"axe\"\t1\n",
      "\"axel\"\t2\n",
      "\"ay\"\t1\n",
      "\"azepam\"\t2\n",
      "\"azurix\"\t10\n",
      "\"baby\"\t2\n",
      "\"baccarat\"\t1\n",
      "\"bachelors\"\t1\n",
      "\"back\"\t26\n",
      "\"backed\"\t1\n",
      "\"background\"\t9\n",
      "\"backgrounds\"\t1\n",
      "\"backup\"\t2\n",
      "\"bacon\"\t1\n",
      "\"bacterial\"\t1\n",
      "\"bad\"\t5\n",
      "\"bade\"\t1\n",
      "\"baggage\"\t1\n",
      "\"bail\"\t9\n",
      "\"bailout\"\t8\n",
      "\"balance\"\t1\n",
      "\"ballot\"\t1\n",
      "\"banging\"\t1\n",
      "\"bank\"\t7\n",
      "\"banked\"\t1\n",
      "\"banker\"\t3\n",
      "\"banking\"\t4\n",
      "\"bankruptcy\"\t20\n",
      "\"banks\"\t1\n",
      "\"bannerco\"\t4\n",
      "\"banners\"\t1\n",
      "\"bannersgomlm\"\t8\n",
      "\"bar\"\t1\n",
      "\"bareback\"\t1\n",
      "\"barely\"\t1\n",
      "\"bargaain\"\t1\n",
      "\"barnard\"\t1\n",
      "\"barney\"\t3\n",
      "\"barraged\"\t1\n",
      "\"barrier\"\t2\n",
      "\"barrow\"\t1\n",
      "\"base\"\t4\n",
      "\"based\"\t15\n",
      "\"basically\"\t1\n",
      "\"basis\"\t5\n",
      "\"baskets\"\t5\n",
      "\"batch\"\t3\n",
      "\"bauxite\"\t1\n",
      "\"bawled\"\t1\n",
      "\"bazzd\"\t1\n",
      "\"bc\"\t1\n",
      "\"bcli\"\t1\n",
      "\"bd\"\t7\n",
      "\"bdf\"\t1\n",
      "\"be\"\t222\n",
      "\"beale\"\t1\n",
      "\"beans\"\t1\n",
      "\"bear\"\t4\n",
      "\"beard\"\t1\n",
      "\"beca\"\t1\n",
      "\"became\"\t4\n",
      "\"because\"\t19\n",
      "\"beck\"\t5\n",
      "\"become\"\t6\n",
      "\"bed\"\t1\n",
      "\"bedfellow\"\t1\n",
      "\"beds\"\t3\n",
      "\"been\"\t52\n",
      "\"beers\"\t1\n",
      "\"beetcn\"\t1\n",
      "\"before\"\t23\n",
      "\"began\"\t6\n",
      "\"begin\"\t5\n",
      "\"beginning\"\t4\n",
      "\"begins\"\t2\n",
      "\"behalf\"\t1\n",
      "\"being\"\t14\n",
      "\"belgium\"\t1\n",
      "\"believable\"\t2\n",
      "\"believe\"\t14\n",
      "\"believed\"\t2\n",
      "\"believes\"\t1\n",
      "\"believing\"\t1\n",
      "\"belong\"\t1\n",
      "\"belonged\"\t1\n",
      "\"belongs\"\t2\n",
      "\"below\"\t16\n",
      "\"benchmarks\"\t3\n",
      "\"bendickson\"\t2\n",
      "\"benedicta\"\t2\n",
      "\"beneficiary\"\t1\n",
      "\"benefit\"\t10\n",
      "\"benefits\"\t11\n",
      "\"beneteau\"\t1\n",
      "\"benewm\"\t1\n",
      "\"bennett\"\t1\n",
      "\"benson\"\t1\n",
      "\"ber\"\t1\n",
      "\"berkovitz\"\t2\n",
      "\"bernice\"\t1\n",
      "\"best\"\t27\n",
      "\"bestowal\"\t1\n",
      "\"bestwaytoshop\"\t1\n",
      "\"betray\"\t1\n",
      "\"better\"\t10\n",
      "\"between\"\t7\n",
      "\"beware\"\t1\n",
      "\"beyond\"\t3\n",
      "\"bgmlm\"\t1\n",
      "\"bharat\"\t1\n",
      "\"bid\"\t1\n",
      "\"big\"\t10\n",
      "\"biggest\"\t1\n",
      "\"bill\"\t8\n",
      "\"billed\"\t2\n",
      "\"billion\"\t6\n",
      "\"bills\"\t6\n",
      "\"birch\"\t1\n",
      "\"bit\"\t2\n",
      "\"biwven\"\t1\n",
      "\"biz\"\t4\n",
      "\"bjeffrie\"\t1\n",
      "\"bjwl\"\t1\n",
      "\"blainey\"\t1\n",
      "\"bless\"\t3\n",
      "\"blessed\"\t2\n",
      "\"block\"\t5\n",
      "\"blocked\"\t2\n",
      "\"blocking\"\t2\n",
      "\"blong\"\t1\n",
      "\"blood\"\t1\n",
      "\"blow\"\t1\n",
      "\"blows\"\t1\n",
      "\"blues\"\t2\n",
      "\"blush\"\t1\n",
      "\"bmar\"\t1\n",
      "\"bmf\"\t1\n",
      "\"bmlm\"\t4\n",
      "\"board\"\t3\n",
      "\"bob\"\t7\n",
      "\"bodies\"\t1\n",
      "\"body\"\t9\n",
      "\"bodyfrankfurter\"\t1\n",
      "\"bold\"\t2\n",
      "\"bolnisi\"\t1\n",
      "\"bombs\"\t3\n",
      "\"bond\"\t1\n",
      "\"bondholders\"\t1\n",
      "\"bonds\"\t6\n",
      "\"bone\"\t1\n",
      "\"bonnard\"\t1\n",
      "\"bonus\"\t5\n",
      "\"bonuses\"\t4\n",
      "\"book\"\t5\n",
      "\"books\"\t2\n",
      "\"boost\"\t1\n",
      "\"boosts\"\t1\n",
      "\"booth\"\t1\n",
      "\"boots\"\t1\n",
      "\"booze\"\t1\n",
      "\"borlan\"\t1\n",
      "\"borland\"\t1\n",
      "\"borrowers\"\t1\n",
      "\"boss\"\t1\n",
      "\"both\"\t15\n",
      "\"bother\"\t1\n",
      "\"bottom\"\t2\n",
      "\"bought\"\t3\n",
      "\"bound\"\t2\n",
      "\"boundary\"\t1\n",
      "\"box\"\t20\n",
      "\"boxes\"\t1\n",
      "\"boy\"\t2\n",
      "\"bp\"\t3\n",
      "\"br\"\t2\n",
      "\"brad\"\t2\n",
      "\"bradford\"\t1\n",
      "\"brainstorm\"\t1\n",
      "\"brand\"\t6\n",
      "\"branded\"\t1\n",
      "\"branding\"\t8\n",
      "\"brazil\"\t8\n",
      "\"brazilian\"\t4\n",
      "\"break\"\t5\n",
      "\"breaking\"\t1\n",
      "\"breakthrough\"\t1\n",
      "\"breath\"\t5\n",
      "\"breathe\"\t2\n",
      "\"bredd\"\t1\n",
      "\"brenda\"\t1\n",
      "\"brennan\"\t2\n",
      "\"brent\"\t2\n",
      "\"brett\"\t3\n",
      "\"brex\"\t2\n",
      "\"brian\"\t1\n",
      "\"brick\"\t5\n",
      "\"bridge\"\t1\n",
      "\"brighton\"\t1\n",
      "\"brim\"\t1\n",
      "\"bring\"\t1\n",
      "\"brings\"\t5\n",
      "\"broad\"\t2\n",
      "\"broker\"\t3\n",
      "\"brought\"\t1\n",
      "\"brown\"\t3\n",
      "\"browser\"\t2\n",
      "\"brutal\"\t1\n",
      "\"bryan\"\t6\n",
      "\"bs\"\t2\n",
      "\"btu\"\t2\n",
      "\"buchsbaum\"\t1\n",
      "\"buck\"\t1\n",
      "\"bucolic\"\t1\n",
      "\"build\"\t12\n",
      "\"building\"\t7\n",
      "\"buildings\"\t1\n",
      "\"buka\"\t2\n",
      "\"bull\"\t1\n",
      "\"bullet\"\t5\n",
      "\"bulleted\"\t2\n",
      "\"bullets\"\t1\n",
      "\"burning\"\t2\n",
      "\"burst\"\t1\n",
      "\"burton\"\t13\n",
      "\"bus\"\t4\n",
      "\"busine\"\t1\n",
      "\"busines\"\t1\n",
      "\"business\"\t64\n",
      "\"businesses\"\t4\n",
      "\"businessopps\"\t2\n",
      "\"bussell\"\t1\n",
      "\"busy\"\t1\n",
      "\"but\"\t67\n",
      "\"butler\"\t1\n",
      "\"button\"\t1\n",
      "\"buy\"\t8\n",
      "\"buybacks\"\t1\n",
      "\"buying\"\t1\n",
      "\"by\"\t143\n",
      "\"bybb\"\t1\n",
      "\"bybtb\"\t1\n",
      "\"bye\"\t1\n",
      "\"byee\"\t2\n",
      "\"bypass\"\t1\n",
      "\"bypasses\"\t1\n",
      "\"bytesize\"\t1\n",
      "\"ca\"\t6\n",
      "\"cabinet\"\t1\n",
      "\"cabinets\"\t1\n",
      "\"caboose\"\t1\n",
      "\"cage\"\t1\n",
      "\"cagey\"\t1\n",
      "\"cal\"\t3\n",
      "\"calamity\"\t2\n",
      "\"calculations\"\t2\n",
      "\"cali\"\t1\n",
      "\"california\"\t12\n",
      "\"call\"\t15\n",
      "\"called\"\t3\n",
      "\"calme\"\t1\n",
      "\"calpine\"\t3\n",
      "\"came\"\t2\n",
      "\"camp\"\t7\n",
      "\"campus\"\t1\n",
      "\"can\"\t90\n",
      "\"canada\"\t4\n",
      "\"canadian\"\t1\n",
      "\"canary\"\t1\n",
      "\"cancel\"\t1\n",
      "\"candidate\"\t1\n",
      "\"cankerworm\"\t1\n",
      "\"cannot\"\t5\n",
      "\"cano\"\t1\n",
      "\"canyonu\"\t1\n",
      "\"capabilities\"\t1\n",
      "\"capability\"\t3\n",
      "\"capacity\"\t2\n",
      "\"capital\"\t7\n",
      "\"capitalisation\"\t1\n",
      "\"capitalize\"\t2\n",
      "\"capitol\"\t1\n",
      "\"car\"\t6\n",
      "\"card\"\t5\n",
      "\"cards\"\t5\n",
      "\"care\"\t9\n",
      "\"careful\"\t1\n",
      "\"carefully\"\t4\n",
      "\"cares\"\t1\n",
      "\"cargill\"\t2\n",
      "\"carlo\"\t1\n",
      "\"carlos\"\t5\n",
      "\"carmody\"\t1\n",
      "\"carol\"\t1\n",
      "\"carolyn\"\t1\n",
      "\"carrera\"\t1\n",
      "\"carriage\"\t1\n",
      "\"carrie\"\t1\n",
      "\"carried\"\t1\n",
      "\"carroll\"\t6\n",
      "\"carry\"\t1\n",
      "\"cars\"\t4\n",
      "\"cart\"\t2\n",
      "\"case\"\t13\n",
      "\"cases\"\t2\n",
      "\"cash\"\t18\n",
      "\"cashpo\"\t2\n",
      "\"cashpromotions\"\t4\n",
      "\"casinos\"\t2\n",
      "\"cat\"\t2\n",
      "\"catalog\"\t5\n",
      "\"catalyze\"\t2\n",
      "\"catchy\"\t1\n",
      "\"category\"\t2\n",
      "\"caucasians\"\t1\n",
      "\"caught\"\t1\n",
      "\"cause\"\t1\n",
      "\"caused\"\t1\n",
      "\"causey\"\t7\n",
      "\"cc\"\t40\n",
      "\"ccprod\"\t3\n",
      "\"cd\"\t2\n",
      "\"ceased\"\t1\n",
      "\"cede\"\t1\n",
      "\"cele\"\t2\n",
      "\"celebrate\"\t1\n",
      "\"celebration\"\t3\n",
      "\"celias\"\t1\n",
      "\"cell\"\t1\n",
      "\"cellulite\"\t1\n",
      "\"cemented\"\t1\n",
      "\"cenochs\"\t1\n",
      "\"cent\"\t1\n",
      "\"center\"\t13\n",
      "\"central\"\t3\n",
      "\"cents\"\t7\n",
      "\"century\"\t1\n",
      "\"ceo\"\t1\n",
      "\"ceos\"\t1\n",
      "\"cernosek\"\t1\n",
      "\"certain\"\t1\n",
      "\"certainly\"\t4\n",
      "\"certificates\"\t1\n",
      "\"cgi\"\t5\n",
      "\"cha\"\t1\n",
      "\"chaeap\"\t1\n",
      "\"chairing\"\t1\n",
      "\"chairman\"\t4\n",
      "\"challenge\"\t1\n",
      "\"challenges\"\t1\n",
      "\"challenging\"\t3\n",
      "\"chambers\"\t1\n",
      "\"champion\"\t3\n",
      "\"chance\"\t6\n",
      "\"chances\"\t4\n",
      "\"chancesto\"\t1\n",
      "\"change\"\t16\n",
      "\"changed\"\t1\n",
      "\"changes\"\t4\n",
      "\"changing\"\t1\n",
      "\"channel\"\t1\n",
      "\"chapman\"\t4\n",
      "\"char\"\t2\n",
      "\"charge\"\t11\n",
      "\"charges\"\t1\n",
      "\"charlie\"\t1\n",
      "\"charset\"\t11\n",
      "\"chart\"\t1\n",
      "\"charter\"\t2\n",
      "\"chartroom\"\t1\n",
      "\"charts\"\t2\n",
      "\"chatham\"\t1\n",
      "\"cheaep\"\t1\n",
      "\"cheap\"\t1\n",
      "\"cheapsoft\"\t3\n",
      "\"cheated\"\t4\n",
      "\"check\"\t3\n",
      "\"checking\"\t4\n",
      "\"checks\"\t1\n",
      "\"cheeap\"\t1\n",
      "\"cheeky\"\t1\n",
      "\"cheers\"\t1\n",
      "\"chewing\"\t2\n",
      "\"chief\"\t4\n",
      "\"child\"\t3\n",
      "\"children\"\t3\n",
      "\"chile\"\t2\n",
      "\"chill\"\t1\n",
      "\"china\"\t3\n",
      "\"chinamen\"\t1\n",
      "\"chinese\"\t1\n",
      "\"chip\"\t1\n",
      "\"chirano\"\t4\n",
      "\"chisholm\"\t1\n",
      "\"choice\"\t2\n",
      "\"chokshi\"\t1\n",
      "\"cholesterol\"\t1\n",
      "\"choose\"\t4\n",
      "\"chosen\"\t4\n",
      "\"chris\"\t1\n",
      "\"christi\"\t1\n",
      "\"christian\"\t1\n",
      "\"christine\"\t1\n",
      "\"christmas\"\t20\n",
      "\"chromium\"\t1\n",
      "\"chronicles\"\t1\n",
      "\"chuck\"\t1\n",
      "\"chumming\"\t1\n",
      "\"chums\"\t1\n",
      "\"chunk\"\t1\n",
      "\"cialis\"\t2\n",
      "\"cigars\"\t1\n",
      "\"cindy\"\t5\n",
      "\"cinergy\"\t1\n",
      "\"circumstances\"\t1\n",
      "\"citizens\"\t2\n",
      "\"citrus\"\t2\n",
      "\"city\"\t5\n",
      "\"civilizirano\"\t1\n",
      "\"cj\"\t5\n",
      "\"ckgby\"\t1\n",
      "\"ckily\"\t1\n",
      "\"claiis\"\t1\n",
      "\"claim\"\t3\n",
      "\"claimed\"\t1\n",
      "\"claiming\"\t1\n",
      "\"claims\"\t4\n",
      "\"clamp\"\t1\n",
      "\"clare\"\t1\n",
      "\"clarification\"\t2\n",
      "\"clarity\"\t1\n",
      "\"clark\"\t1\n",
      "\"class\"\t2\n",
      "\"classes\"\t1\n",
      "\"classic\"\t1\n",
      "\"classifieds\"\t1\n",
      "\"classrom\"\t1\n",
      "\"claude\"\t1\n",
      "\"clear\"\t12\n",
      "\"clearing\"\t1\n",
      "\"clearly\"\t1\n",
      "\"clem\"\t1\n",
      "\"clemmons\"\t1\n",
      "\"clemons\"\t1\n",
      "\"click\"\t41\n",
      "\"clicking\"\t1\n",
      "\"client\"\t1\n",
      "\"clients\"\t1\n",
      "\"cliffhanger\"\t2\n",
      "\"cliickk\"\t2\n",
      "\"climate\"\t1\n",
      "\"clinches\"\t1\n",
      "\"clinging\"\t1\n",
      "\"clips\"\t1\n",
      "\"clon\"\t2\n",
      "\"clonazepam\"\t1\n",
      "\"close\"\t6\n",
      "\"closed\"\t1\n",
      "\"closely\"\t5\n",
      "\"closer\"\t1\n",
      "\"closure\"\t1\n",
      "\"clu\"\t1\n",
      "\"club\"\t1\n",
      "\"cmenergy\"\t1\n",
      "\"co\"\t5\n",
      "\"coaching\"\t1\n",
      "\"coal\"\t2\n",
      "\"coastenergy\"\t1\n",
      "\"cobalt\"\t1\n",
      "\"cochilco\"\t1\n",
      "\"coding\"\t2\n",
      "\"coe\"\t4\n",
      "\"coffee\"\t5\n",
      "\"cohen\"\t1\n",
      "\"cold\"\t2\n",
      "\"coleman\"\t1\n",
      "\"collaborate\"\t3\n",
      "\"collect\"\t2\n",
      "\"college\"\t3\n",
      "\"colliw\"\t1\n",
      "\"colloquy\"\t1\n",
      "\"color\"\t19\n",
      "\"colored\"\t2\n",
      "\"colors\"\t1\n",
      "\"colour\"\t1\n",
      "\"columnar\"\t1\n",
      "\"com\"\t227\n",
      "\"combo\"\t1\n",
      "\"comclick\"\t1\n",
      "\"come\"\t19\n",
      "\"comes\"\t6\n",
      "\"comhttp\"\t1\n",
      "\"coming\"\t5\n",
      "\"commence\"\t2\n",
      "\"commenced\"\t1\n",
      "\"commencement\"\t1\n",
      "\"commentaries\"\t3\n",
      "\"commentary\"\t18\n",
      "\"commentaryto\"\t1\n",
      "\"comments\"\t13\n",
      "\"commercial\"\t20\n",
      "\"commission\"\t3\n",
      "\"commissions\"\t2\n",
      "\"committee\"\t2\n",
      "\"commodities\"\t1\n",
      "\"commodity\"\t8\n",
      "\"common\"\t2\n",
      "\"communicate\"\t2\n",
      "\"communicating\"\t2\n",
      "\"communication\"\t9\n",
      "\"communities\"\t3\n",
      "\"community\"\t23\n",
      "\"companies\"\t8\n",
      "\"company\"\t25\n",
      "\"compare\"\t6\n",
      "\"compared\"\t1\n",
      "\"compelling\"\t1\n",
      "\"compensation\"\t2\n",
      "\"compete\"\t2\n",
      "\"competencies\"\t2\n",
      "\"competing\"\t3\n",
      "\"competition\"\t2\n",
      "\"competitive\"\t3\n",
      "\"complete\"\t4\n",
      "\"completed\"\t2\n",
      "\"completely\"\t2\n",
      "\"completing\"\t1\n",
      "\"completion\"\t3\n",
      "\"compliance\"\t1\n",
      "\"complicated\"\t3\n",
      "\"complications\"\t1\n",
      "\"complimentary\"\t1\n",
      "\"compliments\"\t1\n",
      "\"components\"\t1\n",
      "\"comprehensive\"\t1\n",
      "\"computational\"\t1\n",
      "\"computer\"\t7\n",
      "\"comwww\"\t11\n",
      "\"concealed\"\t2\n",
      "\"conceived\"\t1\n",
      "\"concept\"\t1\n",
      "\"concern\"\t1\n",
      "\"concerned\"\t1\n",
      "\"concernig\"\t2\n",
      "\"concerning\"\t8\n",
      "\"concerns\"\t4\n",
      "\"concluding\"\t2\n",
      "\"condition\"\t2\n",
      "\"conduct\"\t2\n",
      "\"conductor\"\t1\n",
      "\"conference\"\t7\n",
      "\"conferences\"\t1\n",
      "\"confided\"\t1\n",
      "\"confidence\"\t1\n",
      "\"confident\"\t1\n",
      "\"confidential\"\t5\n",
      "\"configuration\"\t1\n",
      "\"confirmation\"\t3\n",
      "\"confirmations\"\t5\n",
      "\"confirmed\"\t1\n",
      "\"conflict\"\t1\n",
      "\"confuses\"\t1\n",
      "\"confusing\"\t1\n",
      "\"congrats\"\t1\n",
      "\"congratulations\"\t6\n",
      "\"congratulatory\"\t1\n",
      "\"conn\"\t1\n",
      "\"connected\"\t1\n",
      "\"connection\"\t3\n",
      "\"connective\"\t1\n",
      "\"connie\"\t1\n",
      "\"conscience\"\t1\n",
      "\"consciously\"\t1\n",
      "\"consequently\"\t1\n",
      "\"consider\"\t4\n",
      "\"considered\"\t1\n",
      "\"consistent\"\t1\n",
      "\"consistently\"\t2\n",
      "\"consisting\"\t1\n",
      "\"consolidation\"\t6\n",
      "\"constantly\"\t1\n",
      "\"consternation\"\t1\n",
      "\"construction\"\t1\n",
      "\"constructive\"\t1\n",
      "\"consultant\"\t3\n",
      "\"consultation\"\t2\n",
      "\"consumer\"\t5\n",
      "\"consumers\"\t3\n",
      "\"consummating\"\t1\n",
      "\"contact\"\t31\n",
      "\"contacts\"\t1\n",
      "\"containing\"\t3\n",
      "\"contains\"\t4\n",
      "\"contemplation\"\t1\n",
      "\"content\"\t13\n",
      "\"continents\"\t1\n",
      "\"continue\"\t15\n",
      "\"continued\"\t3\n",
      "\"continues\"\t3\n",
      "\"continuing\"\t1\n",
      "\"contract\"\t10\n",
      "\"contracted\"\t2\n",
      "\"contracts\"\t12\n",
      "\"contratulations\"\t1\n",
      "\"contribution\"\t1\n",
      "\"control\"\t8\n",
      "\"controlled\"\t2\n",
      "\"controls\"\t6\n",
      "\"convenience\"\t1\n",
      "\"convenient\"\t1\n",
      "\"conversation\"\t1\n",
      "\"conversations\"\t1\n",
      "\"convince\"\t2\n",
      "\"convincible\"\t1\n",
      "\"cook\"\t3\n",
      "\"cool\"\t3\n",
      "\"cooler\"\t1\n",
      "\"cooperation\"\t3\n",
      "\"coordinate\"\t5\n",
      "\"coordinating\"\t1\n",
      "\"coordination\"\t3\n",
      "\"coordinator\"\t1\n",
      "\"cop\"\t2\n",
      "\"copartnery\"\t1\n",
      "\"copenhagen\"\t1\n",
      "\"copper\"\t7\n",
      "\"copy\"\t12\n",
      "\"copying\"\t1\n",
      "\"copyright\"\t7\n",
      "\"coral\"\t4\n",
      "\"cordes\"\t1\n",
      "\"core\"\t1\n",
      "\"corel\"\t4\n",
      "\"coreldraw\"\t2\n",
      "\"corey\"\t2\n",
      "\"cornet\"\t2\n",
      "\"corp\"\t31\n",
      "\"corporate\"\t8\n",
      "\"corporation\"\t4\n",
      "\"correction\"\t2\n",
      "\"correspondence\"\t2\n",
      "\"cost\"\t8\n",
      "\"costed\"\t1\n",
      "\"costs\"\t2\n",
      "\"cote\"\t3\n",
      "\"cotroneo\"\t1\n",
      "\"cough\"\t1\n",
      "\"could\"\t18\n",
      "\"couldn\"\t1\n",
      "\"counted\"\t1\n",
      "\"counterparty\"\t2\n",
      "\"countries\"\t2\n",
      "\"country\"\t23\n",
      "\"couple\"\t2\n",
      "\"course\"\t11\n",
      "\"courses\"\t1\n",
      "\"court\"\t4\n",
      "\"courtesy\"\t1\n",
      "\"cover\"\t2\n",
      "\"coverage\"\t3\n",
      "\"cowry\"\t1\n",
      "\"cp\"\t1\n",
      "\"cpm\"\t6\n",
      "\"cpuc\"\t3\n",
      "\"craft\"\t1\n",
      "\"craig\"\t1\n",
      "\"crank\"\t1\n",
      "\"crapbedspring\"\t1\n",
      "\"crawled\"\t1\n",
      "\"crazy\"\t1\n",
      "\"cre\"\t1\n",
      "\"create\"\t13\n",
      "\"created\"\t7\n",
      "\"creates\"\t2\n",
      "\"creating\"\t2\n",
      "\"creation\"\t3\n",
      "\"creativity\"\t1\n",
      "\"credi\"\t1\n",
      "\"credibility\"\t1\n",
      "\"credit\"\t20\n",
      "\"creditor\"\t1\n",
      "\"creditors\"\t4\n",
      "\"credits\"\t1\n",
      "\"crenshaw\"\t13\n",
      "\"crespigny\"\t2\n",
      "\"crest\"\t1\n",
      "\"critical\"\t10\n",
      "\"critically\"\t2\n",
      "\"critique\"\t1\n",
      "\"crooked\"\t1\n",
      "\"cross\"\t3\n",
      "\"crowd\"\t2\n",
      "\"crowdbut\"\t1\n",
      "\"cryogenic\"\t1\n",
      "\"crystal\"\t2\n",
      "\"cs\"\t2\n",
      "\"csikos\"\t1\n",
      "\"cst\"\t1\n",
      "\"ctise\"\t1\n",
      "\"cultural\"\t1\n",
      "\"cure\"\t2\n",
      "\"cures\"\t1\n",
      "\"curio\"\t1\n",
      "\"currency\"\t1\n",
      "\"current\"\t9\n",
      "\"currently\"\t16\n",
      "\"curricula\"\t1\n",
      "\"curriculum\"\t5\n",
      "\"curtain\"\t1\n",
      "\"cushion\"\t1\n",
      "\"custody\"\t1\n",
      "\"custom\"\t1\n",
      "\"customer\"\t24\n",
      "\"customers\"\t4\n",
      "\"customizable\"\t1\n",
      "\"cuts\"\t1\n",
      "\"cyberopps\"\t2\n",
      "\"cynthia\"\t1\n",
      "\"czkkrxht\"\t1\n",
      "\"dahlienweg\"\t1\n",
      "\"daily\"\t3\n",
      "\"dale\"\t1\n",
      "\"damage\"\t1\n",
      "\"damages\"\t1\n",
      "\"damned\"\t1\n",
      "\"damorganjr\"\t1\n",
      "\"damorgarjr\"\t1\n",
      "\"dana\"\t1\n",
      "\"dancing\"\t1\n",
      "\"dangerous\"\t1\n",
      "\"daniel\"\t2\n",
      "\"danielle\"\t2\n",
      "\"daniels\"\t1\n",
      "\"danny\"\t1\n",
      "\"daren\"\t7\n",
      "\"darren\"\t2\n",
      "\"database\"\t1\n",
      "\"datacenter\"\t1\n",
      "\"date\"\t5\n",
      "\"dates\"\t4\n",
      "\"dave\"\t9\n",
      "\"davenport\"\t1\n",
      "\"david\"\t19\n",
      "\"davidyi\"\t1\n",
      "\"davis\"\t10\n",
      "\"daw\"\t1\n",
      "\"dawn\"\t1\n",
      "\"day\"\t22\n",
      "\"days\"\t10\n",
      "\"daysor\"\t1\n",
      "\"daytime\"\t2\n",
      "\"dc\"\t1\n",
      "\"dci\"\t1\n",
      "\"dclemons\"\t1\n",
      "\"dcoit\"\t1\n",
      "\"de\"\t3\n",
      "\"dea\"\t1\n",
      "\"dead\"\t3\n",
      "\"deadline\"\t6\n",
      "\"deadlines\"\t1\n",
      "\"deal\"\t15\n",
      "\"deals\"\t3\n",
      "\"dean\"\t1\n",
      "\"dear\"\t6\n",
      "\"death\"\t3\n",
      "\"debt\"\t12\n",
      "\"debts\"\t3\n",
      "\"dec\"\t11\n",
      "\"december\"\t19\n",
      "\"decided\"\t5\n",
      "\"decides\"\t1\n",
      "\"decision\"\t2\n",
      "\"decreases\"\t1\n",
      "\"deeds\"\t2\n",
      "\"deemed\"\t2\n",
      "\"deep\"\t1\n",
      "\"deeper\"\t1\n",
      "\"defeat\"\t1\n",
      "\"deficient\"\t1\n",
      "\"defined\"\t1\n",
      "\"delainey\"\t8\n",
      "\"delay\"\t1\n",
      "\"delayed\"\t2\n",
      "\"delays\"\t2\n",
      "\"delegating\"\t1\n",
      "\"delete\"\t8\n",
      "\"delight\"\t1\n",
      "\"delinquent\"\t1\n",
      "\"deliv\"\t2\n",
      "\"deliver\"\t1\n",
      "\"delivered\"\t5\n",
      "\"deliveries\"\t2\n",
      "\"delivering\"\t1\n",
      "\"delivery\"\t11\n",
      "\"delphi\"\t1\n",
      "\"delusive\"\t1\n",
      "\"delux\"\t1\n",
      "\"demand\"\t3\n",
      "\"democratic\"\t2\n",
      "\"democrats\"\t3\n",
      "\"demonstrate\"\t2\n",
      "\"denied\"\t1\n",
      "\"dennis\"\t3\n",
      "\"density\"\t1\n",
      "\"denys\"\t1\n",
      "\"department\"\t1\n",
      "\"depending\"\t2\n",
      "\"deposit\"\t4\n",
      "\"deposited\"\t3\n",
      "\"deposits\"\t2\n",
      "\"depression\"\t1\n",
      "\"dept\"\t2\n",
      "\"derivatives\"\t3\n",
      "\"descendent\"\t1\n",
      "\"described\"\t2\n",
      "\"description\"\t2\n",
      "\"desert\"\t1\n",
      "\"design\"\t9\n",
      "\"designed\"\t5\n",
      "\"designl\"\t1\n",
      "\"designs\"\t4\n",
      "\"desire\"\t3\n",
      "\"desk\"\t12\n",
      "\"desks\"\t2\n",
      "\"desktop\"\t1\n",
      "\"desmeules\"\t1\n",
      "\"desperate\"\t1\n",
      "\"despise\"\t1\n",
      "\"despite\"\t2\n",
      "\"destination\"\t2\n",
      "\"destroy\"\t1\n",
      "\"detail\"\t2\n",
      "\"detailed\"\t4\n",
      "\"details\"\t3\n",
      "\"determine\"\t1\n",
      "\"detract\"\t1\n",
      "\"developed\"\t5\n",
      "\"developing\"\t2\n",
      "\"development\"\t16\n",
      "\"device\"\t1\n",
      "\"devoid\"\t1\n",
      "\"dextails\"\t1\n",
      "\"dfelsinger\"\t1\n",
      "\"dfur\"\t1\n",
      "\"dhar\"\t4\n",
      "\"dhyngem\"\t1\n",
      "\"dial\"\t2\n",
      "\"diamond\"\t2\n",
      "\"diamonds\"\t1\n",
      "\"diane\"\t1\n",
      "\"diaz\"\t2\n",
      "\"dicine\"\t1\n",
      "\"dictate\"\t1\n",
      "\"dictating\"\t1\n",
      "\"dictionary\"\t1\n",
      "\"did\"\t8\n",
      "\"didn\"\t4\n",
      "\"didrex\"\t1\n",
      "\"different\"\t5\n",
      "\"difficult\"\t5\n",
      "\"difficulty\"\t1\n",
      "\"digging\"\t1\n",
      "\"digital\"\t1\n",
      "\"dignity\"\t1\n",
      "\"digression\"\t1\n",
      "\"diligence\"\t1\n",
      "\"diminished\"\t1\n",
      "\"dinner\"\t2\n",
      "\"direct\"\t4\n",
      "\"directed\"\t1\n",
      "\"directing\"\t1\n",
      "\"direction\"\t4\n",
      "\"directions\"\t4\n",
      "\"directly\"\t7\n",
      "\"director\"\t6\n",
      "\"directories\"\t2\n",
      "\"dirtier\"\t1\n",
      "\"disable\"\t1\n",
      "\"disagreement\"\t1\n",
      "\"disappearance\"\t1\n",
      "\"disappointed\"\t1\n",
      "\"discarded\"\t3\n",
      "\"disclaimer\"\t1\n",
      "\"disclosed\"\t2\n",
      "\"discontinue\"\t2\n",
      "\"discoount\"\t1\n",
      "\"discoouunt\"\t1\n",
      "\"discounnt\"\t1\n",
      "\"discount\"\t1\n",
      "\"discounted\"\t1\n",
      "\"discounts\"\t1\n",
      "\"discover\"\t3\n",
      "\"discretely\"\t1\n",
      "\"discretion\"\t1\n",
      "\"discuss\"\t6\n",
      "\"discussed\"\t2\n",
      "\"discussion\"\t8\n",
      "\"disease\"\t1\n",
      "\"dish\"\t3\n",
      "\"dishes\"\t1\n",
      "\"disintegration\"\t1\n",
      "\"dismissed\"\t1\n",
      "\"disordersclump\"\t1\n",
      "\"disordersshrink\"\t1\n",
      "\"disparate\"\t1\n",
      "\"displayed\"\t1\n",
      "\"disposed\"\t1\n",
      "\"disqualified\"\t1\n",
      "\"dissemination\"\t1\n",
      "\"distance\"\t5\n",
      "\"distort\"\t1\n",
      "\"distracted\"\t1\n",
      "\"distributed\"\t1\n",
      "\"distribution\"\t3\n",
      "\"distributions\"\t2\n",
      "\"district\"\t4\n",
      "\"ditch\"\t1\n",
      "\"divert\"\t1\n",
      "\"diverted\"\t1\n",
      "\"divided\"\t1\n",
      "\"division\"\t1\n",
      "\"dkohler\"\t1\n",
      "\"dmao\"\t1\n",
      "\"dnb\"\t1\n",
      "\"do\"\t41\n",
      "\"dobmeos\"\t1\n",
      "\"doc\"\t3\n",
      "\"doctor\"\t2\n",
      "\"doctoral\"\t1\n",
      "\"doctors\"\t2\n",
      "\"doctrine\"\t4\n",
      "\"documenting\"\t2\n",
      "\"documents\"\t4\n",
      "\"does\"\t11\n",
      "\"doesn\"\t10\n",
      "\"doff\"\t1\n",
      "\"dog\"\t1\n",
      "\"doing\"\t6\n",
      "\"dol\"\t1\n",
      "\"dollar\"\t1\n",
      "\"dollars\"\t7\n",
      "\"dolls\"\t1\n",
      "\"domain\"\t5\n",
      "\"domestic\"\t1\n",
      "\"don\"\t33\n",
      "\"done\"\t6\n",
      "\"dont\"\t1\n",
      "\"door\"\t5\n",
      "\"double\"\t2\n",
      "\"doubt\"\t3\n",
      "\"doubts\"\t1\n",
      "\"doug\"\t1\n",
      "\"down\"\t11\n",
      "\"download\"\t1\n",
      "\"dozens\"\t1\n",
      "\"draft\"\t2\n",
      "\"drafting\"\t1\n",
      "\"dramatic\"\t1\n",
      "\"draw\"\t5\n",
      "\"drawing\"\t5\n",
      "\"drawn\"\t2\n",
      "\"dreamwaver\"\t2\n",
      "\"drew\"\t3\n",
      "\"drinking\"\t2\n",
      "\"drive\"\t2\n",
      "\"drives\"\t1\n",
      "\"dronn\"\t1\n",
      "\"drown\"\t1\n",
      "\"drowning\"\t1\n",
      "\"drug\"\t1\n",
      "\"drugs\"\t2\n",
      "\"dryblower\"\t1\n",
      "\"dubhe\"\t1\n",
      "\"dubuque\"\t3\n",
      "\"duck\"\t1\n",
      "\"due\"\t9\n",
      "\"duke\"\t4\n",
      "\"dunns\"\t1\n",
      "\"duns\"\t2\n",
      "\"duplicate\"\t1\n",
      "\"during\"\t9\n",
      "\"dutchess\"\t1\n",
      "\"dutyfreesoft\"\t1\n",
      "\"dvd\"\t1\n",
      "\"dwr\"\t3\n",
      "\"dxqrgu\"\t1\n",
      "\"dycmpf\"\t1\n",
      "\"dynamic\"\t2\n",
      "\"dynamically\"\t1\n",
      "\"dynamics\"\t2\n",
      "\"dynegy\"\t11\n",
      "\"each\"\t27\n",
      "\"earlier\"\t4\n",
      "\"early\"\t8\n",
      "\"earn\"\t6\n",
      "\"earning\"\t1\n",
      "\"earth\"\t1\n",
      "\"earths\"\t1\n",
      "\"easily\"\t4\n",
      "\"east\"\t1\n",
      "\"eastern\"\t1\n",
      "\"easy\"\t16\n",
      "\"eat\"\t3\n",
      "\"eatables\"\t1\n",
      "\"eating\"\t2\n",
      "\"eb\"\t16\n",
      "\"ebl\"\t1\n",
      "\"ebook\"\t3\n",
      "\"ebooks\"\t1\n",
      "\"ebs\"\t1\n",
      "\"ecarmst\"\t1\n",
      "\"eclassifiedshq\"\t1\n",
      "\"ecole\"\t1\n",
      "\"ecom\"\t1\n",
      "\"ecomog\"\t3\n",
      "\"economic\"\t2\n",
      "\"economically\"\t1\n",
      "\"economics\"\t1\n",
      "\"economy\"\t1\n",
      "\"ect\"\t382\n",
      "\"ed\"\t1\n",
      "\"edge\"\t1\n",
      "\"edison\"\t4\n",
      "\"edit\"\t11\n",
      "\"edition\"\t5\n",
      "\"editor\"\t3\n",
      "\"editorial\"\t1\n",
      "\"edt\"\t2\n",
      "\"ee\"\t2\n",
      "\"ees\"\t10\n",
      "\"effect\"\t2\n",
      "\"effective\"\t11\n",
      "\"effectively\"\t5\n",
      "\"effects\"\t1\n",
      "\"efficiency\"\t2\n",
      "\"effort\"\t6\n",
      "\"efforts\"\t2\n",
      "\"efs\"\t1\n",
      "\"egep\"\t1\n",
      "\"ego\"\t2\n",
      "\"eh\"\t1\n",
      "\"ehronline\"\t1\n",
      "\"eiben\"\t1\n",
      "\"eight\"\t2\n",
      "\"eighty\"\t1\n",
      "\"eileen\"\t1\n",
      "\"eincomplete\"\t1\n",
      "\"either\"\t9\n",
      "\"el\"\t2\n",
      "\"elbow\"\t1\n",
      "\"elderly\"\t1\n",
      "\"election\"\t1\n",
      "\"elections\"\t1\n",
      "\"electric\"\t1\n",
      "\"electricity\"\t1\n",
      "\"eliminate\"\t3\n",
      "\"eliminates\"\t1\n",
      "\"eliminationstop\"\t1\n",
      "\"ellendale\"\t2\n",
      "\"ello\"\t1\n",
      "\"elmira\"\t1\n",
      "\"else\"\t2\n",
      "\"elses\"\t2\n",
      "\"emai\"\t1\n",
      "\"email\"\t46\n",
      "\"emailing\"\t2\n",
      "\"embargo\"\t1\n",
      "\"emeet\"\t1\n",
      "\"emerged\"\t1\n",
      "\"emerging\"\t2\n",
      "\"emigrant\"\t1\n",
      "\"emigrants\"\t1\n",
      "\"eminent\"\t2\n",
      "\"emma\"\t1\n",
      "\"emotion\"\t1\n",
      "\"emotional\"\t1\n",
      "\"emove\"\t1\n",
      "\"emphasis\"\t1\n",
      "\"emphasize\"\t1\n",
      "\"emphatically\"\t1\n",
      "\"employed\"\t2\n",
      "\"employee\"\t6\n",
      "\"employees\"\t7\n",
      "\"employer\"\t1\n",
      "\"employment\"\t1\n",
      "\"empowered\"\t1\n",
      "\"en\"\t3\n",
      "\"ena\"\t10\n",
      "\"enable\"\t4\n",
      "\"enacted\"\t2\n",
      "\"encarta\"\t1\n",
      "\"encoding\"\t2\n",
      "\"encompassing\"\t1\n",
      "\"encounters\"\t1\n",
      "\"encourage\"\t4\n",
      "\"encouraged\"\t3\n",
      "\"encyclopedia\"\t1\n",
      "\"end\"\t19\n",
      "\"ending\"\t2\n",
      "\"endless\"\t1\n",
      "\"endorsements\"\t1\n",
      "\"ends\"\t1\n",
      "\"energetic\"\t1\n",
      "\"energy\"\t44\n",
      "\"eneric\"\t1\n",
      "\"eng\"\t1\n",
      "\"engageenergy\"\t1\n",
      "\"engine\"\t3\n",
      "\"engineergeodetic\"\t1\n",
      "\"engineering\"\t2\n",
      "\"engines\"\t2\n",
      "\"enhance\"\t3\n",
      "\"enhancing\"\t1\n",
      "\"enjoy\"\t2\n",
      "\"enormous\"\t1\n",
      "\"enough\"\t6\n",
      "\"enron\"\t127\n",
      "\"enrononline\"\t4\n",
      "\"ensure\"\t3\n",
      "\"ensuring\"\t2\n",
      "\"enter\"\t7\n",
      "\"entered\"\t10\n",
      "\"entergy\"\t6\n",
      "\"entergyr\"\t1\n",
      "\"entering\"\t2\n",
      "\"enterprise\"\t4\n",
      "\"enters\"\t1\n",
      "\"entertaining\"\t1\n",
      "\"entex\"\t14\n",
      "\"entire\"\t2\n",
      "\"entirely\"\t2\n",
      "\"entity\"\t3\n",
      "\"entries\"\t3\n",
      "\"entry\"\t1\n",
      "\"environment\"\t3\n",
      "\"environmental\"\t1\n",
      "\"envy\"\t1\n",
      "\"eo\"\t1\n",
      "\"eops\"\t1\n",
      "\"epam\"\t2\n",
      "\"epcm\"\t2\n",
      "\"epenergy\"\t5\n",
      "\"epmi\"\t2\n",
      "\"eprm\"\t1\n",
      "\"epsc\"\t1\n",
      "\"equity\"\t5\n",
      "\"equivelant\"\t1\n",
      "\"er\"\t2\n",
      "\"ere\"\t1\n",
      "\"ernest\"\t1\n",
      "\"erroneously\"\t1\n",
      "\"error\"\t8\n",
      "\"errors\"\t6\n",
      "\"esa\"\t1\n",
      "\"escape\"\t2\n",
      "\"esiear\"\t2\n",
      "\"espcially\"\t1\n",
      "\"especially\"\t4\n",
      "\"essentially\"\t1\n",
      "\"est\"\t1\n",
      "\"establish\"\t8\n",
      "\"established\"\t3\n",
      "\"establishes\"\t1\n",
      "\"establishthe\"\t1\n",
      "\"estimate\"\t2\n",
      "\"etacitne\"\t1\n",
      "\"etc\"\t9\n",
      "\"eternal\"\t1\n",
      "\"ethic\"\t1\n",
      "\"etringer\"\t2\n",
      "\"europe\"\t1\n",
      "\"european\"\t2\n",
      "\"evaluate\"\t2\n",
      "\"evaluating\"\t1\n",
      "\"evaluation\"\t1\n",
      "\"evelon\"\t1\n",
      "\"even\"\t16\n",
      "\"evening\"\t3\n",
      "\"events\"\t2\n",
      "\"eventually\"\t2\n",
      "\"ever\"\t5\n",
      "\"every\"\t14\n",
      "\"everyday\"\t2\n",
      "\"everyone\"\t17\n",
      "\"everything\"\t8\n",
      "\"evolution\"\t1\n",
      "\"eworld\"\t4\n",
      "\"exact\"\t2\n",
      "\"exactly\"\t4\n",
      "\"exaggerate\"\t1\n",
      "\"examination\"\t1\n",
      "\"examine\"\t3\n",
      "\"examing\"\t1\n",
      "\"examining\"\t1\n",
      "\"example\"\t7\n",
      "\"examples\"\t1\n",
      "\"exceed\"\t1\n",
      "\"exceeded\"\t2\n",
      "\"excellent\"\t4\n",
      "\"except\"\t1\n",
      "\"exception\"\t1\n",
      "\"excerpts\"\t1\n",
      "\"excess\"\t1\n",
      "\"exchange\"\t13\n",
      "\"exchanges\"\t1\n",
      "\"exchanging\"\t1\n",
      "\"excited\"\t3\n",
      "\"exciting\"\t1\n",
      "\"excluding\"\t2\n",
      "\"exclusive\"\t1\n",
      "\"execute\"\t1\n",
      "\"executed\"\t1\n",
      "\"executing\"\t2\n",
      "\"execution\"\t1\n",
      "\"executive\"\t6\n",
      "\"executives\"\t1\n",
      "\"exemptions\"\t2\n",
      "\"exhausted\"\t1\n",
      "\"exhibit\"\t5\n",
      "\"exhibits\"\t2\n",
      "\"exist\"\t2\n",
      "\"existing\"\t5\n",
      "\"expanded\"\t1\n",
      "\"expanding\"\t1\n",
      "\"expanse\"\t1\n",
      "\"expect\"\t9\n",
      "\"expectation\"\t2\n",
      "\"expectations\"\t4\n",
      "\"expected\"\t6\n",
      "\"expecting\"\t2\n",
      "\"expects\"\t3\n",
      "\"expended\"\t1\n",
      "\"expenditures\"\t1\n",
      "\"expenses\"\t3\n",
      "\"experience\"\t17\n",
      "\"experiences\"\t1\n",
      "\"experiment\"\t1\n",
      "\"expertise\"\t8\n",
      "\"expire\"\t1\n",
      "\"expired\"\t1\n",
      "\"explain\"\t2\n",
      "\"explained\"\t1\n",
      "\"explaing\"\t2\n",
      "\"explaining\"\t2\n",
      "\"explicitly\"\t1\n",
      "\"exploration\"\t2\n",
      "\"explorer\"\t3\n",
      "\"exploring\"\t2\n",
      "\"expose\"\t1\n",
      "\"exposure\"\t2\n",
      "\"express\"\t4\n",
      "\"expressed\"\t1\n",
      "\"expressway\"\t1\n",
      "\"ext\"\t3\n",
      "\"extend\"\t1\n",
      "\"extended\"\t3\n",
      "\"extension\"\t1\n",
      "\"extent\"\t1\n",
      "\"externally\"\t2\n",
      "\"extra\"\t7\n",
      "\"extremal\"\t1\n",
      "\"extreme\"\t1\n",
      "\"exultant\"\t1\n",
      "\"eye\"\t1\n",
      "\"eyebrow\"\t2\n",
      "\"eyes\"\t2\n",
      "\"ezine\"\t5\n",
      "\"fabaclbo\"\t1\n",
      "\"face\"\t1\n",
      "\"facelift\"\t1\n",
      "\"faces\"\t1\n",
      "\"facilitate\"\t4\n",
      "\"facilitators\"\t1\n",
      "\"facility\"\t1\n",
      "\"faclities\"\t1\n",
      "\"fact\"\t8\n",
      "\"factor\"\t1\n",
      "\"factual\"\t1\n",
      "\"faded\"\t1\n",
      "\"fails\"\t1\n",
      "\"fainted\"\t1\n",
      "\"fair\"\t2\n",
      "\"faith\"\t1\n",
      "\"fall\"\t2\n",
      "\"fallon\"\t1\n",
      "\"fame\"\t3\n",
      "\"families\"\t2\n",
      "\"family\"\t3\n",
      "\"famous\"\t1\n",
      "\"fanny\"\t1\n",
      "\"fantastic\"\t1\n",
      "\"far\"\t5\n",
      "\"farm\"\t1\n",
      "\"farmer\"\t5\n",
      "\"fashion\"\t1\n",
      "\"fast\"\t4\n",
      "\"faster\"\t2\n",
      "\"fat\"\t1\n",
      "\"father\"\t4\n",
      "\"fathers\"\t1\n",
      "\"fattroglodyte\"\t1\n",
      "\"fault\"\t1\n",
      "\"favor\"\t4\n",
      "\"favorably\"\t1\n",
      "\"favorite\"\t7\n",
      "\"favourably\"\t1\n",
      "\"fax\"\t9\n",
      "\"fe\"\t1\n",
      "\"fear\"\t4\n",
      "\"feature\"\t1\n",
      "\"featured\"\t2\n",
      "\"features\"\t6\n",
      "\"feb\"\t3\n",
      "\"february\"\t10\n",
      "\"federal\"\t4\n",
      "\"fee\"\t6\n",
      "\"feel\"\t19\n",
      "\"feeling\"\t3\n",
      "\"feelings\"\t1\n",
      "\"fees\"\t1\n",
      "\"feet\"\t1\n",
      "\"felipe\"\t2\n",
      "\"fell\"\t2\n",
      "\"fellow\"\t1\n",
      "\"felt\"\t2\n",
      "\"female\"\t3\n",
      "\"few\"\t12\n",
      "\"ffffa\"\t2\n",
      "\"fh\"\t2\n",
      "\"fiducial\"\t1\n",
      "\"field\"\t3\n",
      "\"fields\"\t1\n",
      "\"fifteen\"\t1\n",
      "\"fifth\"\t1\n",
      "\"fight\"\t2\n",
      "\"figure\"\t1\n",
      "\"figured\"\t1\n",
      "\"file\"\t6\n",
      "\"filed\"\t6\n",
      "\"files\"\t3\n",
      "\"filing\"\t11\n",
      "\"fill\"\t6\n",
      "\"filled\"\t2\n",
      "\"filling\"\t1\n",
      "\"filter\"\t1\n",
      "\"final\"\t6\n",
      "\"finalization\"\t2\n",
      "\"finalize\"\t1\n",
      "\"finally\"\t3\n",
      "\"finance\"\t4\n",
      "\"financial\"\t12\n",
      "\"financials\"\t1\n",
      "\"financing\"\t4\n",
      "\"find\"\t5\n",
      "\"finding\"\t1\n",
      "\"fine\"\t2\n",
      "\"finger\"\t1\n",
      "\"finished\"\t6\n",
      "\"finishing\"\t1\n",
      "\"finland\"\t1\n",
      "\"fior\"\t2\n",
      "\"fioricet\"\t1\n",
      "\"fired\"\t1\n",
      "\"fireworks\"\t1\n",
      "\"firing\"\t1\n",
      "\"firm\"\t5\n",
      "\"first\"\t34\n",
      "\"fischer\"\t1\n",
      "\"fishbeck\"\t1\n",
      "\"fit\"\t2\n",
      "\"five\"\t4\n",
      "\"fixed\"\t1\n",
      "\"fl\"\t1\n",
      "\"flash\"\t2\n",
      "\"flat\"\t5\n",
      "\"flatter\"\t1\n",
      "\"flight\"\t1\n",
      "\"flip\"\t1\n",
      "\"fln\"\t1\n",
      "\"floe\"\t1\n",
      "\"flood\"\t2\n",
      "\"floods\"\t1\n",
      "\"floor\"\t4\n",
      "\"flow\"\t8\n",
      "\"fluid\"\t1\n",
      "\"flustrated\"\t1\n",
      "\"flutter\"\t1\n",
      "\"flyers\"\t1\n",
      "\"flynn\"\t1\n",
      "\"focus\"\t4\n",
      "\"focusing\"\t4\n",
      "\"foday\"\t1\n",
      "\"folks\"\t3\n",
      "\"follow\"\t10\n",
      "\"followed\"\t2\n",
      "\"following\"\t27\n",
      "\"font\"\t3\n",
      "\"fonts\"\t2\n",
      "\"foo\"\t1\n",
      "\"foolishness\"\t1\n",
      "\"foot\"\t3\n",
      "\"footmen\"\t1\n",
      "\"fooxr\"\t1\n",
      "\"for\"\t374\n",
      "\"forbearance\"\t4\n",
      "\"force\"\t5\n",
      "\"forced\"\t1\n",
      "\"forces\"\t5\n",
      "\"forcing\"\t1\n",
      "\"ford\"\t1\n",
      "\"forecast\"\t1\n",
      "\"forecasts\"\t2\n",
      "\"foreigner\"\t1\n",
      "\"foreigners\"\t1\n",
      "\"forest\"\t1\n",
      "\"forestall\"\t1\n",
      "\"foretell\"\t1\n",
      "\"forever\"\t3\n",
      "\"forget\"\t1\n",
      "\"forgotten\"\t1\n",
      "\"forhome\"\t1\n",
      "\"fork\"\t2\n",
      "\"form\"\t11\n",
      "\"formal\"\t1\n",
      "\"formally\"\t2\n",
      "\"format\"\t3\n",
      "\"forms\"\t1\n",
      "\"formula\"\t2\n",
      "\"formulated\"\t1\n",
      "\"forp\"\t1\n",
      "\"fort\"\t1\n",
      "\"forthis\"\t1\n",
      "\"fortunately\"\t2\n",
      "\"forty\"\t1\n",
      "\"forum\"\t1\n",
      "\"forward\"\t13\n",
      "\"forwarded\"\t29\n",
      "\"forwarding\"\t1\n",
      "\"found\"\t6\n",
      "\"founder\"\t1\n",
      "\"founding\"\t1\n",
      "\"four\"\t8\n",
      "\"fp\"\t1\n",
      "\"fraction\"\t4\n",
      "\"frame\"\t1\n",
      "\"frames\"\t1\n",
      "\"fran\"\t2\n",
      "\"francisco\"\t1\n",
      "\"frank\"\t1\n",
      "\"fraternal\"\t1\n",
      "\"fraud\"\t1\n",
      "\"fred\"\t1\n",
      "\"free\"\t86\n",
      "\"freebie\"\t2\n",
      "\"freehand\"\t1\n",
      "\"freelinksnetwork\"\t4\n",
      "\"freeonline\"\t1\n",
      "\"freepicklotto\"\t2\n",
      "\"freese\"\t1\n",
      "\"freeze\"\t3\n",
      "\"frequently\"\t1\n",
      "\"frevert\"\t3\n",
      "\"friday\"\t6\n",
      "\"friend\"\t2\n",
      "\"friends\"\t3\n",
      "\"frightened\"\t1\n",
      "\"frightrob\"\t1\n",
      "\"from\"\t135\n",
      "\"front\"\t3\n",
      "\"fronts\"\t1\n",
      "\"frqee\"\t1\n",
      "\"fruit\"\t1\n",
      "\"frusco\"\t3\n",
      "\"frustration\"\t1\n",
      "\"ft\"\t2\n",
      "\"ftp\"\t1\n",
      "\"fuel\"\t1\n",
      "\"fulfill\"\t2\n",
      "\"full\"\t28\n",
      "\"fully\"\t3\n",
      "\"fun\"\t5\n",
      "\"function\"\t5\n",
      "\"functionality\"\t4\n",
      "\"functions\"\t5\n",
      "\"fund\"\t4\n",
      "\"fundamental\"\t2\n",
      "\"funded\"\t1\n",
      "\"funding\"\t1\n",
      "\"funds\"\t10\n",
      "\"fuohqjlsjcqp\"\t1\n",
      "\"further\"\t9\n",
      "\"furthermore\"\t1\n",
      "\"future\"\t14\n",
      "\"fw\"\t3\n",
      "\"fyi\"\t6\n",
      "\"fyl\"\t2\n",
      "\"gaining\"\t1\n",
      "\"game\"\t4\n",
      "\"gary\"\t7\n",
      "\"gas\"\t37\n",
      "\"gb\"\t1\n",
      "\"gee\"\t1\n",
      "\"gemstone\"\t1\n",
      "\"general\"\t5\n",
      "\"generalist\"\t1\n",
      "\"generalities\"\t1\n",
      "\"generalize\"\t1\n",
      "\"generalizing\"\t1\n",
      "\"generate\"\t1\n",
      "\"generating\"\t2\n",
      "\"generation\"\t5\n",
      "\"generators\"\t2\n",
      "\"generic\"\t6\n",
      "\"genuine\"\t2\n",
      "\"geoffrey\"\t1\n",
      "\"geographic\"\t4\n",
      "\"geomatics\"\t1\n",
      "\"george\"\t9\n",
      "\"georgel\"\t2\n",
      "\"georgia\"\t1\n",
      "\"germany\"\t3\n",
      "\"gerry\"\t2\n",
      "\"ges\"\t2\n",
      "\"get\"\t76\n",
      "\"gets\"\t3\n",
      "\"getterscan\"\t1\n",
      "\"getthe\"\t1\n",
      "\"getting\"\t8\n",
      "\"getyour\"\t1\n",
      "\"ghana\"\t2\n",
      "\"ghz\"\t1\n",
      "\"gibner\"\t8\n",
      "\"gibson\"\t1\n",
      "\"gift\"\t13\n",
      "\"gifts\"\t2\n",
      "\"gigabyte\"\t1\n",
      "\"gilbert\"\t1\n",
      "\"gilchrist\"\t1\n",
      "\"gimg\"\t1\n",
      "\"ginsu\"\t1\n",
      "\"girl\"\t4\n",
      "\"gis\"\t2\n",
      "\"gist\"\t2\n",
      "\"giv\"\t1\n",
      "\"give\"\t17\n",
      "\"glad\"\t1\n",
      "\"glandular\"\t1\n",
      "\"glaspie\"\t1\n",
      "\"glen\"\t1\n",
      "\"glencore\"\t2\n",
      "\"glenda\"\t1\n",
      "\"global\"\t44\n",
      "\"globe\"\t3\n",
      "\"glover\"\t1\n",
      "\"glut\"\t1\n",
      "\"gmx\"\t2\n",
      "\"go\"\t11\n",
      "\"goage\"\t1\n",
      "\"goal\"\t5\n",
      "\"goals\"\t1\n",
      "\"goatee\"\t1\n",
      "\"god\"\t3\n",
      "\"godly\"\t1\n",
      "\"goes\"\t1\n",
      "\"going\"\t27\n",
      "\"gold\"\t14\n",
      "\"golnaraghi\"\t1\n",
      "\"gone\"\t2\n",
      "\"gonzalez\"\t1\n",
      "\"good\"\t23\n",
      "\"goodbye\"\t1\n",
      "\"goodmorning\"\t2\n",
      "\"goods\"\t1\n",
      "\"gosnell\"\t1\n",
      "\"got\"\t7\n",
      "\"gov\"\t1\n",
      "\"government\"\t7\n",
      "\"governor\"\t5\n",
      "\"gpg\"\t1\n",
      "\"gpt\"\t1\n",
      "\"gra\"\t3\n",
      "\"grabbing\"\t1\n",
      "\"grabs\"\t1\n",
      "\"gracie\"\t2\n",
      "\"grade\"\t2\n",
      "\"grading\"\t1\n",
      "\"gradually\"\t1\n",
      "\"grammar\"\t1\n",
      "\"grand\"\t3\n",
      "\"grandfathered\"\t1\n",
      "\"grandma\"\t1\n",
      "\"grant\"\t6\n",
      "\"granted\"\t1\n",
      "\"granting\"\t1\n",
      "\"graphics\"\t5\n",
      "\"gratis\"\t1\n",
      "\"gravel\"\t1\n",
      "\"graves\"\t2\n",
      "\"gray\"\t2\n",
      "\"great\"\t20\n",
      "\"greater\"\t1\n",
      "\"greatest\"\t2\n",
      "\"greatly\"\t1\n",
      "\"greedily\"\t1\n",
      "\"greeted\"\t1\n",
      "\"greetings\"\t1\n",
      "\"greg\"\t3\n",
      "\"gregory\"\t1\n",
      "\"griddle\"\t1\n",
      "\"grief\"\t1\n",
      "\"grizzly\"\t1\n",
      "\"gross\"\t3\n",
      "\"ground\"\t1\n",
      "\"group\"\t22\n",
      "\"groups\"\t4\n",
      "\"growing\"\t1\n",
      "\"grown\"\t2\n",
      "\"growth\"\t4\n",
      "\"gs\"\t1\n",
      "\"gssgeomatics\"\t1\n",
      "\"guarantee\"\t5\n",
      "\"guaranteed\"\t4\n",
      "\"guerrilla\"\t1\n",
      "\"guess\"\t1\n",
      "\"guides\"\t1\n",
      "\"guinea\"\t1\n",
      "\"gullweig\"\t1\n",
      "\"gunners\"\t1\n",
      "\"guns\"\t1\n",
      "\"guru\"\t2\n",
      "\"gutierrez\"\t1\n",
      "\"guy\"\t2\n",
      "\"guys\"\t3\n",
      "\"gwen\"\t1\n",
      "\"gxol\"\t1\n",
      "\"gxxu\"\t1\n",
      "\"habitually\"\t1\n",
      "\"had\"\t20\n",
      "\"hair\"\t1\n",
      "\"hal\"\t1\n",
      "\"half\"\t2\n",
      "\"hall\"\t2\n",
      "\"hand\"\t5\n",
      "\"handle\"\t1\n",
      "\"handled\"\t2\n",
      "\"hands\"\t2\n",
      "\"hang\"\t1\n",
      "\"hangover\"\t1\n",
      "\"hans\"\t1\n",
      "\"happen\"\t4\n",
      "\"happens\"\t1\n",
      "\"happy\"\t4\n",
      "\"harbour\"\t1\n",
      "\"hard\"\t10\n",
      "\"hardly\"\t2\n",
      "\"hardware\"\t1\n",
      "\"harriman\"\t1\n",
      "\"harris\"\t2\n",
      "\"harrison\"\t2\n",
      "\"harry\"\t1\n",
      "\"harvey\"\t4\n",
      "\"has\"\t67\n",
      "\"hash\"\t1\n",
      "\"hassle\"\t2\n",
      "\"hate\"\t4\n",
      "\"haunch\"\t1\n",
      "\"have\"\t170\n",
      "\"having\"\t6\n",
      "\"hc\"\t2\n",
      "\"hcokyovrdsprayz\"\t1\n",
      "\"he\"\t47\n",
      "\"head\"\t3\n",
      "\"headache\"\t1\n",
      "\"headachesmerle\"\t1\n",
      "\"heading\"\t1\n",
      "\"headline\"\t2\n",
      "\"headlines\"\t4\n",
      "\"heal\"\t1\n",
      "\"healing\"\t1\n",
      "\"health\"\t2\n",
      "\"hear\"\t3\n",
      "\"heard\"\t2\n",
      "\"hearers\"\t1\n",
      "\"heart\"\t1\n",
      "\"heartburnwestfield\"\t1\n",
      "\"heathman\"\t1\n",
      "\"heating\"\t2\n",
      "\"held\"\t6\n",
      "\"hello\"\t6\n",
      "\"help\"\t16\n",
      "\"helpdesk\"\t2\n",
      "\"helped\"\t1\n",
      "\"helpful\"\t2\n",
      "\"helping\"\t3\n",
      "\"helpless\"\t2\n",
      "\"helps\"\t2\n",
      "\"hemingway\"\t1\n",
      "\"hemisphere\"\t2\n",
      "\"hence\"\t1\n",
      "\"hendricks\"\t2\n",
      "\"heno\"\t1\n",
      "\"her\"\t12\n",
      "\"herbalonline\"\t1\n",
      "\"herbs\"\t1\n",
      "\"here\"\t61\n",
      "\"herem\"\t1\n",
      "\"herewe\"\t1\n",
      "\"herod\"\t1\n",
      "\"hesitate\"\t4\n",
      "\"hey\"\t2\n",
      "\"hgh\"\t5\n",
      "\"hi\"\t2\n",
      "\"hidd\"\t2\n",
      "\"high\"\t15\n",
      "\"higher\"\t4\n",
      "\"highlands\"\t2\n",
      "\"highlight\"\t3\n",
      "\"highly\"\t1\n",
      "\"highs\"\t1\n",
      "\"hijacked\"\t2\n",
      "\"hike\"\t1\n",
      "\"hikes\"\t4\n",
      "\"hillis\"\t1\n",
      "\"hillmancarthage\"\t1\n",
      "\"him\"\t9\n",
      "\"himhe\"\t1\n",
      "\"himself\"\t1\n",
      "\"hindering\"\t1\n",
      "\"hinsch\"\t2\n",
      "\"hint\"\t1\n",
      "\"hire\"\t2\n",
      "\"his\"\t39\n",
      "\"historical\"\t3\n",
      "\"history\"\t2\n",
      "\"hit\"\t2\n",
      "\"hje\"\t1\n",
      "\"hm\"\t1\n",
      "\"hme\"\t1\n",
      "\"ho\"\t3\n",
      "\"hoferc\"\t1\n",
      "\"hoffman\"\t2\n",
      "\"hold\"\t3\n",
      "\"holders\"\t1\n",
      "\"holding\"\t1\n",
      "\"holiday\"\t3\n",
      "\"holidays\"\t2\n",
      "\"home\"\t20\n",
      "\"homemakers\"\t1\n",
      "\"homes\"\t2\n",
      "\"homestead\"\t1\n",
      "\"hone\"\t1\n",
      "\"honest\"\t1\n",
      "\"honesty\"\t1\n",
      "\"hood\"\t1\n",
      "\"hook\"\t2\n",
      "\"hope\"\t9\n",
      "\"hopefully\"\t2\n",
      "\"hopes\"\t1\n",
      "\"hopkins\"\t1\n",
      "\"horizons\"\t1\n",
      "\"hormone\"\t2\n",
      "\"horn\"\t1\n",
      "\"hornbuckle\"\t1\n",
      "\"horror\"\t1\n",
      "\"horse\"\t2\n",
      "\"host\"\t1\n",
      "\"hosted\"\t1\n",
      "\"hot\"\t2\n",
      "\"hotmail\"\t2\n",
      "\"hottest\"\t1\n",
      "\"hou\"\t206\n",
      "\"hour\"\t1\n",
      "\"hourhelp\"\t1\n",
      "\"hours\"\t26\n",
      "\"house\"\t1\n",
      "\"houston\"\t13\n",
      "\"how\"\t36\n",
      "\"howard\"\t14\n",
      "\"however\"\t14\n",
      "\"howl\"\t1\n",
      "\"hp\"\t1\n",
      "\"hpl\"\t12\n",
      "\"hplc\"\t1\n",
      "\"hplr\"\t1\n",
      "\"hr\"\t14\n",
      "\"hrgovcic\"\t5\n",
      "\"hrice\"\t2\n",
      "\"hris\"\t1\n",
      "\"ht\"\t4\n",
      "\"htm\"\t2\n",
      "\"html\"\t9\n",
      "\"http\"\t65\n",
      "\"huang\"\t4\n",
      "\"hubs\"\t3\n",
      "\"huge\"\t2\n",
      "\"hulmeville\"\t1\n",
      "\"human\"\t14\n",
      "\"humble\"\t1\n",
      "\"humility\"\t2\n",
      "\"hundred\"\t2\n",
      "\"hundreds\"\t2\n",
      "\"hunger\"\t1\n",
      "\"hungry\"\t1\n",
      "\"hunt\"\t1\n",
      "\"hunter\"\t2\n",
      "\"hurdles\"\t1\n",
      "\"hurrah\"\t1\n",
      "\"hurry\"\t4\n",
      "\"hurtling\"\t1\n",
      "\"husband\"\t4\n",
      "\"huse\"\t1\n",
      "\"hyde\"\t1\n",
      "\"hydro\"\t2\n",
      "\"hydroxylate\"\t1\n",
      "\"hype\"\t1\n",
      "\"hzriubp\"\t1\n",
      "\"iain\"\t1\n",
      "\"ica\"\t1\n",
      "\"iccenergy\"\t1\n",
      "\"icet\"\t2\n",
      "\"icon\"\t1\n",
      "\"icop\"\t1\n",
      "\"id\"\t14\n",
      "\"idea\"\t5\n",
      "\"ideas\"\t6\n",
      "\"identified\"\t1\n",
      "\"identifies\"\t1\n",
      "\"identify\"\t2\n",
      "\"idiot\"\t1\n",
      "\"idirect\"\t1\n",
      "\"ids\"\t1\n",
      "\"ie\"\t4\n",
      "\"ien\"\t2\n",
      "\"if\"\t107\n",
      "\"igh\"\t1\n",
      "\"ihf\"\t1\n",
      "\"ii\"\t3\n",
      "\"illness\"\t1\n",
      "\"illustrate\"\t2\n",
      "\"illustration\"\t1\n",
      "\"illustrator\"\t2\n",
      "\"ilug\"\t3\n",
      "\"ilydiatt\"\t1\n",
      "\"im\"\t1\n",
      "\"image\"\t9\n",
      "\"imagine\"\t1\n",
      "\"imaging\"\t1\n",
      "\"imitate\"\t2\n",
      "\"immediate\"\t2\n",
      "\"immediately\"\t22\n",
      "\"imminent\"\t1\n",
      "\"immunity\"\t1\n",
      "\"impact\"\t3\n",
      "\"impacted\"\t1\n",
      "\"impacts\"\t1\n",
      "\"impaired\"\t1\n",
      "\"impede\"\t1\n",
      "\"imperial\"\t2\n",
      "\"implement\"\t1\n",
      "\"implementation\"\t9\n",
      "\"implementing\"\t1\n",
      "\"important\"\t12\n",
      "\"importantly\"\t1\n",
      "\"impossible\"\t1\n",
      "\"impresses\"\t1\n",
      "\"impression\"\t3\n",
      "\"impressive\"\t1\n",
      "\"improve\"\t1\n",
      "\"improved\"\t5\n",
      "\"improving\"\t1\n",
      "\"impulse\"\t1\n",
      "\"in\"\t418\n",
      "\"iname\"\t1\n",
      "\"inappropriate\"\t1\n",
      "\"inbox\"\t1\n",
      "\"inc\"\t12\n",
      "\"incessantly\"\t1\n",
      "\"include\"\t12\n",
      "\"included\"\t8\n",
      "\"includes\"\t1\n",
      "\"including\"\t16\n",
      "\"inclusive\"\t1\n",
      "\"income\"\t4\n",
      "\"incomeunlimited\"\t1\n",
      "\"incorporated\"\t1\n",
      "\"incorrectly\"\t1\n",
      "\"increase\"\t12\n",
      "\"increased\"\t5\n",
      "\"increases\"\t2\n",
      "\"increasing\"\t4\n",
      "\"increasingly\"\t1\n",
      "\"incredibily\"\t1\n",
      "\"incredible\"\t1\n",
      "\"incredibly\"\t1\n",
      "\"incurred\"\t3\n",
      "\"india\"\t1\n",
      "\"indicated\"\t1\n",
      "\"indication\"\t1\n",
      "\"indicator\"\t1\n",
      "\"indices\"\t1\n",
      "\"individual\"\t8\n",
      "\"individualized\"\t3\n",
      "\"individuals\"\t4\n",
      "\"indubitable\"\t1\n",
      "\"industries\"\t1\n",
      "\"industry\"\t9\n",
      "\"inferior\"\t1\n",
      "\"influence\"\t2\n",
      "\"info\"\t9\n",
      "\"inform\"\t3\n",
      "\"information\"\t71\n",
      "\"informative\"\t1\n",
      "\"informed\"\t4\n",
      "\"infrastructure\"\t1\n",
      "\"inherently\"\t1\n",
      "\"initial\"\t7\n",
      "\"initializes\"\t1\n",
      "\"initially\"\t4\n",
      "\"initiative\"\t3\n",
      "\"inject\"\t1\n",
      "\"injunction\"\t1\n",
      "\"inlcuding\"\t1\n",
      "\"inlet\"\t4\n",
      "\"innovation\"\t4\n",
      "\"innovative\"\t2\n",
      "\"innovatus\"\t1\n",
      "\"input\"\t6\n",
      "\"inputs\"\t1\n",
      "\"insane\"\t2\n",
      "\"inseminate\"\t1\n",
      "\"inside\"\t2\n",
      "\"insider\"\t2\n",
      "\"insomnia\"\t1\n",
      "\"inspection\"\t1\n",
      "\"instantaneous\"\t1\n",
      "\"instantly\"\t2\n",
      "\"instead\"\t3\n",
      "\"institutions\"\t1\n",
      "\"instruct\"\t1\n",
      "\"instructed\"\t3\n",
      "\"instructions\"\t4\n",
      "\"instructs\"\t1\n",
      "\"instrument\"\t1\n",
      "\"instruments\"\t1\n",
      "\"insufficient\"\t1\n",
      "\"insults\"\t1\n",
      "\"insurance\"\t6\n",
      "\"insure\"\t7\n",
      "\"integrated\"\t2\n",
      "\"integrity\"\t2\n",
      "\"intelligence\"\t1\n",
      "\"intelt\"\t1\n",
      "\"intend\"\t3\n",
      "\"intended\"\t1\n",
      "\"intends\"\t2\n",
      "\"intense\"\t1\n",
      "\"intercreditor\"\t1\n",
      "\"interest\"\t12\n",
      "\"interested\"\t10\n",
      "\"interesting\"\t3\n",
      "\"interests\"\t7\n",
      "\"interfering\"\t1\n",
      "\"intermediary\"\t2\n",
      "\"internal\"\t9\n",
      "\"internally\"\t2\n",
      "\"international\"\t7\n",
      "\"interne\"\t1\n",
      "\"internet\"\t30\n",
      "\"interrupted\"\t1\n",
      "\"interstate\"\t1\n",
      "\"intervened\"\t2\n",
      "\"intl\"\t2\n",
      "\"into\"\t36\n",
      "\"intra\"\t1\n",
      "\"intranet\"\t3\n",
      "\"introduce\"\t1\n",
      "\"introduced\"\t3\n",
      "\"introducing\"\t1\n",
      "\"invest\"\t4\n",
      "\"invested\"\t1\n",
      "\"investigations\"\t1\n",
      "\"investment\"\t18\n",
      "\"investor\"\t1\n",
      "\"investors\"\t1\n",
      "\"invitation\"\t1\n",
      "\"invite\"\t6\n",
      "\"invoices\"\t1\n",
      "\"involuntary\"\t8\n",
      "\"involved\"\t7\n",
      "\"involvement\"\t1\n",
      "\"involves\"\t1\n",
      "\"involving\"\t2\n",
      "\"invovled\"\t2\n",
      "\"ion\"\t1\n",
      "\"iowa\"\t1\n",
      "\"ipos\"\t1\n",
      "\"ipp\"\t2\n",
      "\"ipps\"\t6\n",
      "\"irish\"\t1\n",
      "\"iron\"\t2\n",
      "\"is\"\t249\n",
      "\"isalso\"\t1\n",
      "\"island\"\t2\n",
      "\"isn\"\t3\n",
      "\"iso\"\t10\n",
      "\"isp\"\t8\n",
      "\"isps\"\t3\n",
      "\"issler\"\t5\n",
      "\"issue\"\t21\n",
      "\"issued\"\t4\n",
      "\"issues\"\t19\n",
      "\"it\"\t192\n",
      "\"iteam\"\t1\n",
      "\"item\"\t3\n",
      "\"items\"\t15\n",
      "\"its\"\t27\n",
      "\"itself\"\t3\n",
      "\"ium\"\t2\n",
      "\"ivan\"\t2\n",
      "\"ivernia\"\t2\n",
      "\"ivoire\"\t3\n",
      "\"ja\"\t1\n",
      "\"jackie\"\t1\n",
      "\"jan\"\t4\n",
      "\"jana\"\t3\n",
      "\"jane\"\t1\n",
      "\"janet\"\t1\n",
      "\"janice\"\t1\n",
      "\"janie\"\t1\n",
      "\"january\"\t2\n",
      "\"japan\"\t3\n",
      "\"jason\"\t5\n",
      "\"jauregui\"\t1\n",
      "\"jeff\"\t7\n",
      "\"jersey\"\t1\n",
      "\"jim\"\t3\n",
      "\"jimmy\"\t2\n",
      "\"jirapliegao\"\t1\n",
      "\"jlopes\"\t1\n",
      "\"jm\"\t6\n",
      "\"jnexon\"\t1\n",
      "\"jo\"\t1\n",
      "\"joao\"\t2\n",
      "\"job\"\t3\n",
      "\"joe\"\t1\n",
      "\"joel\"\t6\n",
      "\"johannesburg\"\t2\n",
      "\"john\"\t22\n",
      "\"johnny\"\t2\n",
      "\"johnston\"\t2\n",
      "\"join\"\t10\n",
      "\"joinder\"\t1\n",
      "\"joined\"\t3\n",
      "\"joining\"\t4\n",
      "\"joint\"\t1\n",
      "\"jon\"\t1\n",
      "\"jonathon\"\t1\n",
      "\"jones\"\t3\n",
      "\"jonesg\"\t1\n",
      "\"jose\"\t1\n",
      "\"joseph\"\t7\n",
      "\"josey\"\t7\n",
      "\"journey\"\t1\n",
      "\"journeys\"\t1\n",
      "\"joyce\"\t1\n",
      "\"jpxdltmuk\"\t1\n",
      "\"jshorter\"\t1\n",
      "\"jsp\"\t3\n",
      "\"jturco\"\t2\n",
      "\"jubilar\"\t1\n",
      "\"judge\"\t3\n",
      "\"judgment\"\t1\n",
      "\"judgments\"\t1\n",
      "\"julie\"\t5\n",
      "\"july\"\t2\n",
      "\"june\"\t11\n",
      "\"junk\"\t2\n",
      "\"just\"\t47\n",
      "\"justperform\"\t1\n",
      "\"jvbe\"\t1\n",
      "\"kainantu\"\t2\n",
      "\"kaminski\"\t11\n",
      "\"kaolin\"\t1\n",
      "\"karen\"\t1\n",
      "\"kaskaskia\"\t1\n",
      "\"katamail\"\t1\n",
      "\"kathryn\"\t3\n",
      "\"kathy\"\t1\n",
      "\"kay\"\t5\n",
      "\"kcs\"\t2\n",
      "\"keeley\"\t5\n",
      "\"keen\"\t1\n",
      "\"keep\"\t21\n",
      "\"keeping\"\t4\n",
      "\"kelly\"\t1\n",
      "\"kenny\"\t1\n",
      "\"kept\"\t2\n",
      "\"kerb\"\t1\n",
      "\"kevin\"\t48\n",
      "\"key\"\t10\n",
      "\"keyboard\"\t2\n",
      "\"keyes\"\t1\n",
      "\"keys\"\t1\n",
      "\"keyword\"\t4\n",
      "\"keywordcount\"\t1\n",
      "\"keywords\"\t2\n",
      "\"kfbtyra\"\t1\n",
      "\"kg\"\t3\n",
      "\"khanna\"\t1\n",
      "\"kick\"\t1\n",
      "\"kickoff\"\t2\n",
      "\"kid\"\t1\n",
      "\"killed\"\t2\n",
      "\"killer\"\t1\n",
      "\"killings\"\t2\n",
      "\"kim\"\t3\n",
      "\"kimberley\"\t3\n",
      "\"kimberly\"\t5\n",
      "\"kincaid\"\t2\n",
      "\"kind\"\t7\n",
      "\"kinda\"\t2\n",
      "\"kindall\"\t4\n",
      "\"kindly\"\t1\n",
      "\"kinds\"\t2\n",
      "\"king\"\t5\n",
      "\"kish\"\t1\n",
      "\"kistler\"\t1\n",
      "\"kitchen\"\t3\n",
      "\"kk\"\t1\n",
      "\"klei\"\t1\n",
      "\"knave\"\t3\n",
      "\"knelt\"\t1\n",
      "\"knew\"\t3\n",
      "\"knights\"\t1\n",
      "\"knives\"\t1\n",
      "\"know\"\t42\n",
      "\"knowledge\"\t4\n",
      "\"knowlton\"\t1\n",
      "\"known\"\t4\n",
      "\"knows\"\t2\n",
      "\"knudsen\"\t1\n",
      "\"kokas\"\t1\n",
      "\"kollaros\"\t1\n",
      "\"korea\"\t1\n",
      "\"koromah\"\t2\n",
      "\"krgp\"\t2\n",
      "\"kri\"\t2\n",
      "\"krill\"\t1\n",
      "\"krishna\"\t1\n",
      "\"krishnarao\"\t5\n",
      "\"kristin\"\t2\n",
      "\"kvie\"\t1\n",
      "\"kwh\"\t2\n",
      "\"kyle\"\t1\n",
      "\"label\"\t2\n",
      "\"labor\"\t2\n",
      "\"laborious\"\t1\n",
      "\"lack\"\t1\n",
      "\"lacrecia\"\t1\n",
      "\"lagars\"\t1\n",
      "\"lagrasta\"\t1\n",
      "\"lamb\"\t1\n",
      "\"lamproite\"\t2\n",
      "\"lamps\"\t1\n",
      "\"land\"\t1\n",
      "\"language\"\t3\n",
      "\"lanterns\"\t1\n",
      "\"large\"\t8\n",
      "\"larger\"\t3\n",
      "\"largest\"\t2\n",
      "\"larry\"\t1\n",
      "\"last\"\t18\n",
      "\"lasts\"\t1\n",
      "\"late\"\t5\n",
      "\"later\"\t12\n",
      "\"latin\"\t1\n",
      "\"laughed\"\t1\n",
      "\"launch\"\t2\n",
      "\"lauri\"\t4\n",
      "\"lavorato\"\t6\n",
      "\"law\"\t5\n",
      "\"lawn\"\t3\n",
      "\"layout\"\t3\n",
      "\"layouts\"\t1\n",
      "\"lcd\"\t1\n",
      "\"lead\"\t10\n",
      "\"leaders\"\t1\n",
      "\"leadership\"\t13\n",
      "\"leads\"\t11\n",
      "\"leap\"\t1\n",
      "\"learn\"\t4\n",
      "\"learned\"\t2\n",
      "\"learning\"\t3\n",
      "\"learns\"\t2\n",
      "\"lease\"\t1\n",
      "\"least\"\t12\n",
      "\"leave\"\t4\n",
      "\"leaving\"\t2\n",
      "\"lee\"\t1\n",
      "\"leederville\"\t1\n",
      "\"left\"\t5\n",
      "\"legal\"\t3\n",
      "\"legislative\"\t1\n",
      "\"legislator\"\t1\n",
      "\"legislators\"\t2\n",
      "\"legislature\"\t9\n",
      "\"legs\"\t3\n",
      "\"lehr\"\t1\n",
      "\"lemelman\"\t1\n",
      "\"lend\"\t2\n",
      "\"lender\"\t2\n",
      "\"lenders\"\t4\n",
      "\"length\"\t1\n",
      "\"lengthen\"\t1\n",
      "\"leone\"\t5\n",
      "\"less\"\t20\n",
      "\"lesson\"\t5\n",
      "\"let\"\t35\n",
      "\"lets\"\t1\n",
      "\"letter\"\t27\n",
      "\"letters\"\t11\n",
      "\"level\"\t4\n",
      "\"levels\"\t2\n",
      "\"leverage\"\t1\n",
      "\"liar\"\t2\n",
      "\"licence\"\t1\n",
      "\"licensing\"\t1\n",
      "\"life\"\t12\n",
      "\"lifetime\"\t1\n",
      "\"lift\"\t1\n",
      "\"lifted\"\t1\n",
      "\"lifts\"\t1\n",
      "\"light\"\t1\n",
      "\"like\"\t54\n",
      "\"liked\"\t1\n",
      "\"likelihood\"\t2\n",
      "\"likely\"\t7\n",
      "\"likes\"\t1\n",
      "\"lilly\"\t1\n",
      "\"limitations\"\t1\n",
      "\"limited\"\t14\n",
      "\"limitless\"\t2\n",
      "\"lin\"\t6\n",
      "\"linda\"\t5\n",
      "\"lindiwe\"\t2\n",
      "\"line\"\t21\n",
      "\"lineal\"\t1\n",
      "\"lines\"\t1\n",
      "\"lingerie\"\t2\n",
      "\"link\"\t6\n",
      "\"linkpaks\"\t4\n",
      "\"links\"\t30\n",
      "\"linktocash\"\t1\n",
      "\"linux\"\t4\n",
      "\"lips\"\t1\n",
      "\"liquid\"\t1\n",
      "\"liquids\"\t1\n",
      "\"lisa\"\t2\n",
      "\"list\"\t18\n",
      "\"listed\"\t7\n",
      "\"listen\"\t2\n",
      "\"listened\"\t1\n",
      "\"listinfo\"\t3\n",
      "\"listmaster\"\t1\n",
      "\"lists\"\t2\n",
      "\"lit\"\t1\n",
      "\"literally\"\t1\n",
      "\"literature\"\t1\n",
      "\"litteneker\"\t1\n",
      "\"litterbug\"\t1\n",
      "\"little\"\t9\n",
      "\"live\"\t1\n",
      "\"living\"\t3\n",
      "\"liz\"\t3\n",
      "\"ll\"\t23\n",
      "\"llc\"\t2\n",
      "\"llittle\"\t1\n",
      "\"loads\"\t1\n",
      "\"loan\"\t4\n",
      "\"lobby\"\t1\n",
      "\"lobster\"\t1\n",
      "\"local\"\t6\n",
      "\"locally\"\t2\n",
      "\"locals\"\t1\n",
      "\"located\"\t4\n",
      "\"location\"\t11\n",
      "\"lock\"\t2\n",
      "\"locomotive\"\t1\n",
      "\"loczk\"\t1\n",
      "\"loft\"\t2\n",
      "\"lollipops\"\t1\n",
      "\"london\"\t4\n",
      "\"long\"\t18\n",
      "\"longer\"\t4\n",
      "\"look\"\t14\n",
      "\"looked\"\t1\n",
      "\"looking\"\t4\n",
      "\"looks\"\t5\n",
      "\"loosening\"\t1\n",
      "\"lose\"\t2\n",
      "\"loses\"\t2\n",
      "\"losing\"\t2\n",
      "\"loss\"\t1\n",
      "\"lot\"\t10\n",
      "\"lots\"\t2\n",
      "\"lottery\"\t6\n",
      "\"louise\"\t8\n",
      "\"lounsbury\"\t1\n",
      "\"love\"\t2\n",
      "\"low\"\t10\n",
      "\"lower\"\t1\n",
      "\"lowest\"\t1\n",
      "\"loyal\"\t2\n",
      "\"loyalty\"\t1\n",
      "\"lsc\"\t1\n",
      "\"lst\"\t2\n",
      "\"ltd\"\t2\n",
      "\"lu\"\t5\n",
      "\"luck\"\t2\n",
      "\"lucky\"\t2\n",
      "\"lump\"\t1\n",
      "\"lunch\"\t2\n",
      "\"luo\"\t1\n",
      "\"luong\"\t1\n",
      "\"lx\"\t1\n",
      "\"lycopodium\"\t1\n",
      "\"lyn\"\t7\n",
      "\"lynch\"\t1\n",
      "\"lynda\"\t1\n",
      "\"ma\"\t2\n",
      "\"macarthur\"\t1\n",
      "\"machine\"\t1\n",
      "\"mackey\"\t1\n",
      "\"macquarie\"\t2\n",
      "\"macromedia\"\t6\n",
      "\"madam\"\t2\n",
      "\"made\"\t15\n",
      "\"magellan\"\t1\n",
      "\"magnesium\"\t1\n",
      "\"magnum\"\t1\n",
      "\"magnumo\"\t1\n",
      "\"maidens\"\t1\n",
      "\"mail\"\t32\n",
      "\"mailing\"\t3\n",
      "\"mailings\"\t2\n",
      "\"mailman\"\t3\n",
      "\"mailto\"\t11\n",
      "\"main\"\t1\n",
      "\"maine\"\t1\n",
      "\"maintain\"\t2\n",
      "\"maintainer\"\t1\n",
      "\"major\"\t5\n",
      "\"make\"\t35\n",
      "\"makecashonline\"\t1\n",
      "\"makes\"\t5\n",
      "\"making\"\t17\n",
      "\"male\"\t3\n",
      "\"malina\"\t4\n",
      "\"man\"\t5\n",
      "\"manage\"\t3\n",
      "\"managed\"\t7\n",
      "\"management\"\t54\n",
      "\"manager\"\t8\n",
      "\"managerial\"\t2\n",
      "\"managers\"\t1\n",
      "\"manages\"\t3\n",
      "\"managing\"\t1\n",
      "\"managment\"\t4\n",
      "\"mandated\"\t1\n",
      "\"manganese\"\t1\n",
      "\"manitoba\"\t1\n",
      "\"manual\"\t2\n",
      "\"manufacturers\"\t1\n",
      "\"many\"\t24\n",
      "\"mark\"\t8\n",
      "\"market\"\t12\n",
      "\"marketability\"\t2\n",
      "\"marketer\"\t1\n",
      "\"marketers\"\t1\n",
      "\"marketing\"\t28\n",
      "\"markets\"\t5\n",
      "\"marks\"\t2\n",
      "\"marla\"\t1\n",
      "\"martensite\"\t1\n",
      "\"martin\"\t7\n",
      "\"martina\"\t4\n",
      "\"martinez\"\t1\n",
      "\"mary\"\t7\n",
      "\"maryam\"\t1\n",
      "\"mass\"\t3\n",
      "\"massey\"\t1\n",
      "\"masson\"\t5\n",
      "\"master\"\t3\n",
      "\"match\"\t2\n",
      "\"matches\"\t4\n",
      "\"material\"\t1\n",
      "\"materials\"\t2\n",
      "\"matt\"\t1\n",
      "\"matter\"\t6\n",
      "\"maureen\"\t5\n",
      "\"mauricio\"\t1\n",
      "\"may\"\t27\n",
      "\"maybe\"\t4\n",
      "\"mayerbrown\"\t1\n",
      "\"mayes\"\t1\n",
      "\"mb\"\t1\n",
      "\"mc\"\t1\n",
      "\"mcbeal\"\t1\n",
      "\"mcclankg\"\t1\n",
      "\"mccullough\"\t1\n",
      "\"mcf\"\t2\n",
      "\"mclafferty\"\t1\n",
      "\"mclarney\"\t2\n",
      "\"mclean\"\t1\n",
      "\"mcmullen\"\t2\n",
      "\"mcosta\"\t1\n",
      "\"mcsherry\"\t1\n",
      "\"me\"\t75\n",
      "\"mean\"\t1\n",
      "\"means\"\t6\n",
      "\"meant\"\t1\n",
      "\"meanwhile\"\t3\n",
      "\"measure\"\t1\n",
      "\"measuring\"\t3\n",
      "\"mechanism\"\t1\n",
      "\"media\"\t3\n",
      "\"medical\"\t1\n",
      "\"medication\"\t1\n",
      "\"medications\"\t1\n",
      "\"mediums\"\t1\n",
      "\"meet\"\t9\n",
      "\"meeting\"\t19\n",
      "\"meetings\"\t7\n",
      "\"mega\"\t2\n",
      "\"melissa\"\t3\n",
      "\"melodick\"\t1\n",
      "\"member\"\t21\n",
      "\"members\"\t14\n",
      "\"membership\"\t19\n",
      "\"memo\"\t4\n",
      "\"memory\"\t3\n",
      "\"men\"\t5\n",
      "\"mental\"\t2\n",
      "\"mention\"\t3\n",
      "\"mentioned\"\t5\n",
      "\"merchandise\"\t3\n",
      "\"merchandisethat\"\t1\n",
      "\"merchant\"\t5\n",
      "\"merchants\"\t1\n",
      "\"merely\"\t1\n",
      "\"merry\"\t2\n",
      "\"mesopotamia\"\t1\n",
      "\"message\"\t20\n",
      "\"metal\"\t1\n",
      "\"metaphors\"\t1\n",
      "\"meter\"\t13\n",
      "\"meters\"\t3\n",
      "\"method\"\t1\n",
      "\"methods\"\t1\n",
      "\"mexico\"\t1\n",
      "\"meyers\"\t1\n",
      "\"mg\"\t2\n",
      "\"miami\"\t1\n",
      "\"michael\"\t9\n",
      "\"michelago\"\t2\n",
      "\"michele\"\t1\n",
      "\"micros\"\t2\n",
      "\"microsale\"\t8\n",
      "\"microsoft\"\t6\n",
      "\"mid\"\t3\n",
      "\"midwestern\"\t1\n",
      "\"might\"\t12\n",
      "\"mighty\"\t1\n",
      "\"migraine\"\t1\n",
      "\"miguel\"\t1\n",
      "\"mike\"\t11\n",
      "\"mild\"\t2\n",
      "\"milestone\"\t1\n",
      "\"militarism\"\t1\n",
      "\"millenium\"\t1\n",
      "\"miller\"\t1\n",
      "\"million\"\t17\n",
      "\"millions\"\t2\n",
      "\"mime\"\t1\n",
      "\"min\"\t2\n",
      "\"mind\"\t16\n",
      "\"minds\"\t1\n",
      "\"mine\"\t7\n",
      "\"mineral\"\t2\n",
      "\"minerals\"\t4\n",
      "\"mines\"\t1\n",
      "\"mini\"\t1\n",
      "\"minimal\"\t1\n",
      "\"minimize\"\t1\n",
      "\"minimum\"\t2\n",
      "\"mining\"\t7\n",
      "\"miningnews\"\t9\n",
      "\"minor\"\t1\n",
      "\"minute\"\t4\n",
      "\"minutes\"\t5\n",
      "\"mirant\"\t1\n",
      "\"mircosoft\"\t1\n",
      "\"mirror\"\t3\n",
      "\"miserable\"\t1\n",
      "\"mislead\"\t1\n",
      "\"miss\"\t2\n",
      "\"missed\"\t2\n",
      "\"missing\"\t1\n",
      "\"missouri\"\t1\n",
      "\"misspelled\"\t1\n",
      "\"missss\"\t1\n",
      "\"mitral\"\t1\n",
      "\"mix\"\t2\n",
      "\"mixture\"\t1\n",
      "\"mm\"\t1\n",
      "\"mmbtu\"\t6\n",
      "\"mmce\"\t1\n",
      "\"mo\"\t1\n",
      "\"moates\"\t1\n",
      "\"mobil\"\t1\n",
      "\"mobile\"\t1\n",
      "\"mode\"\t1\n",
      "\"modem\"\t1\n",
      "\"moderate\"\t2\n",
      "\"moderates\"\t2\n",
      "\"moderator\"\t4\n",
      "\"modification\"\t1\n",
      "\"module\"\t1\n",
      "\"modules\"\t4\n",
      "\"moment\"\t3\n",
      "\"moments\"\t1\n",
      "\"monadic\"\t1\n",
      "\"monday\"\t16\n",
      "\"money\"\t35\n",
      "\"mongolia\"\t1\n",
      "\"monies\"\t1\n",
      "\"monitor\"\t1\n",
      "\"montana\"\t1\n",
      "\"month\"\t17\n",
      "\"monthly\"\t2\n",
      "\"months\"\t10\n",
      "\"mood\"\t1\n",
      "\"moore\"\t39\n",
      "\"morality\"\t1\n",
      "\"morayt\"\t1\n",
      "\"more\"\t65\n",
      "\"morne\"\t1\n",
      "\"morning\"\t12\n",
      "\"morris\"\t3\n",
      "\"mortgage\"\t3\n",
      "\"mossel\"\t1\n",
      "\"most\"\t31\n",
      "\"mostly\"\t1\n",
      "\"motero\"\t1\n",
      "\"motivating\"\t1\n",
      "\"mounted\"\t1\n",
      "\"mouse\"\t5\n",
      "\"move\"\t8\n",
      "\"moved\"\t2\n",
      "\"movement\"\t2\n",
      "\"moves\"\t1\n",
      "\"moviebuff\"\t2\n",
      "\"moving\"\t5\n",
      "\"mower\"\t1\n",
      "\"mp\"\t1\n",
      "\"mperkins\"\t1\n",
      "\"mpkemyrxlpq\"\t1\n",
      "\"mr\"\t10\n",
      "\"mrs\"\t8\n",
      "\"ms\"\t10\n",
      "\"mscf\"\t1\n",
      "\"msessa\"\t1\n",
      "\"mst\"\t1\n",
      "\"much\"\t25\n",
      "\"multilanguage\"\t1\n",
      "\"multipart\"\t1\n",
      "\"multiple\"\t7\n",
      "\"murmur\"\t1\n",
      "\"murphy\"\t1\n",
      "\"muscle\"\t2\n",
      "\"music\"\t1\n",
      "\"musically\"\t1\n",
      "\"must\"\t21\n",
      "\"mustard\"\t1\n",
      "\"mutual\"\t1\n",
      "\"mw\"\t3\n",
      "\"mx\"\t6\n",
      "\"my\"\t102\n",
      "\"myers\"\t1\n",
      "\"myinput\"\t4\n",
      "\"myinputare\"\t1\n",
      "\"myself\"\t1\n",
      "\"myshoppingplace\"\t4\n",
      "\"mysiteinc\"\t4\n",
      "\"na\"\t5\n",
      "\"naked\"\t1\n",
      "\"name\"\t22\n",
      "\"names\"\t7\n",
      "\"nas\"\t1\n",
      "\"nation\"\t1\n",
      "\"natives\"\t1\n",
      "\"natural\"\t7\n",
      "\"nature\"\t2\n",
      "\"nbi\"\t1\n",
      "\"ncaa\"\t1\n",
      "\"nd\"\t4\n",
      "\"neaarby\"\t1\n",
      "\"neal\"\t1\n",
      "\"near\"\t6\n",
      "\"nearby\"\t1\n",
      "\"nearly\"\t1\n",
      "\"neat\"\t1\n",
      "\"nebulous\"\t1\n",
      "\"necessary\"\t8\n",
      "\"necessities\"\t1\n",
      "\"neck\"\t1\n",
      "\"need\"\t54\n",
      "\"needed\"\t9\n",
      "\"needs\"\t9\n",
      "\"negative\"\t1\n",
      "\"negotiating\"\t3\n",
      "\"negotiation\"\t1\n",
      "\"neighbor\"\t1\n",
      "\"neighboring\"\t2\n",
      "\"nepco\"\t1\n",
      "\"nero\"\t1\n",
      "\"net\"\t36\n",
      "\"netherland\"\t1\n",
      "\"netherlands\"\t2\n",
      "\"netnoteinc\"\t6\n",
      "\"netrepreneur\"\t1\n",
      "\"netsbestinfo\"\t2\n",
      "\"network\"\t1\n",
      "\"networks\"\t6\n",
      "\"netwww\"\t1\n",
      "\"neuweiler\"\t2\n",
      "\"never\"\t7\n",
      "\"new\"\t66\n",
      "\"newcomers\"\t2\n",
      "\"news\"\t7\n",
      "\"newsboy\"\t2\n",
      "\"newsletter\"\t24\n",
      "\"newsletters\"\t4\n",
      "\"next\"\t27\n",
      "\"nextpart\"\t1\n",
      "\"neyeded\"\t1\n",
      "\"ngo\"\t2\n",
      "\"nguyen\"\t3\n",
      "\"ngx\"\t1\n",
      "\"nice\"\t3\n",
      "\"nickel\"\t4\n",
      "\"nicki\"\t1\n",
      "\"nickname\"\t1\n",
      "\"nicolay\"\t1\n",
      "\"niestrath\"\t1\n",
      "\"nigel\"\t1\n",
      "\"night\"\t4\n",
      "\"nightgear\"\t1\n",
      "\"nighttime\"\t2\n",
      "\"niles\"\t3\n",
      "\"nim\"\t2\n",
      "\"nine\"\t1\n",
      "\"njwa\"\t1\n",
      "\"no\"\t52\n",
      "\"noah\"\t1\n",
      "\"nodded\"\t1\n",
      "\"nom\"\t8\n",
      "\"nominated\"\t4\n",
      "\"nomination\"\t4\n",
      "\"nominations\"\t1\n",
      "\"nommensen\"\t1\n",
      "\"non\"\t5\n",
      "\"none\"\t2\n",
      "\"noon\"\t1\n",
      "\"norma\"\t1\n",
      "\"normal\"\t8\n",
      "\"normally\"\t1\n",
      "\"normet\"\t2\n",
      "\"north\"\t12\n",
      "\"northern\"\t3\n",
      "\"norton\"\t3\n",
      "\"nospam\"\t1\n",
      "\"nostalgia\"\t1\n",
      "\"not\"\t126\n",
      "\"note\"\t9\n",
      "\"noted\"\t4\n",
      "\"notes\"\t1\n",
      "\"nothing\"\t5\n",
      "\"notice\"\t4\n",
      "\"noticed\"\t1\n",
      "\"notiffiyved\"\t1\n",
      "\"notification\"\t1\n",
      "\"notify\"\t2\n",
      "\"notis\"\t2\n",
      "\"nov\"\t5\n",
      "\"novak\"\t1\n",
      "\"novel\"\t1\n",
      "\"novelties\"\t1\n",
      "\"november\"\t3\n",
      "\"now\"\t29\n",
      "\"nowbetterthis\"\t2\n",
      "\"nowthe\"\t1\n",
      "\"nox\"\t2\n",
      "\"nrg\"\t1\n",
      "\"nrw\"\t1\n",
      "\"ns\"\t1\n",
      "\"nt\"\t1\n",
      "\"num\"\t1\n",
      "\"number\"\t17\n",
      "\"numbers\"\t9\n",
      "\"numerous\"\t1\n",
      "\"oak\"\t1\n",
      "\"oblibgat\"\t1\n",
      "\"obligation\"\t2\n",
      "\"obligationin\"\t1\n",
      "\"obligations\"\t2\n",
      "\"observations\"\t2\n",
      "\"obtain\"\t4\n",
      "\"obtained\"\t1\n",
      "\"obviously\"\t4\n",
      "\"occasion\"\t1\n",
      "\"occur\"\t1\n",
      "\"occurs\"\t1\n",
      "\"ocd\"\t1\n",
      "\"oceania\"\t1\n",
      "\"oconan\"\t2\n",
      "\"odin\"\t2\n",
      "\"odlx\"\t1\n",
      "\"oem\"\t3\n",
      "\"of\"\t566\n",
      "\"off\"\t8\n",
      "\"offer\"\t26\n",
      "\"offered\"\t3\n",
      "\"offering\"\t7\n",
      "\"offers\"\t2\n",
      "\"office\"\t26\n",
      "\"officer\"\t3\n",
      "\"offices\"\t3\n",
      "\"official\"\t1\n",
      "\"officially\"\t3\n",
      "\"officials\"\t1\n",
      "\"offsite\"\t2\n",
      "\"often\"\t9\n",
      "\"oh\"\t2\n",
      "\"oil\"\t1\n",
      "\"oilshale\"\t1\n",
      "\"ok\"\t4\n",
      "\"old\"\t7\n",
      "\"olson\"\t2\n",
      "\"omaha\"\t1\n",
      "\"omission\"\t1\n",
      "\"on\"\t271\n",
      "\"once\"\t8\n",
      "\"ondarza\"\t1\n",
      "\"one\"\t68\n",
      "\"onerous\"\t1\n",
      "\"ongoing\"\t2\n",
      "\"online\"\t20\n",
      "\"only\"\t32\n",
      "\"ontacted\"\t1\n",
      "\"oo\"\t6\n",
      "\"op\"\t4\n",
      "\"open\"\t7\n",
      "\"opening\"\t4\n",
      "\"openpage\"\t1\n",
      "\"operate\"\t1\n",
      "\"operation\"\t2\n",
      "\"operational\"\t6\n",
      "\"operations\"\t41\n",
      "\"operators\"\t3\n",
      "\"opinion\"\t5\n",
      "\"opportunities\"\t7\n",
      "\"opportunity\"\t9\n",
      "\"oppose\"\t1\n",
      "\"opposite\"\t1\n",
      "\"opposition\"\t2\n",
      "\"opt\"\t2\n",
      "\"optimistic\"\t1\n",
      "\"option\"\t1\n",
      "\"options\"\t2\n",
      "\"optionscontrol\"\t1\n",
      "\"or\"\t166\n",
      "\"orange\"\t1\n",
      "\"order\"\t44\n",
      "\"ordered\"\t6\n",
      "\"orders\"\t1\n",
      "\"ore\"\t3\n",
      "\"org\"\t4\n",
      "\"organisation\"\t1\n",
      "\"organization\"\t6\n",
      "\"organizational\"\t1\n",
      "\"organize\"\t2\n",
      "\"orgoto\"\t1\n",
      "\"orgtrade\"\t1\n",
      "\"oriental\"\t1\n",
      "\"original\"\t3\n",
      "\"originality\"\t1\n",
      "\"originally\"\t1\n",
      "\"origination\"\t1\n",
      "\"originator\"\t2\n",
      "\"orleantraders\"\t1\n",
      "\"orrick\"\t1\n",
      "\"osman\"\t4\n",
      "\"otc\"\t1\n",
      "\"other\"\t43\n",
      "\"others\"\t4\n",
      "\"otherwise\"\t1\n",
      "\"ounces\"\t1\n",
      "\"our\"\t119\n",
      "\"ourselves\"\t1\n",
      "\"out\"\t70\n",
      "\"outback\"\t1\n",
      "\"outdated\"\t1\n",
      "\"outline\"\t2\n",
      "\"outlined\"\t1\n",
      "\"outlook\"\t3\n",
      "\"outpacing\"\t1\n",
      "\"outrageous\"\t1\n",
      "\"outside\"\t3\n",
      "\"outstanding\"\t4\n",
      "\"over\"\t50\n",
      "\"overall\"\t2\n",
      "\"overgaard\"\t1\n",
      "\"overnight\"\t2\n",
      "\"overpaying\"\t1\n",
      "\"oversee\"\t3\n",
      "\"overseer\"\t1\n",
      "\"overuse\"\t1\n",
      "\"overwhelm\"\t1\n",
      "\"owe\"\t1\n",
      "\"own\"\t15\n",
      "\"owned\"\t5\n",
      "\"owner\"\t2\n",
      "\"owners\"\t2\n",
      "\"ownership\"\t2\n",
      "\"owning\"\t2\n",
      "\"owns\"\t1\n",
      "\"oxidation\"\t1\n",
      "\"oxley\"\t3\n",
      "\"oxx\"\t2\n",
      "\"oxymoron\"\t1\n",
      "\"ozarka\"\t1\n",
      "\"paces\"\t1\n",
      "\"pacific\"\t3\n",
      "\"package\"\t4\n",
      "\"padron\"\t1\n",
      "\"page\"\t23\n",
      "\"pagemaker\"\t2\n",
      "\"pages\"\t9\n",
      "\"paid\"\t5\n",
      "\"paidtosurf\"\t2\n",
      "\"pain\"\t2\n",
      "\"painter\"\t1\n",
      "\"palaeo\"\t1\n",
      "\"pamela\"\t2\n",
      "\"panel\"\t1\n",
      "\"pangs\"\t1\n",
      "\"paper\"\t3\n",
      "\"papers\"\t2\n",
      "\"papua\"\t1\n",
      "\"par\"\t2\n",
      "\"paragraph\"\t6\n",
      "\"paragraphs\"\t8\n",
      "\"parallel\"\t1\n",
      "\"parents\"\t1\n",
      "\"part\"\t9\n",
      "\"participants\"\t2\n",
      "\"participate\"\t4\n",
      "\"participating\"\t1\n",
      "\"participation\"\t1\n",
      "\"particular\"\t2\n",
      "\"particularly\"\t3\n",
      "\"parties\"\t4\n",
      "\"partner\"\t4\n",
      "\"partners\"\t4\n",
      "\"partnership\"\t1\n",
      "\"parts\"\t1\n",
      "\"party\"\t3\n",
      "\"paso\"\t2\n",
      "\"pass\"\t2\n",
      "\"passed\"\t1\n",
      "\"passport\"\t1\n",
      "\"password\"\t5\n",
      "\"past\"\t3\n",
      "\"path\"\t2\n",
      "\"pathetic\"\t1\n",
      "\"pathos\"\t1\n",
      "\"patricia\"\t4\n",
      "\"paul\"\t2\n",
      "\"paulo\"\t5\n",
      "\"pause\"\t1\n",
      "\"pavluk\"\t1\n",
      "\"pay\"\t5\n",
      "\"payback\"\t1\n",
      "\"payers\"\t1\n",
      "\"paying\"\t3\n",
      "\"payment\"\t1\n",
      "\"payments\"\t8\n",
      "\"payne\"\t2\n",
      "\"payroll\"\t5\n",
      "\"pbem\"\t1\n",
      "\"pc\"\t5\n",
      "\"pcenergy\"\t3\n",
      "\"pcp\"\t1\n",
      "\"pdx\"\t1\n",
      "\"peace\"\t4\n",
      "\"peaking\"\t1\n",
      "\"peel\"\t2\n",
      "\"peers\"\t1\n",
      "\"penance\"\t1\n",
      "\"pennsylvania\"\t3\n",
      "\"pentium\"\t1\n",
      "\"people\"\t38\n",
      "\"per\"\t11\n",
      "\"perceived\"\t1\n",
      "\"percent\"\t1\n",
      "\"percentage\"\t2\n",
      "\"perfect\"\t3\n",
      "\"perform\"\t1\n",
      "\"performance\"\t7\n",
      "\"performer\"\t2\n",
      "\"perhaps\"\t3\n",
      "\"period\"\t8\n",
      "\"persist\"\t1\n",
      "\"persistence\"\t2\n",
      "\"persists\"\t1\n",
      "\"person\"\t16\n",
      "\"personage\"\t1\n",
      "\"personal\"\t12\n",
      "\"personality\"\t4\n",
      "\"personally\"\t1\n",
      "\"personnel\"\t7\n",
      "\"persons\"\t1\n",
      "\"perspective\"\t7\n",
      "\"perth\"\t1\n",
      "\"pest\"\t1\n",
      "\"pet\"\t1\n",
      "\"pete\"\t1\n",
      "\"peter\"\t3\n",
      "\"petteway\"\t1\n",
      "\"pg\"\t7\n",
      "\"pgm\"\t1\n",
      "\"ph\"\t3\n",
      "\"phases\"\t2\n",
      "\"phentermine\"\t3\n",
      "\"philadelphia\"\t1\n",
      "\"philip\"\t1\n",
      "\"phillip\"\t1\n",
      "\"phone\"\t15\n",
      "\"phonetic\"\t1\n",
      "\"photo\"\t1\n",
      "\"photoshop\"\t3\n",
      "\"php\"\t3\n",
      "\"phrasemake\"\t1\n",
      "\"phrases\"\t3\n",
      "\"physical\"\t6\n",
      "\"physicians\"\t1\n",
      "\"pibrochs\"\t1\n",
      "\"pick\"\t3\n",
      "\"picture\"\t4\n",
      "\"pictures\"\t8\n",
      "\"piece\"\t1\n",
      "\"pierre\"\t1\n",
      "\"pike\"\t1\n",
      "\"pilkington\"\t1\n",
      "\"pillsburywinthrop\"\t2\n",
      "\"pilocystic\"\t1\n",
      "\"pilot\"\t6\n",
      "\"pinion\"\t1\n",
      "\"pinnacle\"\t1\n",
      "\"pinnamaneni\"\t4\n",
      "\"pipe\"\t1\n",
      "\"pipeline\"\t3\n",
      "\"pipes\"\t2\n",
      "\"pitchers\"\t1\n",
      "\"pitifully\"\t1\n",
      "\"pl\"\t1\n",
      "\"place\"\t20\n",
      "\"placed\"\t1\n",
      "\"placement\"\t2\n",
      "\"places\"\t1\n",
      "\"plain\"\t4\n",
      "\"plan\"\t17\n",
      "\"plans\"\t2\n",
      "\"plant\"\t2\n",
      "\"planted\"\t1\n",
      "\"plants\"\t2\n",
      "\"platform\"\t2\n",
      "\"platitudes\"\t1\n",
      "\"platte\"\t1\n",
      "\"played\"\t1\n",
      "\"player\"\t2\n",
      "\"pleas\"\t1\n",
      "\"pleasant\"\t1\n",
      "\"please\"\t84\n",
      "\"pleased\"\t3\n",
      "\"pleasure\"\t1\n",
      "\"plentiful\"\t1\n",
      "\"plus\"\t4\n",
      "\"plushy\"\t1\n",
      "\"pm\"\t37\n",
      "\"po\"\t1\n",
      "\"point\"\t15\n",
      "\"points\"\t3\n",
      "\"policy\"\t6\n",
      "\"political\"\t3\n",
      "\"politically\"\t1\n",
      "\"politicians\"\t1\n",
      "\"pompey\"\t1\n",
      "\"poor\"\t3\n",
      "\"poors\"\t1\n",
      "\"pops\"\t2\n",
      "\"popular\"\t2\n",
      "\"portion\"\t1\n",
      "\"ports\"\t1\n",
      "\"position\"\t7\n",
      "\"positions\"\t1\n",
      "\"possesses\"\t1\n",
      "\"possibilities\"\t1\n",
      "\"possibility\"\t4\n",
      "\"possible\"\t17\n",
      "\"possibly\"\t2\n",
      "\"post\"\t9\n",
      "\"postal\"\t1\n",
      "\"posting\"\t1\n",
      "\"posts\"\t1\n",
      "\"potency\"\t1\n",
      "\"potential\"\t8\n",
      "\"pound\"\t2\n",
      "\"pounds\"\t1\n",
      "\"power\"\t24\n",
      "\"powered\"\t3\n",
      "\"powerful\"\t7\n",
      "\"powerquest\"\t1\n",
      "\"ppmfztdtet\"\t1\n",
      "\"practices\"\t3\n",
      "\"prager\"\t1\n",
      "\"pray\"\t1\n",
      "\"prbolem\"\t1\n",
      "\"pre\"\t3\n",
      "\"precedent\"\t1\n",
      "\"precious\"\t1\n",
      "\"precluded\"\t1\n",
      "\"preferences\"\t2\n",
      "\"preferred\"\t2\n",
      "\"prefix\"\t1\n",
      "\"premature\"\t1\n",
      "\"premiere\"\t2\n",
      "\"premium\"\t3\n",
      "\"premiums\"\t2\n",
      "\"preneur\"\t2\n",
      "\"prepared\"\t2\n",
      "\"preposition\"\t1\n",
      "\"presas\"\t2\n",
      "\"presccription\"\t1\n",
      "\"prescriptions\"\t1\n",
      "\"presence\"\t3\n",
      "\"present\"\t2\n",
      "\"presentation\"\t1\n",
      "\"presented\"\t1\n",
      "\"president\"\t9\n",
      "\"presidential\"\t1\n",
      "\"press\"\t4\n",
      "\"pressure\"\t5\n",
      "\"pressured\"\t2\n",
      "\"prestigious\"\t1\n",
      "\"presumably\"\t1\n",
      "\"presumed\"\t1\n",
      "\"pretty\"\t4\n",
      "\"prevatt\"\t4\n",
      "\"prevent\"\t1\n",
      "\"previous\"\t9\n",
      "\"previously\"\t2\n",
      "\"prez\"\t1\n",
      "\"price\"\t27\n",
      "\"prices\"\t8\n",
      "\"pricing\"\t4\n",
      "\"pricked\"\t1\n",
      "\"pride\"\t1\n",
      "\"priicce\"\t1\n",
      "\"priice\"\t1\n",
      "\"priices\"\t1\n",
      "\"prilosec\"\t1\n",
      "\"primary\"\t3\n",
      "\"principal\"\t3\n",
      "\"principle\"\t1\n",
      "\"print\"\t1\n",
      "\"printable\"\t2\n",
      "\"printer\"\t23\n",
      "\"prior\"\t8\n",
      "\"priority\"\t2\n",
      "\"priscilla\"\t1\n",
      "\"privacy\"\t6\n",
      "\"private\"\t5\n",
      "\"privileged\"\t1\n",
      "\"prize\"\t1\n",
      "\"pro\"\t2\n",
      "\"probably\"\t7\n",
      "\"problem\"\t5\n",
      "\"problematic\"\t1\n",
      "\"problems\"\t5\n",
      "\"procedures\"\t3\n",
      "\"proceed\"\t2\n",
      "\"proceeds\"\t1\n",
      "\"process\"\t13\n",
      "\"processed\"\t2\n",
      "\"processes\"\t2\n",
      "\"processing\"\t8\n",
      "\"processor\"\t1\n",
      "\"procrustes\"\t1\n",
      "\"procurement\"\t2\n",
      "\"produce\"\t2\n",
      "\"producer\"\t1\n",
      "\"producers\"\t3\n",
      "\"producing\"\t1\n",
      "\"product\"\t36\n",
      "\"production\"\t8\n",
      "\"products\"\t23\n",
      "\"professional\"\t14\n",
      "\"professionals\"\t3\n",
      "\"professor\"\t1\n",
      "\"profile\"\t3\n",
      "\"profit\"\t6\n",
      "\"profitable\"\t1\n",
      "\"profitbanners\"\t4\n",
      "\"profits\"\t1\n",
      "\"program\"\t7\n",
      "\"programs\"\t14\n",
      "\"progress\"\t2\n",
      "\"prohibited\"\t1\n",
      "\"project\"\t18\n",
      "\"projects\"\t2\n",
      "\"proliferation\"\t3\n",
      "\"prominent\"\t2\n",
      "\"promise\"\t1\n",
      "\"promised\"\t1\n",
      "\"promising\"\t1\n",
      "\"promote\"\t2\n",
      "\"promoted\"\t1\n",
      "\"promoting\"\t2\n",
      "\"promotion\"\t1\n",
      "\"promotional\"\t2\n",
      "\"prompt\"\t1\n",
      "\"properly\"\t2\n",
      "\"property\"\t2\n",
      "\"proposal\"\t9\n",
      "\"proposed\"\t3\n",
      "\"prospects\"\t1\n",
      "\"prosper\"\t3\n",
      "\"prostaff\"\t1\n",
      "\"protest\"\t2\n",
      "\"protesting\"\t1\n",
      "\"protocol\"\t1\n",
      "\"prove\"\t2\n",
      "\"proven\"\t1\n",
      "\"provide\"\t21\n",
      "\"provided\"\t3\n",
      "\"provider\"\t3\n",
      "\"providers\"\t2\n",
      "\"provides\"\t2\n",
      "\"providing\"\t6\n",
      "\"province\"\t1\n",
      "\"proxy\"\t7\n",
      "\"prozac\"\t1\n",
      "\"prriicegreat\"\t1\n",
      "\"ps\"\t1\n",
      "\"pst\"\t1\n",
      "\"psychotic\"\t1\n",
      "\"pting\"\t1\n",
      "\"pts\"\t1\n",
      "\"public\"\t2\n",
      "\"publicity\"\t1\n",
      "\"published\"\t5\n",
      "\"publishes\"\t1\n",
      "\"publishing\"\t2\n",
      "\"puc\"\t3\n",
      "\"pull\"\t5\n",
      "\"pulled\"\t1\n",
      "\"pulling\"\t1\n",
      "\"pulp\"\t1\n",
      "\"pun\"\t1\n",
      "\"purchase\"\t11\n",
      "\"purchased\"\t1\n",
      "\"purchases\"\t3\n",
      "\"purchasing\"\t2\n",
      "\"pure\"\t1\n",
      "\"purpose\"\t6\n",
      "\"purposefully\"\t1\n",
      "\"pursuing\"\t1\n",
      "\"pushed\"\t1\n",
      "\"pushes\"\t1\n",
      "\"pushing\"\t1\n",
      "\"put\"\t12\n",
      "\"putpeel\"\t8\n",
      "\"puts\"\t1\n",
      "\"pwarden\"\t1\n",
      "\"quadrangular\"\t1\n",
      "\"qualification\"\t3\n",
      "\"qualified\"\t1\n",
      "\"qualities\"\t1\n",
      "\"quality\"\t15\n",
      "\"qualityproducts\"\t1\n",
      "\"quark\"\t1\n",
      "\"quarter\"\t1\n",
      "\"quasi\"\t1\n",
      "\"queensland\"\t2\n",
      "\"question\"\t11\n",
      "\"questions\"\t36\n",
      "\"quick\"\t3\n",
      "\"quickens\"\t1\n",
      "\"quickly\"\t7\n",
      "\"quite\"\t4\n",
      "\"quitting\"\t1\n",
      "\"quote\"\t1\n",
      "\"quoted\"\t4\n",
      "\"quotes\"\t3\n",
      "\"rabey\"\t1\n",
      "\"rac\"\t1\n",
      "\"race\"\t1\n",
      "\"rail\"\t3\n",
      "\"railing\"\t1\n",
      "\"raise\"\t2\n",
      "\"raised\"\t2\n",
      "\"raises\"\t2\n",
      "\"raising\"\t1\n",
      "\"ram\"\t2\n",
      "\"ramupgradeable\"\t1\n",
      "\"ran\"\t2\n",
      "\"ranch\"\t10\n",
      "\"randall\"\t2\n",
      "\"randle\"\t1\n",
      "\"randomly\"\t1\n",
      "\"randy\"\t1\n",
      "\"ranen\"\t1\n",
      "\"range\"\t2\n",
      "\"rankings\"\t1\n",
      "\"ranks\"\t2\n",
      "\"rapidly\"\t1\n",
      "\"rare\"\t1\n",
      "\"rat\"\t2\n",
      "\"rate\"\t33\n",
      "\"rated\"\t3\n",
      "\"rates\"\t7\n",
      "\"rather\"\t6\n",
      "\"rating\"\t2\n",
      "\"ratio\"\t1\n",
      "\"ravi\"\t6\n",
      "\"ray\"\t4\n",
      "\"raymond\"\t7\n",
      "\"rd\"\t1\n",
      "\"re\"\t33\n",
      "\"rea\"\t1\n",
      "\"reach\"\t7\n",
      "\"reached\"\t3\n",
      "\"reaching\"\t1\n",
      "\"read\"\t18\n",
      "\"reader\"\t23\n",
      "\"readers\"\t3\n",
      "\"readies\"\t1\n",
      "\"reading\"\t1\n",
      "\"reado\"\t1\n",
      "\"reads\"\t2\n",
      "\"ready\"\t5\n",
      "\"real\"\t14\n",
      "\"realize\"\t3\n",
      "\"really\"\t7\n",
      "\"rear\"\t1\n",
      "\"reason\"\t7\n",
      "\"reasonable\"\t2\n",
      "\"reasons\"\t1\n",
      "\"reassigned\"\t1\n",
      "\"rebecca\"\t2\n",
      "\"rebel\"\t2\n",
      "\"rebels\"\t2\n",
      "\"recap\"\t3\n",
      "\"receipt\"\t6\n",
      "\"receipts\"\t1\n",
      "\"receivable\"\t1\n",
      "\"receive\"\t12\n",
      "\"received\"\t5\n",
      "\"receives\"\t4\n",
      "\"receiving\"\t5\n",
      "\"recent\"\t3\n",
      "\"recently\"\t5\n",
      "\"reception\"\t1\n",
      "\"recieved\"\t2\n",
      "\"recipient\"\t2\n",
      "\"reclaimers\"\t1\n",
      "\"recognition\"\t1\n",
      "\"recognizing\"\t4\n",
      "\"recommend\"\t1\n",
      "\"recommendation\"\t1\n",
      "\"recommendations\"\t4\n",
      "\"record\"\t2\n",
      "\"recorded\"\t1\n",
      "\"recover\"\t2\n",
      "\"recovery\"\t2\n",
      "\"recruiting\"\t3\n",
      "\"red\"\t2\n",
      "\"redesign\"\t2\n",
      "\"redesigns\"\t1\n",
      "\"redhat\"\t1\n",
      "\"reduce\"\t1\n",
      "\"reduced\"\t1\n",
      "\"reduces\"\t2\n",
      "\"reduction\"\t4\n",
      "\"ref\"\t2\n",
      "\"refer\"\t2\n",
      "\"reference\"\t2\n",
      "\"references\"\t1\n",
      "\"referendum\"\t6\n",
      "\"referral\"\t2\n",
      "\"referred\"\t2\n",
      "\"refinances\"\t2\n",
      "\"reflect\"\t1\n",
      "\"reflected\"\t1\n",
      "\"reflections\"\t1\n",
      "\"reflux\"\t1\n",
      "\"refugee\"\t3\n",
      "\"refusals\"\t1\n",
      "\"refuse\"\t1\n",
      "\"regard\"\t9\n",
      "\"regarding\"\t2\n",
      "\"regardless\"\t4\n",
      "\"regards\"\t7\n",
      "\"regina\"\t6\n",
      "\"region\"\t6\n",
      "\"regional\"\t11\n",
      "\"regions\"\t6\n",
      "\"registered\"\t4\n",
      "\"regretful\"\t1\n",
      "\"regulations\"\t3\n",
      "\"reins\"\t1\n",
      "\"reiterate\"\t1\n",
      "\"rejoice\"\t1\n",
      "\"related\"\t2\n",
      "\"relates\"\t1\n",
      "\"relating\"\t2\n",
      "\"relation\"\t1\n",
      "\"relations\"\t3\n",
      "\"relationship\"\t6\n",
      "\"relative\"\t2\n",
      "\"release\"\t1\n",
      "\"released\"\t4\n",
      "\"releases\"\t2\n",
      "\"relegated\"\t1\n",
      "\"reliant\"\t4\n",
      "\"reliantenergy\"\t3\n",
      "\"relieved\"\t1\n",
      "\"relieves\"\t1\n",
      "\"remain\"\t1\n",
      "\"remainder\"\t2\n",
      "\"remaining\"\t3\n",
      "\"remember\"\t13\n",
      "\"remind\"\t2\n",
      "\"reminder\"\t1\n",
      "\"remitted\"\t1\n",
      "\"removal\"\t1\n",
      "\"remove\"\t6\n",
      "\"removed\"\t4\n",
      "\"removes\"\t1\n",
      "\"removing\"\t1\n",
      "\"remunerate\"\t1\n",
      "\"renewable\"\t2\n",
      "\"rennie\"\t1\n",
      "\"rental\"\t1\n",
      "\"repeal\"\t1\n",
      "\"repeatedly\"\t2\n",
      "\"replace\"\t2\n",
      "\"replay\"\t2\n",
      "\"replies\"\t3\n",
      "\"repling\"\t1\n",
      "\"reply\"\t5\n",
      "\"replying\"\t1\n",
      "\"report\"\t14\n",
      "\"reportedly\"\t2\n",
      "\"reporting\"\t10\n",
      "\"reports\"\t1\n",
      "\"representatives\"\t2\n",
      "\"republicans\"\t2\n",
      "\"reputation\"\t2\n",
      "\"request\"\t14\n",
      "\"requesting\"\t1\n",
      "\"require\"\t3\n",
      "\"required\"\t2\n",
      "\"requirement\"\t1\n",
      "\"requirements\"\t5\n",
      "\"requires\"\t1\n",
      "\"requiring\"\t1\n",
      "\"reread\"\t1\n",
      "\"research\"\t5\n",
      "\"resell\"\t1\n",
      "\"reseller\"\t1\n",
      "\"reservation\"\t1\n",
      "\"reserve\"\t2\n",
      "\"reserved\"\t3\n",
      "\"residents\"\t1\n",
      "\"residue\"\t1\n",
      "\"resistance\"\t1\n",
      "\"resolve\"\t4\n",
      "\"resolved\"\t1\n",
      "\"resort\"\t2\n",
      "\"resource\"\t5\n",
      "\"resourceful\"\t1\n",
      "\"resources\"\t23\n",
      "\"resourcestocks\"\t1\n",
      "\"respect\"\t4\n",
      "\"respectable\"\t1\n",
      "\"respected\"\t1\n",
      "\"respective\"\t2\n",
      "\"respond\"\t8\n",
      "\"response\"\t4\n",
      "\"responses\"\t8\n",
      "\"responsibilites\"\t2\n",
      "\"responsibilities\"\t7\n",
      "\"responsibility\"\t10\n",
      "\"responsible\"\t4\n",
      "\"rest\"\t5\n",
      "\"restate\"\t1\n",
      "\"restless\"\t1\n",
      "\"restore\"\t1\n",
      "\"restrictions\"\t1\n",
      "\"result\"\t2\n",
      "\"resulted\"\t2\n",
      "\"results\"\t6\n",
      "\"resume\"\t3\n",
      "\"retail\"\t4\n",
      "\"retains\"\t3\n",
      "\"retarding\"\t1\n",
      "\"retentive\"\t1\n",
      "\"retire\"\t3\n",
      "\"retired\"\t2\n",
      "\"retirement\"\t1\n",
      "\"return\"\t8\n",
      "\"returned\"\t2\n",
      "\"rev\"\t4\n",
      "\"revenue\"\t2\n",
      "\"reversed\"\t2\n",
      "\"review\"\t12\n",
      "\"reviewed\"\t4\n",
      "\"reviewing\"\t1\n",
      "\"reviews\"\t6\n",
      "\"revised\"\t2\n",
      "\"revolution\"\t2\n",
      "\"revolutionary\"\t1\n",
      "\"rewarding\"\t2\n",
      "\"rewrite\"\t2\n",
      "\"rge\"\t1\n",
      "\"rhine\"\t1\n",
      "\"rhinopez\"\t1\n",
      "\"rich\"\t1\n",
      "\"richard\"\t3\n",
      "\"richarddaniel\"\t1\n",
      "\"riches\"\t1\n",
      "\"rick\"\t11\n",
      "\"rid\"\t1\n",
      "\"ride\"\t2\n",
      "\"ridiculous\"\t1\n",
      "\"riding\"\t1\n",
      "\"riedel\"\t1\n",
      "\"right\"\t17\n",
      "\"rightly\"\t1\n",
      "\"rights\"\t4\n",
      "\"rise\"\t1\n",
      "\"rising\"\t1\n",
      "\"risk\"\t49\n",
      "\"rita\"\t3\n",
      "\"river\"\t2\n",
      "\"riverdeep\"\t1\n",
      "\"rizzi\"\t2\n",
      "\"rm\"\t1\n",
      "\"rmation\"\t1\n",
      "\"road\"\t2\n",
      "\"roared\"\t1\n",
      "\"rob\"\t3\n",
      "\"robert\"\t7\n",
      "\"roberts\"\t9\n",
      "\"rock\"\t2\n",
      "\"rodgers\"\t1\n",
      "\"rodney\"\t1\n",
      "\"rodriguez\"\t2\n",
      "\"rogram\"\t1\n",
      "\"rohan\"\t1\n",
      "\"roibot\"\t3\n",
      "\"role\"\t18\n",
      "\"roll\"\t1\n",
      "\"roman\"\t4\n",
      "\"romantic\"\t1\n",
      "\"romeo\"\t1\n",
      "\"roof\"\t2\n",
      "\"rook\"\t1\n",
      "\"room\"\t3\n",
      "\"rosalie\"\t1\n",
      "\"rosel\"\t2\n",
      "\"rosenfield\"\t6\n",
      "\"ross\"\t4\n",
      "\"rossman\"\t12\n",
      "\"round\"\t1\n",
      "\"routes\"\t1\n",
      "\"roving\"\t6\n",
      "\"roxio\"\t1\n",
      "\"rsa\"\t1\n",
      "\"rsbaker\"\t1\n",
      "\"rto\"\t1\n",
      "\"rtol\"\t1\n",
      "\"ruanda\"\t1\n",
      "\"rub\"\t1\n",
      "\"rudl\"\t2\n",
      "\"ruin\"\t1\n",
      "\"rule\"\t2\n",
      "\"rules\"\t1\n",
      "\"ruling\"\t2\n",
      "\"run\"\t2\n",
      "\"runkel\"\t1\n",
      "\"running\"\t7\n",
      "\"rush\"\t1\n",
      "\"rushed\"\t1\n",
      "\"russell\"\t1\n",
      "\"ruzika\"\t1\n",
      "\"rvsq\"\t1\n",
      "\"rw\"\t1\n",
      "\"rx\"\t1\n",
      "\"ryanmcgeachie\"\t1\n",
      "\"sa\"\t4\n",
      "\"saa\"\t1\n",
      "\"saave\"\t7\n",
      "\"safe\"\t5\n",
      "\"safely\"\t2\n",
      "\"safety\"\t2\n",
      "\"said\"\t3\n",
      "\"salaried\"\t1\n",
      "\"sale\"\t10\n",
      "\"sales\"\t43\n",
      "\"sallen\"\t1\n",
      "\"sally\"\t34\n",
      "\"salomon\"\t2\n",
      "\"salt\"\t1\n",
      "\"sam\"\t3\n",
      "\"samarium\"\t1\n",
      "\"same\"\t13\n",
      "\"samer\"\t5\n",
      "\"sample\"\t6\n",
      "\"sampling\"\t1\n",
      "\"samuel\"\t1\n",
      "\"san\"\t4\n",
      "\"sand\"\t1\n",
      "\"sandton\"\t2\n",
      "\"sang\"\t1\n",
      "\"sanibel\"\t1\n",
      "\"sankoh\"\t3\n",
      "\"sap\"\t17\n",
      "\"sapphire\"\t1\n",
      "\"sat\"\t1\n",
      "\"satisfied\"\t4\n",
      "\"saturday\"\t1\n",
      "\"save\"\t8\n",
      "\"saving\"\t2\n",
      "\"savings\"\t1\n",
      "\"savvy\"\t1\n",
      "\"saw\"\t1\n",
      "\"say\"\t6\n",
      "\"saying\"\t4\n",
      "\"says\"\t3\n",
      "\"sc\"\t5\n",
      "\"scampbell\"\t1\n",
      "\"scams\"\t1\n",
      "\"scenario\"\t1\n",
      "\"schafer\"\t1\n",
      "\"schaffer\"\t1\n",
      "\"schedule\"\t8\n",
      "\"scheduled\"\t3\n",
      "\"scheduling\"\t4\n",
      "\"schmidt\"\t4\n",
      "\"school\"\t2\n",
      "\"schott\"\t1\n",
      "\"schumack\"\t3\n",
      "\"science\"\t1\n",
      "\"scientific\"\t1\n",
      "\"scope\"\t2\n",
      "\"score\"\t1\n",
      "\"scott\"\t2\n",
      "\"scotty\"\t1\n",
      "\"scout\"\t1\n",
      "\"scratch\"\t1\n",
      "\"screamed\"\t1\n",
      "\"screaming\"\t1\n",
      "\"screen\"\t1\n",
      "\"screening\"\t1\n",
      "\"screwball\"\t1\n",
      "\"script\"\t3\n",
      "\"scroll\"\t3\n",
      "\"scuttle\"\t1\n",
      "\"sdba\"\t1\n",
      "\"sds\"\t1\n",
      "\"search\"\t4\n",
      "\"searching\"\t2\n",
      "\"season\"\t1\n",
      "\"second\"\t4\n",
      "\"secret\"\t8\n",
      "\"secrets\"\t5\n",
      "\"section\"\t4\n",
      "\"sector\"\t3\n",
      "\"secure\"\t3\n",
      "\"secured\"\t1\n",
      "\"securities\"\t5\n",
      "\"securitization\"\t3\n",
      "\"security\"\t10\n",
      "\"see\"\t34\n",
      "\"seeded\"\t1\n",
      "\"seeing\"\t1\n",
      "\"seem\"\t3\n",
      "\"seemed\"\t2\n",
      "\"seems\"\t4\n",
      "\"seen\"\t4\n",
      "\"seize\"\t2\n",
      "\"selected\"\t1\n",
      "\"selection\"\t4\n",
      "\"self\"\t4\n",
      "\"sell\"\t8\n",
      "\"sellens\"\t1\n",
      "\"selling\"\t11\n",
      "\"sellinternetaccess\"\t5\n",
      "\"sells\"\t2\n",
      "\"semester\"\t1\n",
      "\"sempra\"\t1\n",
      "\"sempratrading\"\t1\n",
      "\"sen\"\t1\n",
      "\"senate\"\t2\n",
      "\"senator\"\t5\n",
      "\"send\"\t23\n",
      "\"sending\"\t1\n",
      "\"sengupta\"\t1\n",
      "\"senior\"\t11\n",
      "\"sense\"\t3\n",
      "\"sensitive\"\t2\n",
      "\"sent\"\t16\n",
      "\"sentence\"\t2\n",
      "\"sentences\"\t4\n",
      "\"sentiment\"\t1\n",
      "\"separate\"\t7\n",
      "\"sera\"\t2\n",
      "\"sergeev\"\t5\n",
      "\"serial\"\t2\n",
      "\"serious\"\t1\n",
      "\"serve\"\t6\n",
      "\"served\"\t1\n",
      "\"server\"\t5\n",
      "\"servers\"\t2\n",
      "\"service\"\t48\n",
      "\"services\"\t16\n",
      "\"session\"\t1\n",
      "\"sessions\"\t2\n",
      "\"set\"\t15\n",
      "\"setbacks\"\t1\n",
      "\"settanni\"\t1\n",
      "\"setting\"\t3\n",
      "\"settingt\"\t1\n",
      "\"settled\"\t3\n",
      "\"settlement\"\t2\n",
      "\"settlements\"\t2\n",
      "\"setup\"\t5\n",
      "\"seven\"\t5\n",
      "\"seventhpower\"\t4\n",
      "\"several\"\t17\n",
      "\"severe\"\t1\n",
      "\"seward\"\t1\n",
      "\"sex\"\t1\n",
      "\"sexual\"\t2\n",
      "\"sezgen\"\t4\n",
      "\"shakespeare\"\t3\n",
      "\"shall\"\t9\n",
      "\"shanbhogue\"\t5\n",
      "\"shandong\"\t1\n",
      "\"share\"\t8\n",
      "\"shared\"\t4\n",
      "\"shares\"\t1\n",
      "\"sharing\"\t3\n",
      "\"sharpens\"\t1\n",
      "\"sharply\"\t1\n",
      "\"she\"\t18\n",
      "\"sheila\"\t4\n",
      "\"shenkman\"\t1\n",
      "\"sherlyn\"\t3\n",
      "\"sherri\"\t2\n",
      "\"shift\"\t2\n",
      "\"shiip\"\t2\n",
      "\"shipped\"\t1\n",
      "\"shipping\"\t1\n",
      "\"shirley\"\t18\n",
      "\"shoot\"\t1\n",
      "\"shop\"\t3\n",
      "\"shopping\"\t5\n",
      "\"short\"\t8\n",
      "\"shorter\"\t1\n",
      "\"shortly\"\t1\n",
      "\"shot\"\t1\n",
      "\"should\"\t27\n",
      "\"shoulder\"\t1\n",
      "\"show\"\t7\n",
      "\"showcase\"\t20\n",
      "\"showcases\"\t6\n",
      "\"shown\"\t2\n",
      "\"shows\"\t1\n",
      "\"shults\"\t1\n",
      "\"shut\"\t1\n",
      "\"shutdown\"\t1\n",
      "\"shwc\"\t1\n",
      "\"shy\"\t1\n",
      "\"siberia\"\t1\n",
      "\"sibilant\"\t1\n",
      "\"sick\"\t1\n",
      "\"side\"\t2\n",
      "\"sides\"\t1\n",
      "\"sierra\"\t5\n",
      "\"sight\"\t1\n",
      "\"sign\"\t4\n",
      "\"signature\"\t1\n",
      "\"signed\"\t4\n",
      "\"significance\"\t1\n",
      "\"significant\"\t4\n",
      "\"signing\"\t1\n",
      "\"signups\"\t1\n",
      "\"sillily\"\t1\n",
      "\"silver\"\t1\n",
      "\"similes\"\t1\n",
      "\"simple\"\t10\n",
      "\"simplicity\"\t4\n",
      "\"simply\"\t5\n",
      "\"since\"\t13\n",
      "\"sincerely\"\t4\n",
      "\"singing\"\t1\n",
      "\"single\"\t4\n",
      "\"singleton\"\t1\n",
      "\"sink\"\t1\n",
      "\"sir\"\t2\n",
      "\"sit\"\t1\n",
      "\"sitara\"\t3\n",
      "\"site\"\t60\n",
      "\"sites\"\t31\n",
      "\"situation\"\t4\n",
      "\"six\"\t3\n",
      "\"size\"\t5\n",
      "\"skilling\"\t7\n",
      "\"skills\"\t2\n",
      "\"skin\"\t1\n",
      "\"skinner\"\t3\n",
      "\"slash\"\t1\n",
      "\"slaver\"\t1\n",
      "\"sleep\"\t2\n",
      "\"slgavjmoqq\"\t1\n",
      "\"slightly\"\t1\n",
      "\"slipped\"\t1\n",
      "\"slots\"\t1\n",
      "\"slotting\"\t1\n",
      "\"slow\"\t3\n",
      "\"slower\"\t1\n",
      "\"slowly\"\t1\n",
      "\"small\"\t3\n",
      "\"smaller\"\t7\n",
      "\"smith\"\t7\n",
      "\"smithc\"\t1\n",
      "\"smoker\"\t1\n",
      "\"smoking\"\t7\n",
      "\"sneak\"\t2\n",
      "\"snhezkjzhisbpjhgx\"\t1\n",
      "\"snooping\"\t1\n",
      "\"snowboard\"\t1\n",
      "\"so\"\t60\n",
      "\"soap\"\t2\n",
      "\"socal\"\t4\n",
      "\"softtwares\"\t2\n",
      "\"software\"\t13\n",
      "\"softwares\"\t1\n",
      "\"sokolov\"\t4\n",
      "\"sold\"\t2\n",
      "\"solely\"\t1\n",
      "\"solicit\"\t1\n",
      "\"solicitation\"\t2\n",
      "\"solid\"\t1\n",
      "\"solmonson\"\t1\n",
      "\"solution\"\t2\n",
      "\"solved\"\t1\n",
      "\"soma\"\t1\n",
      "\"some\"\t68\n",
      "\"somehow\"\t1\n",
      "\"someone\"\t11\n",
      "\"something\"\t8\n",
      "\"sometime\"\t2\n",
      "\"sometimes\"\t1\n",
      "\"somewhat\"\t1\n",
      "\"son\"\t10\n",
      "\"songs\"\t1\n",
      "\"soon\"\t9\n",
      "\"sorry\"\t2\n",
      "\"sos\"\t1\n",
      "\"sotware\"\t1\n",
      "\"sound\"\t3\n",
      "\"soundmax\"\t1\n",
      "\"sounds\"\t1\n",
      "\"source\"\t5\n",
      "\"sources\"\t7\n",
      "\"south\"\t15\n",
      "\"southern\"\t1\n",
      "\"southernenergy\"\t2\n",
      "\"southwest\"\t1\n",
      "\"souza\"\t1\n",
      "\"sp\"\t1\n",
      "\"space\"\t7\n",
      "\"spam\"\t7\n",
      "\"spare\"\t1\n",
      "\"spark\"\t2\n",
      "\"speak\"\t8\n",
      "\"speaking\"\t1\n",
      "\"special\"\t14\n",
      "\"specials\"\t4\n",
      "\"specific\"\t7\n",
      "\"specifically\"\t4\n",
      "\"speed\"\t2\n",
      "\"speeding\"\t1\n",
      "\"speeds\"\t1\n",
      "\"spell\"\t2\n",
      "\"spelling\"\t3\n",
      "\"spend\"\t8\n",
      "\"spending\"\t1\n",
      "\"spent\"\t4\n",
      "\"spigot\"\t1\n",
      "\"spirit\"\t2\n",
      "\"split\"\t2\n",
      "\"splitting\"\t1\n",
      "\"spoke\"\t2\n",
      "\"spoken\"\t2\n",
      "\"sponsor\"\t4\n",
      "\"sponsored\"\t1\n",
      "\"sponsoring\"\t1\n",
      "\"sponsorship\"\t9\n",
      "\"sportsbetting\"\t2\n",
      "\"spot\"\t5\n",
      "\"spotlight\"\t1\n",
      "\"spp\"\t1\n",
      "\"spread\"\t1\n",
      "\"spreads\"\t1\n",
      "\"spring\"\t1\n",
      "\"sql\"\t1\n",
      "\"squeeze\"\t1\n",
      "\"squill\"\t1\n",
      "\"sr\"\t1\n",
      "\"srs\"\t1\n",
      "\"ss\"\t1\n",
      "\"ssb\"\t1\n",
      "\"ssmb\"\t1\n",
      "\"st\"\t3\n",
      "\"stability\"\t3\n",
      "\"stable\"\t1\n",
      "\"stacey\"\t4\n",
      "\"stacy\"\t1\n",
      "\"stad\"\t1\n",
      "\"staff\"\t5\n",
      "\"stage\"\t2\n",
      "\"stake\"\t2\n",
      "\"stalling\"\t1\n",
      "\"stand\"\t2\n",
      "\"standard\"\t3\n",
      "\"standing\"\t6\n",
      "\"stands\"\t1\n",
      "\"star\"\t2\n",
      "\"stars\"\t1\n",
      "\"start\"\t9\n",
      "\"startbgmlmezine\"\t2\n",
      "\"started\"\t3\n",
      "\"starting\"\t1\n",
      "\"state\"\t30\n",
      "\"stated\"\t2\n",
      "\"statement\"\t1\n",
      "\"statements\"\t1\n",
      "\"states\"\t5\n",
      "\"station\"\t2\n",
      "\"stats\"\t2\n",
      "\"status\"\t1\n",
      "\"stay\"\t2\n",
      "\"stayed\"\t1\n",
      "\"steadily\"\t1\n",
      "\"steak\"\t1\n",
      "\"stearns\"\t2\n",
      "\"steeves\"\t2\n",
      "\"stefkatz\"\t1\n",
      "\"stella\"\t6\n",
      "\"stelly\"\t1\n",
      "\"stentofon\"\t2\n",
      "\"step\"\t2\n",
      "\"stephanie\"\t1\n",
      "\"steps\"\t1\n",
      "\"stern\"\t1\n",
      "\"steve\"\t3\n",
      "\"stick\"\t2\n",
      "\"stil\"\t2\n",
      "\"still\"\t12\n",
      "\"stilled\"\t1\n",
      "\"stinson\"\t8\n",
      "\"stock\"\t5\n",
      "\"stocker\"\t1\n",
      "\"stockhouse\"\t1\n",
      "\"stomaching\"\t1\n",
      "\"stood\"\t1\n",
      "\"stop\"\t15\n",
      "\"stopping\"\t3\n",
      "\"store\"\t2\n",
      "\"stores\"\t6\n",
      "\"stories\"\t4\n",
      "\"story\"\t17\n",
      "\"stove\"\t1\n",
      "\"straight\"\t4\n",
      "\"strain\"\t1\n",
      "\"strangas\"\t1\n",
      "\"strange\"\t2\n",
      "\"strangulate\"\t1\n",
      "\"stratagem\"\t1\n",
      "\"strategic\"\t3\n",
      "\"strategies\"\t5\n",
      "\"strategist\"\t2\n",
      "\"strategy\"\t2\n",
      "\"stratton\"\t1\n",
      "\"streams\"\t2\n",
      "\"street\"\t1\n",
      "\"streets\"\t1\n",
      "\"strength\"\t1\n",
      "\"strengthened\"\t1\n",
      "\"strengthening\"\t1\n",
      "\"strengths\"\t2\n",
      "\"stress\"\t5\n",
      "\"stretch\"\t3\n",
      "\"strictly\"\t1\n",
      "\"strides\"\t2\n",
      "\"striking\"\t1\n",
      "\"strong\"\t2\n",
      "\"stronger\"\t2\n",
      "\"stroock\"\t1\n",
      "\"struck\"\t2\n",
      "\"structure\"\t5\n",
      "\"students\"\t4\n",
      "\"studio\"\t2\n",
      "\"stuff\"\t4\n",
      "\"stukm\"\t1\n",
      "\"stupid\"\t1\n",
      "\"stupidity\"\t1\n",
      "\"style\"\t1\n",
      "\"styles\"\t1\n",
      "\"subconsciously\"\t1\n",
      "\"subject\"\t53\n",
      "\"submissions\"\t4\n",
      "\"submit\"\t10\n",
      "\"submitted\"\t1\n",
      "\"subscribe\"\t7\n",
      "\"subscribed\"\t4\n",
      "\"subscribers\"\t1\n",
      "\"subscribing\"\t1\n",
      "\"subscription\"\t10\n",
      "\"subscriptions\"\t1\n",
      "\"subsequently\"\t1\n",
      "\"substantial\"\t2\n",
      "\"succeed\"\t3\n",
      "\"succeeded\"\t1\n",
      "\"succeeding\"\t1\n",
      "\"succeeds\"\t1\n",
      "\"success\"\t25\n",
      "\"successes\"\t3\n",
      "\"successful\"\t17\n",
      "\"successfully\"\t1\n",
      "\"such\"\t9\n",
      "\"sue\"\t3\n",
      "\"sugar\"\t3\n",
      "\"suggest\"\t2\n",
      "\"suggested\"\t1\n",
      "\"suggestions\"\t5\n",
      "\"suite\"\t5\n",
      "\"sum\"\t3\n",
      "\"summary\"\t5\n",
      "\"summer\"\t5\n",
      "\"summit\"\t1\n",
      "\"sunrise\"\t1\n",
      "\"sup\"\t1\n",
      "\"super\"\t5\n",
      "\"superb\"\t1\n",
      "\"superman\"\t1\n",
      "\"supervisor\"\t4\n",
      "\"supervisors\"\t5\n",
      "\"supplier\"\t2\n",
      "\"suppliers\"\t6\n",
      "\"supply\"\t4\n",
      "\"support\"\t16\n",
      "\"supported\"\t1\n",
      "\"supporting\"\t6\n",
      "\"supportive\"\t1\n",
      "\"supports\"\t3\n",
      "\"supposedly\"\t1\n",
      "\"suppressant\"\t1\n",
      "\"suprervisagra\"\t1\n",
      "\"sure\"\t11\n",
      "\"surf\"\t5\n",
      "\"surfing\"\t1\n",
      "\"surfola\"\t4\n",
      "\"surged\"\t1\n",
      "\"surgery\"\t1\n",
      "\"surrounding\"\t1\n",
      "\"survey\"\t3\n",
      "\"susan\"\t9\n",
      "\"suspicion\"\t1\n",
      "\"sustainability\"\t1\n",
      "\"suzms\"\t1\n",
      "\"swap\"\t2\n",
      "\"swbe\"\t1\n",
      "\"sweet\"\t3\n",
      "\"swidner\"\t1\n",
      "\"swift\"\t2\n",
      "\"swings\"\t1\n",
      "\"swiss\"\t2\n",
      "\"switch\"\t1\n",
      "\"switchman\"\t1\n",
      "\"sydney\"\t2\n",
      "\"sylg\"\t1\n",
      "\"symaantec\"\t1\n",
      "\"syndicate\"\t1\n",
      "\"system\"\t13\n",
      "\"systems\"\t6\n",
      "\"systemslogical\"\t1\n",
      "\"table\"\t2\n",
      "\"tablet\"\t1\n",
      "\"tablets\"\t1\n",
      "\"tactically\"\t1\n",
      "\"tag\"\t1\n",
      "\"take\"\t19\n",
      "\"takegreat\"\t1\n",
      "\"taken\"\t2\n",
      "\"takeover\"\t2\n",
      "\"takes\"\t7\n",
      "\"taking\"\t4\n",
      "\"takriti\"\t5\n",
      "\"talent\"\t2\n",
      "\"talk\"\t7\n",
      "\"talked\"\t1\n",
      "\"talking\"\t2\n",
      "\"talks\"\t3\n",
      "\"tall\"\t1\n",
      "\"tamarchenko\"\t4\n",
      "\"tang\"\t5\n",
      "\"tangible\"\t1\n",
      "\"tantalum\"\t1\n",
      "\"tanya\"\t4\n",
      "\"target\"\t9\n",
      "\"targeted\"\t11\n",
      "\"targeting\"\t1\n",
      "\"tarrif\"\t2\n",
      "\"tarrin\"\t1\n",
      "\"task\"\t2\n",
      "\"taught\"\t1\n",
      "\"tax\"\t1\n",
      "\"taxation\"\t1\n",
      "\"taylor\"\t4\n",
      "\"taylorja\"\t1\n",
      "\"tea\"\t2\n",
      "\"teach\"\t1\n",
      "\"teacher\"\t1\n",
      "\"teachers\"\t1\n",
      "\"team\"\t19\n",
      "\"tear\"\t1\n",
      "\"tears\"\t1\n",
      "\"technical\"\t3\n",
      "\"technicalities\"\t1\n",
      "\"techniques\"\t5\n",
      "\"technology\"\t3\n",
      "\"teco\"\t2\n",
      "\"teddy\"\t3\n",
      "\"tejones\"\t2\n",
      "\"tel\"\t3\n",
      "\"tele\"\t1\n",
      "\"telephone\"\t3\n",
      "\"teleseminar\"\t2\n",
      "\"television\"\t1\n",
      "\"tell\"\t13\n",
      "\"telling\"\t1\n",
      "\"tells\"\t1\n",
      "\"tempted\"\t1\n",
      "\"tenacity\"\t1\n",
      "\"tenderer\"\t1\n",
      "\"tendererlycopodium\"\t1\n",
      "\"teosrest\"\t1\n",
      "\"terence\"\t1\n",
      "\"term\"\t8\n",
      "\"terminate\"\t1\n",
      "\"terms\"\t5\n",
      "\"terrible\"\t1\n",
      "\"terrific\"\t1\n",
      "\"terrorist\"\t1\n",
      "\"terry\"\t1\n",
      "\"test\"\t1\n",
      "\"testimonials\"\t2\n",
      "\"texaco\"\t6\n",
      "\"texas\"\t1\n",
      "\"text\"\t15\n",
      "\"texts\"\t2\n",
      "\"textual\"\t1\n",
      "\"texture\"\t1\n",
      "\"textures\"\t1\n",
      "\"tgary\"\t1\n",
      "\"th\"\t14\n",
      "\"than\"\t32\n",
      "\"thank\"\t9\n",
      "\"thanking\"\t3\n",
      "\"thanks\"\t34\n",
      "\"that\"\t227\n",
      "\"the\"\t1247\n",
      "\"theinvestment\"\t1\n",
      "\"their\"\t40\n",
      "\"them\"\t56\n",
      "\"themselves\"\t4\n",
      "\"then\"\t28\n",
      "\"theqgrefor\"\t1\n",
      "\"there\"\t56\n",
      "\"thereafter\"\t2\n",
      "\"therefore\"\t7\n",
      "\"thereof\"\t1\n",
      "\"these\"\t50\n",
      "\"they\"\t63\n",
      "\"thickness\"\t1\n",
      "\"thimble\"\t1\n",
      "\"thing\"\t13\n",
      "\"things\"\t8\n",
      "\"think\"\t11\n",
      "\"thinking\"\t1\n",
      "\"third\"\t3\n",
      "\"thirteen\"\t1\n",
      "\"thirty\"\t3\n",
      "\"this\"\t262\n",
      "\"thompson\"\t1\n",
      "\"thorns\"\t1\n",
      "\"thoroughly\"\t1\n",
      "\"those\"\t15\n",
      "\"though\"\t6\n",
      "\"thought\"\t2\n",
      "\"thoughts\"\t2\n",
      "\"thousainds\"\t1\n",
      "\"thousand\"\t2\n",
      "\"thousands\"\t3\n",
      "\"threat\"\t4\n",
      "\"threats\"\t2\n",
      "\"three\"\t17\n",
      "\"thrid\"\t1\n",
      "\"thronged\"\t1\n",
      "\"through\"\t18\n",
      "\"throughout\"\t4\n",
      "\"throw\"\t1\n",
      "\"thu\"\t10\n",
      "\"thunder\"\t1\n",
      "\"thuraisingham\"\t6\n",
      "\"thursday\"\t11\n",
      "\"thus\"\t1\n",
      "\"ticket\"\t2\n",
      "\"tidbits\"\t1\n",
      "\"till\"\t1\n",
      "\"tilts\"\t1\n",
      "\"time\"\t44\n",
      "\"timekeeping\"\t2\n",
      "\"timely\"\t2\n",
      "\"times\"\t5\n",
      "\"timesheets\"\t1\n",
      "\"timing\"\t1\n",
      "\"timotheus\"\t1\n",
      "\"timshometownstories\"\t3\n",
      "\"tin\"\t5\n",
      "\"tinned\"\t1\n",
      "\"tips\"\t4\n",
      "\"tire\"\t1\n",
      "\"tired\"\t2\n",
      "\"tires\"\t3\n",
      "\"tithable\"\t1\n",
      "\"title\"\t4\n",
      "\"titles\"\t3\n",
      "\"tlapek\"\t5\n",
      "\"tm\"\t1\n",
      "\"to\"\t964\n",
      "\"tobacco\"\t2\n",
      "\"today\"\t34\n",
      "\"todd\"\t1\n",
      "\"together\"\t7\n",
      "\"toilet\"\t1\n",
      "\"tokyo\"\t1\n",
      "\"told\"\t6\n",
      "\"toll\"\t3\n",
      "\"tommy\"\t1\n",
      "\"tomorrow\"\t5\n",
      "\"tonai\"\t1\n",
      "\"tone\"\t1\n",
      "\"tonne\"\t1\n",
      "\"too\"\t12\n",
      "\"took\"\t3\n",
      "\"tool\"\t2\n",
      "\"toolbar\"\t7\n",
      "\"top\"\t9\n",
      "\"topic\"\t2\n",
      "\"topics\"\t1\n",
      "\"toronto\"\t1\n",
      "\"tortoises\"\t1\n",
      "\"total\"\t8\n",
      "\"touched\"\t1\n",
      "\"toward\"\t1\n",
      "\"towards\"\t4\n",
      "\"towel\"\t1\n",
      "\"towels\"\t1\n",
      "\"tower\"\t2\n",
      "\"town\"\t4\n",
      "\"toy\"\t2\n",
      "\"tr\"\t2\n",
      "\"track\"\t3\n",
      "\"tracked\"\t1\n",
      "\"tracks\"\t2\n",
      "\"trade\"\t25\n",
      "\"trademarked\"\t2\n",
      "\"trader\"\t4\n",
      "\"traders\"\t1\n",
      "\"trading\"\t29\n",
      "\"tradition\"\t1\n",
      "\"traditional\"\t2\n",
      "\"traffic\"\t10\n",
      "\"trafficmultipliers\"\t1\n",
      "\"train\"\t7\n",
      "\"training\"\t9\n",
      "\"tramadol\"\t2\n",
      "\"trans\"\t1\n",
      "\"transact\"\t1\n",
      "\"transaction\"\t5\n",
      "\"transalta\"\t1\n",
      "\"transcanada\"\t2\n",
      "\"transco\"\t2\n",
      "\"transfer\"\t12\n",
      "\"transferred\"\t3\n",
      "\"transferring\"\t2\n",
      "\"transistion\"\t5\n",
      "\"transition\"\t4\n",
      "\"transmission\"\t12\n",
      "\"transmissions\"\t1\n",
      "\"transport\"\t3\n",
      "\"transportation\"\t2\n",
      "\"transporting\"\t1\n",
      "\"trash\"\t1\n",
      "\"travel\"\t3\n",
      "\"traveling\"\t1\n",
      "\"travelling\"\t1\n",
      "\"travis\"\t1\n",
      "\"treasonous\"\t1\n",
      "\"treasurer\"\t1\n",
      "\"treat\"\t1\n",
      "\"treatment\"\t1\n",
      "\"treats\"\t1\n",
      "\"tree\"\t2\n",
      "\"trevino\"\t4\n",
      "\"trial\"\t3\n",
      "\"trials\"\t1\n",
      "\"triassic\"\t1\n",
      "\"tricky\"\t1\n",
      "\"tried\"\t5\n",
      "\"trigger\"\t2\n",
      "\"trina\"\t1\n",
      "\"trip\"\t2\n",
      "\"triple\"\t1\n",
      "\"trips\"\t1\n",
      "\"trisha\"\t1\n",
      "\"trista\"\t2\n",
      "\"troubled\"\t1\n",
      "\"true\"\t9\n",
      "\"truly\"\t1\n",
      "\"trunk\"\t2\n",
      "\"trust\"\t8\n",
      "\"trusted\"\t2\n",
      "\"truth\"\t2\n",
      "\"try\"\t10\n",
      "\"trying\"\t3\n",
      "\"tuesday\"\t4\n",
      "\"tuned\"\t1\n",
      "\"tuneful\"\t1\n",
      "\"tungsten\"\t1\n",
      "\"tuning\"\t1\n",
      "\"turk\"\t3\n",
      "\"turn\"\t3\n",
      "\"turned\"\t1\n",
      "\"turner\"\t3\n",
      "\"tw\"\t1\n",
      "\"twain\"\t1\n",
      "\"twenty\"\t4\n",
      "\"twice\"\t2\n",
      "\"two\"\t24\n",
      "\"tx\"\t3\n",
      "\"txu\"\t2\n",
      "\"txuelectric\"\t1\n",
      "\"txuenergy\"\t3\n",
      "\"tyone\"\t1\n",
      "\"type\"\t12\n",
      "\"uafn\"\t1\n",
      "\"ugh\"\t1\n",
      "\"uk\"\t4\n",
      "\"ult\"\t2\n",
      "\"ultimate\"\t1\n",
      "\"un\"\t1\n",
      "\"unable\"\t3\n",
      "\"unattainable\"\t2\n",
      "\"unavoidable\"\t1\n",
      "\"unbelievably\"\t1\n",
      "\"unblock\"\t1\n",
      "\"unblocking\"\t4\n",
      "\"unclaimed\"\t1\n",
      "\"unclear\"\t1\n",
      "\"uncollected\"\t1\n",
      "\"uncomfortable\"\t1\n",
      "\"uncover\"\t1\n",
      "\"under\"\t23\n",
      "\"undercollected\"\t1\n",
      "\"undercollection\"\t4\n",
      "\"underga\"\t1\n",
      "\"underground\"\t1\n",
      "\"underneath\"\t1\n",
      "\"understand\"\t7\n",
      "\"understanding\"\t9\n",
      "\"underwrite\"\t1\n",
      "\"undeveloped\"\t1\n",
      "\"unify\"\t3\n",
      "\"union\"\t2\n",
      "\"unions\"\t2\n",
      "\"unique\"\t2\n",
      "\"unit\"\t7\n",
      "\"united\"\t5\n",
      "\"units\"\t4\n",
      "\"universal\"\t1\n",
      "\"university\"\t1\n",
      "\"unknown\"\t6\n",
      "\"unless\"\t5\n",
      "\"unlike\"\t1\n",
      "\"unlimited\"\t4\n",
      "\"unmanly\"\t1\n",
      "\"unnecessarily\"\t2\n",
      "\"unnecessary\"\t1\n",
      "\"unocal\"\t1\n",
      "\"unprofessional\"\t1\n",
      "\"unrealistic\"\t2\n",
      "\"unsubscribe\"\t16\n",
      "\"unsubscribed\"\t1\n",
      "\"until\"\t17\n",
      "\"untouchable\"\t1\n",
      "\"unwarranted\"\t1\n",
      "\"up\"\t47\n",
      "\"upcoming\"\t1\n",
      "\"update\"\t13\n",
      "\"updated\"\t1\n",
      "\"upgradeable\"\t3\n",
      "\"upgraded\"\t1\n",
      "\"upgrades\"\t2\n",
      "\"upload\"\t1\n",
      "\"uploaded\"\t1\n",
      "\"upon\"\t9\n",
      "\"upping\"\t1\n",
      "\"upward\"\t1\n",
      "\"ur\"\t1\n",
      "\"uranium\"\t1\n",
      "\"urg\"\t2\n",
      "\"urgency\"\t1\n",
      "\"urgent\"\t7\n",
      "\"urgently\"\t1\n",
      "\"url\"\t3\n",
      "\"us\"\t50\n",
      "\"usage\"\t4\n",
      "\"usavity\"\t1\n",
      "\"usb\"\t1\n",
      "\"usd\"\t2\n",
      "\"use\"\t43\n",
      "\"used\"\t11\n",
      "\"useful\"\t4\n",
      "\"user\"\t8\n",
      "\"userconf\"\t1\n",
      "\"users\"\t7\n",
      "\"uses\"\t1\n",
      "\"using\"\t18\n",
      "\"utilities\"\t22\n",
      "\"utility\"\t8\n",
      "\"uuz\"\t1\n",
      "\"uvd\"\t1\n",
      "\"uwe\"\t4\n",
      "\"uz\"\t1\n",
      "\"vacation\"\t2\n",
      "\"val\"\t3\n",
      "\"valeria\"\t1\n",
      "\"valid\"\t4\n",
      "\"validate\"\t1\n",
      "\"valium\"\t3\n",
      "\"valley\"\t3\n",
      "\"valuable\"\t9\n",
      "\"valuables\"\t2\n",
      "\"value\"\t11\n",
      "\"valued\"\t1\n",
      "\"van\"\t3\n",
      "\"vanadium\"\t1\n",
      "\"vance\"\t2\n",
      "\"var\"\t1\n",
      "\"variety\"\t1\n",
      "\"vary\"\t1\n",
      "\"vasant\"\t5\n",
      "\"vastar\"\t8\n",
      "\"vaughn\"\t3\n",
      "\"vault\"\t1\n",
      "\"ve\"\t21\n",
      "\"vein\"\t1\n",
      "\"vendor\"\t2\n",
      "\"vendors\"\t1\n",
      "\"venture\"\t5\n",
      "\"verbry\"\t1\n",
      "\"verification\"\t2\n",
      "\"verify\"\t1\n",
      "\"version\"\t9\n",
      "\"versus\"\t2\n",
      "\"very\"\t31\n",
      "\"verypowerful\"\t1\n",
      "\"veteran\"\t1\n",
      "\"vi\"\t2\n",
      "\"via\"\t13\n",
      "\"viag\"\t1\n",
      "\"viagra\"\t5\n",
      "\"vic\"\t2\n",
      "\"vice\"\t9\n",
      "\"vicodin\"\t2\n",
      "\"vicqodin\"\t1\n",
      "\"victor\"\t2\n",
      "\"view\"\t11\n",
      "\"viewer\"\t1\n",
      "\"villarreal\"\t1\n",
      "\"vince\"\t17\n",
      "\"vincent\"\t5\n",
      "\"vintage\"\t2\n",
      "\"virtues\"\t1\n",
      "\"vision\"\t1\n",
      "\"visit\"\t30\n",
      "\"visited\"\t1\n",
      "\"visitor\"\t3\n",
      "\"visitors\"\t2\n",
      "\"visits\"\t1\n",
      "\"visual\"\t1\n",
      "\"visually\"\t1\n",
      "\"voice\"\t6\n",
      "\"voices\"\t1\n",
      "\"volatility\"\t4\n",
      "\"volume\"\t9\n",
      "\"volumes\"\t1\n",
      "\"voluntary\"\t1\n",
      "\"vote\"\t7\n",
      "\"voted\"\t1\n",
      "\"voting\"\t2\n",
      "\"vp\"\t1\n",
      "\"vs\"\t2\n",
      "\"vzxoaxqhg\"\t1\n",
      "\"wa\"\t2\n",
      "\"wacked\"\t1\n",
      "\"waggons\"\t1\n",
      "\"wait\"\t2\n",
      "\"walked\"\t1\n",
      "\"wall\"\t6\n",
      "\"wallis\"\t1\n",
      "\"wallow\"\t1\n",
      "\"walpole\"\t1\n",
      "\"walsh\"\t2\n",
      "\"walton\"\t2\n",
      "\"want\"\t36\n",
      "\"wanted\"\t6\n",
      "\"wanting\"\t4\n",
      "\"wants\"\t2\n",
      "\"war\"\t2\n",
      "\"ward\"\t1\n",
      "\"wardsgiftshop\"\t1\n",
      "\"warrant\"\t1\n",
      "\"warrants\"\t2\n",
      "\"warranty\"\t1\n",
      "\"was\"\t68\n",
      "\"wash\"\t1\n",
      "\"washing\"\t4\n",
      "\"washington\"\t1\n",
      "\"waste\"\t1\n",
      "\"watched\"\t1\n",
      "\"watchfully\"\t1\n",
      "\"water\"\t2\n",
      "\"watson\"\t2\n",
      "\"way\"\t10\n",
      "\"ways\"\t10\n",
      "\"wbom\"\t1\n",
      "\"we\"\t182\n",
      "\"weakness\"\t4\n",
      "\"wealth\"\t2\n",
      "\"weather\"\t2\n",
      "\"web\"\t23\n",
      "\"webmail\"\t1\n",
      "\"webmaster\"\t1\n",
      "\"webpage\"\t4\n",
      "\"website\"\t28\n",
      "\"websites\"\t2\n",
      "\"wedeliverparties\"\t1\n",
      "\"wednesday\"\t6\n",
      "\"weed\"\t1\n",
      "\"week\"\t38\n",
      "\"weekend\"\t3\n",
      "\"weekly\"\t4\n",
      "\"weeks\"\t8\n",
      "\"weep\"\t1\n",
      "\"weight\"\t2\n",
      "\"weightwheezy\"\t1\n",
      "\"weissman\"\t5\n",
      "\"welch\"\t1\n",
      "\"welcome\"\t2\n",
      "\"well\"\t25\n",
      "\"went\"\t3\n",
      "\"were\"\t26\n",
      "\"west\"\t5\n",
      "\"western\"\t6\n",
      "\"westerngas\"\t1\n",
      "\"westward\"\t1\n",
      "\"wfxu\"\t1\n",
      "\"whalley\"\t3\n",
      "\"what\"\t68\n",
      "\"whatever\"\t4\n",
      "\"whats\"\t1\n",
      "\"whatsoever\"\t3\n",
      "\"whelan\"\t1\n",
      "\"when\"\t33\n",
      "\"where\"\t13\n",
      "\"whereby\"\t2\n",
      "\"whether\"\t4\n",
      "\"which\"\t47\n",
      "\"while\"\t14\n",
      "\"whiskey\"\t1\n",
      "\"whitehorse\"\t1\n",
      "\"who\"\t27\n",
      "\"whole\"\t2\n",
      "\"wholesale\"\t15\n",
      "\"whom\"\t1\n",
      "\"whooping\"\t1\n",
      "\"whose\"\t2\n",
      "\"why\"\t11\n",
      "\"wide\"\t1\n",
      "\"widow\"\t2\n",
      "\"wife\"\t3\n",
      "\"wijsman\"\t1\n",
      "\"will\"\t234\n",
      "\"willbe\"\t1\n",
      "\"william\"\t1\n",
      "\"williams\"\t7\n",
      "\"willie\"\t1\n",
      "\"willing\"\t1\n",
      "\"wilson\"\t2\n",
      "\"win\"\t18\n",
      "\"wind\"\t1\n",
      "\"window\"\t1\n",
      "\"windows\"\t12\n",
      "\"windowsentities\"\t1\n",
      "\"windred\"\t1\n",
      "\"wing\"\t1\n",
      "\"winner\"\t3\n",
      "\"winners\"\t2\n",
      "\"winning\"\t4\n",
      "\"wisely\"\t2\n",
      "\"wisew\"\t1\n",
      "\"wish\"\t7\n",
      "\"wishes\"\t1\n",
      "\"wishing\"\t1\n",
      "\"with\"\t201\n",
      "\"withers\"\t4\n",
      "\"within\"\t25\n",
      "\"without\"\t10\n",
      "\"wives\"\t1\n",
      "\"women\"\t3\n",
      "\"won\"\t6\n",
      "\"wonder\"\t2\n",
      "\"wonderful\"\t1\n",
      "\"wondering\"\t1\n",
      "\"woo\"\t1\n",
      "\"wood\"\t1\n",
      "\"woodwork\"\t1\n",
      "\"woolgar\"\t1\n",
      "\"word\"\t9\n",
      "\"wording\"\t1\n",
      "\"words\"\t8\n",
      "\"work\"\t32\n",
      "\"workable\"\t1\n",
      "\"worked\"\t3\n",
      "\"workforce\"\t1\n",
      "\"working\"\t10\n",
      "\"workout\"\t1\n",
      "\"works\"\t11\n",
      "\"workstation\"\t1\n",
      "\"world\"\t10\n",
      "\"worldwide\"\t11\n",
      "\"worry\"\t2\n",
      "\"worrying\"\t1\n",
      "\"worse\"\t1\n",
      "\"worst\"\t1\n",
      "\"worth\"\t1\n",
      "\"worthless\"\t1\n",
      "\"worthwhile\"\t1\n",
      "\"would\"\t73\n",
      "\"wouldn\"\t4\n",
      "\"wound\"\t1\n",
      "\"wpd\"\t2\n",
      "\"wr\"\t1\n",
      "\"wrinkle\"\t1\n",
      "\"write\"\t13\n",
      "\"writing\"\t7\n",
      "\"written\"\t6\n",
      "\"wrong\"\t3\n",
      "\"wrote\"\t3\n",
      "\"ws\"\t1\n",
      "\"wsc\"\t1\n",
      "\"wugn\"\t1\n",
      "\"www\"\t46\n",
      "\"wyn\"\t2\n",
      "\"wynne\"\t2\n",
      "\"wynpublishing\"\t1\n",
      "\"xacnax\"\t1\n",
      "\"xan\"\t2\n",
      "\"xanax\"\t3\n",
      "\"xeni\"\t2\n",
      "\"xent\"\t2\n",
      "\"xes\"\t1\n",
      "\"xm\"\t1\n",
      "\"xp\"\t6\n",
      "\"xpress\"\t1\n",
      "\"xqirzd\"\t1\n",
      "\"yahoo\"\t7\n",
      "\"yanowski\"\t1\n",
      "\"yard\"\t2\n",
      "\"ycon\"\t2\n",
      "\"yeah\"\t2\n",
      "\"year\"\t25\n",
      "\"yearno\"\t1\n",
      "\"years\"\t22\n",
      "\"yellow\"\t1\n",
      "\"yes\"\t7\n",
      "\"yesterday\"\t7\n",
      "\"yesterdays\"\t1\n",
      "\"yet\"\t5\n",
      "\"yjoou\"\t1\n",
      "\"you\"\t445\n",
      "\"youcan\"\t1\n",
      "\"young\"\t2\n",
      "\"your\"\t395\n",
      "\"yourmembership\"\t2\n",
      "\"yours\"\t3\n",
      "\"yourself\"\t11\n",
      "\"yoursuccess\"\t2\n",
      "\"yowman\"\t1\n",
      "\"ypfpb\"\t1\n",
      "\"zaak\"\t2\n",
      "\"zaako\"\t1\n",
      "\"zac\"\t2\n",
      "\"zadorozhny\"\t4\n",
      "\"zero\"\t4\n",
      "\"zesto\"\t10\n",
      "\"zimin\"\t5\n",
      "\"zinc\"\t1\n",
      "\"zk\"\t1\n",
      "\"zo\"\t2\n",
      "\"zolam\"\t2\n",
      "\"zxs\"\t1\n",
      "Removing temp directory /var/folders/0r/78q4n41j3dgdb6ndrr46gw3430x2wk/T/WordCountHW12.z086769.20160701.135730.277857...\n"
     ]
    }
   ],
   "source": [
    "!python WordCountHW12.py  enronemail_1h.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The below will count the overall frequency of the word \"assistance.\"  This is a modification of the code provided, which will validate the mapreduce wordcount job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      10\r\n"
     ]
    }
   ],
   "source": [
    "!grep -o assistance enronemail_1h.txt | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The below will count the number of lines where the word \"assistance\" occurs.   This is exactly the code provided above.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       8\r\n"
     ]
    }
   ],
   "source": [
    "!grep assistance enronemail_1h.txt|cut -d$'\\t' -f4| grep assistance|wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW1.2.1 \n",
    "\n",
    "Using Hadoop MapReduce (or MRJob) and your wordcount job (from HW1.2) determine the top-10 occurring tokens (most frequent tokens) using a single reducer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now that the hw121.txt file has been created and contains the data from enronemail_1h.txt in the (word, wordfrequency) format, the below will read the file back into Python as a dictionary, sort the dictionary by descending wordfrequency, and print the top 10 most frequently occurring words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'to', 'and', 'of', 'you', 'in', 'your', 'ect', 'for', 'on']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prevresults = {}\n",
    "resultdict = [s.split('\\n')[0].split('\\t') for s in open(\"hw121.txt\").readlines()]\n",
    "for word, count in resultdict:\n",
    "    prevresults[word] =  map(int, count.split(\",\"))\n",
    "sorted(prevresults, key=prevresults.get, reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### If the desire was to have both word and frequency..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', [1247]),\n",
       " ('to', [964]),\n",
       " ('and', [670]),\n",
       " ('of', [566]),\n",
       " ('you', [445]),\n",
       " ('in', [418]),\n",
       " ('your', [395]),\n",
       " ('ect', [382]),\n",
       " ('for', [374]),\n",
       " ('on', [271])]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "prevresultscounts = {}\n",
    "resultdict = [s.split('\\n')[0].split('\\t') for s in open(\"hw121.txt\").readlines()]\n",
    "for word, statsStr in resultdict:\n",
    "    prevresultscounts[word] =  map(int, statsStr.split(\",\"))\n",
    "\n",
    "Counter(prevresultscounts).most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW1.3: Multinomial NAIVE BAYES with NO Smoothing using a single reducer\n",
    "\n",
    "Using the Enron data from HW1 and Hadoop MapReduce (or MRJob), write  a mapper/reducer job(s) that\n",
    "   will both learn  Naive Bayes classifier and classify the Enron email messages using the learnt Naive Bayes classifier. Use all white-space delimitted tokens as independent input variables (assume spaces, fullstops, commas as delimiters). Note: for multinomial Naive Bayes, the Pr(X=“assistance”|Y=SPAM) is calculated as follows:\n",
    "\n",
    "   the number of times “assistance” occurs in SPAM labeled documents / the number of words in documents labeled SPAM \n",
    "\n",
    "   E.g.,   “assistance” occurs 5 times in all of the documents Labeled SPAM, and the length in terms of the number of words in all documents labeled as SPAM (when concatenated) is 1,000. Then Pr(X=“assistance”|Y=SPAM) = 5/1000. Note this is a multinomial estimation of the class conditional for a Naive Bayes Classifier. No smoothing is needed in this HW. Multiplying lots of probabilities, which are between 0 and 1, can result in floating-point underflow. Since log(xy) = log(x) + log(y), it is better to perform all computations by summing logs of probabilities rather than multiplying probabilities. Please pay attention to probabilites that are zero! They will need special attention. Count up how many times you need to process a zero probabilty for each class and report. \n",
    "\n",
    "   Report the performance of your learnt classifier in terms of misclassifcation error rate of your multinomial Naive Bayes Classifier. Plot a histogram of the  posterior probabilities (i.e., Pr(Class|Doc)) for each class over the training set. Summarize what you see. \n",
    "\n",
    "   Error Rate = misclassification rate with respect to a provided set (say training set in this case). It is more formally defined here:\n",
    "\n",
    "Let DF represent the evalution set in the following:\n",
    "Err(Model, DF) = |{(X, c(X)) ∈ DF : c(X) != Model(x)}|   / |DF|\n",
    "\n",
    "Where || denotes set cardinality; c(X) denotes the class of the tuple X in DF; and Model(X) denotes the class inferred by the Model “Model”\n",
    "\n",
    "NOTE: please assume one reducer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing NaiveBayesTrainerHW1.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile NaiveBayesTrainerHW1.py\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    " \n",
    "from collections import defaultdict\n",
    " \n",
    "from mrjob.job import MRJob\n",
    "from mrjob.job import MRStep\n",
    "\n",
    "import re, string\n",
    "\n",
    "line_counts = dict()\n",
    "word_counts = dict()\n",
    "\n",
    "class NaiveBayesTrainer(MRJob):\n",
    " \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(NaiveBayesTrainer, self).__init__(*args, **kwargs)\n",
    "        \n",
    "    def jobconf(self):\n",
    "        orig_jobconf = super(NaiveBayesTrainer, self).jobconf()        \n",
    "        custom_jobconf = {\n",
    "            'mapred.reduce.tasks': '1',\n",
    "        }\n",
    "        combined_jobconf = orig_jobconf\n",
    "        combined_jobconf.update(custom_jobconf)\n",
    "        self.jobconf = combined_jobconf\n",
    "        return combined_jobconf\n",
    "    \n",
    "     \n",
    "    def configure_options(self):\n",
    "        super(NaiveBayesTrainer, self).configure_options()\n",
    "        self.add_passthrough_option(\n",
    "            '--smoothmethod', default='nosmooth', choices=['nosmooth', 'laplace', 'jelinekmercer']\n",
    "        )\n",
    "        \n",
    "        self.add_passthrough_option(\n",
    "            '--jmlambda', default=0.3, dest='jmlambda', type='float'\n",
    "        )\n",
    "        \n",
    "    def steps(self):\n",
    "        out = [\n",
    "            MRStep(\n",
    "                mapper = self.mapper,\n",
    "                combiner = self.combiner,\n",
    "                reducer = self.reducer_pre\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        if self.options.smoothmethod == 'laplace': \n",
    "            out.append(MRStep(\n",
    "                reducer = self.reducer_laplace\n",
    "            ))\n",
    "        \n",
    "        elif self.options.smoothmethod == 'jelinekmercer':\n",
    "            out.append(MRStep(\n",
    "                reducer = self.reducer_jelinekmercer\n",
    "            ))\n",
    "            \n",
    "        else:\n",
    "            out.append(MRStep(\n",
    "                reducer = self.reducer_nosmooth\n",
    "            ))\n",
    "        \n",
    "        return out\n",
    " \n",
    "    def mapper(self, _, line):\n",
    "        regex = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "        _, classifier, token = line.strip().split('\\t', 2)\n",
    "        token = regex.sub(' ', token.lower())\n",
    "        token = re.sub( '\\s+', ' ', token )\n",
    "        words = token.split()\n",
    "        yield (('line', classifier), 1)\n",
    " \n",
    "        for word in set(words):                \n",
    "            yield ((word, classifier), words.count(word))\n",
    "            yield (('word', classifier), words.count(word))\n",
    " \n",
    " \n",
    "    def combiner(self, word_classifier, counts):\n",
    "        yield (word_classifier, sum(counts))\n",
    " \n",
    "    def reducer_pre(self, word_classifier, counts):\n",
    "        total_count = sum(counts)\n",
    "        word, classifier = word_classifier\n",
    "\n",
    "        if word == 'word':\n",
    "            if classifier not in word_counts:\n",
    "                word_counts[classifier] = 0\n",
    "                \n",
    "            word_counts[classifier] += total_count\n",
    "            return\n",
    "\n",
    "        if word == 'line':\n",
    "            line_counts[classifier] = total_count\n",
    "            word = 'PriorProb'\n",
    "\n",
    "        if classifier not in word_counts:\n",
    "            word_counts[classifier] = 0\n",
    "            word_counts[classifier] -= total_count\n",
    "        else:\n",
    "            yield (word, {classifier: total_count})\n",
    "            \n",
    "    def reducer_nosmooth(self, word, classified_counts):\n",
    "        combined = defaultdict(lambda: 0)\n",
    "\n",
    "        for entry in classified_counts:\n",
    "            for classifier, count in entry.items():\n",
    "                combined[classifier] += count\n",
    "\n",
    "        for classifier in line_counts.keys():\n",
    "            count = combined.get(classifier, 0)\n",
    " \n",
    "            if word == 'PriorProb':\n",
    "                probability = count / sum(line_counts.values())\n",
    "            else:\n",
    "                probability = count / word_counts[classifier]\n",
    " \n",
    "            yield (word, classifier), probability\n",
    "    \n",
    "    def reducer_laplace(self, word, classified_counts):\n",
    "        combined = defaultdict(lambda: 0)\n",
    "        for entry in classified_counts:\n",
    "            for classifier, count in entry.items():\n",
    "                combined[classifier] += count\n",
    " \n",
    "        for classifier in line_counts.keys():\n",
    "            count = combined.get(classifier, 0)\n",
    " \n",
    "            if word == 'PriorProb':\n",
    "                probability = count / sum(line_counts.values())\n",
    "            else:\n",
    "                probability = (count + 1) / (word_counts[classifier]+ 1)\n",
    " \n",
    "            yield (word, classifier), probability\n",
    "    \n",
    "    def reducer_jelinekmercer(self, word, classified_counts):\n",
    "        combined = defaultdict(lambda: 0)\n",
    "        \n",
    "        for entry in classified_counts:\n",
    "            for classifier, count in entry.items():\n",
    "                combined[classifier] += count\n",
    " \n",
    "        for classifier in line_counts.keys():\n",
    "            count = combined.get(classifier, 0)\n",
    "\n",
    "        for classifier in line_counts.keys():\n",
    "            count = combined.get(classifier, 0)\n",
    "            jmlambda = self.options.jmlambda\n",
    "        \n",
    "            if word == 'PriorProb':\n",
    "                probability = count / sum(line_counts.values())\n",
    "            else:\n",
    "                probability = (\n",
    "                    (1 - jmlambda) * (count / word_counts[classifier]) +\n",
    "                    (jmlambda * sum(combined.values()) / sum(word_counts.values()))\n",
    "                )\n",
    "                \n",
    "            yield (word, classifier), probability \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    NaiveBayesTrainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import NaiveBayesTrainerHW1 as nbTrainer \n",
    "\n",
    "def model(trainer, modelfile, smoothing_type='none', jmlambda=0.3):\n",
    "    nbTrainer.word_counts = dict()\n",
    "    nbTrainer.line_counts = dict()\n",
    "    mr_job = nbTrainer.NaiveBayesTrainer(\n",
    "        args=[\n",
    "            trainer,\n",
    "            '--smoothmethod={}'.format(smoothing_type),\n",
    "            '--jmlambda={}'.format(jmlambda)\n",
    "        ]\n",
    "    )\n",
    "    modelStats = dict()\n",
    "    \n",
    "    with mr_job.make_runner() as runner: \n",
    "        runner.run()\n",
    "        \n",
    "        for line in runner.stream_output():\n",
    "            key, value =  mr_job.parse_output_line(line)\n",
    "            word = key[0]\n",
    "            classifier = int(key[1])\n",
    "\n",
    "            if word not in modelStats:\n",
    "                probs = ['0', '0']\n",
    "                probs[classifier] = str(value)\n",
    "                modelStats[word] = probs                        \n",
    "            else:\n",
    "                modelStats[word][classifier] = str(value)\n",
    "\n",
    "        # Store model locally\n",
    "        with open(modelfile, 'w') as f:\n",
    "            for word, probs in modelStats.items():\n",
    "                f.writelines(word + \"\\t\" + \"\\t\".join(probs) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model(    \n",
    "    trainer='enronemail_1h.txt',\n",
    "    smoothing_type='nosmooth',\n",
    "    modelfile='enron_model_unsmoothed.txt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing NaiveBayesClassifierHW13.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile NaiveBayesClassifierHW13.py\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "import os, re, string, math\n",
    "\n",
    "counts = []\n",
    "\n",
    "class NaiveBayesClassifier(MRJob):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(NaiveBayesClassifier, self).__init__(*args, **kwargs)\n",
    "        \n",
    "    def steps(self):\n",
    "        return [\n",
    "            MRStep(\n",
    "                mapper_init=self.mapper_init, \n",
    "                mapper=self.mapper,\n",
    "                combiner=self.combiner,\n",
    "                reducer=self.reducer  \n",
    "            ),\n",
    "            MRStep(reducer=self.reducer_final)\n",
    "        ]\n",
    "\n",
    "    def configure_options(self):\n",
    "        super(NaiveBayesClassifier, self).configure_options()\n",
    "        \n",
    "        self.add_file_option('--model')\n",
    "        \n",
    "    def mapper_init(self): \n",
    "        self.model_stats = {}\n",
    "\n",
    "        with open(self.options.model, \"r\") as f:\n",
    "            lines = f.read().split('\\n')\n",
    "        \n",
    "        split_lines = [line.split('\\t') for line in lines]\n",
    "        \n",
    "        for entry in split_lines:\n",
    "            word = entry[0]\n",
    "            probs = [float(p) for p in entry[1:]]\n",
    "            self.model_stats[word] = probs\n",
    "    \n",
    "    def mapper(self, _, line):\n",
    "        regex = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "        _, classifier, token = line.strip().split('\\t', 2)\n",
    "        token = regex.sub(' ', token.lower())\n",
    "        token = re.sub( '\\s+', ' ', token )\n",
    "\n",
    "        p0 = math.log10(self.model_stats['PriorProb'][0])\n",
    "        p1 = math.log10(self.model_stats['PriorProb'][1])\n",
    "        \n",
    "        for word in token.split():\n",
    "\n",
    "            probs = self.model_stats.get(word, [0, 0]) \n",
    "            probs = [p if p > 0 else 1 for p in probs] \n",
    "           \n",
    "            p0 += math.log10(probs[0])\n",
    "            p1 += math.log10(probs[1])\n",
    "\n",
    "        if p0 > p1:\n",
    "            prediction = 0\n",
    "        elif p1 > p0:\n",
    "            prediction = 1\n",
    "        else:\n",
    "            prediction = -1 \n",
    "\n",
    "        if prediction == int(classifier):\n",
    "            key = 'correct'\n",
    "        else:\n",
    "            key = 'incorrect'\n",
    "            \n",
    "        yield (key, 1)\n",
    "\n",
    "    def combiner(self, key, values):\n",
    "        yield (key, sum(values))\n",
    "        \n",
    "    def reducer(self, key, values):\n",
    "        values = list(values)\n",
    "        count = sum(values)\n",
    "        counts.append(count)\n",
    "        yield (key, count)\n",
    "      \n",
    "    def reducer_final(self, key, values):\n",
    "        values = list(values)\n",
    "\n",
    "        rate = sum(values) / sum(counts)\n",
    "        output = 'Inaccuracy Rate' if key == 'incorrect' else 'Accuracy Rate'\n",
    "        \n",
    "        yield (output, rate)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    NaiveBayesClassifier.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import NaiveBayesClassifierHW13 as nbClassifier\n",
    "\n",
    "\n",
    "def classify(smoothtype, valer, modelfile):\n",
    "    model_path = os.path.join(\n",
    "        os.path.abspath(os.path.curdir), \n",
    "        modelfile\n",
    "    )\n",
    "    nbClassifier.counts = []\n",
    "    mr_job = nbClassifier.NaiveBayesClassifier(\n",
    "        args=[\n",
    "            valer,\n",
    "            '--model={}'.format(modelfile)\n",
    "        ]\n",
    "    )\n",
    "    out = {'Smooth Method': smoothtype, 'Inaccuracy Rate': 0, 'Accuracy Rate': 0}\n",
    "    \n",
    "    with mr_job.make_runner() as runner: \n",
    "        runner.run()\n",
    "        for line in runner.stream_output():\n",
    "            key, value =  mr_job.parse_output_line(line)\n",
    "            out[key] = value\n",
    "                \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy Rate': 0, 'Inaccuracy Rate': 1.0, 'Smooth Method': 'Unsmoothed'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify('Unsmoothed', 'enronemail_1h.txt', 'enron_model_unsmoothed.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW1.4:  Multinomial Naive Bayes with Smoothing \n",
    "\n",
    "### HW1.4.0: Repeat HW1.3 with the following modification: use Laplace plus-one smoothing. Compare the misclassifcation error rates for HW1.3 versus HW1.4 and explain the differences.\n",
    "\n",
    "For a quick reference on the construction of the Multinomial NAIVE BAYES classifier that you will code,\n",
    "please consult the \"Document Classification\" section of the following wikipedia page:\n",
    "\n",
    "https://en.wikipedia.org/wiki/Naive_Bayes_classifier#Document_classification\n",
    "\n",
    "OR the original paper by the curators of the Enron email data:\n",
    "\n",
    "http://www.aueb.gr/users/ion/docs/ceas2006_paper.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model(    \n",
    "    trainer='enronemail_1h.txt',\n",
    "    smoothing_type='laplace',\n",
    "    modelfile='enron_model_laplace.txt'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _You can see a huge improvement in adding the Laplace smoothing to the Naive Bayes algorithm.  One major reason for why is that the Laplace smoother eliminates nonzero probabilities, so multiplication is less impactful.  As you can see, the accuracy rate for Laplace is 96%, while the accuracy rate for the Unsmoothed method is 0%.  This is a huge increase with minimal additional work._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy Rate': 1.0, 'Inaccuracy Rate': 0, 'Smooth Method': 'Laplace'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify('Laplace', 'enronemail_1h.txt', 'enron_model_laplace.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy Rate': 0, 'Inaccuracy Rate': 1.0, 'Smooth Method': 'Unsmoothed'}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify('Unsmoothed', 'enronemail_1h.txt', 'enron_model_unsmoothed.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW 1.4.1 Jelinek-Mercer (JM) smoothing* \n",
    "\n",
    "HW 1.4.1 Jelinek-Mercer (JM) smoothing* \n",
    "\n",
    "With different smoothing methods, p(wk|ci) (i.e., the word class conditionals) will be computed\n",
    "differently. We consider Jelinek-Mercer (JM) smoothing as an alternative to Laplace  Let c(w, ci) denote\n",
    "the frequency of word w in category ci,  p(w|C) be the maximum likelihood estimation of word w in \n",
    "collection C (relative frequency) and let |C for classi| denote the length of the classi. Then:\n",
    "\n",
    "1) Jelinek-Mercer (JM) smoothing:\n",
    "\n",
    "λp(w|ci) = (1 − λ) * c(w, ci)/sum_over_wJ_in_V(c(wJ, ci))    +  λ p(w|C)\n",
    "\n",
    "Where c(w, ci)/sum_over_wJ_in_V(c(wJ, ci)) essential denotes the relative frequency of word w in class ci, i.e., Pr(w|ci)\n",
    "and one can set λ = 0.3  by default. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model(    \n",
    "    trainer='enronemail_1h.txt',\n",
    "    smoothing_type='jelinekmercer',\n",
    "    modelfile='enron_model_jm.txt',\n",
    "    jmlambda=.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy Rate': 1.0, 'Inaccuracy Rate': 0, 'Smooth Method': 'jm lambda=.3'}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify('jm lambda=.3', 'enronemail_1h.txt', 'enron_model_jm.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW1.4.2 Split data in to training, validation and testing data subsets\n",
    "\n",
    "Split the data using MRJob into three subsets in the following proportions (70% for training, 15% for valdiation, and 15% for testing). Train Multinomial Naive Bayes classifiers using Laplace plus-one smoothing and using  Jelinek-Mercer (JM) smoothing where you consider different hyperparameter values for λ. Please consider λ in {0.0, 0.1, 0.3, 0.5, 0.7, 1}. Present  a table compare the  results of the different approaches: each  row is the approach taken (e.g., Multinomial Naive Bayes with Laplace+1, or Multinomial Naive Bayes with  with JM= 0.3 for λ =0.3) and a column for  error rate on the training, validation and test data sets. Present a graph also (in python) consisting of three curves (where the x-axis represents the approach taken and the y-axis represents the error rate). Dont forget to put a good title on your graph!\n",
    "\n",
    "Looking the validation curve select the best model. How does it perform on the unseen test set? Comment.\n",
    "\n",
    "\n",
    "* REFERENCES \n",
    "   + http://www.ntu.edu.sg/home/gaocong/papers/wpp095-yuan.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "with open(\"enronemail_1h.txt\", \"r\") as f:\n",
    "    fullfile = f.read().split('\\n')\n",
    "\n",
    "linecount = len(fullfile)\n",
    "linecount_70pct = int(.7*linecount)\n",
    "linecount_85pct = int(.85*linecount)\n",
    "\n",
    "\n",
    "trainer_data = fullfile[:linecount_70pct]\n",
    "validation_data = fullfile[linecount_70pct:linecount_85pct]\n",
    "tester_data = fullfile[linecount_85pct:]\n",
    "\n",
    "with open(\"enron_trainer.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(trainer_data))\n",
    "with open(\"enron_valer.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(validation_data))\n",
    "with open(\"enron_tester.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(tester_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "testing_filename = 'enron_tester.txt'\n",
    "validation_filename = 'enron_valer.txt'\n",
    "model_filename = 'enron_model_trial.txt'\n",
    "results = []\n",
    "\n",
    "def modelcompare(smoothtype, smoothing_type, jmlambda=0.3):\n",
    "\n",
    "    model(    \n",
    "        trainer='enron_trainer.txt',\n",
    "        smoothing_type=smoothing_type,\n",
    "        modelfile=model_filename,\n",
    "        jmlambda=jmlambda\n",
    "    )\n",
    "    \n",
    "    out = {'SmoothType': smoothtype}\n",
    "    \n",
    "    results = classify(smoothtype, testing_filename, model_filename)\n",
    "    out['Training Error'] = results['Inaccuracy Rate']\n",
    "    \n",
    "    results = classify(smoothtype, testing_filename, model_filename)\n",
    "    out['Test Error'] = results['Inaccuracy Rate']\n",
    "    \n",
    "    results = classify(smoothtype, validation_filename, model_filename)\n",
    "    out['Validation Error'] = results['Inaccuracy Rate']\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SmoothType</th>\n",
       "      <th>Test Error</th>\n",
       "      <th>Validation Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unsmoothed</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LaPlace</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jelinek-Mercer lambda = 0.0</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jelinek-Mercer lambda = 0.1</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jelinek-Mercer lambda = 0.3</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jelinek-Mercer lambda = 0.5</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Jelinek-Mercer lambda = 0.7</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jelinek-Mercer lambda = 1.0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.466667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    SmoothType  Test Error  Validation Error\n",
       "0                   Unsmoothed    0.800000          0.866667\n",
       "1                      LaPlace    0.200000          0.066667\n",
       "2  Jelinek-Mercer lambda = 0.0    0.800000          0.866667\n",
       "3  Jelinek-Mercer lambda = 0.1    0.133333          0.000000\n",
       "4  Jelinek-Mercer lambda = 0.3    0.200000          0.000000\n",
       "5  Jelinek-Mercer lambda = 0.5    0.200000          0.066667\n",
       "6  Jelinek-Mercer lambda = 0.7    0.200000          0.066667\n",
       "7  Jelinek-Mercer lambda = 1.0    0.600000          0.466667"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results.append(modelcompare('Unsmoothed', 'nosmooth'))\n",
    "results.append(modelcompare('LaPlace', 'laplace'))\n",
    "results.append(modelcompare('Jelinek-Mercer lambda = 0.0', 'jelinekmercer', jmlambda=0.0))\n",
    "results.append(modelcompare('Jelinek-Mercer lambda = 0.1', 'jelinekmercer', jmlambda=0.1))\n",
    "results.append(modelcompare('Jelinek-Mercer lambda = 0.3', 'jelinekmercer', jmlambda=0.3))\n",
    "results.append(modelcompare('Jelinek-Mercer lambda = 0.5', 'jelinekmercer', jmlambda=0.5))\n",
    "results.append(modelcompare('Jelinek-Mercer lambda = 0.7', 'jelinekmercer', jmlambda=0.7))\n",
    "results.append(modelcompare('Jelinek-Mercer lambda = 1.0', 'jelinekmercer', jmlambda=1.0))\n",
    "\n",
    "resultsout = pandas.DataFrame(results)\n",
    "del resultsout['Training Error']\n",
    "from IPython.display import display\n",
    "display(resultsout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x11b379b50>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg8AAAGlCAYAAAB9ShW3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11ae6e210>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import pyplot\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "indices = 10 * resultsout.index\n",
    "\n",
    "fig = pyplot.figure()\n",
    "ax = pyplot.subplot(111)\n",
    "\n",
    "x = ax.scatter(indices, resultsout.error_test,color='y', marker = '*', s=100)\n",
    "y = ax.scatter(indices, resultsout.error_validate,color='r', marker = '.', s=100)\n",
    "pyplot.xticks(indices, resultsout.name, rotation=90)\n",
    "pyplot.ylabel('Error Rate')\n",
    "pyplot.xlabel('Smoothing Method')\n",
    "pyplot.title('Error Rate vs NaiveBayes Smoothing Method')\n",
    "pyplot.legend(bbox_to_anchor=(1.4, 1), loc='best', ncol=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Based on the graph above, when given the validation data set, the Jelinek-Mercer lambda = .1 or lambda = .3 work equally as well (this is confirmed by looking at the data table).  When applied to the unseen test set, the lamdba = .1 worked the best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW1.5: Remove words with frequency of less than three (3) in the training set\n",
    "\n",
    "Repeat HW1.4. This time when modeling and classification ignore tokens with a frequency of less than three (3) in the training set. How does it affect the misclassifcation error of learnt naive multinomial Bayesian Classifier on the training dataset. Report the error and the change in error. HINT: ignore tokens with a frequency of less than three (3). Think of this as a preprocessing step. How many new mapreduce jobs do you need to solve thus homework? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting NaiveBayesTrainerLess3HW1.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile NaiveBayesTrainerLess3HW1.py\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    " \n",
    "from collections import defaultdict\n",
    " \n",
    "from mrjob.job import MRJob\n",
    "from mrjob.job import MRStep\n",
    "\n",
    "import re, string\n",
    "\n",
    "line_counts = dict()\n",
    "word_counts = dict()\n",
    "\n",
    "class NaiveBayesTrainerLess3(MRJob):\n",
    " \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(NaiveBayesTrainerLess3, self).__init__(*args, **kwargs)\n",
    "        \n",
    "    def jobconf(self):\n",
    "        orig_jobconf = super(NaiveBayesTrainerLess3, self).jobconf()        \n",
    "        custom_jobconf = {\n",
    "            'mapred.reduce.tasks': '1',\n",
    "        }\n",
    "        combined_jobconf = orig_jobconf\n",
    "        combined_jobconf.update(custom_jobconf)\n",
    "        self.jobconf = combined_jobconf\n",
    "        return combined_jobconf\n",
    "    \n",
    "     \n",
    "    def configure_options(self):\n",
    "        super(NaiveBayesTrainerLess3, self).configure_options()\n",
    "        self.add_passthrough_option(\n",
    "            '--smoothmethod', default='nosmooth', choices=['nosmooth', 'laplace', 'jelinekmercer']\n",
    "        )\n",
    "        \n",
    "        self.add_passthrough_option(\n",
    "            '--jmlambda', default=0.3, dest='jmlambda', type='float'\n",
    "        )\n",
    "        \n",
    "    def steps(self):\n",
    "        out = [\n",
    "            MRStep(\n",
    "                mapper = self.mapper,\n",
    "                combiner = self.combiner,\n",
    "                reducer = self.reducer_pre\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        if self.options.smoothmethod == 'laplace': \n",
    "            out.append(MRStep(\n",
    "                reducer = self.reducer_laplace\n",
    "            ))\n",
    "        \n",
    "        elif self.options.smoothmethod == 'jelinekmercer':\n",
    "            out.append(MRStep(\n",
    "                reducer = self.reducer_jelinekmercer\n",
    "            ))\n",
    "            \n",
    "        else:\n",
    "            out.append(MRStep(\n",
    "                reducer = self.reducer_nosmooth\n",
    "            ))\n",
    "        \n",
    "        return out\n",
    " \n",
    "    def mapper(self, _, line):\n",
    "        regex = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "        _, classifier, token = line.strip().split('\\t', 2)\n",
    "        token = regex.sub(' ', token.lower())\n",
    "        token = re.sub( '\\s+', ' ', token )\n",
    "        words = token.split()\n",
    "        yield (('line', classifier), 1)\n",
    " \n",
    "        for word in set(words):                \n",
    "            yield ((word, classifier), words.count(word))\n",
    "            yield (('word', classifier), words.count(word))\n",
    " \n",
    " \n",
    "    def combiner(self, word_classifier, counts):\n",
    "        yield (word_classifier, sum(counts))\n",
    " \n",
    "    def reducer_pre(self, word_classifier, counts):\n",
    "        total_count = sum(counts)\n",
    "        word, classifier = word_classifier\n",
    "\n",
    "        if word == 'word':\n",
    "            if classifier not in word_counts:\n",
    "                word_counts[classifier] = 0\n",
    "                \n",
    "            word_counts[classifier] += total_count\n",
    "            return\n",
    "\n",
    "        if word == 'line':\n",
    "            line_counts[classifier] = total_count\n",
    "            word = 'PriorProb'\n",
    "\n",
    "        if total_count <= 3:\n",
    "\n",
    "            if classifier not in word_counts:\n",
    "                word_counts[classifier] = 0\n",
    "            word_counts[classifier] -= total_count\n",
    "        else:\n",
    "            yield (word, {classifier: total_count})\n",
    "            \n",
    "    def reducer_nosmooth(self, word, classified_counts):\n",
    "        combined = defaultdict(lambda: 0)\n",
    "\n",
    "        for entry in classified_counts:\n",
    "            for classifier, count in entry.items():\n",
    "                combined[classifier] += count\n",
    "\n",
    "        for classifier in line_counts.keys():\n",
    "            count = combined.get(classifier, 0)\n",
    " \n",
    "            if word == 'PriorProb':\n",
    "                probability = count / sum(line_counts.values())\n",
    "            else:\n",
    "                probability = count / word_counts[classifier]\n",
    " \n",
    "            yield (word, classifier), probability\n",
    "    \n",
    "    def reducer_laplace(self, word, classified_counts):\n",
    "        combined = defaultdict(lambda: 0)\n",
    "        for entry in classified_counts:\n",
    "            for classifier, count in entry.items():\n",
    "                combined[classifier] += count\n",
    " \n",
    "        for classifier in line_counts.keys():\n",
    "            count = combined.get(classifier, 0)\n",
    " \n",
    "            if word == 'PriorProb':\n",
    "                probability = count / sum(line_counts.values())\n",
    "            else:\n",
    "                probability = (count + 1) / (word_counts[classifier]+ 1)\n",
    " \n",
    "            yield (word, classifier), probability\n",
    "    \n",
    "    def reducer_jelinekmercer(self, word, classified_counts):\n",
    "        combined = defaultdict(lambda: 0)\n",
    "        \n",
    "        for entry in classified_counts:\n",
    "            for classifier, count in entry.items():\n",
    "                combined[classifier] += count\n",
    " \n",
    "        for classifier in line_counts.keys():\n",
    "            count = combined.get(classifier, 0)\n",
    "\n",
    "        for classifier in line_counts.keys():\n",
    "            count = combined.get(classifier, 0)\n",
    "            jmlambda = self.options.jmlambda\n",
    "        \n",
    "            if word == 'PriorProb':\n",
    "                probability = count / sum(line_counts.values())\n",
    "            else:\n",
    "                probability = (\n",
    "                    (1 - jmlambda) * (count / word_counts[classifier]) +\n",
    "                    (jmlambda * sum(combined.values()) / sum(word_counts.values()))\n",
    "                )\n",
    "                \n",
    "            yield (word, classifier), probability \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    NaiveBayesTrainerLess3.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import NaiveBayesTrainerLess3HW1 as nbTrainerL3 \n",
    "\n",
    "def modelL3(trainer, modelfile, smoothing_type='none', jmlambda=0.3):\n",
    "    nbTrainerL3.word_counts = dict()\n",
    "    nbTrainerL3.line_counts = dict()\n",
    "    mr_job = nbTrainerL3.NaiveBayesTrainerLess3(\n",
    "        args=[\n",
    "            trainer,\n",
    "            '--smoothmethod={}'.format(smoothing_type),\n",
    "            '--jmlambda={}'.format(jmlambda)\n",
    "        ]\n",
    "    )\n",
    "    modelStats = dict()\n",
    "    \n",
    "    with mr_job.make_runner() as runner: \n",
    "        runner.run()\n",
    "        \n",
    "        for line in runner.stream_output():\n",
    "            key, value =  mr_job.parse_output_line(line)\n",
    "            word = key[0]\n",
    "            classifier = int(key[1])\n",
    "\n",
    "            if word not in modelStats:\n",
    "                probs = ['0', '0']\n",
    "                probs[classifier] = str(value)\n",
    "                modelStats[word] = probs                        \n",
    "            else:\n",
    "                modelStats[word][classifier] = str(value)\n",
    "\n",
    "        # Store model locally\n",
    "        with open(modelfile, 'w') as f:\n",
    "            for word, probs in modelStats.items():\n",
    "                f.writelines(word + \"\\t\" + \"\\t\".join(probs) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "modelL3(    \n",
    "    trainer='enron_trainer.txt',\n",
    "    smoothing_type='nosmooth',\n",
    "    modelfile='enron_model_unsmoothed.txt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing NaiveBayesLess3HW1.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile NaiveBayesLess3HW1.py\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "import os, re, string, math\n",
    "\n",
    "counts = []\n",
    "\n",
    "class NaiveBayesClassifierL3(MRJob):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(NaiveBayesClassifierL3, self).__init__(*args, **kwargs)\n",
    "        \n",
    "    def steps(self):\n",
    "        return [\n",
    "            MRStep(\n",
    "                mapper_init=self.mapper_init, \n",
    "                mapper=self.mapper,\n",
    "                combiner=self.combiner,\n",
    "                reducer=self.reducer  \n",
    "            ),\n",
    "            MRStep(reducer=self.reducer_final)\n",
    "        ]\n",
    "\n",
    "    def configure_options(self):\n",
    "        super(NaiveBayesClassifierL3, self).configure_options()\n",
    "        \n",
    "        self.add_file_option('--model')\n",
    "        \n",
    "    def mapper_init(self): \n",
    "        self.model_stats = {}\n",
    "\n",
    "        with open(self.options.model, \"r\") as f:\n",
    "            lines = f.read().split('\\n')\n",
    "        \n",
    "        split_lines = [line.split('\\t') for line in lines]\n",
    "        \n",
    "        for entry in split_lines:\n",
    "            word = entry[0]\n",
    "            probs = [float(p) for p in entry[1:]]\n",
    "            self.model_stats[word] = probs\n",
    "    \n",
    "    def mapper(self, _, line):\n",
    "        regex = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "        _, classifier, token = line.strip().split('\\t', 2)\n",
    "        token = regex.sub(' ', token.lower())\n",
    "        token = re.sub( '\\s+', ' ', token )\n",
    "\n",
    "        p0 = math.log10(self.model_stats['PriorProb'][0])\n",
    "        p1 = math.log10(self.model_stats['PriorProb'][1])\n",
    "        \n",
    "        for word in token.split():\n",
    "\n",
    "            probs = self.model_stats.get(word, [0, 0]) \n",
    "            probs = [p if p > 0 else 1 for p in probs] \n",
    "           \n",
    "            p0 += math.log10(probs[0])\n",
    "            p1 += math.log10(probs[1])\n",
    "\n",
    "        if p0 > p1:\n",
    "            prediction = 0\n",
    "        elif p1 > p0:\n",
    "            prediction = 1\n",
    "        else:\n",
    "            prediction = -1 \n",
    "\n",
    "        if prediction == int(classifier):\n",
    "            key = 'correct'\n",
    "        else:\n",
    "            key = 'incorrect'\n",
    "            \n",
    "        yield (key, 1)\n",
    "\n",
    "    def combiner(self, key, values):\n",
    "        yield (key, sum(values))\n",
    "        \n",
    "    def reducer(self, key, values):\n",
    "        values = list(values)\n",
    "        count = sum(values)\n",
    "        counts.append(count)\n",
    "        yield (key, count)\n",
    "      \n",
    "    def reducer_final(self, key, values):\n",
    "        values = list(values)\n",
    "\n",
    "        rate = sum(values) / sum(counts)\n",
    "        output = 'Inaccuracy Rate' if key == 'incorrect' else 'Accuracy Rate'\n",
    "        \n",
    "        yield (output, rate)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    NaiveBayesClassifierL3.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import NaiveBayesLess3HW1 as nbClassifierL3\n",
    "\n",
    "\n",
    "def classifyL3(smoothtype, valer, modelfile):\n",
    "    model_path = os.path.join(\n",
    "        os.path.abspath(os.path.curdir), \n",
    "        modelfile\n",
    "    )\n",
    "    nbClassifierL3.counts = []\n",
    "    mr_job = nbClassifierL3.NaiveBayesClassifierL3(\n",
    "        args=[\n",
    "            valer,\n",
    "            '--model={}'.format(modelfile)\n",
    "        ]\n",
    "    )\n",
    "    out = {'Smooth Method': smoothtype, 'Inaccuracy Rate': 0, 'Accuracy Rate': 0}\n",
    "    \n",
    "    with mr_job.make_runner() as runner: \n",
    "        runner.run()\n",
    "        for line in runner.stream_output():\n",
    "            key, value =  mr_job.parse_output_line(line)\n",
    "            out[key] = value\n",
    "                \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "testing_filename = 'enron_tester.txt'\n",
    "validation_filename = 'enron_valer.txt'\n",
    "model_filename = 'enron_model_trial.txt'\n",
    "L3results = []\n",
    "\n",
    "def modelcompareL3(smoothtype, smoothing_type, jmlambda=0.3):\n",
    "\n",
    "    modelL3(    \n",
    "        trainer='enron_trainer.txt',\n",
    "        smoothing_type=smoothing_type,\n",
    "        modelfile=model_filename,\n",
    "        jmlambda=jmlambda\n",
    "    )\n",
    "    \n",
    "    out = {'SmoothType': smoothtype}\n",
    "    \n",
    "    resultsL3 = classifyL3(smoothtype, testing_filename, model_filename)\n",
    "    out['Training Error'] = resultsL3['Inaccuracy Rate']\n",
    "    \n",
    "    resultsL3 = classifyL3(smoothtype, testing_filename, model_filename)\n",
    "    out['Test Error'] = resultsL3['Inaccuracy Rate']\n",
    "    \n",
    "    resultsL3 = classifyL3(smoothtype, validation_filename, model_filename)\n",
    "    out['Validation Error'] = resultsL3['Inaccuracy Rate']\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SmoothType</th>\n",
       "      <th>Test Error</th>\n",
       "      <th>Validation Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unsmoothed</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LaPlace</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JM lambda = 0.0</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JM lambda = 0.1</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JM lambda = 0.3</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>JM lambda = 0.5</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>JM lambda = 0.7</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>JM lambda = 1.0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.466667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        SmoothType  Test Error  Validation Error\n",
       "0       Unsmoothed    0.733333          0.666667\n",
       "1          LaPlace    0.200000          0.066667\n",
       "2  JM lambda = 0.0    0.733333          0.666667\n",
       "3  JM lambda = 0.1    0.200000          0.200000\n",
       "4  JM lambda = 0.3    0.200000          0.133333\n",
       "5  JM lambda = 0.5    0.200000          0.133333\n",
       "6  JM lambda = 0.7    0.200000          0.133333\n",
       "7  JM lambda = 1.0    0.600000          0.466667"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "L3results.append(modelcompareL3('Unsmoothed', 'nosmooth'))\n",
    "L3results.append(modelcompareL3('LaPlace', 'laplace'))\n",
    "L3results.append(modelcompareL3('JM lambda = 0.0', 'jelinekmercer', jmlambda=0.0))\n",
    "L3results.append(modelcompareL3('JM lambda = 0.1', 'jelinekmercer', jmlambda=0.1))\n",
    "L3results.append(modelcompareL3('JM lambda = 0.3', 'jelinekmercer', jmlambda=0.3))\n",
    "L3results.append(modelcompareL3('JM lambda = 0.5', 'jelinekmercer', jmlambda=0.5))\n",
    "L3results.append(modelcompareL3('JM lambda = 0.7', 'jelinekmercer', jmlambda=0.7))\n",
    "L3results.append(modelcompareL3('JM lambda = 1.0', 'jelinekmercer', jmlambda=1.0))\n",
    "\n",
    "L3resultsout = pandas.DataFrame(L3results)\n",
    "del L3resultsout['Training Error']\n",
    "from IPython.display import display\n",
    "display(L3resultsout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On the test set, the Unsmoothed and the JM lambda = 0 saw a decrease in error rate, with JM Lambda = .1 having an increase.   For the validation set, Unsmoothed and JM lambda = 0 saw decreases, but lambda > 0 all saw increases in error rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# HW1.6 Benchmark your code with the Python SciKit-Learn implementation of the multinomial Naive Bayes algorithm\n",
    "\n",
    "## HW1.6.0: Multinomial Naive Bayes using SciKit-Learn\n",
    "\n",
    "It always a good idea to benchmark your solutions against publicly available libraries such as SciKit-Learn, The Machine Learning toolkit available in Python. In this exercise, we benchmark ourselves against the SciKit-Learn implementation of multinomial Naive Bayes.  For more information on this implementation see: http://scikit-learn.org/stable/modules/naive_bayes.html more  \n",
    "\n",
    "In this exercise, please complete the following:\n",
    "\n",
    "— Run the Multinomial Naive Bayes algorithm (using default settings) from SciKit-Learn over the same training data used in HW1.4.2 and report the misclassification error (please note some data preparation might be needed to get the Multinomial Naive Bayes algorithm from SkiKit-Learn to run over this dataset)\n",
    "- Prepare a table to present your results, where rows correspond to approach used (SkiKit-Learn versus your Hadoop implementation) and the column presents the  misclassification error rates (train, validation, testing)\n",
    "— Explain/justify any differences in terms of training error rates over the dataset in HW1.5 between your Multinomial Naive Bayes implementation (in Map Reduce) versus the Multinomial Naive Bayes implementation in SciKit-Learn \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import *\n",
    "\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "with open('enron_trainer.txt', 'r') as ftrain:\n",
    "    reader = csv.reader(ftrain, delimiter=\"\\t\")\n",
    "    emails = list(reader)\n",
    "train_label = [msg[1] for msg in emails]\n",
    "train_data = [msg[2] + msg[3] if len(msg) == 4 else msg[2] for msg in emails]\n",
    "msg_id = [msg[0].lower() for msg in emails]\n",
    "# print(train_label, train_data, msg_id)\n",
    "\n",
    "# feature vectorization\n",
    "uniVectorizer = CountVectorizer()\n",
    "dtmTrain = uniVectorizer.fit_transform(train_data) \n",
    "# print(uniVectorizer, dtmTrain)\n",
    "\n",
    "# multinomial Naive Bayes Classifier from sklearn\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(dtmTrain, train_label)\n",
    "pred_mnb = mnb.predict(dtmTrain)\n",
    "training_error_mnb = 1.0 * sum(pred_mnb != train_label) / len(train_label)\n",
    "\n",
    "# Bernoulli Naive Bayes Classifier from sklearn\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(dtmTrain, train_label)\n",
    "pred_bnb = bnb.predict(dtmTrain)\n",
    "training_error_bnb = 1.0*sum(pred_bnb != train_label) / len(train_label)\n",
    "\n",
    "\n",
    "\n",
    "with open('enron_tester.txt', 'r') as ftest:\n",
    "    reader = csv.reader(ftest, delimiter=\"\\t\")\n",
    "    emails = list(reader)\n",
    "test_label = [msg[1] for msg in emails]\n",
    "test_data = [msg[2] + msg[3] if len(msg) == 4 else msg[2] for msg in emails]\n",
    "msg_id = [msg[0].lower() for msg in emails]\n",
    "# print(train_label, train_data, msg_id)\n",
    "\n",
    "# feature vectorization\n",
    "uniVectorizer = CountVectorizer()\n",
    "dtmTest = uniVectorizer.fit_transform(test_data) \n",
    "# print(uniVectorizer, dtmTrain)\n",
    "\n",
    "# multinomial Naive Bayes Classifier from sklearn\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(dtmTest, test_label)\n",
    "pred_mnb = mnb.predict(dtmTest)\n",
    "testing_error_mnb = 1.0 * sum(pred_mnb != test_label) / len(test_label)\n",
    "\n",
    "# Bernoulli Naive Bayes Classifier from sklearn\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(dtmTest, test_label)\n",
    "pred_bnb = bnb.predict(dtmTest)\n",
    "testing_error_bnb = 1.0*sum(pred_bnb != test_label) / len(test_label)\n",
    "\n",
    "\n",
    "\n",
    "with open('enron_valer.txt', 'r') as fval:\n",
    "    reader = csv.reader(fval, delimiter=\"\\t\")\n",
    "    emails = list(reader)\n",
    "val_label = [msg[1] for msg in emails]\n",
    "val_data = [msg[2] + msg[3] if len(msg) == 4 else msg[2] for msg in emails]\n",
    "msg_id = [msg[0].lower() for msg in emails]\n",
    "# print(train_label, train_data, msg_id)\n",
    "\n",
    "# feature vectorization\n",
    "uniVectorizer = CountVectorizer()\n",
    "dtmVal = uniVectorizer.fit_transform(val_data) \n",
    "# print(uniVectorizer, dtmTrain)\n",
    "\n",
    "# multinomial Naive Bayes Classifier from sklearn\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(dtmVal, val_label)\n",
    "pred_mnb = mnb.predict(dtmVal)\n",
    "val_error_mnb = 1.0 * sum(pred_mnb != val_label) / len(val_label)\n",
    "\n",
    "# Bernoulli Naive Bayes Classifier from sklearn\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(dtmVal, val_label)\n",
    "pred_bnb = bnb.predict(dtmVal)\n",
    "val_error_bnb = 1.0*sum(pred_bnb != val_label) / len(val_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "validation_filename = 'enron_valer.txt'\n",
    "model_filename = 'enron_model_trial.txt'\n",
    "resultsscikit = []\n",
    "\n",
    "def modelcomparescikit(smoothtype, smoothing_type, jmlambda=0.3):\n",
    "\n",
    "    model(    \n",
    "        trainer='enron_trainer.txt',\n",
    "        smoothing_type=smoothing_type,\n",
    "        modelfile=model_filename,\n",
    "        jmlambda=jmlambda\n",
    "    )\n",
    "    \n",
    "    out = {'SmoothType': smoothtype}\n",
    "    \n",
    "    resultsscikit = classify(smoothtype, validation_filename, model_filename)\n",
    "    out['Training Error'] = resultsL3['Inaccuracy Rate']\n",
    "    \n",
    "    resultsscikit = classify(smoothtype, validation_filename, model_filename)\n",
    "    out['Test Error'] = resultsL3['Inaccuracy Rate']\n",
    "    \n",
    "    resultsscikit = classify(smoothtype, validation_filename, model_filename)\n",
    "    out['Validation Error'] = resultsL3['Inaccuracy Rate']\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SmoothType</th>\n",
       "      <th>Test Error</th>\n",
       "      <th>Training Error</th>\n",
       "      <th>Validation Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unsmoothed</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LaPlace</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JM lambda = 0.0</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JM lambda = 0.1</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JM lambda = 0.3</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>JM lambda = 0.5</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>JM lambda = 0.7</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>JM lambda = 1.0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sci-Kit Binomial</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.157143</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sci-Kit Multinomial</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            SmoothType  Test Error  Training Error  Validation Error\n",
       "0           Unsmoothed    0.733333        0.733333          0.666667\n",
       "1              LaPlace    0.200000        0.200000          0.066667\n",
       "2      JM lambda = 0.0    0.733333        0.733333          0.666667\n",
       "3      JM lambda = 0.1    0.200000        0.200000          0.200000\n",
       "4      JM lambda = 0.3    0.200000        0.200000          0.133333\n",
       "5      JM lambda = 0.5    0.200000        0.200000          0.133333\n",
       "6      JM lambda = 0.7    0.200000        0.200000          0.133333\n",
       "7      JM lambda = 1.0    0.600000        0.600000          0.466667\n",
       "8     Sci-Kit Binomial    0.200000        0.157143          0.333333\n",
       "9  Sci-Kit Multinomial    0.066667        0.000000          0.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "resultsscikit.append(modelcompareL3('Unsmoothed', 'nosmooth'))\n",
    "resultsscikit.append(modelcompareL3('LaPlace', 'laplace'))\n",
    "resultsscikit.append(modelcompareL3('JM lambda = 0.0', 'jelinekmercer', jmlambda=0.0))\n",
    "resultsscikit.append(modelcompareL3('JM lambda = 0.1', 'jelinekmercer', jmlambda=0.1))\n",
    "resultsscikit.append(modelcompareL3('JM lambda = 0.3', 'jelinekmercer', jmlambda=0.3))\n",
    "resultsscikit.append(modelcompareL3('JM lambda = 0.5', 'jelinekmercer', jmlambda=0.5))\n",
    "resultsscikit.append(modelcompareL3('JM lambda = 0.7', 'jelinekmercer', jmlambda=0.7))\n",
    "resultsscikit.append(modelcompareL3('JM lambda = 1.0', 'jelinekmercer', jmlambda=1.0))\n",
    "resultsscikit.append({'SmoothType': 'Sci-Kit Binomial', 'Validation Error': val_error_bnb,\n",
    "                      'Test Error': testing_error_bnb, 'Training Error': training_error_bnb})\n",
    "resultsscikit.append({'SmoothType': 'Sci-Kit Multinomial', 'Validation Error': val_error_mnb,\n",
    "                      'Test Error': testing_error_mnb, 'Training Error': training_error_mnb})\n",
    "\n",
    "resultsscikitout = pandas.DataFrame(resultsscikit)\n",
    "\n",
    "\n",
    "from IPython.display import display\n",
    "display(resultsscikitout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
