{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# <center> Scott Zuehlke Homework 1 </center>\n",
    "#### <center> This homework assignment was done in large partnership with Renee Murray, who was a significant help in the Python coding of the homework assignments.</center>\n",
    "\n",
    "## <center>  Written on a Mac, for a Mac </center>\n",
    "\n",
    "\n",
    "## HW1.0.0. \n",
    "### Define big data. Provide an example of a big data problem in your domain of expertise. \n",
    "\n",
    "#### _Big data is a generic term to represent data sets that are so large, or possibly so complex, that traditional methods of processing and analysis are inadequate.  While the cutoff of what represents \"big data\" is relative to a company and its technological capabilities, there is a tipping point where basic methods (SQL, for example) cannot process the large amounts of data in a sufficient amount of time.  The other side of that tipping point is what is referred to as \"big data.\"_\n",
    "\n",
    "#### _In my domain of retail and e-commerce, a perfect example of \"big data\" would be the data generated by our Target.com website.  A specific use case for this data is the Target.com Personalization Engine.  The Personalization Engine runs in a fraction of a second and pulls data from a Hadoop environment to create a \"people with similar purchase history have also bought...\" type recommendation.  The amount of data to process would take days with a traditional processing technique, but through Hadoop and Spark algorithms, millions of records can be processed almost instantaneously._\n",
    "\n",
    "\n",
    "### What is a race condition in the context of parallel computation? Give an example.\n",
    "\n",
    "#### _A race condition, in the context of parallel computation, is a situation where more than one process reaches the same variable, file, or data set concurrently and alters the final result._\n",
    "\n",
    "#### _A real world example would be a deposit/withdrawal at a bank.  If a customer has 10 dollars in their account on Monday, deposits 25 on Tuesday and tries to withdraw 20 on Wednesday, the withdrawal's success would depend on the deposit happeing BEFORE the withdrawal processes.  Below is some pseudocode to illustrate._\n",
    "```\n",
    "class BankAccount:\n",
    "    \n",
    "    def __init__(self, balance, deposit, withdraw):    \n",
    "        self.balance = balance\n",
    "        self.deposit = deposit\n",
    "        self.withdraw = withdraw\n",
    "    \n",
    "    def ProcessDeposit(balance, deposit):\n",
    "        new_balance = balance + deposit_amt\n",
    "        yield new_balance\n",
    "        \n",
    "        \n",
    "    def ProcessWithdrawal(balance, withdraw):\n",
    "        \n",
    "        if new_balance >= withdraw then:\n",
    "            new_balance = balance + deposit_amt\n",
    "            yield new_balance \n",
    "        else:\n",
    "            yield \"Withdrawal would cause overdraft.\"\n",
    "```\n",
    "            \n",
    "####  _Ideally, if a person were to start with an initial balance of 10 dollars, deposits 25 and then withdraws 20, the ending balance should be 10+25-20 = 15.  However, if the withdrawal were to post first, then balance would actually go negative, i.e. 10 - 20 + 25._ Mathematically, this would yield the same result of 15, but in the example above, since the new_balance would be less than the withdrawal, it would fail to post and yield outcome,\"Withdrawal would cause overdraft.\"_\n",
    "        \n",
    "\n",
    "\n",
    "## What is MapReduce?\n",
    "\n",
    "#### _MapReduce is a programming algorithm for processing, and generating, large data sets.  A mapper is created to apply a specific algorithm to each of a smaller piece of the original data spread out across multiple computers or nodes, creates a key-value pair with the resulting output from each defined key, and then a reducer will merge the key value pairs to create a single output, which is the desired result of analysis on the larger, initial data set._\n",
    "\n",
    "\n",
    "\n",
    "## How does it differ from Hadoop?\n",
    "\n",
    "#### _MapReduce is a \"divide and conquer\" algorithm that allows for processing of \"big data\" by splitting chunks across multiple nodes or clusters.  Hadoop is an infrastructure that utilizes MapReduce to process large, or unstructured/complex, data sets._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW1.0.1 \n",
    "\n",
    "## Which programming paradigm is Hadoop based on? Explain and give a simple example of functional programming in raw python code and show the code running. E.g., in raw python find the average length of a string in and of strings using a python \"map-reduce\" (functional programming) job. Alternatively, you can do this in python Hadoop Streaming.   \n",
    "\n",
    "#### _Hadoop is based on the MapReduce programming paradigm, which is based on functional programming.  So, by extension, it could be said that Hadoop is, actually, based on the functional programming._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **_The below code calculates the average string length in a string of strings.  The provided string was provided in the original homework assignment._**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input string  ['str1', 'string2', 'w261', 'MAchine learning at SCALE'] has an average length of "
     ]
    },
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def stringlength(string):\n",
    "    return len(string)\n",
    "\n",
    "def numelements(string):\n",
    "    return len(string.split())\n",
    " \n",
    "strings = [\"str1\", \"string2\", \"w261\", \"MAchine learning at SCALE\"]\n",
    "stringlengthmap = map(stringlength, strings)\n",
    "\n",
    "import functools\n",
    "print \"The input string \", strings, \"has an average length of \", \n",
    "functools.reduce(lambda x, y: x + y / float(len(stringlengthmap)), stringlengthmap, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **_The below code is now to prove that the code does work, by providing a different, custom string with different string lengths.  _**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input string  ['Really hope', 'this assignment', 'ends better than', 'it started!'] has an average length of "
     ]
    },
    {
     "data": {
      "text/plain": [
       "13.25"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def stringlength(string):\n",
    "    return len(string)\n",
    "\n",
    "def numelements(string):\n",
    "    return len(string.split())\n",
    " \n",
    "strings = [\"Really hope\", \"this assignment\", \"ends better than\", \"it started!\"]\n",
    "stringlengthmap = map(stringlength, strings)\n",
    "\n",
    "import functools\n",
    "print \"The input string \", strings, \"has an average length of \", \n",
    "functools.reduce(lambda x, y: x + y / float(len(stringlengthmap)), stringlengthmap, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW1.1 Cross fold validation \n",
    "\n",
    "## What is cross validation (in partiticular 10-fold cross validation)?\n",
    "\n",
    "#### _Cross-validation is a technique to evaluate predictive models by partitioning the original sample into a training set to train the model, and a test set to evaluate it.  10-fold cross validation is partitioning the original sample into 10 partitions; 9 to train and one to test.  Here's a basic outline of a 10 fold cross validation on a modeling data set:_\n",
    "\n",
    "   * Partition data into, approximately, n/10 where n is the size of the data set.  (If the data set has 1000 records, there would be roughly 1000/10 = 100 data points in each partition).\n",
    "\n",
    "   * Train a model on 9 of the 10 partitions, holding the last for validation.\n",
    "\n",
    "   * Repeat 9 times, with each iteration a different holding partition for validation.\n",
    "\n",
    "   * Calculate a desired metric for the 10 validations (MSE, RMSE, MAPE, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Info for the rest of the assignment: \n",
    "\n",
    "===== SPAM Dataset \n",
    "In the remainder of this assignment you will produce a spam filter\n",
    "that is backed by a multinomial naive Bayes classifier  (see http://nlp.stanford.edu/IR-book/html/htmledition/properties-of-naive-bayes-1.html).\n",
    "\n",
    "For the sake of this assignment we will focus on the basic construction \n",
    "of the parallelized classifier, and not consider its validation or calibration,\n",
    "and so you will have the classifier operate on its own training data (unlike a \n",
    "field application where one would use non-overlapping subsets for training, validation and testing).\n",
    "\n",
    "The data you will use is a curated subset of the Enron email corpus\n",
    "(whose details you may find in the file enronemail_README.txt  in the directory surrounding these instructions).\n",
    "\n",
    "NOTE: please use the subject field and the body field for all your Naive Bayes modeling. \n",
    "\n",
    "NOTE: This SPAM/HAM dataset for HW1 contains 100 records from the Enron SPAM/HAM corpus. Please limit your study to this unless otherwise instructed. There are about 93,000 emails in the original SPAM/HAM corpus. There are several versions of the SPAM/HAM corpus. Other Enron-Spam datasets are available from http://www.aueb.gr/users/ion/data/enron-spam/index.html and http://www.aueb.gr/users/ion/publications.html in both raw and pre-processed form. \n",
    "\n",
    "Doing some exploratory data analysis you will see (with this very small dataset) the following:\n",
    "> wc -l enronemail_1h.txt  #100 email records\n",
    "     100 enronemail_1h.txt\n",
    "> cut -f2 -d$'\\t' enronemail_1h.txt|wc  #extract second field which is SPAM flag\n",
    "     101     394    3999\n",
    "JAMES-SHANAHANs-Desktop-Pro-2:HW1-Questions jshanahan$ cut -f2 -d$'\\t' enronemail_1h.txt|head\n",
    "0\n",
    "0\n",
    "0\n",
    "0\n",
    "0\n",
    "0\n",
    "0\n",
    "0\n",
    "1\n",
    "1\n",
    "\n",
    "> head -n 100 enronemail_1h.txt|tail -1|less \n",
    "\n",
    "### An example SPAM email record\n",
    "018.2001-07-13.SA_and_HP       1        [ilug] we need your assistance to invest in your country        dear sir/madam,  i am well confident of your capability to assist me in  a transaction for mutual benefit of both parties, ie  (me and you) i am also believing that you will not  expose or betray the trust and confidence i am about  to establish with you. i have decided to contact you  with greatest delight and personal respect.  well, i am victor sankoh, son to mr. foday  sankoh  who was arrested by the ecomog peace keeping force  months ago in my country sierra leone. …."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW1.2 \n",
    "\n",
    "### WORDCOUNT\n",
    "Using the Enron dataset and Hadoop MapReduce streaming (or MRJob), write the mapper/reducer job that  will determine the word count (number of occurrences) of each white-space delimitted token (assume spaces, fullstops, comma as delimiters). Examine the word “assistance” and report its word count results.\n",
    "\n",
    " \n",
    "CROSSCHECK: >grep assistance enronemail_1h.txt|cut -d$'\\t' -f4| grep assistance|wc -l    \n",
    "       8   \n",
    "       \n",
    "NOTE:  \"assistance\" occurs on 8 lines but how many times does the token occur? 10 times! This is the number we are looking for!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting WordCountHW12.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile WordCountHW12.py\n",
    "\n",
    "from mrjob.job import MRJob\n",
    "import re, string\n",
    "\n",
    "class MRJobWordCount(MRJob):\n",
    "\n",
    "    def mapper(self, _, line):\n",
    "        regex = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "        token = line.strip().split('\\t', 2)[-1]\n",
    "        token = regex.sub(' ', token.lower())\n",
    "        token = re.sub( '\\s+', ' ', token )\n",
    "        words = token.split()\n",
    "\n",
    "        for word in words:\n",
    "            if len(word) > 1:\n",
    "                yield (word, 1)\n",
    "\n",
    "    def combiner(self, word, counts):\n",
    "        yield(word, sum(counts))\n",
    "\n",
    "    def reducer(self, word, counts):\n",
    "        yield word, sum(counts)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    MRJobWordCount.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "Creating temp directory /var/folders/0r/78q4n41j3dgdb6ndrr46gw3430x2wk/T/WordCountHW12.z086769.20160701.012136.962153\n",
      "Running step 1 of 1...\n",
      "Streaming final output from /var/folders/0r/78q4n41j3dgdb6ndrr46gw3430x2wk/T/WordCountHW12.z086769.20160701.012136.962153/output...\n",
      "\"00\"\t33\n",
      "\"000\"\t52\n",
      "\"001\"\t3\n",
      "\"0011\"\t1\n",
      "\"00450\"\t1\n",
      "\"0080\"\t1\n",
      "\"01\"\t25\n",
      "\"012\"\t4\n",
      "\"02\"\t19\n",
      "\"028\"\t1\n",
      "\"0281\"\t1\n",
      "\"03\"\t3\n",
      "\"036474336\"\t1\n",
      "\"04\"\t7\n",
      "\"048\"\t1\n",
      "\"05\"\t4\n",
      "\"055\"\t2\n",
      "\"06\"\t21\n",
      "\"0643\"\t1\n",
      "\"07\"\t10\n",
      "\"08\"\t22\n",
      "\"081\"\t2\n",
      "\"088889774\"\t1\n",
      "\"09\"\t21\n",
      "\"10\"\t44\n",
      "\"100\"\t19\n",
      "\"100038\"\t1\n",
      "\"1016\"\t1\n",
      "\"103\"\t1\n",
      "\"107\"\t1\n",
      "\"108\"\t1\n",
      "\"11\"\t15\n",
      "\"114427\"\t1\n",
      "\"12\"\t74\n",
      "\"120\"\t1\n",
      "\"1200\"\t2\n",
      "\"122\"\t1\n",
      "\"123\"\t3\n",
      "\"123395\"\t1\n",
      "\"124\"\t3\n",
      "\"125\"\t2\n",
      "\"126\"\t2\n",
      "\"13\"\t13\n",
      "\"134\"\t1\n",
      "\"14\"\t33\n",
      "\"146907159\"\t1\n",
      "\"148415904\"\t1\n",
      "\"1488230796\"\t1\n",
      "\"149\"\t1\n",
      "\"15\"\t25\n",
      "\"150\"\t1\n",
      "\"1500\"\t1\n",
      "\"151\"\t1\n",
      "\"1517\"\t1\n",
      "\"16\"\t5\n",
      "\"161\"\t1\n",
      "\"1687\"\t1\n",
      "\"1689\"\t1\n",
      "\"17\"\t19\n",
      "\"18\"\t18\n",
      "\"1814\"\t1\n",
      "\"1848\"\t1\n",
      "\"1864\"\t1\n",
      "\"19\"\t9\n",
      "\"1928\"\t1\n",
      "\"1930\"\t1\n",
      "\"1932\"\t1\n",
      "\"1933\"\t1\n",
      "\"1934\"\t1\n",
      "\"1935\"\t1\n",
      "\"1936\"\t1\n",
      "\"1938\"\t1\n",
      "\"1941\"\t1\n",
      "\"1942\"\t1\n",
      "\"1944\"\t1\n",
      "\"1945\"\t1\n",
      "\"1947\"\t1\n",
      "\"1949\"\t1\n",
      "\"1953\"\t1\n",
      "\"1980\"\t2\n",
      "\"1990\"\t2\n",
      "\"1992\"\t3\n",
      "\"1997\"\t3\n",
      "\"1998\"\t2\n",
      "\"1999\"\t10\n",
      "\"20\"\t20\n",
      "\"200\"\t3\n",
      "\"2000\"\t30\n",
      "\"2001\"\t29\n",
      "\"2002\"\t2\n",
      "\"2003\"\t19\n",
      "\"2004\"\t16\n",
      "\"2005\"\t3\n",
      "\"201\"\t2\n",
      "\"2020\"\t1\n",
      "\"2086\"\t1\n",
      "\"209318\"\t1\n",
      "\"21\"\t3\n",
      "\"211075433222\"\t2\n",
      "\"212\"\t3\n",
      "\"213\"\t1\n",
      "\"2152\"\t1\n",
      "\"22\"\t8\n",
      "\"224\"\t1\n",
      "\"229\"\t2\n",
      "\"23\"\t4\n",
      "\"230\"\t1\n",
      "\"234\"\t1\n",
      "\"24\"\t27\n",
      "\"249\"\t2\n",
      "\"2497\"\t1\n",
      "\"25\"\t4\n",
      "\"250\"\t1\n",
      "\"2500\"\t1\n",
      "\"252050406\"\t1\n",
      "\"255326837\"\t1\n",
      "\"256\"\t1\n",
      "\"25711\"\t2\n",
      "\"2575\"\t4\n",
      "\"259\"\t1\n",
      "\"26\"\t5\n",
      "\"260\"\t2\n",
      "\"263\"\t2\n",
      "\"2666\"\t1\n",
      "\"27\"\t6\n",
      "\"27049\"\t2\n",
      "\"2753\"\t1\n",
      "\"28\"\t10\n",
      "\"2807\"\t1\n",
      "\"281\"\t1\n",
      "\"2868\"\t1\n",
      "\"29\"\t10\n",
      "\"29155\"\t1\n",
      "\"2963\"\t1\n",
      "\"299\"\t1\n",
      "\"30\"\t20\n",
      "\"300\"\t9\n",
      "\"3000\"\t2\n",
      "\"3011\"\t1\n",
      "\"306\"\t2\n",
      "\"31\"\t4\n",
      "\"312\"\t1\n",
      "\"3130\"\t1\n",
      "\"31615304791\"\t1\n",
      "\"32\"\t12\n",
      "\"321\"\t1\n",
      "\"3267\"\t1\n",
      "\"3300\"\t1\n",
      "\"33155\"\t1\n",
      "\"332\"\t1\n",
      "\"33282\"\t1\n",
      "\"33465\"\t1\n",
      "\"3359\"\t1\n",
      "\"33597\"\t1\n",
      "\"34\"\t4\n",
      "\"3404\"\t1\n",
      "\"3405\"\t2\n",
      "\"34357\"\t1\n",
      "\"345\"\t1\n",
      "\"34710\"\t1\n",
      "\"349\"\t2\n",
      "\"35\"\t2\n",
      "\"35615\"\t1\n",
      "\"35782\"\t1\n",
      "\"36\"\t2\n",
      "\"37\"\t1\n",
      "\"37159\"\t2\n",
      "\"375\"\t1\n",
      "\"38\"\t5\n",
      "\"39\"\t5\n",
      "\"392\"\t2\n",
      "\"39510\"\t2\n",
      "\"399\"\t1\n",
      "\"39934\"\t2\n",
      "\"40\"\t9\n",
      "\"4073\"\t1\n",
      "\"409055\"\t1\n",
      "\"41\"\t1\n",
      "\"415\"\t4\n",
      "\"418\"\t4\n",
      "\"419\"\t1\n",
      "\"420\"\t1\n",
      "\"422\"\t4\n",
      "\"423\"\t2\n",
      "\"43\"\t2\n",
      "\"431\"\t1\n",
      "\"436425795822\"\t1\n",
      "\"44\"\t6\n",
      "\"449\"\t1\n",
      "\"45\"\t6\n",
      "\"4500\"\t2\n",
      "\"46\"\t2\n",
      "\"47\"\t2\n",
      "\"474\"\t1\n",
      "\"4748\"\t1\n",
      "\"4887\"\t1\n",
      "\"49\"\t1\n",
      "\"499\"\t2\n",
      "\"50\"\t15\n",
      "\"500\"\t8\n",
      "\"5000\"\t3\n",
      "\"5022\"\t1\n",
      "\"51\"\t1\n",
      "\"512517\"\t2\n",
      "\"519\"\t1\n",
      "\"52\"\t3\n",
      "\"521\"\t1\n",
      "\"52109\"\t1\n",
      "\"52477\"\t1\n",
      "\"529\"\t3\n",
      "\"5290\"\t2\n",
      "\"54\"\t4\n",
      "\"54804\"\t1\n",
      "\"549\"\t1\n",
      "\"55\"\t4\n",
      "\"553\"\t1\n",
      "\"5555\"\t2\n",
      "\"56\"\t1\n",
      "\"560\"\t1\n",
      "\"57\"\t1\n",
      "\"58\"\t1\n",
      "\"584\"\t1\n",
      "\"59\"\t2\n",
      "\"599\"\t1\n",
      "\"60\"\t6\n",
      "\"600\"\t1\n",
      "\"602\"\t1\n",
      "\"609\"\t1\n",
      "\"61\"\t2\n",
      "\"6207\"\t1\n",
      "\"62163\"\t1\n",
      "\"62413\"\t1\n",
      "\"630\"\t1\n",
      "\"6396\"\t1\n",
      "\"64\"\t1\n",
      "\"642\"\t1\n",
      "\"645\"\t2\n",
      "\"64610\"\t2\n",
      "\"6484\"\t1\n",
      "\"66\"\t1\n",
      "\"6614102\"\t1\n",
      "\"67\"\t2\n",
      "\"674\"\t1\n",
      "\"6761\"\t1\n",
      "\"68\"\t1\n",
      "\"69\"\t1\n",
      "\"6902\"\t1\n",
      "\"69545\"\t1\n",
      "\"6992\"\t2\n",
      "\"70\"\t1\n",
      "\"700\"\t3\n",
      "\"703\"\t1\n",
      "\"706\"\t2\n",
      "\"71\"\t1\n",
      "\"713\"\t6\n",
      "\"7168\"\t1\n",
      "\"7247\"\t1\n",
      "\"7268\"\t3\n",
      "\"731\"\t1\n",
      "\"735670\"\t1\n",
      "\"7358\"\t2\n",
      "\"738\"\t1\n",
      "\"7394\"\t1\n",
      "\"74949\"\t1\n",
      "\"75\"\t5\n",
      "\"7517\"\t1\n",
      "\"7578\"\t1\n",
      "\"76\"\t1\n",
      "\"763\"\t1\n",
      "\"7675213911\"\t1\n",
      "\"77\"\t1\n",
      "\"77056\"\t2\n",
      "\"78\"\t2\n",
      "\"783019\"\t1\n",
      "\"783518\"\t1\n",
      "\"7877\"\t6\n",
      "\"789118270\"\t1\n",
      "\"793\"\t1\n",
      "\"80\"\t5\n",
      "\"800\"\t3\n",
      "\"802\"\t1\n",
      "\"8038\"\t1\n",
      "\"81\"\t2\n",
      "\"816\"\t2\n",
      "\"82\"\t1\n",
      "\"825854664\"\t1\n",
      "\"840\"\t1\n",
      "\"8434\"\t1\n",
      "\"847\"\t1\n",
      "\"8507\"\t1\n",
      "\"8561513507\"\t1\n",
      "\"869279893\"\t1\n",
      "\"87\"\t3\n",
      "\"877\"\t3\n",
      "\"878\"\t1\n",
      "\"8859\"\t10\n",
      "\"888\"\t5\n",
      "\"89\"\t1\n",
      "\"8901\"\t1\n",
      "\"8919\"\t1\n",
      "\"893\"\t1\n",
      "\"90\"\t3\n",
      "\"900\"\t1\n",
      "\"908\"\t1\n",
      "\"9100\"\t1\n",
      "\"92\"\t1\n",
      "\"9213\"\t1\n",
      "\"9237\"\t1\n",
      "\"925\"\t2\n",
      "\"928976257\"\t1\n",
      "\"9291\"\t1\n",
      "\"932\"\t2\n",
      "\"9381\"\t1\n",
      "\"94105\"\t1\n",
      "\"9434\"\t2\n",
      "\"944\"\t1\n",
      "\"9489\"\t1\n",
      "\"95\"\t15\n",
      "\"95394\"\t1\n",
      "\"96\"\t1\n",
      "\"96006681\"\t1\n",
      "\"9610\"\t1\n",
      "\"964\"\t2\n",
      "\"9643\"\t2\n",
      "\"965\"\t1\n",
      "\"97\"\t1\n",
      "\"973\"\t2\n",
      "\"98\"\t1\n",
      "\"982\"\t1\n",
      "\"986782\"\t1\n",
      "\"99\"\t64\n",
      "\"999\"\t3\n",
      "\"ab\"\t5\n",
      "\"abidjan\"\t2\n",
      "\"ability\"\t2\n",
      "\"able\"\t14\n",
      "\"abn\"\t1\n",
      "\"about\"\t52\n",
      "\"above\"\t11\n",
      "\"absent\"\t1\n",
      "\"absenteeism\"\t1\n",
      "\"absolute\"\t2\n",
      "\"absolutely\"\t1\n",
      "\"absorb\"\t1\n",
      "\"abuse\"\t2\n",
      "\"abused\"\t1\n",
      "\"acce\"\t1\n",
      "\"accelerate\"\t1\n",
      "\"accelerated\"\t1\n",
      "\"accept\"\t3\n",
      "\"acceptable\"\t1\n",
      "\"accepted\"\t1\n",
      "\"accepting\"\t2\n",
      "\"accepts\"\t1\n",
      "\"access\"\t12\n",
      "\"accomodate\"\t4\n",
      "\"accomodates\"\t1\n",
      "\"accompanied\"\t1\n",
      "\"according\"\t2\n",
      "\"accordingly\"\t1\n",
      "\"account\"\t36\n",
      "\"accountability\"\t1\n",
      "\"accounting\"\t5\n",
      "\"accounts\"\t1\n",
      "\"accrual\"\t2\n",
      "\"accurate\"\t1\n",
      "\"aches\"\t1\n",
      "\"achieve\"\t1\n",
      "\"achieved\"\t1\n",
      "\"acid\"\t1\n",
      "\"acquire\"\t1\n",
      "\"acquisition\"\t1\n",
      "\"acrobaat\"\t1\n",
      "\"acrobat\"\t1\n",
      "\"across\"\t10\n",
      "\"act\"\t7\n",
      "\"action\"\t1\n",
      "\"activate\"\t4\n",
      "\"active\"\t1\n",
      "\"activists\"\t1\n",
      "\"activities\"\t10\n",
      "\"actor\"\t1\n",
      "\"actress\"\t1\n",
      "\"actual\"\t4\n",
      "\"actually\"\t2\n",
      "\"ad\"\t31\n",
      "\"adage\"\t1\n",
      "\"adams\"\t1\n",
      "\"adapted\"\t1\n",
      "\"add\"\t12\n",
      "\"added\"\t2\n",
      "\"adding\"\t2\n",
      "\"addition\"\t5\n",
      "\"additional\"\t13\n",
      "\"additionally\"\t2\n",
      "\"address\"\t27\n",
      "\"addressed\"\t1\n",
      "\"addresses\"\t5\n",
      "\"addressing\"\t1\n",
      "\"addtional\"\t1\n",
      "\"adequately\"\t1\n",
      "\"adhesion\"\t1\n",
      "\"adm\"\t1\n",
      "\"admin\"\t1\n",
      "\"adminder\"\t2\n",
      "\"administration\"\t3\n",
      "\"admitted\"\t1\n",
      "\"admixture\"\t1\n",
      "\"adobe\"\t12\n",
      "\"adobee\"\t1\n",
      "\"adolescent\"\t1\n",
      "\"adr\"\t1\n",
      "\"adrianbold\"\t2\n",
      "\"ads\"\t5\n",
      "\"adult\"\t3\n",
      "\"adv\"\t1\n",
      "\"advance\"\t4\n",
      "\"advanced\"\t1\n",
      "\"advantage\"\t1\n",
      "\"advantages\"\t1\n",
      "\"advertise\"\t2\n",
      "\"advertised\"\t1\n",
      "\"advertisement\"\t4\n",
      "\"advertisements\"\t1\n",
      "\"advertising\"\t7\n",
      "\"advertisments\"\t1\n",
      "\"advice\"\t4\n",
      "\"advise\"\t2\n",
      "\"advises\"\t1\n",
      "\"advocate\"\t1\n",
      "\"advocates\"\t1\n",
      "\"advs\"\t1\n",
      "\"aec\"\t2\n",
      "\"aeopublishing\"\t29\n",
      "\"afeee\"\t1\n",
      "\"aff\"\t1\n",
      "\"affairs\"\t1\n",
      "\"affect\"\t2\n",
      "\"affectate\"\t1\n",
      "\"affiliate\"\t2\n",
      "\"affiliates\"\t6\n",
      "\"afford\"\t1\n",
      "\"afirst\"\t1\n",
      "\"afraid\"\t4\n",
      "\"africa\"\t10\n",
      "\"after\"\t19\n",
      "\"afternoon\"\t4\n",
      "\"again\"\t12\n",
      "\"against\"\t6\n",
      "\"age\"\t5\n",
      "\"agendas\"\t1\n",
      "\"agent\"\t3\n",
      "\"aggressive\"\t1\n",
      "\"aggressively\"\t3\n",
      "\"ago\"\t1\n",
      "\"agonizing\"\t1\n",
      "\"agouti\"\t1\n",
      "\"agree\"\t3\n",
      "\"agreed\"\t2\n",
      "\"agreeing\"\t1\n",
      "\"agreement\"\t16\n",
      "\"agreements\"\t3\n",
      "\"ague\"\t1\n",
      "\"ah\"\t1\n",
      "\"ahead\"\t1\n",
      "\"aid\"\t1\n",
      "\"aids\"\t1\n",
      "\"air\"\t6\n",
      "\"airport\"\t2\n",
      "\"airs\"\t1\n",
      "\"aka\"\t1\n",
      "\"akkabay\"\t4\n",
      "\"al\"\t2\n",
      "\"albuquerque\"\t2\n",
      "\"alertness\"\t1\n",
      "\"alex\"\t4\n",
      "\"alexios\"\t1\n",
      "\"alhaji\"\t2\n",
      "\"all\"\t111\n",
      "\"allay\"\t1\n",
      "\"allen\"\t5\n",
      "\"alleviates\"\t1\n",
      "\"alli\"\t1\n",
      "\"allocate\"\t1\n",
      "\"allocated\"\t2\n",
      "\"allocating\"\t2\n",
      "\"allocation\"\t6\n",
      "\"allocations\"\t4\n",
      "\"allow\"\t12\n",
      "\"allows\"\t3\n",
      "\"almost\"\t3\n",
      "\"alone\"\t2\n",
      "\"along\"\t4\n",
      "\"alpra\"\t2\n",
      "\"already\"\t13\n",
      "\"alsdorf\"\t1\n",
      "\"also\"\t56\n",
      "\"alternative\"\t1\n",
      "\"alternatively\"\t1\n",
      "\"although\"\t3\n",
      "\"altra\"\t1\n",
      "\"alum\"\t1\n",
      "\"always\"\t10\n",
      "\"am\"\t86\n",
      "\"amadol\"\t2\n",
      "\"amazed\"\t1\n",
      "\"amb\"\t2\n",
      "\"ambien\"\t2\n",
      "\"ambrose\"\t1\n",
      "\"amended\"\t1\n",
      "\"americ\"\t2\n",
      "\"america\"\t15\n",
      "\"american\"\t2\n",
      "\"amex\"\t1\n",
      "\"ami\"\t1\n",
      "\"amiable\"\t1\n",
      "\"amigo\"\t1\n",
      "\"amitava\"\t4\n",
      "\"among\"\t7\n",
      "\"amortize\"\t4\n",
      "\"amount\"\t7\n",
      "\"amounts\"\t2\n",
      "\"amsterdam\"\t1\n",
      "\"amy\"\t2\n",
      "\"an\"\t77\n",
      "\"anabel\"\t1\n",
      "\"anal\"\t1\n",
      "\"analyses\"\t1\n",
      "\"analysis\"\t3\n",
      "\"analyst\"\t2\n",
      "\"analyze\"\t1\n",
      "\"ancillary\"\t2\n",
      "\"and\"\t670\n",
      "\"andorra\"\t1\n",
      "\"andrea\"\t3\n",
      "\"angelova\"\t4\n",
      "\"angels\"\t2\n",
      "\"angrily\"\t1\n",
      "\"angry\"\t1\n",
      "\"anheuser\"\t1\n",
      "\"anita\"\t2\n",
      "\"annals\"\t1\n",
      "\"annie\"\t2\n",
      "\"announcement\"\t7\n",
      "\"announcements\"\t4\n",
      "\"annoy\"\t1\n",
      "\"annoying\"\t1\n",
      "\"annuallouy\"\t1\n",
      "\"anonymise\"\t1\n",
      "\"anonymizer\"\t1\n",
      "\"anonymously\"\t1\n",
      "\"another\"\t15\n",
      "\"answer\"\t7\n",
      "\"answered\"\t1\n",
      "\"answering\"\t3\n",
      "\"answers\"\t7\n",
      "\"ante\"\t1\n",
      "\"anticipate\"\t1\n",
      "\"antivirus\"\t1\n",
      "\"antoine\"\t1\n",
      "\"any\"\t77\n",
      "\"anyare\"\t1\n",
      "\"anybody\"\t1\n",
      "\"anyhow\"\t5\n",
      "\"anyone\"\t7\n",
      "\"anything\"\t11\n",
      "\"anyway\"\t2\n",
      "\"anywhere\"\t3\n",
      "\"anz\"\t2\n",
      "\"aol\"\t6\n",
      "\"apachi\"\t1\n",
      "\"apart\"\t2\n",
      "\"apex\"\t1\n",
      "\"aphrodite\"\t1\n",
      "\"apoligize\"\t2\n",
      "\"apollo\"\t1\n",
      "\"apologies\"\t2\n",
      "\"apologize\"\t3\n",
      "\"apparently\"\t2\n",
      "\"appeals\"\t4\n",
      "\"appear\"\t7\n",
      "\"appearance\"\t2\n",
      "\"appears\"\t3\n",
      "\"appellate\"\t1\n",
      "\"appetite\"\t2\n",
      "\"application\"\t4\n",
      "\"applied\"\t5\n",
      "\"apply\"\t4\n",
      "\"appreciate\"\t2\n",
      "\"appreciated\"\t1\n",
      "\"appreciation\"\t2\n",
      "\"approach\"\t2\n",
      "\"appropriate\"\t3\n",
      "\"approval\"\t1\n",
      "\"approved\"\t6\n",
      "\"approximately\"\t4\n",
      "\"aqmd\"\t2\n",
      "\"aqoj\"\t1\n",
      "\"arbitrage\"\t4\n",
      "\"architect\"\t1\n",
      "\"archive\"\t1\n",
      "\"arcy\"\t7\n",
      "\"are\"\t169\n",
      "\"area\"\t4\n",
      "\"areas\"\t3\n",
      "\"aren\"\t3\n",
      "\"argentine\"\t4\n",
      "\"argue\"\t1\n",
      "\"argument\"\t2\n",
      "\"arizona\"\t1\n",
      "\"ark\"\t1\n",
      "\"arlene\"\t2\n",
      "\"arm\"\t1\n",
      "\"armstrong\"\t2\n",
      "\"around\"\t6\n",
      "\"arousing\"\t1\n",
      "\"arrange\"\t5\n",
      "\"arranged\"\t1\n",
      "\"arrangement\"\t2\n",
      "\"arrangements\"\t3\n",
      "\"arrest\"\t4\n",
      "\"arrested\"\t1\n",
      "\"arrival\"\t1\n",
      "\"art\"\t2\n",
      "\"arthur\"\t1\n",
      "\"article\"\t3\n",
      "\"articles\"\t2\n",
      "\"as\"\t138\n",
      "\"asap\"\t1\n",
      "\"ascii\"\t1\n",
      "\"ashburton\"\t3\n",
      "\"asia\"\t1\n",
      "\"aside\"\t4\n",
      "\"ask\"\t9\n",
      "\"asked\"\t3\n",
      "\"asking\"\t10\n",
      "\"asks\"\t1\n",
      "\"aspermont\"\t3\n",
      "\"assault\"\t1\n",
      "\"assay\"\t1\n",
      "\"assays\"\t1\n",
      "\"assembly\"\t2\n",
      "\"assemblyman\"\t3\n",
      "\"asset\"\t1\n",
      "\"assets\"\t14\n",
      "\"assignment\"\t1\n",
      "\"assist\"\t7\n",
      "\"assistance\"\t10\n",
      "\"assistant\"\t2\n",
      "\"associate\"\t3\n",
      "\"associated\"\t4\n",
      "\"association\"\t3\n",
      "\"assortment\"\t1\n",
      "\"assume\"\t1\n",
      "\"assuming\"\t1\n",
      "\"assumption\"\t1\n",
      "\"assure\"\t4\n",
      "\"asthma\"\t1\n",
      "\"at\"\t146\n",
      "\"ate\"\t3\n",
      "\"ativan\"\t1\n",
      "\"atop\"\t1\n",
      "\"atreus\"\t1\n",
      "\"attached\"\t8\n",
      "\"attack\"\t1\n",
      "\"attacked\"\t1\n",
      "\"attatched\"\t2\n",
      "\"attempt\"\t2\n",
      "\"attend\"\t7\n",
      "\"attendance\"\t2\n",
      "\"attended\"\t1\n",
      "\"attendees\"\t2\n",
      "\"attending\"\t1\n",
      "\"attention\"\t3\n",
      "\"attest\"\t1\n",
      "\"attitudinal\"\t1\n",
      "\"attl\"\t1\n",
      "\"attn\"\t2\n",
      "\"attractive\"\t2\n",
      "\"attributable\"\t1\n",
      "\"audience\"\t10\n",
      "\"audio\"\t2\n",
      "\"audit\"\t3\n",
      "\"auditor\"\t1\n",
      "\"august\"\t1\n",
      "\"australia\"\t10\n",
      "\"australian\"\t3\n",
      "\"australiasds\"\t1\n",
      "\"authenticity\"\t1\n",
      "\"author\"\t4\n",
      "\"authorities\"\t1\n",
      "\"authority\"\t1\n",
      "\"authorized\"\t1\n",
      "\"authors\"\t1\n",
      "\"automated\"\t2\n",
      "\"automatically\"\t7\n",
      "\"automobile\"\t1\n",
      "\"availability\"\t2\n",
      "\"available\"\t23\n",
      "\"average\"\t4\n",
      "\"aviation\"\t1\n",
      "\"avoid\"\t10\n",
      "\"avoided\"\t1\n",
      "\"await\"\t4\n",
      "\"awaking\"\t1\n",
      "\"award\"\t1\n",
      "\"aware\"\t1\n",
      "\"away\"\t9\n",
      "\"awesome\"\t1\n",
      "\"ax\"\t2\n",
      "\"axe\"\t1\n",
      "\"axel\"\t2\n",
      "\"ay\"\t1\n",
      "\"azepam\"\t2\n",
      "\"azurix\"\t10\n",
      "\"baby\"\t2\n",
      "\"baccarat\"\t1\n",
      "\"bachelors\"\t1\n",
      "\"back\"\t26\n",
      "\"backed\"\t1\n",
      "\"background\"\t9\n",
      "\"backgrounds\"\t1\n",
      "\"backup\"\t2\n",
      "\"bacon\"\t1\n",
      "\"bacterial\"\t1\n",
      "\"bad\"\t5\n",
      "\"bade\"\t1\n",
      "\"baggage\"\t1\n",
      "\"bail\"\t9\n",
      "\"bailout\"\t8\n",
      "\"balance\"\t1\n",
      "\"ballot\"\t1\n",
      "\"banging\"\t1\n",
      "\"bank\"\t7\n",
      "\"banked\"\t1\n",
      "\"banker\"\t3\n",
      "\"banking\"\t4\n",
      "\"bankruptcy\"\t20\n",
      "\"banks\"\t1\n",
      "\"bannerco\"\t4\n",
      "\"banners\"\t1\n",
      "\"bannersgomlm\"\t8\n",
      "\"bar\"\t1\n",
      "\"bareback\"\t1\n",
      "\"barely\"\t1\n",
      "\"bargaain\"\t1\n",
      "\"barnard\"\t1\n",
      "\"barney\"\t3\n",
      "\"barraged\"\t1\n",
      "\"barrier\"\t2\n",
      "\"barrow\"\t1\n",
      "\"base\"\t4\n",
      "\"based\"\t15\n",
      "\"basically\"\t1\n",
      "\"basis\"\t5\n",
      "\"baskets\"\t5\n",
      "\"batch\"\t3\n",
      "\"bauxite\"\t1\n",
      "\"bawled\"\t1\n",
      "\"bazzd\"\t1\n",
      "\"bc\"\t1\n",
      "\"bcli\"\t1\n",
      "\"bd\"\t7\n",
      "\"bdf\"\t1\n",
      "\"be\"\t222\n",
      "\"beale\"\t1\n",
      "\"beans\"\t1\n",
      "\"bear\"\t4\n",
      "\"beard\"\t1\n",
      "\"beca\"\t1\n",
      "\"became\"\t4\n",
      "\"because\"\t19\n",
      "\"beck\"\t5\n",
      "\"become\"\t6\n",
      "\"bed\"\t1\n",
      "\"bedfellow\"\t1\n",
      "\"beds\"\t3\n",
      "\"been\"\t52\n",
      "\"beers\"\t1\n",
      "\"beetcn\"\t1\n",
      "\"before\"\t23\n",
      "\"began\"\t6\n",
      "\"begin\"\t5\n",
      "\"beginning\"\t4\n",
      "\"begins\"\t2\n",
      "\"behalf\"\t1\n",
      "\"being\"\t14\n",
      "\"belgium\"\t1\n",
      "\"believable\"\t2\n",
      "\"believe\"\t14\n",
      "\"believed\"\t2\n",
      "\"believes\"\t1\n",
      "\"believing\"\t1\n",
      "\"belong\"\t1\n",
      "\"belonged\"\t1\n",
      "\"belongs\"\t2\n",
      "\"below\"\t16\n",
      "\"benchmarks\"\t3\n",
      "\"bendickson\"\t2\n",
      "\"benedicta\"\t2\n",
      "\"beneficiary\"\t1\n",
      "\"benefit\"\t10\n",
      "\"benefits\"\t11\n",
      "\"beneteau\"\t1\n",
      "\"benewm\"\t1\n",
      "\"bennett\"\t1\n",
      "\"benson\"\t1\n",
      "\"ber\"\t1\n",
      "\"berkovitz\"\t2\n",
      "\"bernice\"\t1\n",
      "\"best\"\t27\n",
      "\"bestowal\"\t1\n",
      "\"bestwaytoshop\"\t1\n",
      "\"betray\"\t1\n",
      "\"better\"\t10\n",
      "\"between\"\t7\n",
      "\"beware\"\t1\n",
      "\"beyond\"\t3\n",
      "\"bgmlm\"\t1\n",
      "\"bharat\"\t1\n",
      "\"bid\"\t1\n",
      "\"big\"\t10\n",
      "\"biggest\"\t1\n",
      "\"bill\"\t8\n",
      "\"billed\"\t2\n",
      "\"billion\"\t6\n",
      "\"bills\"\t6\n",
      "\"birch\"\t1\n",
      "\"bit\"\t2\n",
      "\"biwven\"\t1\n",
      "\"biz\"\t4\n",
      "\"bjeffrie\"\t1\n",
      "\"bjwl\"\t1\n",
      "\"blainey\"\t1\n",
      "\"bless\"\t3\n",
      "\"blessed\"\t2\n",
      "\"block\"\t5\n",
      "\"blocked\"\t2\n",
      "\"blocking\"\t2\n",
      "\"blong\"\t1\n",
      "\"blood\"\t1\n",
      "\"blow\"\t1\n",
      "\"blows\"\t1\n",
      "\"blues\"\t2\n",
      "\"blush\"\t1\n",
      "\"bmar\"\t1\n",
      "\"bmf\"\t1\n",
      "\"bmlm\"\t4\n",
      "\"board\"\t3\n",
      "\"bob\"\t7\n",
      "\"bodies\"\t1\n",
      "\"body\"\t9\n",
      "\"bodyfrankfurter\"\t1\n",
      "\"bold\"\t2\n",
      "\"bolnisi\"\t1\n",
      "\"bombs\"\t3\n",
      "\"bond\"\t1\n",
      "\"bondholders\"\t1\n",
      "\"bonds\"\t6\n",
      "\"bone\"\t1\n",
      "\"bonnard\"\t1\n",
      "\"bonus\"\t5\n",
      "\"bonuses\"\t4\n",
      "\"book\"\t5\n",
      "\"books\"\t2\n",
      "\"boost\"\t1\n",
      "\"boosts\"\t1\n",
      "\"booth\"\t1\n",
      "\"boots\"\t1\n",
      "\"booze\"\t1\n",
      "\"borlan\"\t1\n",
      "\"borland\"\t1\n",
      "\"borrowers\"\t1\n",
      "\"boss\"\t1\n",
      "\"both\"\t15\n",
      "\"bother\"\t1\n",
      "\"bottom\"\t2\n",
      "\"bought\"\t3\n",
      "\"bound\"\t2\n",
      "\"boundary\"\t1\n",
      "\"box\"\t20\n",
      "\"boxes\"\t1\n",
      "\"boy\"\t2\n",
      "\"bp\"\t3\n",
      "\"br\"\t2\n",
      "\"brad\"\t2\n",
      "\"bradford\"\t1\n",
      "\"brainstorm\"\t1\n",
      "\"brand\"\t6\n",
      "\"branded\"\t1\n",
      "\"branding\"\t8\n",
      "\"brazil\"\t8\n",
      "\"brazilian\"\t4\n",
      "\"break\"\t5\n",
      "\"breaking\"\t1\n",
      "\"breakthrough\"\t1\n",
      "\"breath\"\t5\n",
      "\"breathe\"\t2\n",
      "\"bredd\"\t1\n",
      "\"brenda\"\t1\n",
      "\"brennan\"\t2\n",
      "\"brent\"\t2\n",
      "\"brett\"\t3\n",
      "\"brex\"\t2\n",
      "\"brian\"\t1\n",
      "\"brick\"\t5\n",
      "\"bridge\"\t1\n",
      "\"brighton\"\t1\n",
      "\"brim\"\t1\n",
      "\"bring\"\t1\n",
      "\"brings\"\t5\n",
      "\"broad\"\t2\n",
      "\"broker\"\t3\n",
      "\"brought\"\t1\n",
      "\"brown\"\t3\n",
      "\"browser\"\t2\n",
      "\"brutal\"\t1\n",
      "\"bryan\"\t6\n",
      "\"bs\"\t2\n",
      "\"btu\"\t2\n",
      "\"buchsbaum\"\t1\n",
      "\"buck\"\t1\n",
      "\"bucolic\"\t1\n",
      "\"build\"\t12\n",
      "\"building\"\t7\n",
      "\"buildings\"\t1\n",
      "\"buka\"\t2\n",
      "\"bull\"\t1\n",
      "\"bullet\"\t5\n",
      "\"bulleted\"\t2\n",
      "\"bullets\"\t1\n",
      "\"burning\"\t2\n",
      "\"burst\"\t1\n",
      "\"burton\"\t13\n",
      "\"bus\"\t4\n",
      "\"busine\"\t1\n",
      "\"busines\"\t1\n",
      "\"business\"\t64\n",
      "\"businesses\"\t4\n",
      "\"businessopps\"\t2\n",
      "\"bussell\"\t1\n",
      "\"busy\"\t1\n",
      "\"but\"\t67\n",
      "\"butler\"\t1\n",
      "\"button\"\t1\n",
      "\"buy\"\t8\n",
      "\"buybacks\"\t1\n",
      "\"buying\"\t1\n",
      "\"by\"\t143\n",
      "\"bybb\"\t1\n",
      "\"bybtb\"\t1\n",
      "\"bye\"\t1\n",
      "\"byee\"\t2\n",
      "\"bypass\"\t1\n",
      "\"bypasses\"\t1\n",
      "\"bytesize\"\t1\n",
      "\"ca\"\t6\n",
      "\"cabinet\"\t1\n",
      "\"cabinets\"\t1\n",
      "\"caboose\"\t1\n",
      "\"cage\"\t1\n",
      "\"cagey\"\t1\n",
      "\"cal\"\t3\n",
      "\"calamity\"\t2\n",
      "\"calculations\"\t2\n",
      "\"cali\"\t1\n",
      "\"california\"\t12\n",
      "\"call\"\t15\n",
      "\"called\"\t3\n",
      "\"calme\"\t1\n",
      "\"calpine\"\t3\n",
      "\"came\"\t2\n",
      "\"camp\"\t7\n",
      "\"campus\"\t1\n",
      "\"can\"\t90\n",
      "\"canada\"\t4\n",
      "\"canadian\"\t1\n",
      "\"canary\"\t1\n",
      "\"cancel\"\t1\n",
      "\"candidate\"\t1\n",
      "\"cankerworm\"\t1\n",
      "\"cannot\"\t5\n",
      "\"cano\"\t1\n",
      "\"canyonu\"\t1\n",
      "\"capabilities\"\t1\n",
      "\"capability\"\t3\n",
      "\"capacity\"\t2\n",
      "\"capital\"\t7\n",
      "\"capitalisation\"\t1\n",
      "\"capitalize\"\t2\n",
      "\"capitol\"\t1\n",
      "\"car\"\t6\n",
      "\"card\"\t5\n",
      "\"cards\"\t5\n",
      "\"care\"\t9\n",
      "\"careful\"\t1\n",
      "\"carefully\"\t4\n",
      "\"cares\"\t1\n",
      "\"cargill\"\t2\n",
      "\"carlo\"\t1\n",
      "\"carlos\"\t5\n",
      "\"carmody\"\t1\n",
      "\"carol\"\t1\n",
      "\"carolyn\"\t1\n",
      "\"carrera\"\t1\n",
      "\"carriage\"\t1\n",
      "\"carrie\"\t1\n",
      "\"carried\"\t1\n",
      "\"carroll\"\t6\n",
      "\"carry\"\t1\n",
      "\"cars\"\t4\n",
      "\"cart\"\t2\n",
      "\"case\"\t13\n",
      "\"cases\"\t2\n",
      "\"cash\"\t18\n",
      "\"cashpo\"\t2\n",
      "\"cashpromotions\"\t4\n",
      "\"casinos\"\t2\n",
      "\"cat\"\t2\n",
      "\"catalog\"\t5\n",
      "\"catalyze\"\t2\n",
      "\"catchy\"\t1\n",
      "\"category\"\t2\n",
      "\"caucasians\"\t1\n",
      "\"caught\"\t1\n",
      "\"cause\"\t1\n",
      "\"caused\"\t1\n",
      "\"causey\"\t7\n",
      "\"cc\"\t40\n",
      "\"ccprod\"\t3\n",
      "\"cd\"\t2\n",
      "\"ceased\"\t1\n",
      "\"cede\"\t1\n",
      "\"cele\"\t2\n",
      "\"celebrate\"\t1\n",
      "\"celebration\"\t3\n",
      "\"celias\"\t1\n",
      "\"cell\"\t1\n",
      "\"cellulite\"\t1\n",
      "\"cemented\"\t1\n",
      "\"cenochs\"\t1\n",
      "\"cent\"\t1\n",
      "\"center\"\t13\n",
      "\"central\"\t3\n",
      "\"cents\"\t7\n",
      "\"century\"\t1\n",
      "\"ceo\"\t1\n",
      "\"ceos\"\t1\n",
      "\"cernosek\"\t1\n",
      "\"certain\"\t1\n",
      "\"certainly\"\t4\n",
      "\"certificates\"\t1\n",
      "\"cgi\"\t5\n",
      "\"cha\"\t1\n",
      "\"chaeap\"\t1\n",
      "\"chairing\"\t1\n",
      "\"chairman\"\t4\n",
      "\"challenge\"\t1\n",
      "\"challenges\"\t1\n",
      "\"challenging\"\t3\n",
      "\"chambers\"\t1\n",
      "\"champion\"\t3\n",
      "\"chance\"\t6\n",
      "\"chances\"\t4\n",
      "\"chancesto\"\t1\n",
      "\"change\"\t16\n",
      "\"changed\"\t1\n",
      "\"changes\"\t4\n",
      "\"changing\"\t1\n",
      "\"channel\"\t1\n",
      "\"chapman\"\t4\n",
      "\"char\"\t2\n",
      "\"charge\"\t11\n",
      "\"charges\"\t1\n",
      "\"charlie\"\t1\n",
      "\"charset\"\t11\n",
      "\"chart\"\t1\n",
      "\"charter\"\t2\n",
      "\"chartroom\"\t1\n",
      "\"charts\"\t2\n",
      "\"chatham\"\t1\n",
      "\"cheaep\"\t1\n",
      "\"cheap\"\t1\n",
      "\"cheapsoft\"\t3\n",
      "\"cheated\"\t4\n",
      "\"check\"\t3\n",
      "\"checking\"\t4\n",
      "\"checks\"\t1\n",
      "\"cheeap\"\t1\n",
      "\"cheeky\"\t1\n",
      "\"cheers\"\t1\n",
      "\"chewing\"\t2\n",
      "\"chief\"\t4\n",
      "\"child\"\t3\n",
      "\"children\"\t3\n",
      "\"chile\"\t2\n",
      "\"chill\"\t1\n",
      "\"china\"\t3\n",
      "\"chinamen\"\t1\n",
      "\"chinese\"\t1\n",
      "\"chip\"\t1\n",
      "\"chirano\"\t4\n",
      "\"chisholm\"\t1\n",
      "\"choice\"\t2\n",
      "\"chokshi\"\t1\n",
      "\"cholesterol\"\t1\n",
      "\"choose\"\t4\n",
      "\"chosen\"\t4\n",
      "\"chris\"\t1\n",
      "\"christi\"\t1\n",
      "\"christian\"\t1\n",
      "\"christine\"\t1\n",
      "\"christmas\"\t20\n",
      "\"chromium\"\t1\n",
      "\"chronicles\"\t1\n",
      "\"chuck\"\t1\n",
      "\"chumming\"\t1\n",
      "\"chums\"\t1\n",
      "\"chunk\"\t1\n",
      "\"cialis\"\t2\n",
      "\"cigars\"\t1\n",
      "\"cindy\"\t5\n",
      "\"cinergy\"\t1\n",
      "\"circumstances\"\t1\n",
      "\"citizens\"\t2\n",
      "\"citrus\"\t2\n",
      "\"city\"\t5\n",
      "\"civilizirano\"\t1\n",
      "\"cj\"\t5\n",
      "\"ckgby\"\t1\n",
      "\"ckily\"\t1\n",
      "\"claiis\"\t1\n",
      "\"claim\"\t3\n",
      "\"claimed\"\t1\n",
      "\"claiming\"\t1\n",
      "\"claims\"\t4\n",
      "\"clamp\"\t1\n",
      "\"clare\"\t1\n",
      "\"clarification\"\t2\n",
      "\"clarity\"\t1\n",
      "\"clark\"\t1\n",
      "\"class\"\t2\n",
      "\"classes\"\t1\n",
      "\"classic\"\t1\n",
      "\"classifieds\"\t1\n",
      "\"classrom\"\t1\n",
      "\"claude\"\t1\n",
      "\"clear\"\t12\n",
      "\"clearing\"\t1\n",
      "\"clearly\"\t1\n",
      "\"clem\"\t1\n",
      "\"clemmons\"\t1\n",
      "\"clemons\"\t1\n",
      "\"click\"\t41\n",
      "\"clicking\"\t1\n",
      "\"client\"\t1\n",
      "\"clients\"\t1\n",
      "\"cliffhanger\"\t2\n",
      "\"cliickk\"\t2\n",
      "\"climate\"\t1\n",
      "\"clinches\"\t1\n",
      "\"clinging\"\t1\n",
      "\"clips\"\t1\n",
      "\"clon\"\t2\n",
      "\"clonazepam\"\t1\n",
      "\"close\"\t6\n",
      "\"closed\"\t1\n",
      "\"closely\"\t5\n",
      "\"closer\"\t1\n",
      "\"closure\"\t1\n",
      "\"clu\"\t1\n",
      "\"club\"\t1\n",
      "\"cmenergy\"\t1\n",
      "\"co\"\t5\n",
      "\"coaching\"\t1\n",
      "\"coal\"\t2\n",
      "\"coastenergy\"\t1\n",
      "\"cobalt\"\t1\n",
      "\"cochilco\"\t1\n",
      "\"coding\"\t2\n",
      "\"coe\"\t4\n",
      "\"coffee\"\t5\n",
      "\"cohen\"\t1\n",
      "\"cold\"\t2\n",
      "\"coleman\"\t1\n",
      "\"collaborate\"\t3\n",
      "\"collect\"\t2\n",
      "\"college\"\t3\n",
      "\"colliw\"\t1\n",
      "\"colloquy\"\t1\n",
      "\"color\"\t19\n",
      "\"colored\"\t2\n",
      "\"colors\"\t1\n",
      "\"colour\"\t1\n",
      "\"columnar\"\t1\n",
      "\"com\"\t227\n",
      "\"combo\"\t1\n",
      "\"comclick\"\t1\n",
      "\"come\"\t19\n",
      "\"comes\"\t6\n",
      "\"comhttp\"\t1\n",
      "\"coming\"\t5\n",
      "\"commence\"\t2\n",
      "\"commenced\"\t1\n",
      "\"commencement\"\t1\n",
      "\"commentaries\"\t3\n",
      "\"commentary\"\t18\n",
      "\"commentaryto\"\t1\n",
      "\"comments\"\t13\n",
      "\"commercial\"\t20\n",
      "\"commission\"\t3\n",
      "\"commissions\"\t2\n",
      "\"committee\"\t2\n",
      "\"commodities\"\t1\n",
      "\"commodity\"\t8\n",
      "\"common\"\t2\n",
      "\"communicate\"\t2\n",
      "\"communicating\"\t2\n",
      "\"communication\"\t9\n",
      "\"communities\"\t3\n",
      "\"community\"\t23\n",
      "\"companies\"\t8\n",
      "\"company\"\t25\n",
      "\"compare\"\t6\n",
      "\"compared\"\t1\n",
      "\"compelling\"\t1\n",
      "\"compensation\"\t2\n",
      "\"compete\"\t2\n",
      "\"competencies\"\t2\n",
      "\"competing\"\t3\n",
      "\"competition\"\t2\n",
      "\"competitive\"\t3\n",
      "\"complete\"\t4\n",
      "\"completed\"\t2\n",
      "\"completely\"\t2\n",
      "\"completing\"\t1\n",
      "\"completion\"\t3\n",
      "\"compliance\"\t1\n",
      "\"complicated\"\t3\n",
      "\"complications\"\t1\n",
      "\"complimentary\"\t1\n",
      "\"compliments\"\t1\n",
      "\"components\"\t1\n",
      "\"comprehensive\"\t1\n",
      "\"computational\"\t1\n",
      "\"computer\"\t7\n",
      "\"comwww\"\t11\n",
      "\"concealed\"\t2\n",
      "\"conceived\"\t1\n",
      "\"concept\"\t1\n",
      "\"concern\"\t1\n",
      "\"concerned\"\t1\n",
      "\"concernig\"\t2\n",
      "\"concerning\"\t8\n",
      "\"concerns\"\t4\n",
      "\"concluding\"\t2\n",
      "\"condition\"\t2\n",
      "\"conduct\"\t2\n",
      "\"conductor\"\t1\n",
      "\"conference\"\t7\n",
      "\"conferences\"\t1\n",
      "\"confided\"\t1\n",
      "\"confidence\"\t1\n",
      "\"confident\"\t1\n",
      "\"confidential\"\t5\n",
      "\"configuration\"\t1\n",
      "\"confirmation\"\t3\n",
      "\"confirmations\"\t5\n",
      "\"confirmed\"\t1\n",
      "\"conflict\"\t1\n",
      "\"confuses\"\t1\n",
      "\"confusing\"\t1\n",
      "\"congrats\"\t1\n",
      "\"congratulations\"\t6\n",
      "\"congratulatory\"\t1\n",
      "\"conn\"\t1\n",
      "\"connected\"\t1\n",
      "\"connection\"\t3\n",
      "\"connective\"\t1\n",
      "\"connie\"\t1\n",
      "\"conscience\"\t1\n",
      "\"consciously\"\t1\n",
      "\"consequently\"\t1\n",
      "\"consider\"\t4\n",
      "\"considered\"\t1\n",
      "\"consistent\"\t1\n",
      "\"consistently\"\t2\n",
      "\"consisting\"\t1\n",
      "\"consolidation\"\t6\n",
      "\"constantly\"\t1\n",
      "\"consternation\"\t1\n",
      "\"construction\"\t1\n",
      "\"constructive\"\t1\n",
      "\"consultant\"\t3\n",
      "\"consultation\"\t2\n",
      "\"consumer\"\t5\n",
      "\"consumers\"\t3\n",
      "\"consummating\"\t1\n",
      "\"contact\"\t31\n",
      "\"contacts\"\t1\n",
      "\"containing\"\t3\n",
      "\"contains\"\t4\n",
      "\"contemplation\"\t1\n",
      "\"content\"\t13\n",
      "\"continents\"\t1\n",
      "\"continue\"\t15\n",
      "\"continued\"\t3\n",
      "\"continues\"\t3\n",
      "\"continuing\"\t1\n",
      "\"contract\"\t10\n",
      "\"contracted\"\t2\n",
      "\"contracts\"\t12\n",
      "\"contratulations\"\t1\n",
      "\"contribution\"\t1\n",
      "\"control\"\t8\n",
      "\"controlled\"\t2\n",
      "\"controls\"\t6\n",
      "\"convenience\"\t1\n",
      "\"convenient\"\t1\n",
      "\"conversation\"\t1\n",
      "\"conversations\"\t1\n",
      "\"convince\"\t2\n",
      "\"convincible\"\t1\n",
      "\"cook\"\t3\n",
      "\"cool\"\t3\n",
      "\"cooler\"\t1\n",
      "\"cooperation\"\t3\n",
      "\"coordinate\"\t5\n",
      "\"coordinating\"\t1\n",
      "\"coordination\"\t3\n",
      "\"coordinator\"\t1\n",
      "\"cop\"\t2\n",
      "\"copartnery\"\t1\n",
      "\"copenhagen\"\t1\n",
      "\"copper\"\t7\n",
      "\"copy\"\t12\n",
      "\"copying\"\t1\n",
      "\"copyright\"\t7\n",
      "\"coral\"\t4\n",
      "\"cordes\"\t1\n",
      "\"core\"\t1\n",
      "\"corel\"\t4\n",
      "\"coreldraw\"\t2\n",
      "\"corey\"\t2\n",
      "\"cornet\"\t2\n",
      "\"corp\"\t31\n",
      "\"corporate\"\t8\n",
      "\"corporation\"\t4\n",
      "\"correction\"\t2\n",
      "\"correspondence\"\t2\n",
      "\"cost\"\t8\n",
      "\"costed\"\t1\n",
      "\"costs\"\t2\n",
      "\"cote\"\t3\n",
      "\"cotroneo\"\t1\n",
      "\"cough\"\t1\n",
      "\"could\"\t18\n",
      "\"couldn\"\t1\n",
      "\"counted\"\t1\n",
      "\"counterparty\"\t2\n",
      "\"countries\"\t2\n",
      "\"country\"\t23\n",
      "\"couple\"\t2\n",
      "\"course\"\t11\n",
      "\"courses\"\t1\n",
      "\"court\"\t4\n",
      "\"courtesy\"\t1\n",
      "\"cover\"\t2\n",
      "\"coverage\"\t3\n",
      "\"cowry\"\t1\n",
      "\"cp\"\t1\n",
      "\"cpm\"\t6\n",
      "\"cpuc\"\t3\n",
      "\"craft\"\t1\n",
      "\"craig\"\t1\n",
      "\"crank\"\t1\n",
      "\"crapbedspring\"\t1\n",
      "\"crawled\"\t1\n",
      "\"crazy\"\t1\n",
      "\"cre\"\t1\n",
      "\"create\"\t13\n",
      "\"created\"\t7\n",
      "\"creates\"\t2\n",
      "\"creating\"\t2\n",
      "\"creation\"\t3\n",
      "\"creativity\"\t1\n",
      "\"credi\"\t1\n",
      "\"credibility\"\t1\n",
      "\"credit\"\t20\n",
      "\"creditor\"\t1\n",
      "\"creditors\"\t4\n",
      "\"credits\"\t1\n",
      "\"crenshaw\"\t13\n",
      "\"crespigny\"\t2\n",
      "\"crest\"\t1\n",
      "\"critical\"\t10\n",
      "\"critically\"\t2\n",
      "\"critique\"\t1\n",
      "\"crooked\"\t1\n",
      "\"cross\"\t3\n",
      "\"crowd\"\t2\n",
      "\"crowdbut\"\t1\n",
      "\"cryogenic\"\t1\n",
      "\"crystal\"\t2\n",
      "\"cs\"\t2\n",
      "\"csikos\"\t1\n",
      "\"cst\"\t1\n",
      "\"ctise\"\t1\n",
      "\"cultural\"\t1\n",
      "\"cure\"\t2\n",
      "\"cures\"\t1\n",
      "\"curio\"\t1\n",
      "\"currency\"\t1\n",
      "\"current\"\t9\n",
      "\"currently\"\t16\n",
      "\"curricula\"\t1\n",
      "\"curriculum\"\t5\n",
      "\"curtain\"\t1\n",
      "\"cushion\"\t1\n",
      "\"custody\"\t1\n",
      "\"custom\"\t1\n",
      "\"customer\"\t24\n",
      "\"customers\"\t4\n",
      "\"customizable\"\t1\n",
      "\"cuts\"\t1\n",
      "\"cyberopps\"\t2\n",
      "\"cynthia\"\t1\n",
      "\"czkkrxht\"\t1\n",
      "\"dahlienweg\"\t1\n",
      "\"daily\"\t3\n",
      "\"dale\"\t1\n",
      "\"damage\"\t1\n",
      "\"damages\"\t1\n",
      "\"damned\"\t1\n",
      "\"damorganjr\"\t1\n",
      "\"damorgarjr\"\t1\n",
      "\"dana\"\t1\n",
      "\"dancing\"\t1\n",
      "\"dangerous\"\t1\n",
      "\"daniel\"\t2\n",
      "\"danielle\"\t2\n",
      "\"daniels\"\t1\n",
      "\"danny\"\t1\n",
      "\"daren\"\t7\n",
      "\"darren\"\t2\n",
      "\"database\"\t1\n",
      "\"datacenter\"\t1\n",
      "\"date\"\t5\n",
      "\"dates\"\t4\n",
      "\"dave\"\t9\n",
      "\"davenport\"\t1\n",
      "\"david\"\t19\n",
      "\"davidyi\"\t1\n",
      "\"davis\"\t10\n",
      "\"daw\"\t1\n",
      "\"dawn\"\t1\n",
      "\"day\"\t22\n",
      "\"days\"\t10\n",
      "\"daysor\"\t1\n",
      "\"daytime\"\t2\n",
      "\"dc\"\t1\n",
      "\"dci\"\t1\n",
      "\"dclemons\"\t1\n",
      "\"dcoit\"\t1\n",
      "\"de\"\t3\n",
      "\"dea\"\t1\n",
      "\"dead\"\t3\n",
      "\"deadline\"\t6\n",
      "\"deadlines\"\t1\n",
      "\"deal\"\t15\n",
      "\"deals\"\t3\n",
      "\"dean\"\t1\n",
      "\"dear\"\t6\n",
      "\"death\"\t3\n",
      "\"debt\"\t12\n",
      "\"debts\"\t3\n",
      "\"dec\"\t11\n",
      "\"december\"\t19\n",
      "\"decided\"\t5\n",
      "\"decides\"\t1\n",
      "\"decision\"\t2\n",
      "\"decreases\"\t1\n",
      "\"deeds\"\t2\n",
      "\"deemed\"\t2\n",
      "\"deep\"\t1\n",
      "\"deeper\"\t1\n",
      "\"defeat\"\t1\n",
      "\"deficient\"\t1\n",
      "\"defined\"\t1\n",
      "\"delainey\"\t8\n",
      "\"delay\"\t1\n",
      "\"delayed\"\t2\n",
      "\"delays\"\t2\n",
      "\"delegating\"\t1\n",
      "\"delete\"\t8\n",
      "\"delight\"\t1\n",
      "\"delinquent\"\t1\n",
      "\"deliv\"\t2\n",
      "\"deliver\"\t1\n",
      "\"delivered\"\t5\n",
      "\"deliveries\"\t2\n",
      "\"delivering\"\t1\n",
      "\"delivery\"\t11\n",
      "\"delphi\"\t1\n",
      "\"delusive\"\t1\n",
      "\"delux\"\t1\n",
      "\"demand\"\t3\n",
      "\"democratic\"\t2\n",
      "\"democrats\"\t3\n",
      "\"demonstrate\"\t2\n",
      "\"denied\"\t1\n",
      "\"dennis\"\t3\n",
      "\"density\"\t1\n",
      "\"denys\"\t1\n",
      "\"department\"\t1\n",
      "\"depending\"\t2\n",
      "\"deposit\"\t4\n",
      "\"deposited\"\t3\n",
      "\"deposits\"\t2\n",
      "\"depression\"\t1\n",
      "\"dept\"\t2\n",
      "\"derivatives\"\t3\n",
      "\"descendent\"\t1\n",
      "\"described\"\t2\n",
      "\"description\"\t2\n",
      "\"desert\"\t1\n",
      "\"design\"\t9\n",
      "\"designed\"\t5\n",
      "\"designl\"\t1\n",
      "\"designs\"\t4\n",
      "\"desire\"\t3\n",
      "\"desk\"\t12\n",
      "\"desks\"\t2\n",
      "\"desktop\"\t1\n",
      "\"desmeules\"\t1\n",
      "\"desperate\"\t1\n",
      "\"despise\"\t1\n",
      "\"despite\"\t2\n",
      "\"destination\"\t2\n",
      "\"destroy\"\t1\n",
      "\"detail\"\t2\n",
      "\"detailed\"\t4\n",
      "\"details\"\t3\n",
      "\"determine\"\t1\n",
      "\"detract\"\t1\n",
      "\"developed\"\t5\n",
      "\"developing\"\t2\n",
      "\"development\"\t16\n",
      "\"device\"\t1\n",
      "\"devoid\"\t1\n",
      "\"dextails\"\t1\n",
      "\"dfelsinger\"\t1\n",
      "\"dfur\"\t1\n",
      "\"dhar\"\t4\n",
      "\"dhyngem\"\t1\n",
      "\"dial\"\t2\n",
      "\"diamond\"\t2\n",
      "\"diamonds\"\t1\n",
      "\"diane\"\t1\n",
      "\"diaz\"\t2\n",
      "\"dicine\"\t1\n",
      "\"dictate\"\t1\n",
      "\"dictating\"\t1\n",
      "\"dictionary\"\t1\n",
      "\"did\"\t8\n",
      "\"didn\"\t4\n",
      "\"didrex\"\t1\n",
      "\"different\"\t5\n",
      "\"difficult\"\t5\n",
      "\"difficulty\"\t1\n",
      "\"digging\"\t1\n",
      "\"digital\"\t1\n",
      "\"dignity\"\t1\n",
      "\"digression\"\t1\n",
      "\"diligence\"\t1\n",
      "\"diminished\"\t1\n",
      "\"dinner\"\t2\n",
      "\"direct\"\t4\n",
      "\"directed\"\t1\n",
      "\"directing\"\t1\n",
      "\"direction\"\t4\n",
      "\"directions\"\t4\n",
      "\"directly\"\t7\n",
      "\"director\"\t6\n",
      "\"directories\"\t2\n",
      "\"dirtier\"\t1\n",
      "\"disable\"\t1\n",
      "\"disagreement\"\t1\n",
      "\"disappearance\"\t1\n",
      "\"disappointed\"\t1\n",
      "\"discarded\"\t3\n",
      "\"disclaimer\"\t1\n",
      "\"disclosed\"\t2\n",
      "\"discontinue\"\t2\n",
      "\"discoount\"\t1\n",
      "\"discoouunt\"\t1\n",
      "\"discounnt\"\t1\n",
      "\"discount\"\t1\n",
      "\"discounted\"\t1\n",
      "\"discounts\"\t1\n",
      "\"discover\"\t3\n",
      "\"discretely\"\t1\n",
      "\"discretion\"\t1\n",
      "\"discuss\"\t6\n",
      "\"discussed\"\t2\n",
      "\"discussion\"\t8\n",
      "\"disease\"\t1\n",
      "\"dish\"\t3\n",
      "\"dishes\"\t1\n",
      "\"disintegration\"\t1\n",
      "\"dismissed\"\t1\n",
      "\"disordersclump\"\t1\n",
      "\"disordersshrink\"\t1\n",
      "\"disparate\"\t1\n",
      "\"displayed\"\t1\n",
      "\"disposed\"\t1\n",
      "\"disqualified\"\t1\n",
      "\"dissemination\"\t1\n",
      "\"distance\"\t5\n",
      "\"distort\"\t1\n",
      "\"distracted\"\t1\n",
      "\"distributed\"\t1\n",
      "\"distribution\"\t3\n",
      "\"distributions\"\t2\n",
      "\"district\"\t4\n",
      "\"ditch\"\t1\n",
      "\"divert\"\t1\n",
      "\"diverted\"\t1\n",
      "\"divided\"\t1\n",
      "\"division\"\t1\n",
      "\"dkohler\"\t1\n",
      "\"dmao\"\t1\n",
      "\"dnb\"\t1\n",
      "\"do\"\t41\n",
      "\"dobmeos\"\t1\n",
      "\"doc\"\t3\n",
      "\"doctor\"\t2\n",
      "\"doctoral\"\t1\n",
      "\"doctors\"\t2\n",
      "\"doctrine\"\t4\n",
      "\"documenting\"\t2\n",
      "\"documents\"\t4\n",
      "\"does\"\t11\n",
      "\"doesn\"\t10\n",
      "\"doff\"\t1\n",
      "\"dog\"\t1\n",
      "\"doing\"\t6\n",
      "\"dol\"\t1\n",
      "\"dollar\"\t1\n",
      "\"dollars\"\t7\n",
      "\"dolls\"\t1\n",
      "\"domain\"\t5\n",
      "\"domestic\"\t1\n",
      "\"don\"\t33\n",
      "\"done\"\t6\n",
      "\"dont\"\t1\n",
      "\"door\"\t5\n",
      "\"double\"\t2\n",
      "\"doubt\"\t3\n",
      "\"doubts\"\t1\n",
      "\"doug\"\t1\n",
      "\"down\"\t11\n",
      "\"download\"\t1\n",
      "\"dozens\"\t1\n",
      "\"draft\"\t2\n",
      "\"drafting\"\t1\n",
      "\"dramatic\"\t1\n",
      "\"draw\"\t5\n",
      "\"drawing\"\t5\n",
      "\"drawn\"\t2\n",
      "\"dreamwaver\"\t2\n",
      "\"drew\"\t3\n",
      "\"drinking\"\t2\n",
      "\"drive\"\t2\n",
      "\"drives\"\t1\n",
      "\"dronn\"\t1\n",
      "\"drown\"\t1\n",
      "\"drowning\"\t1\n",
      "\"drug\"\t1\n",
      "\"drugs\"\t2\n",
      "\"dryblower\"\t1\n",
      "\"dubhe\"\t1\n",
      "\"dubuque\"\t3\n",
      "\"duck\"\t1\n",
      "\"due\"\t9\n",
      "\"duke\"\t4\n",
      "\"dunns\"\t1\n",
      "\"duns\"\t2\n",
      "\"duplicate\"\t1\n",
      "\"during\"\t9\n",
      "\"dutchess\"\t1\n",
      "\"dutyfreesoft\"\t1\n",
      "\"dvd\"\t1\n",
      "\"dwr\"\t3\n",
      "\"dxqrgu\"\t1\n",
      "\"dycmpf\"\t1\n",
      "\"dynamic\"\t2\n",
      "\"dynamically\"\t1\n",
      "\"dynamics\"\t2\n",
      "\"dynegy\"\t11\n",
      "\"each\"\t27\n",
      "\"earlier\"\t4\n",
      "\"early\"\t8\n",
      "\"earn\"\t6\n",
      "\"earning\"\t1\n",
      "\"earth\"\t1\n",
      "\"earths\"\t1\n",
      "\"easily\"\t4\n",
      "\"east\"\t1\n",
      "\"eastern\"\t1\n",
      "\"easy\"\t16\n",
      "\"eat\"\t3\n",
      "\"eatables\"\t1\n",
      "\"eating\"\t2\n",
      "\"eb\"\t16\n",
      "\"ebl\"\t1\n",
      "\"ebook\"\t3\n",
      "\"ebooks\"\t1\n",
      "\"ebs\"\t1\n",
      "\"ecarmst\"\t1\n",
      "\"eclassifiedshq\"\t1\n",
      "\"ecole\"\t1\n",
      "\"ecom\"\t1\n",
      "\"ecomog\"\t3\n",
      "\"economic\"\t2\n",
      "\"economically\"\t1\n",
      "\"economics\"\t1\n",
      "\"economy\"\t1\n",
      "\"ect\"\t382\n",
      "\"ed\"\t1\n",
      "\"edge\"\t1\n",
      "\"edison\"\t4\n",
      "\"edit\"\t11\n",
      "\"edition\"\t5\n",
      "\"editor\"\t3\n",
      "\"editorial\"\t1\n",
      "\"edt\"\t2\n",
      "\"ee\"\t2\n",
      "\"ees\"\t10\n",
      "\"effect\"\t2\n",
      "\"effective\"\t11\n",
      "\"effectively\"\t5\n",
      "\"effects\"\t1\n",
      "\"efficiency\"\t2\n",
      "\"effort\"\t6\n",
      "\"efforts\"\t2\n",
      "\"efs\"\t1\n",
      "\"egep\"\t1\n",
      "\"ego\"\t2\n",
      "\"eh\"\t1\n",
      "\"ehronline\"\t1\n",
      "\"eiben\"\t1\n",
      "\"eight\"\t2\n",
      "\"eighty\"\t1\n",
      "\"eileen\"\t1\n",
      "\"eincomplete\"\t1\n",
      "\"either\"\t9\n",
      "\"el\"\t2\n",
      "\"elbow\"\t1\n",
      "\"elderly\"\t1\n",
      "\"election\"\t1\n",
      "\"elections\"\t1\n",
      "\"electric\"\t1\n",
      "\"electricity\"\t1\n",
      "\"eliminate\"\t3\n",
      "\"eliminates\"\t1\n",
      "\"eliminationstop\"\t1\n",
      "\"ellendale\"\t2\n",
      "\"ello\"\t1\n",
      "\"elmira\"\t1\n",
      "\"else\"\t2\n",
      "\"elses\"\t2\n",
      "\"emai\"\t1\n",
      "\"email\"\t46\n",
      "\"emailing\"\t2\n",
      "\"embargo\"\t1\n",
      "\"emeet\"\t1\n",
      "\"emerged\"\t1\n",
      "\"emerging\"\t2\n",
      "\"emigrant\"\t1\n",
      "\"emigrants\"\t1\n",
      "\"eminent\"\t2\n",
      "\"emma\"\t1\n",
      "\"emotion\"\t1\n",
      "\"emotional\"\t1\n",
      "\"emove\"\t1\n",
      "\"emphasis\"\t1\n",
      "\"emphasize\"\t1\n",
      "\"emphatically\"\t1\n",
      "\"employed\"\t2\n",
      "\"employee\"\t6\n",
      "\"employees\"\t7\n",
      "\"employer\"\t1\n",
      "\"employment\"\t1\n",
      "\"empowered\"\t1\n",
      "\"en\"\t3\n",
      "\"ena\"\t10\n",
      "\"enable\"\t4\n",
      "\"enacted\"\t2\n",
      "\"encarta\"\t1\n",
      "\"encoding\"\t2\n",
      "\"encompassing\"\t1\n",
      "\"encounters\"\t1\n",
      "\"encourage\"\t4\n",
      "\"encouraged\"\t3\n",
      "\"encyclopedia\"\t1\n",
      "\"end\"\t19\n",
      "\"ending\"\t2\n",
      "\"endless\"\t1\n",
      "\"endorsements\"\t1\n",
      "\"ends\"\t1\n",
      "\"energetic\"\t1\n",
      "\"energy\"\t44\n",
      "\"eneric\"\t1\n",
      "\"eng\"\t1\n",
      "\"engageenergy\"\t1\n",
      "\"engine\"\t3\n",
      "\"engineergeodetic\"\t1\n",
      "\"engineering\"\t2\n",
      "\"engines\"\t2\n",
      "\"enhance\"\t3\n",
      "\"enhancing\"\t1\n",
      "\"enjoy\"\t2\n",
      "\"enormous\"\t1\n",
      "\"enough\"\t6\n",
      "\"enron\"\t127\n",
      "\"enrononline\"\t4\n",
      "\"ensure\"\t3\n",
      "\"ensuring\"\t2\n",
      "\"enter\"\t7\n",
      "\"entered\"\t10\n",
      "\"entergy\"\t6\n",
      "\"entergyr\"\t1\n",
      "\"entering\"\t2\n",
      "\"enterprise\"\t4\n",
      "\"enters\"\t1\n",
      "\"entertaining\"\t1\n",
      "\"entex\"\t14\n",
      "\"entire\"\t2\n",
      "\"entirely\"\t2\n",
      "\"entity\"\t3\n",
      "\"entries\"\t3\n",
      "\"entry\"\t1\n",
      "\"environment\"\t3\n",
      "\"environmental\"\t1\n",
      "\"envy\"\t1\n",
      "\"eo\"\t1\n",
      "\"eops\"\t1\n",
      "\"epam\"\t2\n",
      "\"epcm\"\t2\n",
      "\"epenergy\"\t5\n",
      "\"epmi\"\t2\n",
      "\"eprm\"\t1\n",
      "\"epsc\"\t1\n",
      "\"equity\"\t5\n",
      "\"equivelant\"\t1\n",
      "\"er\"\t2\n",
      "\"ere\"\t1\n",
      "\"ernest\"\t1\n",
      "\"erroneously\"\t1\n",
      "\"error\"\t8\n",
      "\"errors\"\t6\n",
      "\"esa\"\t1\n",
      "\"escape\"\t2\n",
      "\"esiear\"\t2\n",
      "\"espcially\"\t1\n",
      "\"especially\"\t4\n",
      "\"essentially\"\t1\n",
      "\"est\"\t1\n",
      "\"establish\"\t8\n",
      "\"established\"\t3\n",
      "\"establishes\"\t1\n",
      "\"establishthe\"\t1\n",
      "\"estimate\"\t2\n",
      "\"etacitne\"\t1\n",
      "\"etc\"\t9\n",
      "\"eternal\"\t1\n",
      "\"ethic\"\t1\n",
      "\"etringer\"\t2\n",
      "\"europe\"\t1\n",
      "\"european\"\t2\n",
      "\"evaluate\"\t2\n",
      "\"evaluating\"\t1\n",
      "\"evaluation\"\t1\n",
      "\"evelon\"\t1\n",
      "\"even\"\t16\n",
      "\"evening\"\t3\n",
      "\"events\"\t2\n",
      "\"eventually\"\t2\n",
      "\"ever\"\t5\n",
      "\"every\"\t14\n",
      "\"everyday\"\t2\n",
      "\"everyone\"\t17\n",
      "\"everything\"\t8\n",
      "\"evolution\"\t1\n",
      "\"eworld\"\t4\n",
      "\"exact\"\t2\n",
      "\"exactly\"\t4\n",
      "\"exaggerate\"\t1\n",
      "\"examination\"\t1\n",
      "\"examine\"\t3\n",
      "\"examing\"\t1\n",
      "\"examining\"\t1\n",
      "\"example\"\t7\n",
      "\"examples\"\t1\n",
      "\"exceed\"\t1\n",
      "\"exceeded\"\t2\n",
      "\"excellent\"\t4\n",
      "\"except\"\t1\n",
      "\"exception\"\t1\n",
      "\"excerpts\"\t1\n",
      "\"excess\"\t1\n",
      "\"exchange\"\t13\n",
      "\"exchanges\"\t1\n",
      "\"exchanging\"\t1\n",
      "\"excited\"\t3\n",
      "\"exciting\"\t1\n",
      "\"excluding\"\t2\n",
      "\"exclusive\"\t1\n",
      "\"execute\"\t1\n",
      "\"executed\"\t1\n",
      "\"executing\"\t2\n",
      "\"execution\"\t1\n",
      "\"executive\"\t6\n",
      "\"executives\"\t1\n",
      "\"exemptions\"\t2\n",
      "\"exhausted\"\t1\n",
      "\"exhibit\"\t5\n",
      "\"exhibits\"\t2\n",
      "\"exist\"\t2\n",
      "\"existing\"\t5\n",
      "\"expanded\"\t1\n",
      "\"expanding\"\t1\n",
      "\"expanse\"\t1\n",
      "\"expect\"\t9\n",
      "\"expectation\"\t2\n",
      "\"expectations\"\t4\n",
      "\"expected\"\t6\n",
      "\"expecting\"\t2\n",
      "\"expects\"\t3\n",
      "\"expended\"\t1\n",
      "\"expenditures\"\t1\n",
      "\"expenses\"\t3\n",
      "\"experience\"\t17\n",
      "\"experiences\"\t1\n",
      "\"experiment\"\t1\n",
      "\"expertise\"\t8\n",
      "\"expire\"\t1\n",
      "\"expired\"\t1\n",
      "\"explain\"\t2\n",
      "\"explained\"\t1\n",
      "\"explaing\"\t2\n",
      "\"explaining\"\t2\n",
      "\"explicitly\"\t1\n",
      "\"exploration\"\t2\n",
      "\"explorer\"\t3\n",
      "\"exploring\"\t2\n",
      "\"expose\"\t1\n",
      "\"exposure\"\t2\n",
      "\"express\"\t4\n",
      "\"expressed\"\t1\n",
      "\"expressway\"\t1\n",
      "\"ext\"\t3\n",
      "\"extend\"\t1\n",
      "\"extended\"\t3\n",
      "\"extension\"\t1\n",
      "\"extent\"\t1\n",
      "\"externally\"\t2\n",
      "\"extra\"\t7\n",
      "\"extremal\"\t1\n",
      "\"extreme\"\t1\n",
      "\"exultant\"\t1\n",
      "\"eye\"\t1\n",
      "\"eyebrow\"\t2\n",
      "\"eyes\"\t2\n",
      "\"ezine\"\t5\n",
      "\"fabaclbo\"\t1\n",
      "\"face\"\t1\n",
      "\"facelift\"\t1\n",
      "\"faces\"\t1\n",
      "\"facilitate\"\t4\n",
      "\"facilitators\"\t1\n",
      "\"facility\"\t1\n",
      "\"faclities\"\t1\n",
      "\"fact\"\t8\n",
      "\"factor\"\t1\n",
      "\"factual\"\t1\n",
      "\"faded\"\t1\n",
      "\"fails\"\t1\n",
      "\"fainted\"\t1\n",
      "\"fair\"\t2\n",
      "\"faith\"\t1\n",
      "\"fall\"\t2\n",
      "\"fallon\"\t1\n",
      "\"fame\"\t3\n",
      "\"families\"\t2\n",
      "\"family\"\t3\n",
      "\"famous\"\t1\n",
      "\"fanny\"\t1\n",
      "\"fantastic\"\t1\n",
      "\"far\"\t5\n",
      "\"farm\"\t1\n",
      "\"farmer\"\t5\n",
      "\"fashion\"\t1\n",
      "\"fast\"\t4\n",
      "\"faster\"\t2\n",
      "\"fat\"\t1\n",
      "\"father\"\t4\n",
      "\"fathers\"\t1\n",
      "\"fattroglodyte\"\t1\n",
      "\"fault\"\t1\n",
      "\"favor\"\t4\n",
      "\"favorably\"\t1\n",
      "\"favorite\"\t7\n",
      "\"favourably\"\t1\n",
      "\"fax\"\t9\n",
      "\"fe\"\t1\n",
      "\"fear\"\t4\n",
      "\"feature\"\t1\n",
      "\"featured\"\t2\n",
      "\"features\"\t6\n",
      "\"feb\"\t3\n",
      "\"february\"\t10\n",
      "\"federal\"\t4\n",
      "\"fee\"\t6\n",
      "\"feel\"\t19\n",
      "\"feeling\"\t3\n",
      "\"feelings\"\t1\n",
      "\"fees\"\t1\n",
      "\"feet\"\t1\n",
      "\"felipe\"\t2\n",
      "\"fell\"\t2\n",
      "\"fellow\"\t1\n",
      "\"felt\"\t2\n",
      "\"female\"\t3\n",
      "\"few\"\t12\n",
      "\"ffffa\"\t2\n",
      "\"fh\"\t2\n",
      "\"fiducial\"\t1\n",
      "\"field\"\t3\n",
      "\"fields\"\t1\n",
      "\"fifteen\"\t1\n",
      "\"fifth\"\t1\n",
      "\"fight\"\t2\n",
      "\"figure\"\t1\n",
      "\"figured\"\t1\n",
      "\"file\"\t6\n",
      "\"filed\"\t6\n",
      "\"files\"\t3\n",
      "\"filing\"\t11\n",
      "\"fill\"\t6\n",
      "\"filled\"\t2\n",
      "\"filling\"\t1\n",
      "\"filter\"\t1\n",
      "\"final\"\t6\n",
      "\"finalization\"\t2\n",
      "\"finalize\"\t1\n",
      "\"finally\"\t3\n",
      "\"finance\"\t4\n",
      "\"financial\"\t12\n",
      "\"financials\"\t1\n",
      "\"financing\"\t4\n",
      "\"find\"\t5\n",
      "\"finding\"\t1\n",
      "\"fine\"\t2\n",
      "\"finger\"\t1\n",
      "\"finished\"\t6\n",
      "\"finishing\"\t1\n",
      "\"finland\"\t1\n",
      "\"fior\"\t2\n",
      "\"fioricet\"\t1\n",
      "\"fired\"\t1\n",
      "\"fireworks\"\t1\n",
      "\"firing\"\t1\n",
      "\"firm\"\t5\n",
      "\"first\"\t34\n",
      "\"fischer\"\t1\n",
      "\"fishbeck\"\t1\n",
      "\"fit\"\t2\n",
      "\"five\"\t4\n",
      "\"fixed\"\t1\n",
      "\"fl\"\t1\n",
      "\"flash\"\t2\n",
      "\"flat\"\t5\n",
      "\"flatter\"\t1\n",
      "\"flight\"\t1\n",
      "\"flip\"\t1\n",
      "\"fln\"\t1\n",
      "\"floe\"\t1\n",
      "\"flood\"\t2\n",
      "\"floods\"\t1\n",
      "\"floor\"\t4\n",
      "\"flow\"\t8\n",
      "\"fluid\"\t1\n",
      "\"flustrated\"\t1\n",
      "\"flutter\"\t1\n",
      "\"flyers\"\t1\n",
      "\"flynn\"\t1\n",
      "\"focus\"\t4\n",
      "\"focusing\"\t4\n",
      "\"foday\"\t1\n",
      "\"folks\"\t3\n",
      "\"follow\"\t10\n",
      "\"followed\"\t2\n",
      "\"following\"\t27\n",
      "\"font\"\t3\n",
      "\"fonts\"\t2\n",
      "\"foo\"\t1\n",
      "\"foolishness\"\t1\n",
      "\"foot\"\t3\n",
      "\"footmen\"\t1\n",
      "\"fooxr\"\t1\n",
      "\"for\"\t374\n",
      "\"forbearance\"\t4\n",
      "\"force\"\t5\n",
      "\"forced\"\t1\n",
      "\"forces\"\t5\n",
      "\"forcing\"\t1\n",
      "\"ford\"\t1\n",
      "\"forecast\"\t1\n",
      "\"forecasts\"\t2\n",
      "\"foreigner\"\t1\n",
      "\"foreigners\"\t1\n",
      "\"forest\"\t1\n",
      "\"forestall\"\t1\n",
      "\"foretell\"\t1\n",
      "\"forever\"\t3\n",
      "\"forget\"\t1\n",
      "\"forgotten\"\t1\n",
      "\"forhome\"\t1\n",
      "\"fork\"\t2\n",
      "\"form\"\t11\n",
      "\"formal\"\t1\n",
      "\"formally\"\t2\n",
      "\"format\"\t3\n",
      "\"forms\"\t1\n",
      "\"formula\"\t2\n",
      "\"formulated\"\t1\n",
      "\"forp\"\t1\n",
      "\"fort\"\t1\n",
      "\"forthis\"\t1\n",
      "\"fortunately\"\t2\n",
      "\"forty\"\t1\n",
      "\"forum\"\t1\n",
      "\"forward\"\t13\n",
      "\"forwarded\"\t29\n",
      "\"forwarding\"\t1\n",
      "\"found\"\t6\n",
      "\"founder\"\t1\n",
      "\"founding\"\t1\n",
      "\"four\"\t8\n",
      "\"fp\"\t1\n",
      "\"fraction\"\t4\n",
      "\"frame\"\t1\n",
      "\"frames\"\t1\n",
      "\"fran\"\t2\n",
      "\"francisco\"\t1\n",
      "\"frank\"\t1\n",
      "\"fraternal\"\t1\n",
      "\"fraud\"\t1\n",
      "\"fred\"\t1\n",
      "\"free\"\t86\n",
      "\"freebie\"\t2\n",
      "\"freehand\"\t1\n",
      "\"freelinksnetwork\"\t4\n",
      "\"freeonline\"\t1\n",
      "\"freepicklotto\"\t2\n",
      "\"freese\"\t1\n",
      "\"freeze\"\t3\n",
      "\"frequently\"\t1\n",
      "\"frevert\"\t3\n",
      "\"friday\"\t6\n",
      "\"friend\"\t2\n",
      "\"friends\"\t3\n",
      "\"frightened\"\t1\n",
      "\"frightrob\"\t1\n",
      "\"from\"\t135\n",
      "\"front\"\t3\n",
      "\"fronts\"\t1\n",
      "\"frqee\"\t1\n",
      "\"fruit\"\t1\n",
      "\"frusco\"\t3\n",
      "\"frustration\"\t1\n",
      "\"ft\"\t2\n",
      "\"ftp\"\t1\n",
      "\"fuel\"\t1\n",
      "\"fulfill\"\t2\n",
      "\"full\"\t28\n",
      "\"fully\"\t3\n",
      "\"fun\"\t5\n",
      "\"function\"\t5\n",
      "\"functionality\"\t4\n",
      "\"functions\"\t5\n",
      "\"fund\"\t4\n",
      "\"fundamental\"\t2\n",
      "\"funded\"\t1\n",
      "\"funding\"\t1\n",
      "\"funds\"\t10\n",
      "\"fuohqjlsjcqp\"\t1\n",
      "\"further\"\t9\n",
      "\"furthermore\"\t1\n",
      "\"future\"\t14\n",
      "\"fw\"\t3\n",
      "\"fyi\"\t6\n",
      "\"fyl\"\t2\n",
      "\"gaining\"\t1\n",
      "\"game\"\t4\n",
      "\"gary\"\t7\n",
      "\"gas\"\t37\n",
      "\"gb\"\t1\n",
      "\"gee\"\t1\n",
      "\"gemstone\"\t1\n",
      "\"general\"\t5\n",
      "\"generalist\"\t1\n",
      "\"generalities\"\t1\n",
      "\"generalize\"\t1\n",
      "\"generalizing\"\t1\n",
      "\"generate\"\t1\n",
      "\"generating\"\t2\n",
      "\"generation\"\t5\n",
      "\"generators\"\t2\n",
      "\"generic\"\t6\n",
      "\"genuine\"\t2\n",
      "\"geoffrey\"\t1\n",
      "\"geographic\"\t4\n",
      "\"geomatics\"\t1\n",
      "\"george\"\t9\n",
      "\"georgel\"\t2\n",
      "\"georgia\"\t1\n",
      "\"germany\"\t3\n",
      "\"gerry\"\t2\n",
      "\"ges\"\t2\n",
      "\"get\"\t76\n",
      "\"gets\"\t3\n",
      "\"getterscan\"\t1\n",
      "\"getthe\"\t1\n",
      "\"getting\"\t8\n",
      "\"getyour\"\t1\n",
      "\"ghana\"\t2\n",
      "\"ghz\"\t1\n",
      "\"gibner\"\t8\n",
      "\"gibson\"\t1\n",
      "\"gift\"\t13\n",
      "\"gifts\"\t2\n",
      "\"gigabyte\"\t1\n",
      "\"gilbert\"\t1\n",
      "\"gilchrist\"\t1\n",
      "\"gimg\"\t1\n",
      "\"ginsu\"\t1\n",
      "\"girl\"\t4\n",
      "\"gis\"\t2\n",
      "\"gist\"\t2\n",
      "\"giv\"\t1\n",
      "\"give\"\t17\n",
      "\"glad\"\t1\n",
      "\"glandular\"\t1\n",
      "\"glaspie\"\t1\n",
      "\"glen\"\t1\n",
      "\"glencore\"\t2\n",
      "\"glenda\"\t1\n",
      "\"global\"\t44\n",
      "\"globe\"\t3\n",
      "\"glover\"\t1\n",
      "\"glut\"\t1\n",
      "\"gmx\"\t2\n",
      "\"go\"\t11\n",
      "\"goage\"\t1\n",
      "\"goal\"\t5\n",
      "\"goals\"\t1\n",
      "\"goatee\"\t1\n",
      "\"god\"\t3\n",
      "\"godly\"\t1\n",
      "\"goes\"\t1\n",
      "\"going\"\t27\n",
      "\"gold\"\t14\n",
      "\"golnaraghi\"\t1\n",
      "\"gone\"\t2\n",
      "\"gonzalez\"\t1\n",
      "\"good\"\t23\n",
      "\"goodbye\"\t1\n",
      "\"goodmorning\"\t2\n",
      "\"goods\"\t1\n",
      "\"gosnell\"\t1\n",
      "\"got\"\t7\n",
      "\"gov\"\t1\n",
      "\"government\"\t7\n",
      "\"governor\"\t5\n",
      "\"gpg\"\t1\n",
      "\"gpt\"\t1\n",
      "\"gra\"\t3\n",
      "\"grabbing\"\t1\n",
      "\"grabs\"\t1\n",
      "\"gracie\"\t2\n",
      "\"grade\"\t2\n",
      "\"grading\"\t1\n",
      "\"gradually\"\t1\n",
      "\"grammar\"\t1\n",
      "\"grand\"\t3\n",
      "\"grandfathered\"\t1\n",
      "\"grandma\"\t1\n",
      "\"grant\"\t6\n",
      "\"granted\"\t1\n",
      "\"granting\"\t1\n",
      "\"graphics\"\t5\n",
      "\"gratis\"\t1\n",
      "\"gravel\"\t1\n",
      "\"graves\"\t2\n",
      "\"gray\"\t2\n",
      "\"great\"\t20\n",
      "\"greater\"\t1\n",
      "\"greatest\"\t2\n",
      "\"greatly\"\t1\n",
      "\"greedily\"\t1\n",
      "\"greeted\"\t1\n",
      "\"greetings\"\t1\n",
      "\"greg\"\t3\n",
      "\"gregory\"\t1\n",
      "\"griddle\"\t1\n",
      "\"grief\"\t1\n",
      "\"grizzly\"\t1\n",
      "\"gross\"\t3\n",
      "\"ground\"\t1\n",
      "\"group\"\t22\n",
      "\"groups\"\t4\n",
      "\"growing\"\t1\n",
      "\"grown\"\t2\n",
      "\"growth\"\t4\n",
      "\"gs\"\t1\n",
      "\"gssgeomatics\"\t1\n",
      "\"guarantee\"\t5\n",
      "\"guaranteed\"\t4\n",
      "\"guerrilla\"\t1\n",
      "\"guess\"\t1\n",
      "\"guides\"\t1\n",
      "\"guinea\"\t1\n",
      "\"gullweig\"\t1\n",
      "\"gunners\"\t1\n",
      "\"guns\"\t1\n",
      "\"guru\"\t2\n",
      "\"gutierrez\"\t1\n",
      "\"guy\"\t2\n",
      "\"guys\"\t3\n",
      "\"gwen\"\t1\n",
      "\"gxol\"\t1\n",
      "\"gxxu\"\t1\n",
      "\"habitually\"\t1\n",
      "\"had\"\t20\n",
      "\"hair\"\t1\n",
      "\"hal\"\t1\n",
      "\"half\"\t2\n",
      "\"hall\"\t2\n",
      "\"hand\"\t5\n",
      "\"handle\"\t1\n",
      "\"handled\"\t2\n",
      "\"hands\"\t2\n",
      "\"hang\"\t1\n",
      "\"hangover\"\t1\n",
      "\"hans\"\t1\n",
      "\"happen\"\t4\n",
      "\"happens\"\t1\n",
      "\"happy\"\t4\n",
      "\"harbour\"\t1\n",
      "\"hard\"\t10\n",
      "\"hardly\"\t2\n",
      "\"hardware\"\t1\n",
      "\"harriman\"\t1\n",
      "\"harris\"\t2\n",
      "\"harrison\"\t2\n",
      "\"harry\"\t1\n",
      "\"harvey\"\t4\n",
      "\"has\"\t67\n",
      "\"hash\"\t1\n",
      "\"hassle\"\t2\n",
      "\"hate\"\t4\n",
      "\"haunch\"\t1\n",
      "\"have\"\t170\n",
      "\"having\"\t6\n",
      "\"hc\"\t2\n",
      "\"hcokyovrdsprayz\"\t1\n",
      "\"he\"\t47\n",
      "\"head\"\t3\n",
      "\"headache\"\t1\n",
      "\"headachesmerle\"\t1\n",
      "\"heading\"\t1\n",
      "\"headline\"\t2\n",
      "\"headlines\"\t4\n",
      "\"heal\"\t1\n",
      "\"healing\"\t1\n",
      "\"health\"\t2\n",
      "\"hear\"\t3\n",
      "\"heard\"\t2\n",
      "\"hearers\"\t1\n",
      "\"heart\"\t1\n",
      "\"heartburnwestfield\"\t1\n",
      "\"heathman\"\t1\n",
      "\"heating\"\t2\n",
      "\"held\"\t6\n",
      "\"hello\"\t6\n",
      "\"help\"\t16\n",
      "\"helpdesk\"\t2\n",
      "\"helped\"\t1\n",
      "\"helpful\"\t2\n",
      "\"helping\"\t3\n",
      "\"helpless\"\t2\n",
      "\"helps\"\t2\n",
      "\"hemingway\"\t1\n",
      "\"hemisphere\"\t2\n",
      "\"hence\"\t1\n",
      "\"hendricks\"\t2\n",
      "\"heno\"\t1\n",
      "\"her\"\t12\n",
      "\"herbalonline\"\t1\n",
      "\"herbs\"\t1\n",
      "\"here\"\t61\n",
      "\"herem\"\t1\n",
      "\"herewe\"\t1\n",
      "\"herod\"\t1\n",
      "\"hesitate\"\t4\n",
      "\"hey\"\t2\n",
      "\"hgh\"\t5\n",
      "\"hi\"\t2\n",
      "\"hidd\"\t2\n",
      "\"high\"\t15\n",
      "\"higher\"\t4\n",
      "\"highlands\"\t2\n",
      "\"highlight\"\t3\n",
      "\"highly\"\t1\n",
      "\"highs\"\t1\n",
      "\"hijacked\"\t2\n",
      "\"hike\"\t1\n",
      "\"hikes\"\t4\n",
      "\"hillis\"\t1\n",
      "\"hillmancarthage\"\t1\n",
      "\"him\"\t9\n",
      "\"himhe\"\t1\n",
      "\"himself\"\t1\n",
      "\"hindering\"\t1\n",
      "\"hinsch\"\t2\n",
      "\"hint\"\t1\n",
      "\"hire\"\t2\n",
      "\"his\"\t39\n",
      "\"historical\"\t3\n",
      "\"history\"\t2\n",
      "\"hit\"\t2\n",
      "\"hje\"\t1\n",
      "\"hm\"\t1\n",
      "\"hme\"\t1\n",
      "\"ho\"\t3\n",
      "\"hoferc\"\t1\n",
      "\"hoffman\"\t2\n",
      "\"hold\"\t3\n",
      "\"holders\"\t1\n",
      "\"holding\"\t1\n",
      "\"holiday\"\t3\n",
      "\"holidays\"\t2\n",
      "\"home\"\t20\n",
      "\"homemakers\"\t1\n",
      "\"homes\"\t2\n",
      "\"homestead\"\t1\n",
      "\"hone\"\t1\n",
      "\"honest\"\t1\n",
      "\"honesty\"\t1\n",
      "\"hood\"\t1\n",
      "\"hook\"\t2\n",
      "\"hope\"\t9\n",
      "\"hopefully\"\t2\n",
      "\"hopes\"\t1\n",
      "\"hopkins\"\t1\n",
      "\"horizons\"\t1\n",
      "\"hormone\"\t2\n",
      "\"horn\"\t1\n",
      "\"hornbuckle\"\t1\n",
      "\"horror\"\t1\n",
      "\"horse\"\t2\n",
      "\"host\"\t1\n",
      "\"hosted\"\t1\n",
      "\"hot\"\t2\n",
      "\"hotmail\"\t2\n",
      "\"hottest\"\t1\n",
      "\"hou\"\t206\n",
      "\"hour\"\t1\n",
      "\"hourhelp\"\t1\n",
      "\"hours\"\t26\n",
      "\"house\"\t1\n",
      "\"houston\"\t13\n",
      "\"how\"\t36\n",
      "\"howard\"\t14\n",
      "\"however\"\t14\n",
      "\"howl\"\t1\n",
      "\"hp\"\t1\n",
      "\"hpl\"\t12\n",
      "\"hplc\"\t1\n",
      "\"hplr\"\t1\n",
      "\"hr\"\t14\n",
      "\"hrgovcic\"\t5\n",
      "\"hrice\"\t2\n",
      "\"hris\"\t1\n",
      "\"ht\"\t4\n",
      "\"htm\"\t2\n",
      "\"html\"\t9\n",
      "\"http\"\t65\n",
      "\"huang\"\t4\n",
      "\"hubs\"\t3\n",
      "\"huge\"\t2\n",
      "\"hulmeville\"\t1\n",
      "\"human\"\t14\n",
      "\"humble\"\t1\n",
      "\"humility\"\t2\n",
      "\"hundred\"\t2\n",
      "\"hundreds\"\t2\n",
      "\"hunger\"\t1\n",
      "\"hungry\"\t1\n",
      "\"hunt\"\t1\n",
      "\"hunter\"\t2\n",
      "\"hurdles\"\t1\n",
      "\"hurrah\"\t1\n",
      "\"hurry\"\t4\n",
      "\"hurtling\"\t1\n",
      "\"husband\"\t4\n",
      "\"huse\"\t1\n",
      "\"hyde\"\t1\n",
      "\"hydro\"\t2\n",
      "\"hydroxylate\"\t1\n",
      "\"hype\"\t1\n",
      "\"hzriubp\"\t1\n",
      "\"iain\"\t1\n",
      "\"ica\"\t1\n",
      "\"iccenergy\"\t1\n",
      "\"icet\"\t2\n",
      "\"icon\"\t1\n",
      "\"icop\"\t1\n",
      "\"id\"\t14\n",
      "\"idea\"\t5\n",
      "\"ideas\"\t6\n",
      "\"identified\"\t1\n",
      "\"identifies\"\t1\n",
      "\"identify\"\t2\n",
      "\"idiot\"\t1\n",
      "\"idirect\"\t1\n",
      "\"ids\"\t1\n",
      "\"ie\"\t4\n",
      "\"ien\"\t2\n",
      "\"if\"\t107\n",
      "\"igh\"\t1\n",
      "\"ihf\"\t1\n",
      "\"ii\"\t3\n",
      "\"illness\"\t1\n",
      "\"illustrate\"\t2\n",
      "\"illustration\"\t1\n",
      "\"illustrator\"\t2\n",
      "\"ilug\"\t3\n",
      "\"ilydiatt\"\t1\n",
      "\"im\"\t1\n",
      "\"image\"\t9\n",
      "\"imagine\"\t1\n",
      "\"imaging\"\t1\n",
      "\"imitate\"\t2\n",
      "\"immediate\"\t2\n",
      "\"immediately\"\t22\n",
      "\"imminent\"\t1\n",
      "\"immunity\"\t1\n",
      "\"impact\"\t3\n",
      "\"impacted\"\t1\n",
      "\"impacts\"\t1\n",
      "\"impaired\"\t1\n",
      "\"impede\"\t1\n",
      "\"imperial\"\t2\n",
      "\"implement\"\t1\n",
      "\"implementation\"\t9\n",
      "\"implementing\"\t1\n",
      "\"important\"\t12\n",
      "\"importantly\"\t1\n",
      "\"impossible\"\t1\n",
      "\"impresses\"\t1\n",
      "\"impression\"\t3\n",
      "\"impressive\"\t1\n",
      "\"improve\"\t1\n",
      "\"improved\"\t5\n",
      "\"improving\"\t1\n",
      "\"impulse\"\t1\n",
      "\"in\"\t418\n",
      "\"iname\"\t1\n",
      "\"inappropriate\"\t1\n",
      "\"inbox\"\t1\n",
      "\"inc\"\t12\n",
      "\"incessantly\"\t1\n",
      "\"include\"\t12\n",
      "\"included\"\t8\n",
      "\"includes\"\t1\n",
      "\"including\"\t16\n",
      "\"inclusive\"\t1\n",
      "\"income\"\t4\n",
      "\"incomeunlimited\"\t1\n",
      "\"incorporated\"\t1\n",
      "\"incorrectly\"\t1\n",
      "\"increase\"\t12\n",
      "\"increased\"\t5\n",
      "\"increases\"\t2\n",
      "\"increasing\"\t4\n",
      "\"increasingly\"\t1\n",
      "\"incredibily\"\t1\n",
      "\"incredible\"\t1\n",
      "\"incredibly\"\t1\n",
      "\"incurred\"\t3\n",
      "\"india\"\t1\n",
      "\"indicated\"\t1\n",
      "\"indication\"\t1\n",
      "\"indicator\"\t1\n",
      "\"indices\"\t1\n",
      "\"individual\"\t8\n",
      "\"individualized\"\t3\n",
      "\"individuals\"\t4\n",
      "\"indubitable\"\t1\n",
      "\"industries\"\t1\n",
      "\"industry\"\t9\n",
      "\"inferior\"\t1\n",
      "\"influence\"\t2\n",
      "\"info\"\t9\n",
      "\"inform\"\t3\n",
      "\"information\"\t71\n",
      "\"informative\"\t1\n",
      "\"informed\"\t4\n",
      "\"infrastructure\"\t1\n",
      "\"inherently\"\t1\n",
      "\"initial\"\t7\n",
      "\"initializes\"\t1\n",
      "\"initially\"\t4\n",
      "\"initiative\"\t3\n",
      "\"inject\"\t1\n",
      "\"injunction\"\t1\n",
      "\"inlcuding\"\t1\n",
      "\"inlet\"\t4\n",
      "\"innovation\"\t4\n",
      "\"innovative\"\t2\n",
      "\"innovatus\"\t1\n",
      "\"input\"\t6\n",
      "\"inputs\"\t1\n",
      "\"insane\"\t2\n",
      "\"inseminate\"\t1\n",
      "\"inside\"\t2\n",
      "\"insider\"\t2\n",
      "\"insomnia\"\t1\n",
      "\"inspection\"\t1\n",
      "\"instantaneous\"\t1\n",
      "\"instantly\"\t2\n",
      "\"instead\"\t3\n",
      "\"institutions\"\t1\n",
      "\"instruct\"\t1\n",
      "\"instructed\"\t3\n",
      "\"instructions\"\t4\n",
      "\"instructs\"\t1\n",
      "\"instrument\"\t1\n",
      "\"instruments\"\t1\n",
      "\"insufficient\"\t1\n",
      "\"insults\"\t1\n",
      "\"insurance\"\t6\n",
      "\"insure\"\t7\n",
      "\"integrated\"\t2\n",
      "\"integrity\"\t2\n",
      "\"intelligence\"\t1\n",
      "\"intelt\"\t1\n",
      "\"intend\"\t3\n",
      "\"intended\"\t1\n",
      "\"intends\"\t2\n",
      "\"intense\"\t1\n",
      "\"intercreditor\"\t1\n",
      "\"interest\"\t12\n",
      "\"interested\"\t10\n",
      "\"interesting\"\t3\n",
      "\"interests\"\t7\n",
      "\"interfering\"\t1\n",
      "\"intermediary\"\t2\n",
      "\"internal\"\t9\n",
      "\"internally\"\t2\n",
      "\"international\"\t7\n",
      "\"interne\"\t1\n",
      "\"internet\"\t30\n",
      "\"interrupted\"\t1\n",
      "\"interstate\"\t1\n",
      "\"intervened\"\t2\n",
      "\"intl\"\t2\n",
      "\"into\"\t36\n",
      "\"intra\"\t1\n",
      "\"intranet\"\t3\n",
      "\"introduce\"\t1\n",
      "\"introduced\"\t3\n",
      "\"introducing\"\t1\n",
      "\"invest\"\t4\n",
      "\"invested\"\t1\n",
      "\"investigations\"\t1\n",
      "\"investment\"\t18\n",
      "\"investor\"\t1\n",
      "\"investors\"\t1\n",
      "\"invitation\"\t1\n",
      "\"invite\"\t6\n",
      "\"invoices\"\t1\n",
      "\"involuntary\"\t8\n",
      "\"involved\"\t7\n",
      "\"involvement\"\t1\n",
      "\"involves\"\t1\n",
      "\"involving\"\t2\n",
      "\"invovled\"\t2\n",
      "\"ion\"\t1\n",
      "\"iowa\"\t1\n",
      "\"ipos\"\t1\n",
      "\"ipp\"\t2\n",
      "\"ipps\"\t6\n",
      "\"irish\"\t1\n",
      "\"iron\"\t2\n",
      "\"is\"\t249\n",
      "\"isalso\"\t1\n",
      "\"island\"\t2\n",
      "\"isn\"\t3\n",
      "\"iso\"\t10\n",
      "\"isp\"\t8\n",
      "\"isps\"\t3\n",
      "\"issler\"\t5\n",
      "\"issue\"\t21\n",
      "\"issued\"\t4\n",
      "\"issues\"\t19\n",
      "\"it\"\t192\n",
      "\"iteam\"\t1\n",
      "\"item\"\t3\n",
      "\"items\"\t15\n",
      "\"its\"\t27\n",
      "\"itself\"\t3\n",
      "\"ium\"\t2\n",
      "\"ivan\"\t2\n",
      "\"ivernia\"\t2\n",
      "\"ivoire\"\t3\n",
      "\"ja\"\t1\n",
      "\"jackie\"\t1\n",
      "\"jan\"\t4\n",
      "\"jana\"\t3\n",
      "\"jane\"\t1\n",
      "\"janet\"\t1\n",
      "\"janice\"\t1\n",
      "\"janie\"\t1\n",
      "\"january\"\t2\n",
      "\"japan\"\t3\n",
      "\"jason\"\t5\n",
      "\"jauregui\"\t1\n",
      "\"jeff\"\t7\n",
      "\"jersey\"\t1\n",
      "\"jim\"\t3\n",
      "\"jimmy\"\t2\n",
      "\"jirapliegao\"\t1\n",
      "\"jlopes\"\t1\n",
      "\"jm\"\t6\n",
      "\"jnexon\"\t1\n",
      "\"jo\"\t1\n",
      "\"joao\"\t2\n",
      "\"job\"\t3\n",
      "\"joe\"\t1\n",
      "\"joel\"\t6\n",
      "\"johannesburg\"\t2\n",
      "\"john\"\t22\n",
      "\"johnny\"\t2\n",
      "\"johnston\"\t2\n",
      "\"join\"\t10\n",
      "\"joinder\"\t1\n",
      "\"joined\"\t3\n",
      "\"joining\"\t4\n",
      "\"joint\"\t1\n",
      "\"jon\"\t1\n",
      "\"jonathon\"\t1\n",
      "\"jones\"\t3\n",
      "\"jonesg\"\t1\n",
      "\"jose\"\t1\n",
      "\"joseph\"\t7\n",
      "\"josey\"\t7\n",
      "\"journey\"\t1\n",
      "\"journeys\"\t1\n",
      "\"joyce\"\t1\n",
      "\"jpxdltmuk\"\t1\n",
      "\"jshorter\"\t1\n",
      "\"jsp\"\t3\n",
      "\"jturco\"\t2\n",
      "\"jubilar\"\t1\n",
      "\"judge\"\t3\n",
      "\"judgment\"\t1\n",
      "\"judgments\"\t1\n",
      "\"julie\"\t5\n",
      "\"july\"\t2\n",
      "\"june\"\t11\n",
      "\"junk\"\t2\n",
      "\"just\"\t47\n",
      "\"justperform\"\t1\n",
      "\"jvbe\"\t1\n",
      "\"kainantu\"\t2\n",
      "\"kaminski\"\t11\n",
      "\"kaolin\"\t1\n",
      "\"karen\"\t1\n",
      "\"kaskaskia\"\t1\n",
      "\"katamail\"\t1\n",
      "\"kathryn\"\t3\n",
      "\"kathy\"\t1\n",
      "\"kay\"\t5\n",
      "\"kcs\"\t2\n",
      "\"keeley\"\t5\n",
      "\"keen\"\t1\n",
      "\"keep\"\t21\n",
      "\"keeping\"\t4\n",
      "\"kelly\"\t1\n",
      "\"kenny\"\t1\n",
      "\"kept\"\t2\n",
      "\"kerb\"\t1\n",
      "\"kevin\"\t48\n",
      "\"key\"\t10\n",
      "\"keyboard\"\t2\n",
      "\"keyes\"\t1\n",
      "\"keys\"\t1\n",
      "\"keyword\"\t4\n",
      "\"keywordcount\"\t1\n",
      "\"keywords\"\t2\n",
      "\"kfbtyra\"\t1\n",
      "\"kg\"\t3\n",
      "\"khanna\"\t1\n",
      "\"kick\"\t1\n",
      "\"kickoff\"\t2\n",
      "\"kid\"\t1\n",
      "\"killed\"\t2\n",
      "\"killer\"\t1\n",
      "\"killings\"\t2\n",
      "\"kim\"\t3\n",
      "\"kimberley\"\t3\n",
      "\"kimberly\"\t5\n",
      "\"kincaid\"\t2\n",
      "\"kind\"\t7\n",
      "\"kinda\"\t2\n",
      "\"kindall\"\t4\n",
      "\"kindly\"\t1\n",
      "\"kinds\"\t2\n",
      "\"king\"\t5\n",
      "\"kish\"\t1\n",
      "\"kistler\"\t1\n",
      "\"kitchen\"\t3\n",
      "\"kk\"\t1\n",
      "\"klei\"\t1\n",
      "\"knave\"\t3\n",
      "\"knelt\"\t1\n",
      "\"knew\"\t3\n",
      "\"knights\"\t1\n",
      "\"knives\"\t1\n",
      "\"know\"\t42\n",
      "\"knowledge\"\t4\n",
      "\"knowlton\"\t1\n",
      "\"known\"\t4\n",
      "\"knows\"\t2\n",
      "\"knudsen\"\t1\n",
      "\"kokas\"\t1\n",
      "\"kollaros\"\t1\n",
      "\"korea\"\t1\n",
      "\"koromah\"\t2\n",
      "\"krgp\"\t2\n",
      "\"kri\"\t2\n",
      "\"krill\"\t1\n",
      "\"krishna\"\t1\n",
      "\"krishnarao\"\t5\n",
      "\"kristin\"\t2\n",
      "\"kvie\"\t1\n",
      "\"kwh\"\t2\n",
      "\"kyle\"\t1\n",
      "\"label\"\t2\n",
      "\"labor\"\t2\n",
      "\"laborious\"\t1\n",
      "\"lack\"\t1\n",
      "\"lacrecia\"\t1\n",
      "\"lagars\"\t1\n",
      "\"lagrasta\"\t1\n",
      "\"lamb\"\t1\n",
      "\"lamproite\"\t2\n",
      "\"lamps\"\t1\n",
      "\"land\"\t1\n",
      "\"language\"\t3\n",
      "\"lanterns\"\t1\n",
      "\"large\"\t8\n",
      "\"larger\"\t3\n",
      "\"largest\"\t2\n",
      "\"larry\"\t1\n",
      "\"last\"\t18\n",
      "\"lasts\"\t1\n",
      "\"late\"\t5\n",
      "\"later\"\t12\n",
      "\"latin\"\t1\n",
      "\"laughed\"\t1\n",
      "\"launch\"\t2\n",
      "\"lauri\"\t4\n",
      "\"lavorato\"\t6\n",
      "\"law\"\t5\n",
      "\"lawn\"\t3\n",
      "\"layout\"\t3\n",
      "\"layouts\"\t1\n",
      "\"lcd\"\t1\n",
      "\"lead\"\t10\n",
      "\"leaders\"\t1\n",
      "\"leadership\"\t13\n",
      "\"leads\"\t11\n",
      "\"leap\"\t1\n",
      "\"learn\"\t4\n",
      "\"learned\"\t2\n",
      "\"learning\"\t3\n",
      "\"learns\"\t2\n",
      "\"lease\"\t1\n",
      "\"least\"\t12\n",
      "\"leave\"\t4\n",
      "\"leaving\"\t2\n",
      "\"lee\"\t1\n",
      "\"leederville\"\t1\n",
      "\"left\"\t5\n",
      "\"legal\"\t3\n",
      "\"legislative\"\t1\n",
      "\"legislator\"\t1\n",
      "\"legislators\"\t2\n",
      "\"legislature\"\t9\n",
      "\"legs\"\t3\n",
      "\"lehr\"\t1\n",
      "\"lemelman\"\t1\n",
      "\"lend\"\t2\n",
      "\"lender\"\t2\n",
      "\"lenders\"\t4\n",
      "\"length\"\t1\n",
      "\"lengthen\"\t1\n",
      "\"leone\"\t5\n",
      "\"less\"\t20\n",
      "\"lesson\"\t5\n",
      "\"let\"\t35\n",
      "\"lets\"\t1\n",
      "\"letter\"\t27\n",
      "\"letters\"\t11\n",
      "\"level\"\t4\n",
      "\"levels\"\t2\n",
      "\"leverage\"\t1\n",
      "\"liar\"\t2\n",
      "\"licence\"\t1\n",
      "\"licensing\"\t1\n",
      "\"life\"\t12\n",
      "\"lifetime\"\t1\n",
      "\"lift\"\t1\n",
      "\"lifted\"\t1\n",
      "\"lifts\"\t1\n",
      "\"light\"\t1\n",
      "\"like\"\t54\n",
      "\"liked\"\t1\n",
      "\"likelihood\"\t2\n",
      "\"likely\"\t7\n",
      "\"likes\"\t1\n",
      "\"lilly\"\t1\n",
      "\"limitations\"\t1\n",
      "\"limited\"\t14\n",
      "\"limitless\"\t2\n",
      "\"lin\"\t6\n",
      "\"linda\"\t5\n",
      "\"lindiwe\"\t2\n",
      "\"line\"\t21\n",
      "\"lineal\"\t1\n",
      "\"lines\"\t1\n",
      "\"lingerie\"\t2\n",
      "\"link\"\t6\n",
      "\"linkpaks\"\t4\n",
      "\"links\"\t30\n",
      "\"linktocash\"\t1\n",
      "\"linux\"\t4\n",
      "\"lips\"\t1\n",
      "\"liquid\"\t1\n",
      "\"liquids\"\t1\n",
      "\"lisa\"\t2\n",
      "\"list\"\t18\n",
      "\"listed\"\t7\n",
      "\"listen\"\t2\n",
      "\"listened\"\t1\n",
      "\"listinfo\"\t3\n",
      "\"listmaster\"\t1\n",
      "\"lists\"\t2\n",
      "\"lit\"\t1\n",
      "\"literally\"\t1\n",
      "\"literature\"\t1\n",
      "\"litteneker\"\t1\n",
      "\"litterbug\"\t1\n",
      "\"little\"\t9\n",
      "\"live\"\t1\n",
      "\"living\"\t3\n",
      "\"liz\"\t3\n",
      "\"ll\"\t23\n",
      "\"llc\"\t2\n",
      "\"llittle\"\t1\n",
      "\"loads\"\t1\n",
      "\"loan\"\t4\n",
      "\"lobby\"\t1\n",
      "\"lobster\"\t1\n",
      "\"local\"\t6\n",
      "\"locally\"\t2\n",
      "\"locals\"\t1\n",
      "\"located\"\t4\n",
      "\"location\"\t11\n",
      "\"lock\"\t2\n",
      "\"locomotive\"\t1\n",
      "\"loczk\"\t1\n",
      "\"loft\"\t2\n",
      "\"lollipops\"\t1\n",
      "\"london\"\t4\n",
      "\"long\"\t18\n",
      "\"longer\"\t4\n",
      "\"look\"\t14\n",
      "\"looked\"\t1\n",
      "\"looking\"\t4\n",
      "\"looks\"\t5\n",
      "\"loosening\"\t1\n",
      "\"lose\"\t2\n",
      "\"loses\"\t2\n",
      "\"losing\"\t2\n",
      "\"loss\"\t1\n",
      "\"lot\"\t10\n",
      "\"lots\"\t2\n",
      "\"lottery\"\t6\n",
      "\"louise\"\t8\n",
      "\"lounsbury\"\t1\n",
      "\"love\"\t2\n",
      "\"low\"\t10\n",
      "\"lower\"\t1\n",
      "\"lowest\"\t1\n",
      "\"loyal\"\t2\n",
      "\"loyalty\"\t1\n",
      "\"lsc\"\t1\n",
      "\"lst\"\t2\n",
      "\"ltd\"\t2\n",
      "\"lu\"\t5\n",
      "\"luck\"\t2\n",
      "\"lucky\"\t2\n",
      "\"lump\"\t1\n",
      "\"lunch\"\t2\n",
      "\"luo\"\t1\n",
      "\"luong\"\t1\n",
      "\"lx\"\t1\n",
      "\"lycopodium\"\t1\n",
      "\"lyn\"\t7\n",
      "\"lynch\"\t1\n",
      "\"lynda\"\t1\n",
      "\"ma\"\t2\n",
      "\"macarthur\"\t1\n",
      "\"machine\"\t1\n",
      "\"mackey\"\t1\n",
      "\"macquarie\"\t2\n",
      "\"macromedia\"\t6\n",
      "\"madam\"\t2\n",
      "\"made\"\t15\n",
      "\"magellan\"\t1\n",
      "\"magnesium\"\t1\n",
      "\"magnum\"\t1\n",
      "\"magnumo\"\t1\n",
      "\"maidens\"\t1\n",
      "\"mail\"\t32\n",
      "\"mailing\"\t3\n",
      "\"mailings\"\t2\n",
      "\"mailman\"\t3\n",
      "\"mailto\"\t11\n",
      "\"main\"\t1\n",
      "\"maine\"\t1\n",
      "\"maintain\"\t2\n",
      "\"maintainer\"\t1\n",
      "\"major\"\t5\n",
      "\"make\"\t35\n",
      "\"makecashonline\"\t1\n",
      "\"makes\"\t5\n",
      "\"making\"\t17\n",
      "\"male\"\t3\n",
      "\"malina\"\t4\n",
      "\"man\"\t5\n",
      "\"manage\"\t3\n",
      "\"managed\"\t7\n",
      "\"management\"\t54\n",
      "\"manager\"\t8\n",
      "\"managerial\"\t2\n",
      "\"managers\"\t1\n",
      "\"manages\"\t3\n",
      "\"managing\"\t1\n",
      "\"managment\"\t4\n",
      "\"mandated\"\t1\n",
      "\"manganese\"\t1\n",
      "\"manitoba\"\t1\n",
      "\"manual\"\t2\n",
      "\"manufacturers\"\t1\n",
      "\"many\"\t24\n",
      "\"mark\"\t8\n",
      "\"market\"\t12\n",
      "\"marketability\"\t2\n",
      "\"marketer\"\t1\n",
      "\"marketers\"\t1\n",
      "\"marketing\"\t28\n",
      "\"markets\"\t5\n",
      "\"marks\"\t2\n",
      "\"marla\"\t1\n",
      "\"martensite\"\t1\n",
      "\"martin\"\t7\n",
      "\"martina\"\t4\n",
      "\"martinez\"\t1\n",
      "\"mary\"\t7\n",
      "\"maryam\"\t1\n",
      "\"mass\"\t3\n",
      "\"massey\"\t1\n",
      "\"masson\"\t5\n",
      "\"master\"\t3\n",
      "\"match\"\t2\n",
      "\"matches\"\t4\n",
      "\"material\"\t1\n",
      "\"materials\"\t2\n",
      "\"matt\"\t1\n",
      "\"matter\"\t6\n",
      "\"maureen\"\t5\n",
      "\"mauricio\"\t1\n",
      "\"may\"\t27\n",
      "\"maybe\"\t4\n",
      "\"mayerbrown\"\t1\n",
      "\"mayes\"\t1\n",
      "\"mb\"\t1\n",
      "\"mc\"\t1\n",
      "\"mcbeal\"\t1\n",
      "\"mcclankg\"\t1\n",
      "\"mccullough\"\t1\n",
      "\"mcf\"\t2\n",
      "\"mclafferty\"\t1\n",
      "\"mclarney\"\t2\n",
      "\"mclean\"\t1\n",
      "\"mcmullen\"\t2\n",
      "\"mcosta\"\t1\n",
      "\"mcsherry\"\t1\n",
      "\"me\"\t75\n",
      "\"mean\"\t1\n",
      "\"means\"\t6\n",
      "\"meant\"\t1\n",
      "\"meanwhile\"\t3\n",
      "\"measure\"\t1\n",
      "\"measuring\"\t3\n",
      "\"mechanism\"\t1\n",
      "\"media\"\t3\n",
      "\"medical\"\t1\n",
      "\"medication\"\t1\n",
      "\"medications\"\t1\n",
      "\"mediums\"\t1\n",
      "\"meet\"\t9\n",
      "\"meeting\"\t19\n",
      "\"meetings\"\t7\n",
      "\"mega\"\t2\n",
      "\"melissa\"\t3\n",
      "\"melodick\"\t1\n",
      "\"member\"\t21\n",
      "\"members\"\t14\n",
      "\"membership\"\t19\n",
      "\"memo\"\t4\n",
      "\"memory\"\t3\n",
      "\"men\"\t5\n",
      "\"mental\"\t2\n",
      "\"mention\"\t3\n",
      "\"mentioned\"\t5\n",
      "\"merchandise\"\t3\n",
      "\"merchandisethat\"\t1\n",
      "\"merchant\"\t5\n",
      "\"merchants\"\t1\n",
      "\"merely\"\t1\n",
      "\"merry\"\t2\n",
      "\"mesopotamia\"\t1\n",
      "\"message\"\t20\n",
      "\"metal\"\t1\n",
      "\"metaphors\"\t1\n",
      "\"meter\"\t13\n",
      "\"meters\"\t3\n",
      "\"method\"\t1\n",
      "\"methods\"\t1\n",
      "\"mexico\"\t1\n",
      "\"meyers\"\t1\n",
      "\"mg\"\t2\n",
      "\"miami\"\t1\n",
      "\"michael\"\t9\n",
      "\"michelago\"\t2\n",
      "\"michele\"\t1\n",
      "\"micros\"\t2\n",
      "\"microsale\"\t8\n",
      "\"microsoft\"\t6\n",
      "\"mid\"\t3\n",
      "\"midwestern\"\t1\n",
      "\"might\"\t12\n",
      "\"mighty\"\t1\n",
      "\"migraine\"\t1\n",
      "\"miguel\"\t1\n",
      "\"mike\"\t11\n",
      "\"mild\"\t2\n",
      "\"milestone\"\t1\n",
      "\"militarism\"\t1\n",
      "\"millenium\"\t1\n",
      "\"miller\"\t1\n",
      "\"million\"\t17\n",
      "\"millions\"\t2\n",
      "\"mime\"\t1\n",
      "\"min\"\t2\n",
      "\"mind\"\t16\n",
      "\"minds\"\t1\n",
      "\"mine\"\t7\n",
      "\"mineral\"\t2\n",
      "\"minerals\"\t4\n",
      "\"mines\"\t1\n",
      "\"mini\"\t1\n",
      "\"minimal\"\t1\n",
      "\"minimize\"\t1\n",
      "\"minimum\"\t2\n",
      "\"mining\"\t7\n",
      "\"miningnews\"\t9\n",
      "\"minor\"\t1\n",
      "\"minute\"\t4\n",
      "\"minutes\"\t5\n",
      "\"mirant\"\t1\n",
      "\"mircosoft\"\t1\n",
      "\"mirror\"\t3\n",
      "\"miserable\"\t1\n",
      "\"mislead\"\t1\n",
      "\"miss\"\t2\n",
      "\"missed\"\t2\n",
      "\"missing\"\t1\n",
      "\"missouri\"\t1\n",
      "\"misspelled\"\t1\n",
      "\"missss\"\t1\n",
      "\"mitral\"\t1\n",
      "\"mix\"\t2\n",
      "\"mixture\"\t1\n",
      "\"mm\"\t1\n",
      "\"mmbtu\"\t6\n",
      "\"mmce\"\t1\n",
      "\"mo\"\t1\n",
      "\"moates\"\t1\n",
      "\"mobil\"\t1\n",
      "\"mobile\"\t1\n",
      "\"mode\"\t1\n",
      "\"modem\"\t1\n",
      "\"moderate\"\t2\n",
      "\"moderates\"\t2\n",
      "\"moderator\"\t4\n",
      "\"modification\"\t1\n",
      "\"module\"\t1\n",
      "\"modules\"\t4\n",
      "\"moment\"\t3\n",
      "\"moments\"\t1\n",
      "\"monadic\"\t1\n",
      "\"monday\"\t16\n",
      "\"money\"\t35\n",
      "\"mongolia\"\t1\n",
      "\"monies\"\t1\n",
      "\"monitor\"\t1\n",
      "\"montana\"\t1\n",
      "\"month\"\t17\n",
      "\"monthly\"\t2\n",
      "\"months\"\t10\n",
      "\"mood\"\t1\n",
      "\"moore\"\t39\n",
      "\"morality\"\t1\n",
      "\"morayt\"\t1\n",
      "\"more\"\t65\n",
      "\"morne\"\t1\n",
      "\"morning\"\t12\n",
      "\"morris\"\t3\n",
      "\"mortgage\"\t3\n",
      "\"mossel\"\t1\n",
      "\"most\"\t31\n",
      "\"mostly\"\t1\n",
      "\"motero\"\t1\n",
      "\"motivating\"\t1\n",
      "\"mounted\"\t1\n",
      "\"mouse\"\t5\n",
      "\"move\"\t8\n",
      "\"moved\"\t2\n",
      "\"movement\"\t2\n",
      "\"moves\"\t1\n",
      "\"moviebuff\"\t2\n",
      "\"moving\"\t5\n",
      "\"mower\"\t1\n",
      "\"mp\"\t1\n",
      "\"mperkins\"\t1\n",
      "\"mpkemyrxlpq\"\t1\n",
      "\"mr\"\t10\n",
      "\"mrs\"\t8\n",
      "\"ms\"\t10\n",
      "\"mscf\"\t1\n",
      "\"msessa\"\t1\n",
      "\"mst\"\t1\n",
      "\"much\"\t25\n",
      "\"multilanguage\"\t1\n",
      "\"multipart\"\t1\n",
      "\"multiple\"\t7\n",
      "\"murmur\"\t1\n",
      "\"murphy\"\t1\n",
      "\"muscle\"\t2\n",
      "\"music\"\t1\n",
      "\"musically\"\t1\n",
      "\"must\"\t21\n",
      "\"mustard\"\t1\n",
      "\"mutual\"\t1\n",
      "\"mw\"\t3\n",
      "\"mx\"\t6\n",
      "\"my\"\t102\n",
      "\"myers\"\t1\n",
      "\"myinput\"\t4\n",
      "\"myinputare\"\t1\n",
      "\"myself\"\t1\n",
      "\"myshoppingplace\"\t4\n",
      "\"mysiteinc\"\t4\n",
      "\"na\"\t5\n",
      "\"naked\"\t1\n",
      "\"name\"\t22\n",
      "\"names\"\t7\n",
      "\"nas\"\t1\n",
      "\"nation\"\t1\n",
      "\"natives\"\t1\n",
      "\"natural\"\t7\n",
      "\"nature\"\t2\n",
      "\"nbi\"\t1\n",
      "\"ncaa\"\t1\n",
      "\"nd\"\t4\n",
      "\"neaarby\"\t1\n",
      "\"neal\"\t1\n",
      "\"near\"\t6\n",
      "\"nearby\"\t1\n",
      "\"nearly\"\t1\n",
      "\"neat\"\t1\n",
      "\"nebulous\"\t1\n",
      "\"necessary\"\t8\n",
      "\"necessities\"\t1\n",
      "\"neck\"\t1\n",
      "\"need\"\t54\n",
      "\"needed\"\t9\n",
      "\"needs\"\t9\n",
      "\"negative\"\t1\n",
      "\"negotiating\"\t3\n",
      "\"negotiation\"\t1\n",
      "\"neighbor\"\t1\n",
      "\"neighboring\"\t2\n",
      "\"nepco\"\t1\n",
      "\"nero\"\t1\n",
      "\"net\"\t36\n",
      "\"netherland\"\t1\n",
      "\"netherlands\"\t2\n",
      "\"netnoteinc\"\t6\n",
      "\"netrepreneur\"\t1\n",
      "\"netsbestinfo\"\t2\n",
      "\"network\"\t1\n",
      "\"networks\"\t6\n",
      "\"netwww\"\t1\n",
      "\"neuweiler\"\t2\n",
      "\"never\"\t7\n",
      "\"new\"\t66\n",
      "\"newcomers\"\t2\n",
      "\"news\"\t7\n",
      "\"newsboy\"\t2\n",
      "\"newsletter\"\t24\n",
      "\"newsletters\"\t4\n",
      "\"next\"\t27\n",
      "\"nextpart\"\t1\n",
      "\"neyeded\"\t1\n",
      "\"ngo\"\t2\n",
      "\"nguyen\"\t3\n",
      "\"ngx\"\t1\n",
      "\"nice\"\t3\n",
      "\"nickel\"\t4\n",
      "\"nicki\"\t1\n",
      "\"nickname\"\t1\n",
      "\"nicolay\"\t1\n",
      "\"niestrath\"\t1\n",
      "\"nigel\"\t1\n",
      "\"night\"\t4\n",
      "\"nightgear\"\t1\n",
      "\"nighttime\"\t2\n",
      "\"niles\"\t3\n",
      "\"nim\"\t2\n",
      "\"nine\"\t1\n",
      "\"njwa\"\t1\n",
      "\"no\"\t52\n",
      "\"noah\"\t1\n",
      "\"nodded\"\t1\n",
      "\"nom\"\t8\n",
      "\"nominated\"\t4\n",
      "\"nomination\"\t4\n",
      "\"nominations\"\t1\n",
      "\"nommensen\"\t1\n",
      "\"non\"\t5\n",
      "\"none\"\t2\n",
      "\"noon\"\t1\n",
      "\"norma\"\t1\n",
      "\"normal\"\t8\n",
      "\"normally\"\t1\n",
      "\"normet\"\t2\n",
      "\"north\"\t12\n",
      "\"northern\"\t3\n",
      "\"norton\"\t3\n",
      "\"nospam\"\t1\n",
      "\"nostalgia\"\t1\n",
      "\"not\"\t126\n",
      "\"note\"\t9\n",
      "\"noted\"\t4\n",
      "\"notes\"\t1\n",
      "\"nothing\"\t5\n",
      "\"notice\"\t4\n",
      "\"noticed\"\t1\n",
      "\"notiffiyved\"\t1\n",
      "\"notification\"\t1\n",
      "\"notify\"\t2\n",
      "\"notis\"\t2\n",
      "\"nov\"\t5\n",
      "\"novak\"\t1\n",
      "\"novel\"\t1\n",
      "\"novelties\"\t1\n",
      "\"november\"\t3\n",
      "\"now\"\t29\n",
      "\"nowbetterthis\"\t2\n",
      "\"nowthe\"\t1\n",
      "\"nox\"\t2\n",
      "\"nrg\"\t1\n",
      "\"nrw\"\t1\n",
      "\"ns\"\t1\n",
      "\"nt\"\t1\n",
      "\"num\"\t1\n",
      "\"number\"\t17\n",
      "\"numbers\"\t9\n",
      "\"numerous\"\t1\n",
      "\"oak\"\t1\n",
      "\"oblibgat\"\t1\n",
      "\"obligation\"\t2\n",
      "\"obligationin\"\t1\n",
      "\"obligations\"\t2\n",
      "\"observations\"\t2\n",
      "\"obtain\"\t4\n",
      "\"obtained\"\t1\n",
      "\"obviously\"\t4\n",
      "\"occasion\"\t1\n",
      "\"occur\"\t1\n",
      "\"occurs\"\t1\n",
      "\"ocd\"\t1\n",
      "\"oceania\"\t1\n",
      "\"oconan\"\t2\n",
      "\"odin\"\t2\n",
      "\"odlx\"\t1\n",
      "\"oem\"\t3\n",
      "\"of\"\t566\n",
      "\"off\"\t8\n",
      "\"offer\"\t26\n",
      "\"offered\"\t3\n",
      "\"offering\"\t7\n",
      "\"offers\"\t2\n",
      "\"office\"\t26\n",
      "\"officer\"\t3\n",
      "\"offices\"\t3\n",
      "\"official\"\t1\n",
      "\"officially\"\t3\n",
      "\"officials\"\t1\n",
      "\"offsite\"\t2\n",
      "\"often\"\t9\n",
      "\"oh\"\t2\n",
      "\"oil\"\t1\n",
      "\"oilshale\"\t1\n",
      "\"ok\"\t4\n",
      "\"old\"\t7\n",
      "\"olson\"\t2\n",
      "\"omaha\"\t1\n",
      "\"omission\"\t1\n",
      "\"on\"\t271\n",
      "\"once\"\t8\n",
      "\"ondarza\"\t1\n",
      "\"one\"\t68\n",
      "\"onerous\"\t1\n",
      "\"ongoing\"\t2\n",
      "\"online\"\t20\n",
      "\"only\"\t32\n",
      "\"ontacted\"\t1\n",
      "\"oo\"\t6\n",
      "\"op\"\t4\n",
      "\"open\"\t7\n",
      "\"opening\"\t4\n",
      "\"openpage\"\t1\n",
      "\"operate\"\t1\n",
      "\"operation\"\t2\n",
      "\"operational\"\t6\n",
      "\"operations\"\t41\n",
      "\"operators\"\t3\n",
      "\"opinion\"\t5\n",
      "\"opportunities\"\t7\n",
      "\"opportunity\"\t9\n",
      "\"oppose\"\t1\n",
      "\"opposite\"\t1\n",
      "\"opposition\"\t2\n",
      "\"opt\"\t2\n",
      "\"optimistic\"\t1\n",
      "\"option\"\t1\n",
      "\"options\"\t2\n",
      "\"optionscontrol\"\t1\n",
      "\"or\"\t166\n",
      "\"orange\"\t1\n",
      "\"order\"\t44\n",
      "\"ordered\"\t6\n",
      "\"orders\"\t1\n",
      "\"ore\"\t3\n",
      "\"org\"\t4\n",
      "\"organisation\"\t1\n",
      "\"organization\"\t6\n",
      "\"organizational\"\t1\n",
      "\"organize\"\t2\n",
      "\"orgoto\"\t1\n",
      "\"orgtrade\"\t1\n",
      "\"oriental\"\t1\n",
      "\"original\"\t3\n",
      "\"originality\"\t1\n",
      "\"originally\"\t1\n",
      "\"origination\"\t1\n",
      "\"originator\"\t2\n",
      "\"orleantraders\"\t1\n",
      "\"orrick\"\t1\n",
      "\"osman\"\t4\n",
      "\"otc\"\t1\n",
      "\"other\"\t43\n",
      "\"others\"\t4\n",
      "\"otherwise\"\t1\n",
      "\"ounces\"\t1\n",
      "\"our\"\t119\n",
      "\"ourselves\"\t1\n",
      "\"out\"\t70\n",
      "\"outback\"\t1\n",
      "\"outdated\"\t1\n",
      "\"outline\"\t2\n",
      "\"outlined\"\t1\n",
      "\"outlook\"\t3\n",
      "\"outpacing\"\t1\n",
      "\"outrageous\"\t1\n",
      "\"outside\"\t3\n",
      "\"outstanding\"\t4\n",
      "\"over\"\t50\n",
      "\"overall\"\t2\n",
      "\"overgaard\"\t1\n",
      "\"overnight\"\t2\n",
      "\"overpaying\"\t1\n",
      "\"oversee\"\t3\n",
      "\"overseer\"\t1\n",
      "\"overuse\"\t1\n",
      "\"overwhelm\"\t1\n",
      "\"owe\"\t1\n",
      "\"own\"\t15\n",
      "\"owned\"\t5\n",
      "\"owner\"\t2\n",
      "\"owners\"\t2\n",
      "\"ownership\"\t2\n",
      "\"owning\"\t2\n",
      "\"owns\"\t1\n",
      "\"oxidation\"\t1\n",
      "\"oxley\"\t3\n",
      "\"oxx\"\t2\n",
      "\"oxymoron\"\t1\n",
      "\"ozarka\"\t1\n",
      "\"paces\"\t1\n",
      "\"pacific\"\t3\n",
      "\"package\"\t4\n",
      "\"padron\"\t1\n",
      "\"page\"\t23\n",
      "\"pagemaker\"\t2\n",
      "\"pages\"\t9\n",
      "\"paid\"\t5\n",
      "\"paidtosurf\"\t2\n",
      "\"pain\"\t2\n",
      "\"painter\"\t1\n",
      "\"palaeo\"\t1\n",
      "\"pamela\"\t2\n",
      "\"panel\"\t1\n",
      "\"pangs\"\t1\n",
      "\"paper\"\t3\n",
      "\"papers\"\t2\n",
      "\"papua\"\t1\n",
      "\"par\"\t2\n",
      "\"paragraph\"\t6\n",
      "\"paragraphs\"\t8\n",
      "\"parallel\"\t1\n",
      "\"parents\"\t1\n",
      "\"part\"\t9\n",
      "\"participants\"\t2\n",
      "\"participate\"\t4\n",
      "\"participating\"\t1\n",
      "\"participation\"\t1\n",
      "\"particular\"\t2\n",
      "\"particularly\"\t3\n",
      "\"parties\"\t4\n",
      "\"partner\"\t4\n",
      "\"partners\"\t4\n",
      "\"partnership\"\t1\n",
      "\"parts\"\t1\n",
      "\"party\"\t3\n",
      "\"paso\"\t2\n",
      "\"pass\"\t2\n",
      "\"passed\"\t1\n",
      "\"passport\"\t1\n",
      "\"password\"\t5\n",
      "\"past\"\t3\n",
      "\"path\"\t2\n",
      "\"pathetic\"\t1\n",
      "\"pathos\"\t1\n",
      "\"patricia\"\t4\n",
      "\"paul\"\t2\n",
      "\"paulo\"\t5\n",
      "\"pause\"\t1\n",
      "\"pavluk\"\t1\n",
      "\"pay\"\t5\n",
      "\"payback\"\t1\n",
      "\"payers\"\t1\n",
      "\"paying\"\t3\n",
      "\"payment\"\t1\n",
      "\"payments\"\t8\n",
      "\"payne\"\t2\n",
      "\"payroll\"\t5\n",
      "\"pbem\"\t1\n",
      "\"pc\"\t5\n",
      "\"pcenergy\"\t3\n",
      "\"pcp\"\t1\n",
      "\"pdx\"\t1\n",
      "\"peace\"\t4\n",
      "\"peaking\"\t1\n",
      "\"peel\"\t2\n",
      "\"peers\"\t1\n",
      "\"penance\"\t1\n",
      "\"pennsylvania\"\t3\n",
      "\"pentium\"\t1\n",
      "\"people\"\t38\n",
      "\"per\"\t11\n",
      "\"perceived\"\t1\n",
      "\"percent\"\t1\n",
      "\"percentage\"\t2\n",
      "\"perfect\"\t3\n",
      "\"perform\"\t1\n",
      "\"performance\"\t7\n",
      "\"performer\"\t2\n",
      "\"perhaps\"\t3\n",
      "\"period\"\t8\n",
      "\"persist\"\t1\n",
      "\"persistence\"\t2\n",
      "\"persists\"\t1\n",
      "\"person\"\t16\n",
      "\"personage\"\t1\n",
      "\"personal\"\t12\n",
      "\"personality\"\t4\n",
      "\"personally\"\t1\n",
      "\"personnel\"\t7\n",
      "\"persons\"\t1\n",
      "\"perspective\"\t7\n",
      "\"perth\"\t1\n",
      "\"pest\"\t1\n",
      "\"pet\"\t1\n",
      "\"pete\"\t1\n",
      "\"peter\"\t3\n",
      "\"petteway\"\t1\n",
      "\"pg\"\t7\n",
      "\"pgm\"\t1\n",
      "\"ph\"\t3\n",
      "\"phases\"\t2\n",
      "\"phentermine\"\t3\n",
      "\"philadelphia\"\t1\n",
      "\"philip\"\t1\n",
      "\"phillip\"\t1\n",
      "\"phone\"\t15\n",
      "\"phonetic\"\t1\n",
      "\"photo\"\t1\n",
      "\"photoshop\"\t3\n",
      "\"php\"\t3\n",
      "\"phrasemake\"\t1\n",
      "\"phrases\"\t3\n",
      "\"physical\"\t6\n",
      "\"physicians\"\t1\n",
      "\"pibrochs\"\t1\n",
      "\"pick\"\t3\n",
      "\"picture\"\t4\n",
      "\"pictures\"\t8\n",
      "\"piece\"\t1\n",
      "\"pierre\"\t1\n",
      "\"pike\"\t1\n",
      "\"pilkington\"\t1\n",
      "\"pillsburywinthrop\"\t2\n",
      "\"pilocystic\"\t1\n",
      "\"pilot\"\t6\n",
      "\"pinion\"\t1\n",
      "\"pinnacle\"\t1\n",
      "\"pinnamaneni\"\t4\n",
      "\"pipe\"\t1\n",
      "\"pipeline\"\t3\n",
      "\"pipes\"\t2\n",
      "\"pitchers\"\t1\n",
      "\"pitifully\"\t1\n",
      "\"pl\"\t1\n",
      "\"place\"\t20\n",
      "\"placed\"\t1\n",
      "\"placement\"\t2\n",
      "\"places\"\t1\n",
      "\"plain\"\t4\n",
      "\"plan\"\t17\n",
      "\"plans\"\t2\n",
      "\"plant\"\t2\n",
      "\"planted\"\t1\n",
      "\"plants\"\t2\n",
      "\"platform\"\t2\n",
      "\"platitudes\"\t1\n",
      "\"platte\"\t1\n",
      "\"played\"\t1\n",
      "\"player\"\t2\n",
      "\"pleas\"\t1\n",
      "\"pleasant\"\t1\n",
      "\"please\"\t84\n",
      "\"pleased\"\t3\n",
      "\"pleasure\"\t1\n",
      "\"plentiful\"\t1\n",
      "\"plus\"\t4\n",
      "\"plushy\"\t1\n",
      "\"pm\"\t37\n",
      "\"po\"\t1\n",
      "\"point\"\t15\n",
      "\"points\"\t3\n",
      "\"policy\"\t6\n",
      "\"political\"\t3\n",
      "\"politically\"\t1\n",
      "\"politicians\"\t1\n",
      "\"pompey\"\t1\n",
      "\"poor\"\t3\n",
      "\"poors\"\t1\n",
      "\"pops\"\t2\n",
      "\"popular\"\t2\n",
      "\"portion\"\t1\n",
      "\"ports\"\t1\n",
      "\"position\"\t7\n",
      "\"positions\"\t1\n",
      "\"possesses\"\t1\n",
      "\"possibilities\"\t1\n",
      "\"possibility\"\t4\n",
      "\"possible\"\t17\n",
      "\"possibly\"\t2\n",
      "\"post\"\t9\n",
      "\"postal\"\t1\n",
      "\"posting\"\t1\n",
      "\"posts\"\t1\n",
      "\"potency\"\t1\n",
      "\"potential\"\t8\n",
      "\"pound\"\t2\n",
      "\"pounds\"\t1\n",
      "\"power\"\t24\n",
      "\"powered\"\t3\n",
      "\"powerful\"\t7\n",
      "\"powerquest\"\t1\n",
      "\"ppmfztdtet\"\t1\n",
      "\"practices\"\t3\n",
      "\"prager\"\t1\n",
      "\"pray\"\t1\n",
      "\"prbolem\"\t1\n",
      "\"pre\"\t3\n",
      "\"precedent\"\t1\n",
      "\"precious\"\t1\n",
      "\"precluded\"\t1\n",
      "\"preferences\"\t2\n",
      "\"preferred\"\t2\n",
      "\"prefix\"\t1\n",
      "\"premature\"\t1\n",
      "\"premiere\"\t2\n",
      "\"premium\"\t3\n",
      "\"premiums\"\t2\n",
      "\"preneur\"\t2\n",
      "\"prepared\"\t2\n",
      "\"preposition\"\t1\n",
      "\"presas\"\t2\n",
      "\"presccription\"\t1\n",
      "\"prescriptions\"\t1\n",
      "\"presence\"\t3\n",
      "\"present\"\t2\n",
      "\"presentation\"\t1\n",
      "\"presented\"\t1\n",
      "\"president\"\t9\n",
      "\"presidential\"\t1\n",
      "\"press\"\t4\n",
      "\"pressure\"\t5\n",
      "\"pressured\"\t2\n",
      "\"prestigious\"\t1\n",
      "\"presumably\"\t1\n",
      "\"presumed\"\t1\n",
      "\"pretty\"\t4\n",
      "\"prevatt\"\t4\n",
      "\"prevent\"\t1\n",
      "\"previous\"\t9\n",
      "\"previously\"\t2\n",
      "\"prez\"\t1\n",
      "\"price\"\t27\n",
      "\"prices\"\t8\n",
      "\"pricing\"\t4\n",
      "\"pricked\"\t1\n",
      "\"pride\"\t1\n",
      "\"priicce\"\t1\n",
      "\"priice\"\t1\n",
      "\"priices\"\t1\n",
      "\"prilosec\"\t1\n",
      "\"primary\"\t3\n",
      "\"principal\"\t3\n",
      "\"principle\"\t1\n",
      "\"print\"\t1\n",
      "\"printable\"\t2\n",
      "\"printer\"\t23\n",
      "\"prior\"\t8\n",
      "\"priority\"\t2\n",
      "\"priscilla\"\t1\n",
      "\"privacy\"\t6\n",
      "\"private\"\t5\n",
      "\"privileged\"\t1\n",
      "\"prize\"\t1\n",
      "\"pro\"\t2\n",
      "\"probably\"\t7\n",
      "\"problem\"\t5\n",
      "\"problematic\"\t1\n",
      "\"problems\"\t5\n",
      "\"procedures\"\t3\n",
      "\"proceed\"\t2\n",
      "\"proceeds\"\t1\n",
      "\"process\"\t13\n",
      "\"processed\"\t2\n",
      "\"processes\"\t2\n",
      "\"processing\"\t8\n",
      "\"processor\"\t1\n",
      "\"procrustes\"\t1\n",
      "\"procurement\"\t2\n",
      "\"produce\"\t2\n",
      "\"producer\"\t1\n",
      "\"producers\"\t3\n",
      "\"producing\"\t1\n",
      "\"product\"\t36\n",
      "\"production\"\t8\n",
      "\"products\"\t23\n",
      "\"professional\"\t14\n",
      "\"professionals\"\t3\n",
      "\"professor\"\t1\n",
      "\"profile\"\t3\n",
      "\"profit\"\t6\n",
      "\"profitable\"\t1\n",
      "\"profitbanners\"\t4\n",
      "\"profits\"\t1\n",
      "\"program\"\t7\n",
      "\"programs\"\t14\n",
      "\"progress\"\t2\n",
      "\"prohibited\"\t1\n",
      "\"project\"\t18\n",
      "\"projects\"\t2\n",
      "\"proliferation\"\t3\n",
      "\"prominent\"\t2\n",
      "\"promise\"\t1\n",
      "\"promised\"\t1\n",
      "\"promising\"\t1\n",
      "\"promote\"\t2\n",
      "\"promoted\"\t1\n",
      "\"promoting\"\t2\n",
      "\"promotion\"\t1\n",
      "\"promotional\"\t2\n",
      "\"prompt\"\t1\n",
      "\"properly\"\t2\n",
      "\"property\"\t2\n",
      "\"proposal\"\t9\n",
      "\"proposed\"\t3\n",
      "\"prospects\"\t1\n",
      "\"prosper\"\t3\n",
      "\"prostaff\"\t1\n",
      "\"protest\"\t2\n",
      "\"protesting\"\t1\n",
      "\"protocol\"\t1\n",
      "\"prove\"\t2\n",
      "\"proven\"\t1\n",
      "\"provide\"\t21\n",
      "\"provided\"\t3\n",
      "\"provider\"\t3\n",
      "\"providers\"\t2\n",
      "\"provides\"\t2\n",
      "\"providing\"\t6\n",
      "\"province\"\t1\n",
      "\"proxy\"\t7\n",
      "\"prozac\"\t1\n",
      "\"prriicegreat\"\t1\n",
      "\"ps\"\t1\n",
      "\"pst\"\t1\n",
      "\"psychotic\"\t1\n",
      "\"pting\"\t1\n",
      "\"pts\"\t1\n",
      "\"public\"\t2\n",
      "\"publicity\"\t1\n",
      "\"published\"\t5\n",
      "\"publishes\"\t1\n",
      "\"publishing\"\t2\n",
      "\"puc\"\t3\n",
      "\"pull\"\t5\n",
      "\"pulled\"\t1\n",
      "\"pulling\"\t1\n",
      "\"pulp\"\t1\n",
      "\"pun\"\t1\n",
      "\"purchase\"\t11\n",
      "\"purchased\"\t1\n",
      "\"purchases\"\t3\n",
      "\"purchasing\"\t2\n",
      "\"pure\"\t1\n",
      "\"purpose\"\t6\n",
      "\"purposefully\"\t1\n",
      "\"pursuing\"\t1\n",
      "\"pushed\"\t1\n",
      "\"pushes\"\t1\n",
      "\"pushing\"\t1\n",
      "\"put\"\t12\n",
      "\"putpeel\"\t8\n",
      "\"puts\"\t1\n",
      "\"pwarden\"\t1\n",
      "\"quadrangular\"\t1\n",
      "\"qualification\"\t3\n",
      "\"qualified\"\t1\n",
      "\"qualities\"\t1\n",
      "\"quality\"\t15\n",
      "\"qualityproducts\"\t1\n",
      "\"quark\"\t1\n",
      "\"quarter\"\t1\n",
      "\"quasi\"\t1\n",
      "\"queensland\"\t2\n",
      "\"question\"\t11\n",
      "\"questions\"\t36\n",
      "\"quick\"\t3\n",
      "\"quickens\"\t1\n",
      "\"quickly\"\t7\n",
      "\"quite\"\t4\n",
      "\"quitting\"\t1\n",
      "\"quote\"\t1\n",
      "\"quoted\"\t4\n",
      "\"quotes\"\t3\n",
      "\"rabey\"\t1\n",
      "\"rac\"\t1\n",
      "\"race\"\t1\n",
      "\"rail\"\t3\n",
      "\"railing\"\t1\n",
      "\"raise\"\t2\n",
      "\"raised\"\t2\n",
      "\"raises\"\t2\n",
      "\"raising\"\t1\n",
      "\"ram\"\t2\n",
      "\"ramupgradeable\"\t1\n",
      "\"ran\"\t2\n",
      "\"ranch\"\t10\n",
      "\"randall\"\t2\n",
      "\"randle\"\t1\n",
      "\"randomly\"\t1\n",
      "\"randy\"\t1\n",
      "\"ranen\"\t1\n",
      "\"range\"\t2\n",
      "\"rankings\"\t1\n",
      "\"ranks\"\t2\n",
      "\"rapidly\"\t1\n",
      "\"rare\"\t1\n",
      "\"rat\"\t2\n",
      "\"rate\"\t33\n",
      "\"rated\"\t3\n",
      "\"rates\"\t7\n",
      "\"rather\"\t6\n",
      "\"rating\"\t2\n",
      "\"ratio\"\t1\n",
      "\"ravi\"\t6\n",
      "\"ray\"\t4\n",
      "\"raymond\"\t7\n",
      "\"rd\"\t1\n",
      "\"re\"\t33\n",
      "\"rea\"\t1\n",
      "\"reach\"\t7\n",
      "\"reached\"\t3\n",
      "\"reaching\"\t1\n",
      "\"read\"\t18\n",
      "\"reader\"\t23\n",
      "\"readers\"\t3\n",
      "\"readies\"\t1\n",
      "\"reading\"\t1\n",
      "\"reado\"\t1\n",
      "\"reads\"\t2\n",
      "\"ready\"\t5\n",
      "\"real\"\t14\n",
      "\"realize\"\t3\n",
      "\"really\"\t7\n",
      "\"rear\"\t1\n",
      "\"reason\"\t7\n",
      "\"reasonable\"\t2\n",
      "\"reasons\"\t1\n",
      "\"reassigned\"\t1\n",
      "\"rebecca\"\t2\n",
      "\"rebel\"\t2\n",
      "\"rebels\"\t2\n",
      "\"recap\"\t3\n",
      "\"receipt\"\t6\n",
      "\"receipts\"\t1\n",
      "\"receivable\"\t1\n",
      "\"receive\"\t12\n",
      "\"received\"\t5\n",
      "\"receives\"\t4\n",
      "\"receiving\"\t5\n",
      "\"recent\"\t3\n",
      "\"recently\"\t5\n",
      "\"reception\"\t1\n",
      "\"recieved\"\t2\n",
      "\"recipient\"\t2\n",
      "\"reclaimers\"\t1\n",
      "\"recognition\"\t1\n",
      "\"recognizing\"\t4\n",
      "\"recommend\"\t1\n",
      "\"recommendation\"\t1\n",
      "\"recommendations\"\t4\n",
      "\"record\"\t2\n",
      "\"recorded\"\t1\n",
      "\"recover\"\t2\n",
      "\"recovery\"\t2\n",
      "\"recruiting\"\t3\n",
      "\"red\"\t2\n",
      "\"redesign\"\t2\n",
      "\"redesigns\"\t1\n",
      "\"redhat\"\t1\n",
      "\"reduce\"\t1\n",
      "\"reduced\"\t1\n",
      "\"reduces\"\t2\n",
      "\"reduction\"\t4\n",
      "\"ref\"\t2\n",
      "\"refer\"\t2\n",
      "\"reference\"\t2\n",
      "\"references\"\t1\n",
      "\"referendum\"\t6\n",
      "\"referral\"\t2\n",
      "\"referred\"\t2\n",
      "\"refinances\"\t2\n",
      "\"reflect\"\t1\n",
      "\"reflected\"\t1\n",
      "\"reflections\"\t1\n",
      "\"reflux\"\t1\n",
      "\"refugee\"\t3\n",
      "\"refusals\"\t1\n",
      "\"refuse\"\t1\n",
      "\"regard\"\t9\n",
      "\"regarding\"\t2\n",
      "\"regardless\"\t4\n",
      "\"regards\"\t7\n",
      "\"regina\"\t6\n",
      "\"region\"\t6\n",
      "\"regional\"\t11\n",
      "\"regions\"\t6\n",
      "\"registered\"\t4\n",
      "\"regretful\"\t1\n",
      "\"regulations\"\t3\n",
      "\"reins\"\t1\n",
      "\"reiterate\"\t1\n",
      "\"rejoice\"\t1\n",
      "\"related\"\t2\n",
      "\"relates\"\t1\n",
      "\"relating\"\t2\n",
      "\"relation\"\t1\n",
      "\"relations\"\t3\n",
      "\"relationship\"\t6\n",
      "\"relative\"\t2\n",
      "\"release\"\t1\n",
      "\"released\"\t4\n",
      "\"releases\"\t2\n",
      "\"relegated\"\t1\n",
      "\"reliant\"\t4\n",
      "\"reliantenergy\"\t3\n",
      "\"relieved\"\t1\n",
      "\"relieves\"\t1\n",
      "\"remain\"\t1\n",
      "\"remainder\"\t2\n",
      "\"remaining\"\t3\n",
      "\"remember\"\t13\n",
      "\"remind\"\t2\n",
      "\"reminder\"\t1\n",
      "\"remitted\"\t1\n",
      "\"removal\"\t1\n",
      "\"remove\"\t6\n",
      "\"removed\"\t4\n",
      "\"removes\"\t1\n",
      "\"removing\"\t1\n",
      "\"remunerate\"\t1\n",
      "\"renewable\"\t2\n",
      "\"rennie\"\t1\n",
      "\"rental\"\t1\n",
      "\"repeal\"\t1\n",
      "\"repeatedly\"\t2\n",
      "\"replace\"\t2\n",
      "\"replay\"\t2\n",
      "\"replies\"\t3\n",
      "\"repling\"\t1\n",
      "\"reply\"\t5\n",
      "\"replying\"\t1\n",
      "\"report\"\t14\n",
      "\"reportedly\"\t2\n",
      "\"reporting\"\t10\n",
      "\"reports\"\t1\n",
      "\"representatives\"\t2\n",
      "\"republicans\"\t2\n",
      "\"reputation\"\t2\n",
      "\"request\"\t14\n",
      "\"requesting\"\t1\n",
      "\"require\"\t3\n",
      "\"required\"\t2\n",
      "\"requirement\"\t1\n",
      "\"requirements\"\t5\n",
      "\"requires\"\t1\n",
      "\"requiring\"\t1\n",
      "\"reread\"\t1\n",
      "\"research\"\t5\n",
      "\"resell\"\t1\n",
      "\"reseller\"\t1\n",
      "\"reservation\"\t1\n",
      "\"reserve\"\t2\n",
      "\"reserved\"\t3\n",
      "\"residents\"\t1\n",
      "\"residue\"\t1\n",
      "\"resistance\"\t1\n",
      "\"resolve\"\t4\n",
      "\"resolved\"\t1\n",
      "\"resort\"\t2\n",
      "\"resource\"\t5\n",
      "\"resourceful\"\t1\n",
      "\"resources\"\t23\n",
      "\"resourcestocks\"\t1\n",
      "\"respect\"\t4\n",
      "\"respectable\"\t1\n",
      "\"respected\"\t1\n",
      "\"respective\"\t2\n",
      "\"respond\"\t8\n",
      "\"response\"\t4\n",
      "\"responses\"\t8\n",
      "\"responsibilites\"\t2\n",
      "\"responsibilities\"\t7\n",
      "\"responsibility\"\t10\n",
      "\"responsible\"\t4\n",
      "\"rest\"\t5\n",
      "\"restate\"\t1\n",
      "\"restless\"\t1\n",
      "\"restore\"\t1\n",
      "\"restrictions\"\t1\n",
      "\"result\"\t2\n",
      "\"resulted\"\t2\n",
      "\"results\"\t6\n",
      "\"resume\"\t3\n",
      "\"retail\"\t4\n",
      "\"retains\"\t3\n",
      "\"retarding\"\t1\n",
      "\"retentive\"\t1\n",
      "\"retire\"\t3\n",
      "\"retired\"\t2\n",
      "\"retirement\"\t1\n",
      "\"return\"\t8\n",
      "\"returned\"\t2\n",
      "\"rev\"\t4\n",
      "\"revenue\"\t2\n",
      "\"reversed\"\t2\n",
      "\"review\"\t12\n",
      "\"reviewed\"\t4\n",
      "\"reviewing\"\t1\n",
      "\"reviews\"\t6\n",
      "\"revised\"\t2\n",
      "\"revolution\"\t2\n",
      "\"revolutionary\"\t1\n",
      "\"rewarding\"\t2\n",
      "\"rewrite\"\t2\n",
      "\"rge\"\t1\n",
      "\"rhine\"\t1\n",
      "\"rhinopez\"\t1\n",
      "\"rich\"\t1\n",
      "\"richard\"\t3\n",
      "\"richarddaniel\"\t1\n",
      "\"riches\"\t1\n",
      "\"rick\"\t11\n",
      "\"rid\"\t1\n",
      "\"ride\"\t2\n",
      "\"ridiculous\"\t1\n",
      "\"riding\"\t1\n",
      "\"riedel\"\t1\n",
      "\"right\"\t17\n",
      "\"rightly\"\t1\n",
      "\"rights\"\t4\n",
      "\"rise\"\t1\n",
      "\"rising\"\t1\n",
      "\"risk\"\t49\n",
      "\"rita\"\t3\n",
      "\"river\"\t2\n",
      "\"riverdeep\"\t1\n",
      "\"rizzi\"\t2\n",
      "\"rm\"\t1\n",
      "\"rmation\"\t1\n",
      "\"road\"\t2\n",
      "\"roared\"\t1\n",
      "\"rob\"\t3\n",
      "\"robert\"\t7\n",
      "\"roberts\"\t9\n",
      "\"rock\"\t2\n",
      "\"rodgers\"\t1\n",
      "\"rodney\"\t1\n",
      "\"rodriguez\"\t2\n",
      "\"rogram\"\t1\n",
      "\"rohan\"\t1\n",
      "\"roibot\"\t3\n",
      "\"role\"\t18\n",
      "\"roll\"\t1\n",
      "\"roman\"\t4\n",
      "\"romantic\"\t1\n",
      "\"romeo\"\t1\n",
      "\"roof\"\t2\n",
      "\"rook\"\t1\n",
      "\"room\"\t3\n",
      "\"rosalie\"\t1\n",
      "\"rosel\"\t2\n",
      "\"rosenfield\"\t6\n",
      "\"ross\"\t4\n",
      "\"rossman\"\t12\n",
      "\"round\"\t1\n",
      "\"routes\"\t1\n",
      "\"roving\"\t6\n",
      "\"roxio\"\t1\n",
      "\"rsa\"\t1\n",
      "\"rsbaker\"\t1\n",
      "\"rto\"\t1\n",
      "\"rtol\"\t1\n",
      "\"ruanda\"\t1\n",
      "\"rub\"\t1\n",
      "\"rudl\"\t2\n",
      "\"ruin\"\t1\n",
      "\"rule\"\t2\n",
      "\"rules\"\t1\n",
      "\"ruling\"\t2\n",
      "\"run\"\t2\n",
      "\"runkel\"\t1\n",
      "\"running\"\t7\n",
      "\"rush\"\t1\n",
      "\"rushed\"\t1\n",
      "\"russell\"\t1\n",
      "\"ruzika\"\t1\n",
      "\"rvsq\"\t1\n",
      "\"rw\"\t1\n",
      "\"rx\"\t1\n",
      "\"ryanmcgeachie\"\t1\n",
      "\"sa\"\t4\n",
      "\"saa\"\t1\n",
      "\"saave\"\t7\n",
      "\"safe\"\t5\n",
      "\"safely\"\t2\n",
      "\"safety\"\t2\n",
      "\"said\"\t3\n",
      "\"salaried\"\t1\n",
      "\"sale\"\t10\n",
      "\"sales\"\t43\n",
      "\"sallen\"\t1\n",
      "\"sally\"\t34\n",
      "\"salomon\"\t2\n",
      "\"salt\"\t1\n",
      "\"sam\"\t3\n",
      "\"samarium\"\t1\n",
      "\"same\"\t13\n",
      "\"samer\"\t5\n",
      "\"sample\"\t6\n",
      "\"sampling\"\t1\n",
      "\"samuel\"\t1\n",
      "\"san\"\t4\n",
      "\"sand\"\t1\n",
      "\"sandton\"\t2\n",
      "\"sang\"\t1\n",
      "\"sanibel\"\t1\n",
      "\"sankoh\"\t3\n",
      "\"sap\"\t17\n",
      "\"sapphire\"\t1\n",
      "\"sat\"\t1\n",
      "\"satisfied\"\t4\n",
      "\"saturday\"\t1\n",
      "\"save\"\t8\n",
      "\"saving\"\t2\n",
      "\"savings\"\t1\n",
      "\"savvy\"\t1\n",
      "\"saw\"\t1\n",
      "\"say\"\t6\n",
      "\"saying\"\t4\n",
      "\"says\"\t3\n",
      "\"sc\"\t5\n",
      "\"scampbell\"\t1\n",
      "\"scams\"\t1\n",
      "\"scenario\"\t1\n",
      "\"schafer\"\t1\n",
      "\"schaffer\"\t1\n",
      "\"schedule\"\t8\n",
      "\"scheduled\"\t3\n",
      "\"scheduling\"\t4\n",
      "\"schmidt\"\t4\n",
      "\"school\"\t2\n",
      "\"schott\"\t1\n",
      "\"schumack\"\t3\n",
      "\"science\"\t1\n",
      "\"scientific\"\t1\n",
      "\"scope\"\t2\n",
      "\"score\"\t1\n",
      "\"scott\"\t2\n",
      "\"scotty\"\t1\n",
      "\"scout\"\t1\n",
      "\"scratch\"\t1\n",
      "\"screamed\"\t1\n",
      "\"screaming\"\t1\n",
      "\"screen\"\t1\n",
      "\"screening\"\t1\n",
      "\"screwball\"\t1\n",
      "\"script\"\t3\n",
      "\"scroll\"\t3\n",
      "\"scuttle\"\t1\n",
      "\"sdba\"\t1\n",
      "\"sds\"\t1\n",
      "\"search\"\t4\n",
      "\"searching\"\t2\n",
      "\"season\"\t1\n",
      "\"second\"\t4\n",
      "\"secret\"\t8\n",
      "\"secrets\"\t5\n",
      "\"section\"\t4\n",
      "\"sector\"\t3\n",
      "\"secure\"\t3\n",
      "\"secured\"\t1\n",
      "\"securities\"\t5\n",
      "\"securitization\"\t3\n",
      "\"security\"\t10\n",
      "\"see\"\t34\n",
      "\"seeded\"\t1\n",
      "\"seeing\"\t1\n",
      "\"seem\"\t3\n",
      "\"seemed\"\t2\n",
      "\"seems\"\t4\n",
      "\"seen\"\t4\n",
      "\"seize\"\t2\n",
      "\"selected\"\t1\n",
      "\"selection\"\t4\n",
      "\"self\"\t4\n",
      "\"sell\"\t8\n",
      "\"sellens\"\t1\n",
      "\"selling\"\t11\n",
      "\"sellinternetaccess\"\t5\n",
      "\"sells\"\t2\n",
      "\"semester\"\t1\n",
      "\"sempra\"\t1\n",
      "\"sempratrading\"\t1\n",
      "\"sen\"\t1\n",
      "\"senate\"\t2\n",
      "\"senator\"\t5\n",
      "\"send\"\t23\n",
      "\"sending\"\t1\n",
      "\"sengupta\"\t1\n",
      "\"senior\"\t11\n",
      "\"sense\"\t3\n",
      "\"sensitive\"\t2\n",
      "\"sent\"\t16\n",
      "\"sentence\"\t2\n",
      "\"sentences\"\t4\n",
      "\"sentiment\"\t1\n",
      "\"separate\"\t7\n",
      "\"sera\"\t2\n",
      "\"sergeev\"\t5\n",
      "\"serial\"\t2\n",
      "\"serious\"\t1\n",
      "\"serve\"\t6\n",
      "\"served\"\t1\n",
      "\"server\"\t5\n",
      "\"servers\"\t2\n",
      "\"service\"\t48\n",
      "\"services\"\t16\n",
      "\"session\"\t1\n",
      "\"sessions\"\t2\n",
      "\"set\"\t15\n",
      "\"setbacks\"\t1\n",
      "\"settanni\"\t1\n",
      "\"setting\"\t3\n",
      "\"settingt\"\t1\n",
      "\"settled\"\t3\n",
      "\"settlement\"\t2\n",
      "\"settlements\"\t2\n",
      "\"setup\"\t5\n",
      "\"seven\"\t5\n",
      "\"seventhpower\"\t4\n",
      "\"several\"\t17\n",
      "\"severe\"\t1\n",
      "\"seward\"\t1\n",
      "\"sex\"\t1\n",
      "\"sexual\"\t2\n",
      "\"sezgen\"\t4\n",
      "\"shakespeare\"\t3\n",
      "\"shall\"\t9\n",
      "\"shanbhogue\"\t5\n",
      "\"shandong\"\t1\n",
      "\"share\"\t8\n",
      "\"shared\"\t4\n",
      "\"shares\"\t1\n",
      "\"sharing\"\t3\n",
      "\"sharpens\"\t1\n",
      "\"sharply\"\t1\n",
      "\"she\"\t18\n",
      "\"sheila\"\t4\n",
      "\"shenkman\"\t1\n",
      "\"sherlyn\"\t3\n",
      "\"sherri\"\t2\n",
      "\"shift\"\t2\n",
      "\"shiip\"\t2\n",
      "\"shipped\"\t1\n",
      "\"shipping\"\t1\n",
      "\"shirley\"\t18\n",
      "\"shoot\"\t1\n",
      "\"shop\"\t3\n",
      "\"shopping\"\t5\n",
      "\"short\"\t8\n",
      "\"shorter\"\t1\n",
      "\"shortly\"\t1\n",
      "\"shot\"\t1\n",
      "\"should\"\t27\n",
      "\"shoulder\"\t1\n",
      "\"show\"\t7\n",
      "\"showcase\"\t20\n",
      "\"showcases\"\t6\n",
      "\"shown\"\t2\n",
      "\"shows\"\t1\n",
      "\"shults\"\t1\n",
      "\"shut\"\t1\n",
      "\"shutdown\"\t1\n",
      "\"shwc\"\t1\n",
      "\"shy\"\t1\n",
      "\"siberia\"\t1\n",
      "\"sibilant\"\t1\n",
      "\"sick\"\t1\n",
      "\"side\"\t2\n",
      "\"sides\"\t1\n",
      "\"sierra\"\t5\n",
      "\"sight\"\t1\n",
      "\"sign\"\t4\n",
      "\"signature\"\t1\n",
      "\"signed\"\t4\n",
      "\"significance\"\t1\n",
      "\"significant\"\t4\n",
      "\"signing\"\t1\n",
      "\"signups\"\t1\n",
      "\"sillily\"\t1\n",
      "\"silver\"\t1\n",
      "\"similes\"\t1\n",
      "\"simple\"\t10\n",
      "\"simplicity\"\t4\n",
      "\"simply\"\t5\n",
      "\"since\"\t13\n",
      "\"sincerely\"\t4\n",
      "\"singing\"\t1\n",
      "\"single\"\t4\n",
      "\"singleton\"\t1\n",
      "\"sink\"\t1\n",
      "\"sir\"\t2\n",
      "\"sit\"\t1\n",
      "\"sitara\"\t3\n",
      "\"site\"\t60\n",
      "\"sites\"\t31\n",
      "\"situation\"\t4\n",
      "\"six\"\t3\n",
      "\"size\"\t5\n",
      "\"skilling\"\t7\n",
      "\"skills\"\t2\n",
      "\"skin\"\t1\n",
      "\"skinner\"\t3\n",
      "\"slash\"\t1\n",
      "\"slaver\"\t1\n",
      "\"sleep\"\t2\n",
      "\"slgavjmoqq\"\t1\n",
      "\"slightly\"\t1\n",
      "\"slipped\"\t1\n",
      "\"slots\"\t1\n",
      "\"slotting\"\t1\n",
      "\"slow\"\t3\n",
      "\"slower\"\t1\n",
      "\"slowly\"\t1\n",
      "\"small\"\t3\n",
      "\"smaller\"\t7\n",
      "\"smith\"\t7\n",
      "\"smithc\"\t1\n",
      "\"smoker\"\t1\n",
      "\"smoking\"\t7\n",
      "\"sneak\"\t2\n",
      "\"snhezkjzhisbpjhgx\"\t1\n",
      "\"snooping\"\t1\n",
      "\"snowboard\"\t1\n",
      "\"so\"\t60\n",
      "\"soap\"\t2\n",
      "\"socal\"\t4\n",
      "\"softtwares\"\t2\n",
      "\"software\"\t13\n",
      "\"softwares\"\t1\n",
      "\"sokolov\"\t4\n",
      "\"sold\"\t2\n",
      "\"solely\"\t1\n",
      "\"solicit\"\t1\n",
      "\"solicitation\"\t2\n",
      "\"solid\"\t1\n",
      "\"solmonson\"\t1\n",
      "\"solution\"\t2\n",
      "\"solved\"\t1\n",
      "\"soma\"\t1\n",
      "\"some\"\t68\n",
      "\"somehow\"\t1\n",
      "\"someone\"\t11\n",
      "\"something\"\t8\n",
      "\"sometime\"\t2\n",
      "\"sometimes\"\t1\n",
      "\"somewhat\"\t1\n",
      "\"son\"\t10\n",
      "\"songs\"\t1\n",
      "\"soon\"\t9\n",
      "\"sorry\"\t2\n",
      "\"sos\"\t1\n",
      "\"sotware\"\t1\n",
      "\"sound\"\t3\n",
      "\"soundmax\"\t1\n",
      "\"sounds\"\t1\n",
      "\"source\"\t5\n",
      "\"sources\"\t7\n",
      "\"south\"\t15\n",
      "\"southern\"\t1\n",
      "\"southernenergy\"\t2\n",
      "\"southwest\"\t1\n",
      "\"souza\"\t1\n",
      "\"sp\"\t1\n",
      "\"space\"\t7\n",
      "\"spam\"\t7\n",
      "\"spare\"\t1\n",
      "\"spark\"\t2\n",
      "\"speak\"\t8\n",
      "\"speaking\"\t1\n",
      "\"special\"\t14\n",
      "\"specials\"\t4\n",
      "\"specific\"\t7\n",
      "\"specifically\"\t4\n",
      "\"speed\"\t2\n",
      "\"speeding\"\t1\n",
      "\"speeds\"\t1\n",
      "\"spell\"\t2\n",
      "\"spelling\"\t3\n",
      "\"spend\"\t8\n",
      "\"spending\"\t1\n",
      "\"spent\"\t4\n",
      "\"spigot\"\t1\n",
      "\"spirit\"\t2\n",
      "\"split\"\t2\n",
      "\"splitting\"\t1\n",
      "\"spoke\"\t2\n",
      "\"spoken\"\t2\n",
      "\"sponsor\"\t4\n",
      "\"sponsored\"\t1\n",
      "\"sponsoring\"\t1\n",
      "\"sponsorship\"\t9\n",
      "\"sportsbetting\"\t2\n",
      "\"spot\"\t5\n",
      "\"spotlight\"\t1\n",
      "\"spp\"\t1\n",
      "\"spread\"\t1\n",
      "\"spreads\"\t1\n",
      "\"spring\"\t1\n",
      "\"sql\"\t1\n",
      "\"squeeze\"\t1\n",
      "\"squill\"\t1\n",
      "\"sr\"\t1\n",
      "\"srs\"\t1\n",
      "\"ss\"\t1\n",
      "\"ssb\"\t1\n",
      "\"ssmb\"\t1\n",
      "\"st\"\t3\n",
      "\"stability\"\t3\n",
      "\"stable\"\t1\n",
      "\"stacey\"\t4\n",
      "\"stacy\"\t1\n",
      "\"stad\"\t1\n",
      "\"staff\"\t5\n",
      "\"stage\"\t2\n",
      "\"stake\"\t2\n",
      "\"stalling\"\t1\n",
      "\"stand\"\t2\n",
      "\"standard\"\t3\n",
      "\"standing\"\t6\n",
      "\"stands\"\t1\n",
      "\"star\"\t2\n",
      "\"stars\"\t1\n",
      "\"start\"\t9\n",
      "\"startbgmlmezine\"\t2\n",
      "\"started\"\t3\n",
      "\"starting\"\t1\n",
      "\"state\"\t30\n",
      "\"stated\"\t2\n",
      "\"statement\"\t1\n",
      "\"statements\"\t1\n",
      "\"states\"\t5\n",
      "\"station\"\t2\n",
      "\"stats\"\t2\n",
      "\"status\"\t1\n",
      "\"stay\"\t2\n",
      "\"stayed\"\t1\n",
      "\"steadily\"\t1\n",
      "\"steak\"\t1\n",
      "\"stearns\"\t2\n",
      "\"steeves\"\t2\n",
      "\"stefkatz\"\t1\n",
      "\"stella\"\t6\n",
      "\"stelly\"\t1\n",
      "\"stentofon\"\t2\n",
      "\"step\"\t2\n",
      "\"stephanie\"\t1\n",
      "\"steps\"\t1\n",
      "\"stern\"\t1\n",
      "\"steve\"\t3\n",
      "\"stick\"\t2\n",
      "\"stil\"\t2\n",
      "\"still\"\t12\n",
      "\"stilled\"\t1\n",
      "\"stinson\"\t8\n",
      "\"stock\"\t5\n",
      "\"stocker\"\t1\n",
      "\"stockhouse\"\t1\n",
      "\"stomaching\"\t1\n",
      "\"stood\"\t1\n",
      "\"stop\"\t15\n",
      "\"stopping\"\t3\n",
      "\"store\"\t2\n",
      "\"stores\"\t6\n",
      "\"stories\"\t4\n",
      "\"story\"\t17\n",
      "\"stove\"\t1\n",
      "\"straight\"\t4\n",
      "\"strain\"\t1\n",
      "\"strangas\"\t1\n",
      "\"strange\"\t2\n",
      "\"strangulate\"\t1\n",
      "\"stratagem\"\t1\n",
      "\"strategic\"\t3\n",
      "\"strategies\"\t5\n",
      "\"strategist\"\t2\n",
      "\"strategy\"\t2\n",
      "\"stratton\"\t1\n",
      "\"streams\"\t2\n",
      "\"street\"\t1\n",
      "\"streets\"\t1\n",
      "\"strength\"\t1\n",
      "\"strengthened\"\t1\n",
      "\"strengthening\"\t1\n",
      "\"strengths\"\t2\n",
      "\"stress\"\t5\n",
      "\"stretch\"\t3\n",
      "\"strictly\"\t1\n",
      "\"strides\"\t2\n",
      "\"striking\"\t1\n",
      "\"strong\"\t2\n",
      "\"stronger\"\t2\n",
      "\"stroock\"\t1\n",
      "\"struck\"\t2\n",
      "\"structure\"\t5\n",
      "\"students\"\t4\n",
      "\"studio\"\t2\n",
      "\"stuff\"\t4\n",
      "\"stukm\"\t1\n",
      "\"stupid\"\t1\n",
      "\"stupidity\"\t1\n",
      "\"style\"\t1\n",
      "\"styles\"\t1\n",
      "\"subconsciously\"\t1\n",
      "\"subject\"\t53\n",
      "\"submissions\"\t4\n",
      "\"submit\"\t10\n",
      "\"submitted\"\t1\n",
      "\"subscribe\"\t7\n",
      "\"subscribed\"\t4\n",
      "\"subscribers\"\t1\n",
      "\"subscribing\"\t1\n",
      "\"subscription\"\t10\n",
      "\"subscriptions\"\t1\n",
      "\"subsequently\"\t1\n",
      "\"substantial\"\t2\n",
      "\"succeed\"\t3\n",
      "\"succeeded\"\t1\n",
      "\"succeeding\"\t1\n",
      "\"succeeds\"\t1\n",
      "\"success\"\t25\n",
      "\"successes\"\t3\n",
      "\"successful\"\t17\n",
      "\"successfully\"\t1\n",
      "\"such\"\t9\n",
      "\"sue\"\t3\n",
      "\"sugar\"\t3\n",
      "\"suggest\"\t2\n",
      "\"suggested\"\t1\n",
      "\"suggestions\"\t5\n",
      "\"suite\"\t5\n",
      "\"sum\"\t3\n",
      "\"summary\"\t5\n",
      "\"summer\"\t5\n",
      "\"summit\"\t1\n",
      "\"sunrise\"\t1\n",
      "\"sup\"\t1\n",
      "\"super\"\t5\n",
      "\"superb\"\t1\n",
      "\"superman\"\t1\n",
      "\"supervisor\"\t4\n",
      "\"supervisors\"\t5\n",
      "\"supplier\"\t2\n",
      "\"suppliers\"\t6\n",
      "\"supply\"\t4\n",
      "\"support\"\t16\n",
      "\"supported\"\t1\n",
      "\"supporting\"\t6\n",
      "\"supportive\"\t1\n",
      "\"supports\"\t3\n",
      "\"supposedly\"\t1\n",
      "\"suppressant\"\t1\n",
      "\"suprervisagra\"\t1\n",
      "\"sure\"\t11\n",
      "\"surf\"\t5\n",
      "\"surfing\"\t1\n",
      "\"surfola\"\t4\n",
      "\"surged\"\t1\n",
      "\"surgery\"\t1\n",
      "\"surrounding\"\t1\n",
      "\"survey\"\t3\n",
      "\"susan\"\t9\n",
      "\"suspicion\"\t1\n",
      "\"sustainability\"\t1\n",
      "\"suzms\"\t1\n",
      "\"swap\"\t2\n",
      "\"swbe\"\t1\n",
      "\"sweet\"\t3\n",
      "\"swidner\"\t1\n",
      "\"swift\"\t2\n",
      "\"swings\"\t1\n",
      "\"swiss\"\t2\n",
      "\"switch\"\t1\n",
      "\"switchman\"\t1\n",
      "\"sydney\"\t2\n",
      "\"sylg\"\t1\n",
      "\"symaantec\"\t1\n",
      "\"syndicate\"\t1\n",
      "\"system\"\t13\n",
      "\"systems\"\t6\n",
      "\"systemslogical\"\t1\n",
      "\"table\"\t2\n",
      "\"tablet\"\t1\n",
      "\"tablets\"\t1\n",
      "\"tactically\"\t1\n",
      "\"tag\"\t1\n",
      "\"take\"\t19\n",
      "\"takegreat\"\t1\n",
      "\"taken\"\t2\n",
      "\"takeover\"\t2\n",
      "\"takes\"\t7\n",
      "\"taking\"\t4\n",
      "\"takriti\"\t5\n",
      "\"talent\"\t2\n",
      "\"talk\"\t7\n",
      "\"talked\"\t1\n",
      "\"talking\"\t2\n",
      "\"talks\"\t3\n",
      "\"tall\"\t1\n",
      "\"tamarchenko\"\t4\n",
      "\"tang\"\t5\n",
      "\"tangible\"\t1\n",
      "\"tantalum\"\t1\n",
      "\"tanya\"\t4\n",
      "\"target\"\t9\n",
      "\"targeted\"\t11\n",
      "\"targeting\"\t1\n",
      "\"tarrif\"\t2\n",
      "\"tarrin\"\t1\n",
      "\"task\"\t2\n",
      "\"taught\"\t1\n",
      "\"tax\"\t1\n",
      "\"taxation\"\t1\n",
      "\"taylor\"\t4\n",
      "\"taylorja\"\t1\n",
      "\"tea\"\t2\n",
      "\"teach\"\t1\n",
      "\"teacher\"\t1\n",
      "\"teachers\"\t1\n",
      "\"team\"\t19\n",
      "\"tear\"\t1\n",
      "\"tears\"\t1\n",
      "\"technical\"\t3\n",
      "\"technicalities\"\t1\n",
      "\"techniques\"\t5\n",
      "\"technology\"\t3\n",
      "\"teco\"\t2\n",
      "\"teddy\"\t3\n",
      "\"tejones\"\t2\n",
      "\"tel\"\t3\n",
      "\"tele\"\t1\n",
      "\"telephone\"\t3\n",
      "\"teleseminar\"\t2\n",
      "\"television\"\t1\n",
      "\"tell\"\t13\n",
      "\"telling\"\t1\n",
      "\"tells\"\t1\n",
      "\"tempted\"\t1\n",
      "\"tenacity\"\t1\n",
      "\"tenderer\"\t1\n",
      "\"tendererlycopodium\"\t1\n",
      "\"teosrest\"\t1\n",
      "\"terence\"\t1\n",
      "\"term\"\t8\n",
      "\"terminate\"\t1\n",
      "\"terms\"\t5\n",
      "\"terrible\"\t1\n",
      "\"terrific\"\t1\n",
      "\"terrorist\"\t1\n",
      "\"terry\"\t1\n",
      "\"test\"\t1\n",
      "\"testimonials\"\t2\n",
      "\"texaco\"\t6\n",
      "\"texas\"\t1\n",
      "\"text\"\t15\n",
      "\"texts\"\t2\n",
      "\"textual\"\t1\n",
      "\"texture\"\t1\n",
      "\"textures\"\t1\n",
      "\"tgary\"\t1\n",
      "\"th\"\t14\n",
      "\"than\"\t32\n",
      "\"thank\"\t9\n",
      "\"thanking\"\t3\n",
      "\"thanks\"\t34\n",
      "\"that\"\t227\n",
      "\"the\"\t1247\n",
      "\"theinvestment\"\t1\n",
      "\"their\"\t40\n",
      "\"them\"\t56\n",
      "\"themselves\"\t4\n",
      "\"then\"\t28\n",
      "\"theqgrefor\"\t1\n",
      "\"there\"\t56\n",
      "\"thereafter\"\t2\n",
      "\"therefore\"\t7\n",
      "\"thereof\"\t1\n",
      "\"these\"\t50\n",
      "\"they\"\t63\n",
      "\"thickness\"\t1\n",
      "\"thimble\"\t1\n",
      "\"thing\"\t13\n",
      "\"things\"\t8\n",
      "\"think\"\t11\n",
      "\"thinking\"\t1\n",
      "\"third\"\t3\n",
      "\"thirteen\"\t1\n",
      "\"thirty\"\t3\n",
      "\"this\"\t262\n",
      "\"thompson\"\t1\n",
      "\"thorns\"\t1\n",
      "\"thoroughly\"\t1\n",
      "\"those\"\t15\n",
      "\"though\"\t6\n",
      "\"thought\"\t2\n",
      "\"thoughts\"\t2\n",
      "\"thousainds\"\t1\n",
      "\"thousand\"\t2\n",
      "\"thousands\"\t3\n",
      "\"threat\"\t4\n",
      "\"threats\"\t2\n",
      "\"three\"\t17\n",
      "\"thrid\"\t1\n",
      "\"thronged\"\t1\n",
      "\"through\"\t18\n",
      "\"throughout\"\t4\n",
      "\"throw\"\t1\n",
      "\"thu\"\t10\n",
      "\"thunder\"\t1\n",
      "\"thuraisingham\"\t6\n",
      "\"thursday\"\t11\n",
      "\"thus\"\t1\n",
      "\"ticket\"\t2\n",
      "\"tidbits\"\t1\n",
      "\"till\"\t1\n",
      "\"tilts\"\t1\n",
      "\"time\"\t44\n",
      "\"timekeeping\"\t2\n",
      "\"timely\"\t2\n",
      "\"times\"\t5\n",
      "\"timesheets\"\t1\n",
      "\"timing\"\t1\n",
      "\"timotheus\"\t1\n",
      "\"timshometownstories\"\t3\n",
      "\"tin\"\t5\n",
      "\"tinned\"\t1\n",
      "\"tips\"\t4\n",
      "\"tire\"\t1\n",
      "\"tired\"\t2\n",
      "\"tires\"\t3\n",
      "\"tithable\"\t1\n",
      "\"title\"\t4\n",
      "\"titles\"\t3\n",
      "\"tlapek\"\t5\n",
      "\"tm\"\t1\n",
      "\"to\"\t964\n",
      "\"tobacco\"\t2\n",
      "\"today\"\t34\n",
      "\"todd\"\t1\n",
      "\"together\"\t7\n",
      "\"toilet\"\t1\n",
      "\"tokyo\"\t1\n",
      "\"told\"\t6\n",
      "\"toll\"\t3\n",
      "\"tommy\"\t1\n",
      "\"tomorrow\"\t5\n",
      "\"tonai\"\t1\n",
      "\"tone\"\t1\n",
      "\"tonne\"\t1\n",
      "\"too\"\t12\n",
      "\"took\"\t3\n",
      "\"tool\"\t2\n",
      "\"toolbar\"\t7\n",
      "\"top\"\t9\n",
      "\"topic\"\t2\n",
      "\"topics\"\t1\n",
      "\"toronto\"\t1\n",
      "\"tortoises\"\t1\n",
      "\"total\"\t8\n",
      "\"touched\"\t1\n",
      "\"toward\"\t1\n",
      "\"towards\"\t4\n",
      "\"towel\"\t1\n",
      "\"towels\"\t1\n",
      "\"tower\"\t2\n",
      "\"town\"\t4\n",
      "\"toy\"\t2\n",
      "\"tr\"\t2\n",
      "\"track\"\t3\n",
      "\"tracked\"\t1\n",
      "\"tracks\"\t2\n",
      "\"trade\"\t25\n",
      "\"trademarked\"\t2\n",
      "\"trader\"\t4\n",
      "\"traders\"\t1\n",
      "\"trading\"\t29\n",
      "\"tradition\"\t1\n",
      "\"traditional\"\t2\n",
      "\"traffic\"\t10\n",
      "\"trafficmultipliers\"\t1\n",
      "\"train\"\t7\n",
      "\"training\"\t9\n",
      "\"tramadol\"\t2\n",
      "\"trans\"\t1\n",
      "\"transact\"\t1\n",
      "\"transaction\"\t5\n",
      "\"transalta\"\t1\n",
      "\"transcanada\"\t2\n",
      "\"transco\"\t2\n",
      "\"transfer\"\t12\n",
      "\"transferred\"\t3\n",
      "\"transferring\"\t2\n",
      "\"transistion\"\t5\n",
      "\"transition\"\t4\n",
      "\"transmission\"\t12\n",
      "\"transmissions\"\t1\n",
      "\"transport\"\t3\n",
      "\"transportation\"\t2\n",
      "\"transporting\"\t1\n",
      "\"trash\"\t1\n",
      "\"travel\"\t3\n",
      "\"traveling\"\t1\n",
      "\"travelling\"\t1\n",
      "\"travis\"\t1\n",
      "\"treasonous\"\t1\n",
      "\"treasurer\"\t1\n",
      "\"treat\"\t1\n",
      "\"treatment\"\t1\n",
      "\"treats\"\t1\n",
      "\"tree\"\t2\n",
      "\"trevino\"\t4\n",
      "\"trial\"\t3\n",
      "\"trials\"\t1\n",
      "\"triassic\"\t1\n",
      "\"tricky\"\t1\n",
      "\"tried\"\t5\n",
      "\"trigger\"\t2\n",
      "\"trina\"\t1\n",
      "\"trip\"\t2\n",
      "\"triple\"\t1\n",
      "\"trips\"\t1\n",
      "\"trisha\"\t1\n",
      "\"trista\"\t2\n",
      "\"troubled\"\t1\n",
      "\"true\"\t9\n",
      "\"truly\"\t1\n",
      "\"trunk\"\t2\n",
      "\"trust\"\t8\n",
      "\"trusted\"\t2\n",
      "\"truth\"\t2\n",
      "\"try\"\t10\n",
      "\"trying\"\t3\n",
      "\"tuesday\"\t4\n",
      "\"tuned\"\t1\n",
      "\"tuneful\"\t1\n",
      "\"tungsten\"\t1\n",
      "\"tuning\"\t1\n",
      "\"turk\"\t3\n",
      "\"turn\"\t3\n",
      "\"turned\"\t1\n",
      "\"turner\"\t3\n",
      "\"tw\"\t1\n",
      "\"twain\"\t1\n",
      "\"twenty\"\t4\n",
      "\"twice\"\t2\n",
      "\"two\"\t24\n",
      "\"tx\"\t3\n",
      "\"txu\"\t2\n",
      "\"txuelectric\"\t1\n",
      "\"txuenergy\"\t3\n",
      "\"tyone\"\t1\n",
      "\"type\"\t12\n",
      "\"uafn\"\t1\n",
      "\"ugh\"\t1\n",
      "\"uk\"\t4\n",
      "\"ult\"\t2\n",
      "\"ultimate\"\t1\n",
      "\"un\"\t1\n",
      "\"unable\"\t3\n",
      "\"unattainable\"\t2\n",
      "\"unavoidable\"\t1\n",
      "\"unbelievably\"\t1\n",
      "\"unblock\"\t1\n",
      "\"unblocking\"\t4\n",
      "\"unclaimed\"\t1\n",
      "\"unclear\"\t1\n",
      "\"uncollected\"\t1\n",
      "\"uncomfortable\"\t1\n",
      "\"uncover\"\t1\n",
      "\"under\"\t23\n",
      "\"undercollected\"\t1\n",
      "\"undercollection\"\t4\n",
      "\"underga\"\t1\n",
      "\"underground\"\t1\n",
      "\"underneath\"\t1\n",
      "\"understand\"\t7\n",
      "\"understanding\"\t9\n",
      "\"underwrite\"\t1\n",
      "\"undeveloped\"\t1\n",
      "\"unify\"\t3\n",
      "\"union\"\t2\n",
      "\"unions\"\t2\n",
      "\"unique\"\t2\n",
      "\"unit\"\t7\n",
      "\"united\"\t5\n",
      "\"units\"\t4\n",
      "\"universal\"\t1\n",
      "\"university\"\t1\n",
      "\"unknown\"\t6\n",
      "\"unless\"\t5\n",
      "\"unlike\"\t1\n",
      "\"unlimited\"\t4\n",
      "\"unmanly\"\t1\n",
      "\"unnecessarily\"\t2\n",
      "\"unnecessary\"\t1\n",
      "\"unocal\"\t1\n",
      "\"unprofessional\"\t1\n",
      "\"unrealistic\"\t2\n",
      "\"unsubscribe\"\t16\n",
      "\"unsubscribed\"\t1\n",
      "\"until\"\t17\n",
      "\"untouchable\"\t1\n",
      "\"unwarranted\"\t1\n",
      "\"up\"\t47\n",
      "\"upcoming\"\t1\n",
      "\"update\"\t13\n",
      "\"updated\"\t1\n",
      "\"upgradeable\"\t3\n",
      "\"upgraded\"\t1\n",
      "\"upgrades\"\t2\n",
      "\"upload\"\t1\n",
      "\"uploaded\"\t1\n",
      "\"upon\"\t9\n",
      "\"upping\"\t1\n",
      "\"upward\"\t1\n",
      "\"ur\"\t1\n",
      "\"uranium\"\t1\n",
      "\"urg\"\t2\n",
      "\"urgency\"\t1\n",
      "\"urgent\"\t7\n",
      "\"urgently\"\t1\n",
      "\"url\"\t3\n",
      "\"us\"\t50\n",
      "\"usage\"\t4\n",
      "\"usavity\"\t1\n",
      "\"usb\"\t1\n",
      "\"usd\"\t2\n",
      "\"use\"\t43\n",
      "\"used\"\t11\n",
      "\"useful\"\t4\n",
      "\"user\"\t8\n",
      "\"userconf\"\t1\n",
      "\"users\"\t7\n",
      "\"uses\"\t1\n",
      "\"using\"\t18\n",
      "\"utilities\"\t22\n",
      "\"utility\"\t8\n",
      "\"uuz\"\t1\n",
      "\"uvd\"\t1\n",
      "\"uwe\"\t4\n",
      "\"uz\"\t1\n",
      "\"vacation\"\t2\n",
      "\"val\"\t3\n",
      "\"valeria\"\t1\n",
      "\"valid\"\t4\n",
      "\"validate\"\t1\n",
      "\"valium\"\t3\n",
      "\"valley\"\t3\n",
      "\"valuable\"\t9\n",
      "\"valuables\"\t2\n",
      "\"value\"\t11\n",
      "\"valued\"\t1\n",
      "\"van\"\t3\n",
      "\"vanadium\"\t1\n",
      "\"vance\"\t2\n",
      "\"var\"\t1\n",
      "\"variety\"\t1\n",
      "\"vary\"\t1\n",
      "\"vasant\"\t5\n",
      "\"vastar\"\t8\n",
      "\"vaughn\"\t3\n",
      "\"vault\"\t1\n",
      "\"ve\"\t21\n",
      "\"vein\"\t1\n",
      "\"vendor\"\t2\n",
      "\"vendors\"\t1\n",
      "\"venture\"\t5\n",
      "\"verbry\"\t1\n",
      "\"verification\"\t2\n",
      "\"verify\"\t1\n",
      "\"version\"\t9\n",
      "\"versus\"\t2\n",
      "\"very\"\t31\n",
      "\"verypowerful\"\t1\n",
      "\"veteran\"\t1\n",
      "\"vi\"\t2\n",
      "\"via\"\t13\n",
      "\"viag\"\t1\n",
      "\"viagra\"\t5\n",
      "\"vic\"\t2\n",
      "\"vice\"\t9\n",
      "\"vicodin\"\t2\n",
      "\"vicqodin\"\t1\n",
      "\"victor\"\t2\n",
      "\"view\"\t11\n",
      "\"viewer\"\t1\n",
      "\"villarreal\"\t1\n",
      "\"vince\"\t17\n",
      "\"vincent\"\t5\n",
      "\"vintage\"\t2\n",
      "\"virtues\"\t1\n",
      "\"vision\"\t1\n",
      "\"visit\"\t30\n",
      "\"visited\"\t1\n",
      "\"visitor\"\t3\n",
      "\"visitors\"\t2\n",
      "\"visits\"\t1\n",
      "\"visual\"\t1\n",
      "\"visually\"\t1\n",
      "\"voice\"\t6\n",
      "\"voices\"\t1\n",
      "\"volatility\"\t4\n",
      "\"volume\"\t9\n",
      "\"volumes\"\t1\n",
      "\"voluntary\"\t1\n",
      "\"vote\"\t7\n",
      "\"voted\"\t1\n",
      "\"voting\"\t2\n",
      "\"vp\"\t1\n",
      "\"vs\"\t2\n",
      "\"vzxoaxqhg\"\t1\n",
      "\"wa\"\t2\n",
      "\"wacked\"\t1\n",
      "\"waggons\"\t1\n",
      "\"wait\"\t2\n",
      "\"walked\"\t1\n",
      "\"wall\"\t6\n",
      "\"wallis\"\t1\n",
      "\"wallow\"\t1\n",
      "\"walpole\"\t1\n",
      "\"walsh\"\t2\n",
      "\"walton\"\t2\n",
      "\"want\"\t36\n",
      "\"wanted\"\t6\n",
      "\"wanting\"\t4\n",
      "\"wants\"\t2\n",
      "\"war\"\t2\n",
      "\"ward\"\t1\n",
      "\"wardsgiftshop\"\t1\n",
      "\"warrant\"\t1\n",
      "\"warrants\"\t2\n",
      "\"warranty\"\t1\n",
      "\"was\"\t68\n",
      "\"wash\"\t1\n",
      "\"washing\"\t4\n",
      "\"washington\"\t1\n",
      "\"waste\"\t1\n",
      "\"watched\"\t1\n",
      "\"watchfully\"\t1\n",
      "\"water\"\t2\n",
      "\"watson\"\t2\n",
      "\"way\"\t10\n",
      "\"ways\"\t10\n",
      "\"wbom\"\t1\n",
      "\"we\"\t182\n",
      "\"weakness\"\t4\n",
      "\"wealth\"\t2\n",
      "\"weather\"\t2\n",
      "\"web\"\t23\n",
      "\"webmail\"\t1\n",
      "\"webmaster\"\t1\n",
      "\"webpage\"\t4\n",
      "\"website\"\t28\n",
      "\"websites\"\t2\n",
      "\"wedeliverparties\"\t1\n",
      "\"wednesday\"\t6\n",
      "\"weed\"\t1\n",
      "\"week\"\t38\n",
      "\"weekend\"\t3\n",
      "\"weekly\"\t4\n",
      "\"weeks\"\t8\n",
      "\"weep\"\t1\n",
      "\"weight\"\t2\n",
      "\"weightwheezy\"\t1\n",
      "\"weissman\"\t5\n",
      "\"welch\"\t1\n",
      "\"welcome\"\t2\n",
      "\"well\"\t25\n",
      "\"went\"\t3\n",
      "\"were\"\t26\n",
      "\"west\"\t5\n",
      "\"western\"\t6\n",
      "\"westerngas\"\t1\n",
      "\"westward\"\t1\n",
      "\"wfxu\"\t1\n",
      "\"whalley\"\t3\n",
      "\"what\"\t68\n",
      "\"whatever\"\t4\n",
      "\"whats\"\t1\n",
      "\"whatsoever\"\t3\n",
      "\"whelan\"\t1\n",
      "\"when\"\t33\n",
      "\"where\"\t13\n",
      "\"whereby\"\t2\n",
      "\"whether\"\t4\n",
      "\"which\"\t47\n",
      "\"while\"\t14\n",
      "\"whiskey\"\t1\n",
      "\"whitehorse\"\t1\n",
      "\"who\"\t27\n",
      "\"whole\"\t2\n",
      "\"wholesale\"\t15\n",
      "\"whom\"\t1\n",
      "\"whooping\"\t1\n",
      "\"whose\"\t2\n",
      "\"why\"\t11\n",
      "\"wide\"\t1\n",
      "\"widow\"\t2\n",
      "\"wife\"\t3\n",
      "\"wijsman\"\t1\n",
      "\"will\"\t234\n",
      "\"willbe\"\t1\n",
      "\"william\"\t1\n",
      "\"williams\"\t7\n",
      "\"willie\"\t1\n",
      "\"willing\"\t1\n",
      "\"wilson\"\t2\n",
      "\"win\"\t18\n",
      "\"wind\"\t1\n",
      "\"window\"\t1\n",
      "\"windows\"\t12\n",
      "\"windowsentities\"\t1\n",
      "\"windred\"\t1\n",
      "\"wing\"\t1\n",
      "\"winner\"\t3\n",
      "\"winners\"\t2\n",
      "\"winning\"\t4\n",
      "\"wisely\"\t2\n",
      "\"wisew\"\t1\n",
      "\"wish\"\t7\n",
      "\"wishes\"\t1\n",
      "\"wishing\"\t1\n",
      "\"with\"\t201\n",
      "\"withers\"\t4\n",
      "\"within\"\t25\n",
      "\"without\"\t10\n",
      "\"wives\"\t1\n",
      "\"women\"\t3\n",
      "\"won\"\t6\n",
      "\"wonder\"\t2\n",
      "\"wonderful\"\t1\n",
      "\"wondering\"\t1\n",
      "\"woo\"\t1\n",
      "\"wood\"\t1\n",
      "\"woodwork\"\t1\n",
      "\"woolgar\"\t1\n",
      "\"word\"\t9\n",
      "\"wording\"\t1\n",
      "\"words\"\t8\n",
      "\"work\"\t32\n",
      "\"workable\"\t1\n",
      "\"worked\"\t3\n",
      "\"workforce\"\t1\n",
      "\"working\"\t10\n",
      "\"workout\"\t1\n",
      "\"works\"\t11\n",
      "\"workstation\"\t1\n",
      "\"world\"\t10\n",
      "\"worldwide\"\t11\n",
      "\"worry\"\t2\n",
      "\"worrying\"\t1\n",
      "\"worse\"\t1\n",
      "\"worst\"\t1\n",
      "\"worth\"\t1\n",
      "\"worthless\"\t1\n",
      "\"worthwhile\"\t1\n",
      "\"would\"\t73\n",
      "\"wouldn\"\t4\n",
      "\"wound\"\t1\n",
      "\"wpd\"\t2\n",
      "\"wr\"\t1\n",
      "\"wrinkle\"\t1\n",
      "\"write\"\t13\n",
      "\"writing\"\t7\n",
      "\"written\"\t6\n",
      "\"wrong\"\t3\n",
      "\"wrote\"\t3\n",
      "\"ws\"\t1\n",
      "\"wsc\"\t1\n",
      "\"wugn\"\t1\n",
      "\"www\"\t46\n",
      "\"wyn\"\t2\n",
      "\"wynne\"\t2\n",
      "\"wynpublishing\"\t1\n",
      "\"xacnax\"\t1\n",
      "\"xan\"\t2\n",
      "\"xanax\"\t3\n",
      "\"xeni\"\t2\n",
      "\"xent\"\t2\n",
      "\"xes\"\t1\n",
      "\"xm\"\t1\n",
      "\"xp\"\t6\n",
      "\"xpress\"\t1\n",
      "\"xqirzd\"\t1\n",
      "\"yahoo\"\t7\n",
      "\"yanowski\"\t1\n",
      "\"yard\"\t2\n",
      "\"ycon\"\t2\n",
      "\"yeah\"\t2\n",
      "\"year\"\t25\n",
      "\"yearno\"\t1\n",
      "\"years\"\t22\n",
      "\"yellow\"\t1\n",
      "\"yes\"\t7\n",
      "\"yesterday\"\t7\n",
      "\"yesterdays\"\t1\n",
      "\"yet\"\t5\n",
      "\"yjoou\"\t1\n",
      "\"you\"\t445\n",
      "\"youcan\"\t1\n",
      "\"young\"\t2\n",
      "\"your\"\t395\n",
      "\"yourmembership\"\t2\n",
      "\"yours\"\t3\n",
      "\"yourself\"\t11\n",
      "\"yoursuccess\"\t2\n",
      "\"yowman\"\t1\n",
      "\"ypfpb\"\t1\n",
      "\"zaak\"\t2\n",
      "\"zaako\"\t1\n",
      "\"zac\"\t2\n",
      "\"zadorozhny\"\t4\n",
      "\"zero\"\t4\n",
      "\"zesto\"\t10\n",
      "\"zimin\"\t5\n",
      "\"zinc\"\t1\n",
      "\"zk\"\t1\n",
      "\"zo\"\t2\n",
      "\"zolam\"\t2\n",
      "\"zxs\"\t1\n",
      "Removing temp directory /var/folders/0r/78q4n41j3dgdb6ndrr46gw3430x2wk/T/WordCountHW12.z086769.20160701.012136.962153...\n"
     ]
    }
   ],
   "source": [
    "!python WordCountHW12.py  enronemail_1h.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The below will count the overall frequency of the word \"assistance.\"  This is a modification of the code provided, which will validate the mapreduce wordcount job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      10\r\n"
     ]
    }
   ],
   "source": [
    "!grep -o assistance enronemail_1h.txt | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The below will count the number of lines where the word \"assistance\" occurs.   This is exactly the code provided above.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       8\r\n"
     ]
    }
   ],
   "source": [
    "!grep assistance enronemail_1h.txt|cut -d$'\\t' -f4| grep assistance|wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW1.2.1 \n",
    "\n",
    "Using Hadoop MapReduce (or MRJob) and your wordcount job (from HW1.2) determine the top-10 occurring tokens (most frequent tokens) using a single reducer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The below code will read in data from enronemail_1h.txt, create a text file called hw121.txt in the format of (word, wordfrequency).  This is an intermediate step in the solution of printing the top-10 occurring tokens.  The file WordCountHW12 has a single reducer and is provided above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from WordCountHW12 import MRJobWordCount \n",
    "     \n",
    "inputData = 'enronemail_1h.txt'\n",
    "\n",
    "mr_job = MRJobWordCount(args=[inputData])\n",
    "results={}\n",
    "with mr_job.make_runner() as runner: \n",
    "    runner.run()\n",
    "\n",
    "    for line in runner.stream_output():\n",
    "        key,value =  mr_job.parse_output_line(line)\n",
    "        results[key] = value            \n",
    "\n",
    "    with open('hw121.txt', 'w') as f:\n",
    "        for k in results.keys():\n",
    "            f.writelines( k + \"\\t\"+ str(results[k]) +\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW1.2.1 \n",
    "\n",
    "Using Hadoop MapReduce (or MRJob) and your wordcount job (from HW1.2) determine the top-10 occurring tokens (most frequent tokens) using a single reducer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now that the hw121.txt file has been created and contains the data from enronemail_1h.txt in the (word, wordfrequency) format, the below will read the file back into Python as a dictionary, sort the dictionary by descending wordfrequency, and print the top 10 most frequently occurring words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'to', 'and', 'of', 'you', 'in', 'your', 'ect', 'for', 'on']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prevresults = {}\n",
    "resultdict = [s.split('\\n')[0].split('\\t') for s in open(\"hw121.txt\").readlines()]\n",
    "for word, count in resultdict:\n",
    "    prevresults[word] =  map(int, count.split(\",\"))\n",
    "sorted(prevresults, key=prevresults.get, reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### If the desire was to have both word and frequency..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', [1247]),\n",
       " ('to', [964]),\n",
       " ('and', [670]),\n",
       " ('of', [566]),\n",
       " ('you', [445]),\n",
       " ('in', [418]),\n",
       " ('your', [395]),\n",
       " ('ect', [382]),\n",
       " ('for', [374]),\n",
       " ('on', [271])]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "prevresultscounts = {}\n",
    "resultdict = [s.split('\\n')[0].split('\\t') for s in open(\"hw121.txt\").readlines()]\n",
    "for word, statsStr in resultdict:\n",
    "    prevresultscounts[word] =  map(int, statsStr.split(\",\"))\n",
    "\n",
    "Counter(prevresultscounts).most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW1.3: Multinomial NAIVE BAYES with NO Smoothing using a single reducer\n",
    "\n",
    "Using the Enron data from HW1 and Hadoop MapReduce (or MRJob), write  a mapper/reducer job(s) that\n",
    "   will both learn  Naive Bayes classifier and classify the Enron email messages using the learnt Naive Bayes classifier. Use all white-space delimitted tokens as independent input variables (assume spaces, fullstops, commas as delimiters). Note: for multinomial Naive Bayes, the Pr(X=“assistance”|Y=SPAM) is calculated as follows:\n",
    "\n",
    "   the number of times “assistance” occurs in SPAM labeled documents / the number of words in documents labeled SPAM \n",
    "\n",
    "   E.g.,   “assistance” occurs 5 times in all of the documents Labeled SPAM, and the length in terms of the number of words in all documents labeled as SPAM (when concatenated) is 1,000. Then Pr(X=“assistance”|Y=SPAM) = 5/1000. Note this is a multinomial estimation of the class conditional for a Naive Bayes Classifier. No smoothing is needed in this HW. Multiplying lots of probabilities, which are between 0 and 1, can result in floating-point underflow. Since log(xy) = log(x) + log(y), it is better to perform all computations by summing logs of probabilities rather than multiplying probabilities. Please pay attention to probabilites that are zero! They will need special attention. Count up how many times you need to process a zero probabilty for each class and report. \n",
    "\n",
    "   Report the performance of your learnt classifier in terms of misclassifcation error rate of your multinomial Naive Bayes Classifier. Plot a histogram of the  posterior probabilities (i.e., Pr(Class|Doc)) for each class over the training set. Summarize what you see. \n",
    "\n",
    "   Error Rate = misclassification rate with respect to a provided set (say training set in this case). It is more formally defined here:\n",
    "\n",
    "Let DF represent the evalution set in the following:\n",
    "Err(Model, DF) = |{(X, c(X)) ∈ DF : c(X) != Model(x)}|   / |DF|\n",
    "\n",
    "Where || denotes set cardinality; c(X) denotes the class of the tuple X in DF; and Model(X) denotes the class inferred by the Model “Model”\n",
    "\n",
    "NOTE: please assume one reducer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting NaiveBayesTrainerHW1.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile NaiveBayesTrainerHW1.py\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    " \n",
    "from collections import defaultdict\n",
    " \n",
    "from mrjob.job import MRJob\n",
    "from mrjob.job import MRStep\n",
    "\n",
    "import re, string\n",
    "\n",
    "line_counts = dict()\n",
    "word_counts = dict()\n",
    "\n",
    "class NaiveBayesTrainer(MRJob):\n",
    " \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(NaiveBayesTrainer, self).__init__(*args, **kwargs)\n",
    "        \n",
    "    def jobconf(self):\n",
    "        orig_jobconf = super(NaiveBayesTrainer, self).jobconf()        \n",
    "        custom_jobconf = {\n",
    "            'mapred.reduce.tasks': '1',\n",
    "        }\n",
    "        combined_jobconf = orig_jobconf\n",
    "        combined_jobconf.update(custom_jobconf)\n",
    "        self.jobconf = combined_jobconf\n",
    "        return combined_jobconf\n",
    "    \n",
    "     \n",
    "    def configure_options(self):\n",
    "        super(NaiveBayesTrainer, self).configure_options()\n",
    "        self.add_passthrough_option(\n",
    "            '--smoothmethod', default='nosmooth', choices=['nosmooth', 'laplace', 'jelinekmercer']\n",
    "        )\n",
    "        \n",
    "        self.add_passthrough_option(\n",
    "            '--jmlambda', default=0.3, dest='jmlambda', type='float'\n",
    "        )\n",
    "        \n",
    "    def steps(self):\n",
    "        out = [\n",
    "            MRStep(\n",
    "                mapper = self.mapper,\n",
    "                combiner = self.combiner,\n",
    "                reducer = self.reducer_pre\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        if self.options.smoothmethod == 'laplace': \n",
    "            out.append(MRStep(\n",
    "                reducer = self.reducer_laplace\n",
    "            ))\n",
    "        \n",
    "        elif self.options.smoothmethod == 'jelinekmercer':\n",
    "            out.append(MRStep(\n",
    "                reducer = self.reducer_jelinekmercer\n",
    "            ))\n",
    "            \n",
    "        else:\n",
    "            out.append(MRStep(\n",
    "                reducer = self.reducer_nosmooth\n",
    "            ))\n",
    "        \n",
    "        return out\n",
    " \n",
    "    def mapper(self, _, line):\n",
    "        regex = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "        _, classifier, token = line.strip().split('\\t', 2)\n",
    "        token = regex.sub(' ', token.lower())\n",
    "        token = re.sub( '\\s+', ' ', token )\n",
    "        words = token.split()\n",
    "        yield (('line', classifier), 1)\n",
    " \n",
    "        for word in set(words):                \n",
    "            yield ((word, classifier), words.count(word))\n",
    "            yield (('word', classifier), words.count(word))\n",
    " \n",
    " \n",
    "    def combiner(self, word_classifier, counts):\n",
    "        yield (word_classifier, sum(counts))\n",
    " \n",
    "    def reducer_pre(self, word_classifier, counts):\n",
    "        total_count = sum(counts)\n",
    "        word, classifier = word_classifier\n",
    "\n",
    "        if word == 'word':\n",
    "            if classifier not in word_counts:\n",
    "                word_counts[classifier] = 0\n",
    "                \n",
    "            word_counts[classifier] += total_count\n",
    "            return\n",
    "\n",
    "        if word == 'line':\n",
    "            line_counts[classifier] = total_count\n",
    "            word = 'PriorProb'\n",
    "\n",
    "        if classifier not in word_counts:\n",
    "            word_counts[classifier] = 0\n",
    "            word_counts[classifier] -= total_count\n",
    "        else:\n",
    "            yield (word, {classifier: total_count})\n",
    "            \n",
    "    def reducer_nosmooth(self, word, classified_counts):\n",
    "        combined = defaultdict(lambda: 0)\n",
    "\n",
    "        for entry in classified_counts:\n",
    "            for classifier, count in entry.items():\n",
    "                combined[classifier] += count\n",
    "\n",
    "        for classifier in line_counts.keys():\n",
    "            count = combined.get(classifier, 0)\n",
    " \n",
    "            if word == 'PriorProb':\n",
    "                probability = count / sum(line_counts.values())\n",
    "            else:\n",
    "                probability = count / word_counts[classifier]\n",
    " \n",
    "            yield (word, classifier), probability\n",
    "    \n",
    "    def reducer_laplace(self, word, classified_counts):\n",
    "        combined = defaultdict(lambda: 0)\n",
    "        for entry in classified_counts:\n",
    "            for classifier, count in entry.items():\n",
    "                combined[classifier] += count\n",
    " \n",
    "        for classifier in line_counts.keys():\n",
    "            count = combined.get(classifier, 0)\n",
    " \n",
    "            if word == 'PriorProb':\n",
    "                probability = count / sum(line_counts.values())\n",
    "            else:\n",
    "                probability = (count + 1) / (word_counts[classifier]+ 1)\n",
    " \n",
    "            yield (word, classifier), probability\n",
    "    \n",
    "    def reducer_jelinekmercer(self, word, classified_counts):\n",
    "        combined = defaultdict(lambda: 0)\n",
    "        \n",
    "        for entry in classified_counts:\n",
    "            for classifier, count in entry.items():\n",
    "                combined[classifier] += count\n",
    " \n",
    "        for classifier in line_counts.keys():\n",
    "            count = combined.get(classifier, 0)\n",
    "\n",
    "        for classifier in line_counts.keys():\n",
    "            count = combined.get(classifier, 0)\n",
    "            jmlambda = self.options.jmlambda\n",
    "        \n",
    "            if word == 'PriorProb':\n",
    "                probability = count / sum(line_counts.values())\n",
    "            else:\n",
    "                probability = (\n",
    "                    (1 - jmlambda) * (count / word_counts[classifier]) +\n",
    "                    (jmlambda * sum(combined.values()) / sum(word_counts.values()))\n",
    "                )\n",
    "                \n",
    "            yield (word, classifier), probability \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    NaiveBayesTrainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import NaiveBayesTrainerHW1 as nbTrainer \n",
    "\n",
    "def model(trainer, modelfile, smoothing_type='none', jmlambda=0.3):\n",
    "    nbTrainer.word_counts = dict()\n",
    "    nbTrainer.line_counts = dict()\n",
    "    mr_job = nbTrainer.NaiveBayesTrainer(\n",
    "        args=[\n",
    "            trainer,\n",
    "            '--smoothmethod={}'.format(smoothing_type),\n",
    "            '--jmlambda={}'.format(jmlambda)\n",
    "        ]\n",
    "    )\n",
    "    modelStats = dict()\n",
    "    \n",
    "    with mr_job.make_runner() as runner: \n",
    "        runner.run()\n",
    "        \n",
    "        for line in runner.stream_output():\n",
    "            key, value =  mr_job.parse_output_line(line)\n",
    "            word = key[0]\n",
    "            classifier = int(key[1])\n",
    "\n",
    "            if word not in modelStats:\n",
    "                probs = ['0', '0']\n",
    "                probs[classifier] = str(value)\n",
    "                modelStats[word] = probs                        \n",
    "            else:\n",
    "                modelStats[word][classifier] = str(value)\n",
    "\n",
    "        # Store model locally\n",
    "        with open(modelfile, 'w') as f:\n",
    "            for word, probs in modelStats.items():\n",
    "                f.writelines(word + \"\\t\" + \"\\t\".join(probs) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model(    \n",
    "    trainer='enronemail_1h.txt',\n",
    "    smoothing_type='nosmooth',\n",
    "    modelfile='enron_model_unsmoothed.txt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting NaiveBayesClassifierHW13.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile NaiveBayesClassifierHW13.py\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "import os, re, string, math\n",
    "\n",
    "counts = []\n",
    "\n",
    "class NaiveBayesClassifier(MRJob):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(NaiveBayesClassifier, self).__init__(*args, **kwargs)\n",
    "        \n",
    "    def steps(self):\n",
    "        return [\n",
    "            MRStep(\n",
    "                mapper_init=self.mapper_init, \n",
    "                mapper=self.mapper,\n",
    "                combiner=self.combiner,\n",
    "                reducer=self.reducer  \n",
    "            ),\n",
    "            MRStep(reducer=self.reducer_final)\n",
    "        ]\n",
    "\n",
    "    def configure_options(self):\n",
    "        super(NaiveBayesClassifier, self).configure_options()\n",
    "        \n",
    "        self.add_file_option('--model')\n",
    "        \n",
    "    def mapper_init(self): \n",
    "        self.model_stats = {}\n",
    "\n",
    "        with open(self.options.model, \"r\") as f:\n",
    "            lines = f.read().split('\\n')\n",
    "        \n",
    "        split_lines = [line.split('\\t') for line in lines]\n",
    "        \n",
    "        for entry in split_lines:\n",
    "            word = entry[0]\n",
    "            probs = [float(p) for p in entry[1:]]\n",
    "            self.model_stats[word] = probs\n",
    "    \n",
    "    def mapper(self, _, line):\n",
    "        regex = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "        _, classifier, token = line.strip().split('\\t', 2)\n",
    "        token = regex.sub(' ', token.lower())\n",
    "        token = re.sub( '\\s+', ' ', token )\n",
    "\n",
    "        p0 = math.log10(self.model_stats['PriorProb'][0])\n",
    "        p1 = math.log10(self.model_stats['PriorProb'][1])\n",
    "        \n",
    "        for word in token.split():\n",
    "\n",
    "            probs = self.model_stats.get(word, [0, 0]) \n",
    "            probs = [p if p > 0 else 1 for p in probs] \n",
    "           \n",
    "            p0 += math.log10(probs[0])\n",
    "            p1 += math.log10(probs[1])\n",
    "\n",
    "        if p0 > p1:\n",
    "            prediction = 0\n",
    "        elif p1 > p0:\n",
    "            prediction = 1\n",
    "        else:\n",
    "            prediction = -1 \n",
    "\n",
    "        if prediction == int(classifier):\n",
    "            key = 'correct'\n",
    "        else:\n",
    "            key = 'incorrect'\n",
    "            \n",
    "        yield (key, 1)\n",
    "\n",
    "    def combiner(self, key, values):\n",
    "        yield (key, sum(values))\n",
    "        \n",
    "    def reducer(self, key, values):\n",
    "        values = list(values)\n",
    "        count = sum(values)\n",
    "        counts.append(count)\n",
    "        yield (key, count)\n",
    "      \n",
    "    def reducer_final(self, key, values):\n",
    "        values = list(values)\n",
    "\n",
    "        rate = sum(values) / sum(counts)\n",
    "        output = 'Inaccuracy Rate' if key == 'incorrect' else 'Accuracy Rate'\n",
    "        \n",
    "        yield (output, rate)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    NaiveBayesClassifier.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import NaiveBayesClassifierHW13 as nbClassifier\n",
    "\n",
    "\n",
    "def classify(smoothtype, valer, modelfile):\n",
    "    model_path = os.path.join(\n",
    "        os.path.abspath(os.path.curdir), \n",
    "        modelfile\n",
    "    )\n",
    "    nbClassifier.counts = []\n",
    "    mr_job = nbClassifier.NaiveBayesClassifier(\n",
    "        args=[\n",
    "            valer,\n",
    "            '--model={}'.format(modelfile)\n",
    "        ]\n",
    "    )\n",
    "    out = {'Smooth Method': smoothtype, 'Inaccuracy Rate': 0, 'Accuracy Rate': 0}\n",
    "    \n",
    "    with mr_job.make_runner() as runner: \n",
    "        runner.run()\n",
    "        for line in runner.stream_output():\n",
    "            key, value =  mr_job.parse_output_line(line)\n",
    "            out[key] = value\n",
    "                \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy Rate': 0, 'Inaccuracy Rate': 1.0, 'Smooth Method': 'Unsmoothed'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify('Unsmoothed', 'enronemail_1h.txt', 'enron_model_unsmoothed.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW1.4:  Multinomial Naive Bayes with Smoothing \n",
    "\n",
    "### HW1.4.0: Repeat HW1.3 with the following modification: use Laplace plus-one smoothing. Compare the misclassifcation error rates for HW1.3 versus HW1.4 and explain the differences.\n",
    "\n",
    "For a quick reference on the construction of the Multinomial NAIVE BAYES classifier that you will code,\n",
    "please consult the \"Document Classification\" section of the following wikipedia page:\n",
    "\n",
    "https://en.wikipedia.org/wiki/Naive_Bayes_classifier#Document_classification\n",
    "\n",
    "OR the original paper by the curators of the Enron email data:\n",
    "\n",
    "http://www.aueb.gr/users/ion/docs/ceas2006_paper.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model(    \n",
    "    trainer='enronemail_1h.txt',\n",
    "    smoothing_type='laplace',\n",
    "    modelfile='enron_model_laplace.txt'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### _You can see a huge improvement in adding the Laplace smoothing to the Naive Bayes algorithm.  One major reason for why is that the Laplace smoother eliminates nonzero probabilities, so multiplication is less impactful.  As you can see, the accuracy rate for Laplace is 96%, while the accuracy rate for the Unsmoothed method is 0%.  This is a huge increase with minimal additional work._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy Rate': 1.0, 'Inaccuracy Rate': 0, 'Smooth Method': 'Laplace'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify('Laplace', 'enronemail_1h.txt', 'enron_model_laplace.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy Rate': 0, 'Inaccuracy Rate': 1.0, 'Smooth Method': 'Unsmoothed'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify('Unsmoothed', 'enronemail_1h.txt', 'enron_model_unsmoothed.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW 1.4.1 Jelinek-Mercer (JM) smoothing* \n",
    "\n",
    "HW 1.4.1 Jelinek-Mercer (JM) smoothing* \n",
    "\n",
    "With different smoothing methods, p(wk|ci) (i.e., the word class conditionals) will be computed\n",
    "differently. We consider Jelinek-Mercer (JM) smoothing as an alternative to Laplace  Let c(w, ci) denote\n",
    "the frequency of word w in category ci,  p(w|C) be the maximum likelihood estimation of word w in \n",
    "collection C (relative frequency) and let |C for classi| denote the length of the classi. Then:\n",
    "\n",
    "1) Jelinek-Mercer (JM) smoothing:\n",
    "\n",
    "λp(w|ci) = (1 − λ) * c(w, ci)/sum_over_wJ_in_V(c(wJ, ci))    +  λ p(w|C)\n",
    "\n",
    "Where c(w, ci)/sum_over_wJ_in_V(c(wJ, ci)) essential denotes the relative frequency of word w in class ci, i.e., Pr(w|ci)\n",
    "and one can set λ = 0.3  by default. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model(    \n",
    "    trainer='enronemail_1h.txt',\n",
    "    smoothing_type='jelinekmercer',\n",
    "    modelfile='enron_model_jm.txt',\n",
    "    jmlambda=.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy Rate': 1.0, 'Inaccuracy Rate': 0, 'Smooth Method': 'jm lambda=.3'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify('jm lambda=.3', 'enronemail_1h.txt', 'enron_model_jm.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW1.4.2 Split data in to training, validation and testing data subsets\n",
    "\n",
    "Split the data using MRJob into three subsets in the following proportions (70% for training, 15% for valdiation, and 15% for testing). Train Multinomial Naive Bayes classifiers using Laplace plus-one smoothing and using  Jelinek-Mercer (JM) smoothing where you consider different hyperparameter values for λ. Please consider λ in {0.0, 0.1, 0.3, 0.5, 0.7, 1}. Present  a table compare the  results of the different approaches: each  row is the approach taken (e.g., Multinomial Naive Bayes with Laplace+1, or Multinomial Naive Bayes with  with JM= 0.3 for λ =0.3) and a column for  error rate on the training, validation and test data sets. Present a graph also (in python) consisting of three curves (where the x-axis represents the approach taken and the y-axis represents the error rate). Dont forget to put a good title on your graph!\n",
    "\n",
    "Looking the validation curve select the best model. How does it perform on the unseen test set? Comment.\n",
    "\n",
    "\n",
    "* REFERENCES \n",
    "   + http://www.ntu.edu.sg/home/gaocong/papers/wpp095-yuan.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "with open(\"enronemail_1h.txt\", \"r\") as f:\n",
    "    fullfile = f.read().split('\\n')\n",
    "\n",
    "linecount = len(fullfile)\n",
    "linecount_70pct = int(.7*linecount)\n",
    "linecount_85pct = int(.85*linecount)\n",
    "\n",
    "\n",
    "trainer_data = fullfile[:linecount_70pct]\n",
    "validation_data = fullfile[linecount_70pct:linecount_85pct]\n",
    "tester_data = fullfile[linecount_85pct:]\n",
    "\n",
    "with open(\"enron_trainer.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(trainer_data))\n",
    "with open(\"enron_valer.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(validation_data))\n",
    "with open(\"enron_tester.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(tester_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "testing_filename = 'enron_tester.txt'\n",
    "validation_filename = 'enron_valer.txt'\n",
    "model_filename = 'enron_model_trial.txt'\n",
    "results = []\n",
    "\n",
    "def modelcompare(smoothtype, smoothing_type, jmlambda=0.3):\n",
    "\n",
    "    model(    \n",
    "        trainer='enron_trainer.txt',\n",
    "        smoothing_type=smoothing_type,\n",
    "        modelfile=model_filename,\n",
    "        jmlambda=jmlambda\n",
    "    )\n",
    "    \n",
    "    out = {'name': smoothtype}\n",
    "    \n",
    "    results = classify(smoothtype, testing_filename, model_filename)\n",
    "    out['error_test'] = results['Inaccuracy Rate']\n",
    "    \n",
    "    results = classify(smoothtype, validation_filename, model_filename)\n",
    "    out['error_validate'] = results['Inaccuracy Rate']\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   error_test  error_validate                         name\n",
      "0    0.800000        0.866667                   Unsmoothed\n",
      "1    0.200000        0.066667                      LaPlace\n",
      "2    0.800000        0.866667  Jelinek-Mercer lambda = 0.0\n",
      "3    0.133333        0.000000  Jelinek-Mercer lambda = 0.1\n",
      "4    0.200000        0.000000  Jelinek-Mercer lambda = 0.3\n",
      "5    0.200000        0.066667  Jelinek-Mercer lambda = 0.5\n",
      "6    0.200000        0.066667  Jelinek-Mercer lambda = 0.7\n",
      "7    0.600000        0.466667  Jelinek-Mercer lambda = 1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results.append(modelcompare('Unsmoothed', 'nosmooth'))\n",
    "results.append(modelcompare('LaPlace', 'laplace'))\n",
    "results.append(modelcompare('Jelinek-Mercer lambda = 0.0', 'jelinekmercer', jmlambda=0.0))\n",
    "results.append(modelcompare('Jelinek-Mercer lambda = 0.1', 'jelinekmercer', jmlambda=0.1))\n",
    "results.append(modelcompare('Jelinek-Mercer lambda = 0.3', 'jelinekmercer', jmlambda=0.3))\n",
    "results.append(modelcompare('Jelinek-Mercer lambda = 0.5', 'jelinekmercer', jmlambda=0.5))\n",
    "results.append(modelcompare('Jelinek-Mercer lambda = 0.7', 'jelinekmercer', jmlambda=0.7))\n",
    "results.append(modelcompare('Jelinek-Mercer lambda = 1.0', 'jelinekmercer', jmlambda=1.0))\n",
    "\n",
    "resultsout = pandas.DataFrame(results)\n",
    "print(resultsout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x114900c10>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAGlCAYAAAACrXq3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x113fe0150>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import pyplot\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "indices = 10 * resultsout.index\n",
    "\n",
    "fig = pyplot.figure()\n",
    "ax = pyplot.subplot(111)\n",
    "\n",
    "x = ax.scatter(indices, resultsout.error_test,color='y', marker = '*', s=100)\n",
    "y = ax.scatter(indices, resultsout.error_validate,color='r', marker = '.', s=100)\n",
    "pyplot.xticks(indices, resultsout.name, rotation=90)\n",
    "pyplot.ylabel('Error Rate')\n",
    "pyplot.xlabel('Smoothing Method')\n",
    "pyplot.title('Error Rate vs NaiveBayes Smoothing Method')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Based on the graph above, when given the validation data set, the Jelinek-Mercer lambda = .1 or lambda = .3 work equally as well (this is confirmed by looking at the data table).  When applied to the unseen test set, the lamdba = .1 worked the best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW1.5: Remove words with frequency of less than three (3) in the training set\n",
    "\n",
    "Repeat HW1.4. This time when modeling and classification ignore tokens with a frequency of less than three (3) in the training set. How does it affect the misclassifcation error of learnt naive multinomial Bayesian Classifier on the training dataset. Report the error and the change in error. HINT: ignore tokens with a frequency of less than three (3). Think of this as a preprocessing step. How many new mapreduce jobs do you need to solve thus homework? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting NaiveBayesTrainerLess3HW1.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile NaiveBayesTrainerLess3HW1.py\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    " \n",
    "from collections import defaultdict\n",
    " \n",
    "from mrjob.job import MRJob\n",
    "from mrjob.job import MRStep\n",
    "\n",
    "import re, string\n",
    "\n",
    "line_counts = dict()\n",
    "word_counts = dict()\n",
    "\n",
    "class NaiveBayesTrainerLess3(MRJob):\n",
    " \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(NaiveBayesTrainerLess3, self).__init__(*args, **kwargs)\n",
    "        \n",
    "    def jobconf(self):\n",
    "        orig_jobconf = super(NaiveBayesTrainerLess3, self).jobconf()        \n",
    "        custom_jobconf = {\n",
    "            'mapred.reduce.tasks': '1',\n",
    "        }\n",
    "        combined_jobconf = orig_jobconf\n",
    "        combined_jobconf.update(custom_jobconf)\n",
    "        self.jobconf = combined_jobconf\n",
    "        return combined_jobconf\n",
    "    \n",
    "     \n",
    "    def configure_options(self):\n",
    "        super(NaiveBayesTrainerLess3, self).configure_options()\n",
    "        self.add_passthrough_option(\n",
    "            '--smoothmethod', default='nosmooth', choices=['nosmooth', 'laplace', 'jelinekmercer']\n",
    "        )\n",
    "        \n",
    "        self.add_passthrough_option(\n",
    "            '--jmlambda', default=0.3, dest='jmlambda', type='float'\n",
    "        )\n",
    "        \n",
    "    def steps(self):\n",
    "        out = [\n",
    "            MRStep(\n",
    "                mapper = self.mapper,\n",
    "                combiner = self.combiner,\n",
    "                reducer = self.reducer_pre\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        if self.options.smoothmethod == 'laplace': \n",
    "            out.append(MRStep(\n",
    "                reducer = self.reducer_laplace\n",
    "            ))\n",
    "        \n",
    "        elif self.options.smoothmethod == 'jelinekmercer':\n",
    "            out.append(MRStep(\n",
    "                reducer = self.reducer_jelinekmercer\n",
    "            ))\n",
    "            \n",
    "        else:\n",
    "            out.append(MRStep(\n",
    "                reducer = self.reducer_nosmooth\n",
    "            ))\n",
    "        \n",
    "        return out\n",
    " \n",
    "    def mapper(self, _, line):\n",
    "        regex = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "        _, classifier, token = line.strip().split('\\t', 2)\n",
    "        token = regex.sub(' ', token.lower())\n",
    "        token = re.sub( '\\s+', ' ', token )\n",
    "        words = token.split()\n",
    "        yield (('line', classifier), 1)\n",
    " \n",
    "        for word in set(words):                \n",
    "            yield ((word, classifier), words.count(word))\n",
    "            yield (('word', classifier), words.count(word))\n",
    " \n",
    " \n",
    "    def combiner(self, word_classifier, counts):\n",
    "        yield (word_classifier, sum(counts))\n",
    " \n",
    "    def reducer_pre(self, word_classifier, counts):\n",
    "        total_count = sum(counts)\n",
    "        word, classifier = word_classifier\n",
    "\n",
    "        if word == 'word':\n",
    "            if classifier not in word_counts:\n",
    "                word_counts[classifier] = 0\n",
    "                \n",
    "            word_counts[classifier] += total_count\n",
    "            return\n",
    "\n",
    "        if word == 'line':\n",
    "            line_counts[classifier] = total_count\n",
    "            word = 'PriorProb'\n",
    "\n",
    "        if total_count <= 3:\n",
    "\n",
    "            if classifier not in word_counts:\n",
    "                word_counts[classifier] = 0\n",
    "            word_counts[classifier] -= total_count\n",
    "        else:\n",
    "            yield (word, {classifier: total_count})\n",
    "            \n",
    "    def reducer_nosmooth(self, word, classified_counts):\n",
    "        combined = defaultdict(lambda: 0)\n",
    "\n",
    "        for entry in classified_counts:\n",
    "            for classifier, count in entry.items():\n",
    "                combined[classifier] += count\n",
    "\n",
    "        for classifier in line_counts.keys():\n",
    "            count = combined.get(classifier, 0)\n",
    " \n",
    "            if word == 'PriorProb':\n",
    "                probability = count / sum(line_counts.values())\n",
    "            else:\n",
    "                probability = count / word_counts[classifier]\n",
    " \n",
    "            yield (word, classifier), probability\n",
    "    \n",
    "    def reducer_laplace(self, word, classified_counts):\n",
    "        combined = defaultdict(lambda: 0)\n",
    "        for entry in classified_counts:\n",
    "            for classifier, count in entry.items():\n",
    "                combined[classifier] += count\n",
    " \n",
    "        for classifier in line_counts.keys():\n",
    "            count = combined.get(classifier, 0)\n",
    " \n",
    "            if word == 'PriorProb':\n",
    "                probability = count / sum(line_counts.values())\n",
    "            else:\n",
    "                probability = (count + 1) / (word_counts[classifier]+ 1)\n",
    " \n",
    "            yield (word, classifier), probability\n",
    "    \n",
    "    def reducer_jelinekmercer(self, word, classified_counts):\n",
    "        combined = defaultdict(lambda: 0)\n",
    "        \n",
    "        for entry in classified_counts:\n",
    "            for classifier, count in entry.items():\n",
    "                combined[classifier] += count\n",
    " \n",
    "        for classifier in line_counts.keys():\n",
    "            count = combined.get(classifier, 0)\n",
    "\n",
    "        for classifier in line_counts.keys():\n",
    "            count = combined.get(classifier, 0)\n",
    "            jmlambda = self.options.jmlambda\n",
    "        \n",
    "            if word == 'PriorProb':\n",
    "                probability = count / sum(line_counts.values())\n",
    "            else:\n",
    "                probability = (\n",
    "                    (1 - jmlambda) * (count / word_counts[classifier]) +\n",
    "                    (jmlambda * sum(combined.values()) / sum(word_counts.values()))\n",
    "                )\n",
    "                \n",
    "            yield (word, classifier), probability \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    NaiveBayesTrainerLess3.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import NaiveBayesTrainerLess3HW1 as nbTrainerL3 \n",
    "\n",
    "def modelL3(trainer, modelfile, smoothing_type='none', jmlambda=0.3):\n",
    "    nbTrainerL3.word_counts = dict()\n",
    "    nbTrainerL3.line_counts = dict()\n",
    "    mr_job = nbTrainerL3.NaiveBayesTrainerLess3(\n",
    "        args=[\n",
    "            trainer,\n",
    "            '--smoothmethod={}'.format(smoothing_type),\n",
    "            '--jmlambda={}'.format(jmlambda)\n",
    "        ]\n",
    "    )\n",
    "    modelStats = dict()\n",
    "    \n",
    "    with mr_job.make_runner() as runner: \n",
    "        runner.run()\n",
    "        \n",
    "        for line in runner.stream_output():\n",
    "            key, value =  mr_job.parse_output_line(line)\n",
    "            word = key[0]\n",
    "            classifier = int(key[1])\n",
    "\n",
    "            if word not in modelStats:\n",
    "                probs = ['0', '0']\n",
    "                probs[classifier] = str(value)\n",
    "                modelStats[word] = probs                        \n",
    "            else:\n",
    "                modelStats[word][classifier] = str(value)\n",
    "\n",
    "        # Store model locally\n",
    "        with open(modelfile, 'w') as f:\n",
    "            for word, probs in modelStats.items():\n",
    "                f.writelines(word + \"\\t\" + \"\\t\".join(probs) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "modelL3(    \n",
    "    trainer='enron_trainer.txt',\n",
    "    smoothing_type='nosmooth',\n",
    "    modelfile='enron_model_unsmoothed.txt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting NaiveBayesLess3HW1.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile NaiveBayesLess3HW1.py\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "import os, re, string, math\n",
    "\n",
    "counts = []\n",
    "\n",
    "class NaiveBayesClassifierL3(MRJob):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(NaiveBayesClassifierL3, self).__init__(*args, **kwargs)\n",
    "        \n",
    "    def steps(self):\n",
    "        return [\n",
    "            MRStep(\n",
    "                mapper_init=self.mapper_init, \n",
    "                mapper=self.mapper,\n",
    "                combiner=self.combiner,\n",
    "                reducer=self.reducer  \n",
    "            ),\n",
    "            MRStep(reducer=self.reducer_final)\n",
    "        ]\n",
    "\n",
    "    def configure_options(self):\n",
    "        super(NaiveBayesClassifierL3, self).configure_options()\n",
    "        \n",
    "        self.add_file_option('--model')\n",
    "        \n",
    "    def mapper_init(self): \n",
    "        self.model_stats = {}\n",
    "\n",
    "        with open(self.options.model, \"r\") as f:\n",
    "            lines = f.read().split('\\n')\n",
    "        \n",
    "        split_lines = [line.split('\\t') for line in lines]\n",
    "        \n",
    "        for entry in split_lines:\n",
    "            word = entry[0]\n",
    "            probs = [float(p) for p in entry[1:]]\n",
    "            self.model_stats[word] = probs\n",
    "    \n",
    "    def mapper(self, _, line):\n",
    "        regex = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "        _, classifier, token = line.strip().split('\\t', 2)\n",
    "        token = regex.sub(' ', token.lower())\n",
    "        token = re.sub( '\\s+', ' ', token )\n",
    "\n",
    "        p0 = math.log10(self.model_stats['PriorProb'][0])\n",
    "        p1 = math.log10(self.model_stats['PriorProb'][1])\n",
    "        \n",
    "        for word in token.split():\n",
    "\n",
    "            probs = self.model_stats.get(word, [0, 0]) \n",
    "            probs = [p if p > 0 else 1 for p in probs] \n",
    "           \n",
    "            p0 += math.log10(probs[0])\n",
    "            p1 += math.log10(probs[1])\n",
    "\n",
    "        if p0 > p1:\n",
    "            prediction = 0\n",
    "        elif p1 > p0:\n",
    "            prediction = 1\n",
    "        else:\n",
    "            prediction = -1 \n",
    "\n",
    "        if prediction == int(classifier):\n",
    "            key = 'correct'\n",
    "        else:\n",
    "            key = 'incorrect'\n",
    "            \n",
    "        yield (key, 1)\n",
    "\n",
    "    def combiner(self, key, values):\n",
    "        yield (key, sum(values))\n",
    "        \n",
    "    def reducer(self, key, values):\n",
    "        values = list(values)\n",
    "        count = sum(values)\n",
    "        counts.append(count)\n",
    "        yield (key, count)\n",
    "      \n",
    "    def reducer_final(self, key, values):\n",
    "        values = list(values)\n",
    "\n",
    "        rate = sum(values) / sum(counts)\n",
    "        output = 'Inaccuracy Rate' if key == 'incorrect' else 'Accuracy Rate'\n",
    "        \n",
    "        yield (output, rate)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    NaiveBayesClassifierL3.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import NaiveBayesLess3HW1 as nbClassifierL3\n",
    "\n",
    "\n",
    "def classifyL3(smoothtype, valer, modelfile):\n",
    "    model_path = os.path.join(\n",
    "        os.path.abspath(os.path.curdir), \n",
    "        modelfile\n",
    "    )\n",
    "    nbClassifierL3.counts = []\n",
    "    mr_job = nbClassifierL3.NaiveBayesClassifierL3(\n",
    "        args=[\n",
    "            valer,\n",
    "            '--model={}'.format(modelfile)\n",
    "        ]\n",
    "    )\n",
    "    out = {'Smooth Method': smoothtype, 'Inaccuracy Rate': 0, 'Accuracy Rate': 0}\n",
    "    \n",
    "    with mr_job.make_runner() as runner: \n",
    "        runner.run()\n",
    "        for line in runner.stream_output():\n",
    "            key, value =  mr_job.parse_output_line(line)\n",
    "            out[key] = value\n",
    "                \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "testing_filename = 'enron_tester.txt'\n",
    "validation_filename = 'enron_valer.txt'\n",
    "model_filename = 'enron_model_trial.txt'\n",
    "L3results = []\n",
    "\n",
    "def modelcompareL3(smoothtype, smoothing_type, jmlambda=0.3):\n",
    "\n",
    "    modelL3(    \n",
    "        trainer='enron_trainer.txt',\n",
    "        smoothing_type=smoothing_type,\n",
    "        modelfile=model_filename,\n",
    "        jmlambda=jmlambda\n",
    "    )\n",
    "    \n",
    "    out = {'name': smoothtype}\n",
    "    \n",
    "    resultsL3 = classifyL3(smoothtype, testing_filename, model_filename)\n",
    "    out['error_test'] = resultsL3['Inaccuracy Rate']\n",
    "    \n",
    "    resultsL3 = classifyL3(smoothtype, validation_filename, model_filename)\n",
    "    out['error_validate'] = resultsL3['Inaccuracy Rate']\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   error_test  error_validate             name\n",
      "0    0.733333        0.666667       Unsmoothed\n",
      "1    0.200000        0.066667          LaPlace\n",
      "2    0.733333        0.666667  JM lambda = 0.0\n",
      "3    0.200000        0.200000  JM lambda = 0.1\n",
      "4    0.200000        0.133333  JM lambda = 0.3\n",
      "5    0.200000        0.133333  JM lambda = 0.5\n",
      "6    0.200000        0.133333  JM lambda = 0.7\n",
      "7    0.600000        0.466667  JM lambda = 1.0\n"
     ]
    }
   ],
   "source": [
    "L3results.append(modelcompareL3('Unsmoothed', 'nosmooth'))\n",
    "L3results.append(modelcompareL3('LaPlace', 'laplace'))\n",
    "L3results.append(modelcompareL3('JM lambda = 0.0', 'jelinekmercer', jmlambda=0.0))\n",
    "L3results.append(modelcompareL3('JM lambda = 0.1', 'jelinekmercer', jmlambda=0.1))\n",
    "L3results.append(modelcompareL3('JM lambda = 0.3', 'jelinekmercer', jmlambda=0.3))\n",
    "L3results.append(modelcompareL3('JM lambda = 0.5', 'jelinekmercer', jmlambda=0.5))\n",
    "L3results.append(modelcompareL3('JM lambda = 0.7', 'jelinekmercer', jmlambda=0.7))\n",
    "L3results.append(modelcompareL3('JM lambda = 1.0', 'jelinekmercer', jmlambda=1.0))\n",
    "\n",
    "L3resultsout = pandas.DataFrame(L3results)\n",
    "print(L3resultsout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rearrange the table for readability and calculate test_delta and validation_delta columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              name  test_delta  validation_delta\n",
      "0       Unsmoothed   -0.066667         -0.200000\n",
      "1          LaPlace    0.000000          0.000000\n",
      "2  JM lambda = 0.0   -0.066667         -0.200000\n",
      "3  JM lambda = 0.1    0.066667          0.200000\n",
      "4  JM lambda = 0.3    0.000000          0.133333\n",
      "5  JM lambda = 0.5    0.000000          0.066667\n",
      "6  JM lambda = 0.7    0.000000          0.066667\n",
      "7  JM lambda = 1.0    0.000000          0.000000\n"
     ]
    }
   ],
   "source": [
    "L3resultsout['test_delta'] = L3resultsout['error_test'] - resultsout['error_test']\n",
    "L3resultsout['validation_delta'] = L3resultsout['error_validate'] - resultsout['error_validate']\n",
    "L3resultsout = L3resultsout[['name','test_delta','validation_delta']]\n",
    "print(L3resultsout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On the test set, the Unsmoothed and the JM lambda = 0 saw a decrease in error rate, with JM Lambda = .1 having an increase.   For the validation set, Unsmoothed and JM lambda = 0 saw decreases, but lambda > 0 all saw increases in error rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# HW1.6 Benchmark your code with the Python SciKit-Learn implementation of the multinomial Naive Bayes algorithm\n",
    "\n",
    "## HW1.6.0: Multinomial Naive Bayes using SciKit-Learn\n",
    "\n",
    "It always a good idea to benchmark your solutions against publicly available libraries such as SciKit-Learn, The Machine Learning toolkit available in Python. In this exercise, we benchmark ourselves against the SciKit-Learn implementation of multinomial Naive Bayes.  For more information on this implementation see: http://scikit-learn.org/stable/modules/naive_bayes.html more  \n",
    "\n",
    "In this exercise, please complete the following:\n",
    "\n",
    "— Run the Multinomial Naive Bayes algorithm (using default settings) from SciKit-Learn over the same training data used in HW1.4.2 and report the misclassification error (please note some data preparation might be needed to get the Multinomial Naive Bayes algorithm from SkiKit-Learn to run over this dataset)\n",
    "- Prepare a table to present your results, where rows correspond to approach used (SkiKit-Learn versus your Hadoop implementation) and the column presents the  misclassification error rates (train, validation, testing)\n",
    "— Explain/justify any differences in terms of training error rates over the dataset in HW1.5 between your Multinomial Naive Bayes implementation (in Map Reduce) versus the Multinomial Naive Bayes implementation in SciKit-Learn \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SK- multinomial NB training error: 0.0000\n",
      "SK- Bernoulli   NB training error: 0.1571\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import *\n",
    "\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "with open('enron_trainer.txt', 'r') as f:\n",
    "    reader = csv.reader(f, delimiter=\"\\t\")\n",
    "    emails = list(reader)\n",
    "train_label = [msg[1] for msg in emails]\n",
    "train_data = [msg[2] + msg[3] if len(msg) == 4 else msg[2] for msg in emails]\n",
    "msg_id = [msg[0].lower() for msg in emails]\n",
    "# print(train_label, train_data, msg_id)\n",
    "\n",
    "# feature vectorization\n",
    "uniVectorizer = CountVectorizer()\n",
    "dtmTrain = uniVectorizer.fit_transform(train_data) \n",
    "# print(uniVectorizer, dtmTrain)\n",
    "\n",
    "# multinomial Naive Bayes Classifier from sklearn\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(dtmTrain, train_label)\n",
    "pred_mnb = mnb.predict(dtmTrain)\n",
    "training_error_mnb = 1.0 * sum(pred_mnb != train_label) / len(train_label)\n",
    "\n",
    "# Bernoulli Naive Bayes Classifier from sklearn\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(dtmTrain, train_label)\n",
    "pred_bnb = bnb.predict(dtmTrain)\n",
    "training_error_bnb = 1.0*sum(pred_bnb != train_label) / len(train_label)\n",
    "\n",
    "print 'SK- multinomial NB training error: %.4f' %training_error_mnb\n",
    "print 'SK- Bernoulli   NB training error: %.4f' %training_error_bnb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
