{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting chineseExample.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile chineseExample.txt\n",
    "D1\t1\tChinese Beijing\tChinese\n",
    "D2\t1\tChinese Chinese\tShanghai\n",
    "D3\t1\tChinese\tMacao\n",
    "D4\t0\tTokyo Japan\tChinese\n",
    "D5\t0\tChinese Chinese\tChinese Tokyo Japan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting MRNaiveBayesTrainer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile MRNaiveBayesTrainer.py\n",
    "\n",
    "\"\"\"An implementation of a multinomial Naive Bayes learner as an MRJob.\n",
    "   This is meant as an example of why mapper_final is useful.\n",
    "   \n",
    "   This learning algorithm implementation can be further optimised. HOW?\n",
    "   \n",
    "   Use a cool pattern to do this!\n",
    "\n",
    "\"\"\"\n",
    "from mrjob.job import MRJob\n",
    "\n",
    "class MRNaiveBayesTrainer(MRJob):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(MRNaiveBayesTrainer, self).__init__(*args, **kwargs)\n",
    "        self.modelStats = {}\n",
    "        self.classTotalFreq = [0, 0]\n",
    "        self.vocab=0\n",
    "\n",
    "    def jobconf(self):\n",
    "        \n",
    "        orig_jobconf = super(MRNaiveBayesTrainer, self).jobconf()        \n",
    "        custom_jobconf = {\n",
    "            'mapred.output.key.comparator.class': 'org.apache.hadoop.mapred.lib.KeyFieldBasedComparator',\n",
    "            'mapred.text.key.comparator.options': '-k1rn',\n",
    "            'mapred.reduce.tasks': '1',\n",
    "        }\n",
    "        combined_jobconf = orig_jobconf\n",
    "        combined_jobconf.update(custom_jobconf)\n",
    "        self.jobconf = combined_jobconf\n",
    "        return combined_jobconf\n",
    "\n",
    "    def mapper(self, _, line):\n",
    "        \n",
    "        docID, docClass,text = line.split(\"\\t\",2)   \n",
    "        words = text.split()\n",
    "        vocab = {}\n",
    "        if docID != \"D5\":\n",
    "            if docClass == \"1\":\n",
    "                yield(\"PriorProbs\", \"0,1\")\n",
    "                yield(\"*classTotalFreq\", (\"0, \" + str(len(words))))\n",
    "                for word in words:\n",
    "                    vocab[word] = 1\n",
    "                    yield(word, \"0,1\")\n",
    "            else:\n",
    "                yield(\"PriorProbs\", \"1,0\")\n",
    "                yield(\"*classTotalFreq\", (str(len(words)) + \", 0\"))\n",
    "                for word in words:\n",
    "                    vocab[word] = 1\n",
    "                    yield(word, \"1,0\")\n",
    "        for k in vocab.keys():\n",
    "            yield \"*!\"+k, \"1,0\"\n",
    "\n",
    "    def reducer(self, word, values):    \n",
    "        #aggregate counts for Pr(Word|Class)\n",
    "        #yield(\"number of values for \"+word, str(values))\n",
    "        w0Total=0\n",
    "        w1Total=0\n",
    "        c0Total=0\n",
    "        c1Total=1\n",
    "        for value in values:\n",
    "            w0, w1 =  value.split(\",\")\n",
    "            w0Total += float(w0)\n",
    "            w1Total += float(w1)  \n",
    "        if word == \"*classTotalFreq\":\n",
    "            self.modelStats[word] = [w0Total, w1Total]\n",
    "        elif word.startswith(\"*!\"):\n",
    "            self.vocab += 1\n",
    "        elif word == \"TomsPriors\":\n",
    "            yield(\"TomsPriors\", ','.join(str(j) for j in [w0Total,w1Total,w0Total/(w0Total+w1Total),w1Total/(w0Total+w1Total)]))\n",
    "        else:\n",
    "            yield(word, ','.join(str(j) for j in [w0Total,w1Total,(w0Total+1)/(self.modelStats[\"*classTotalFreq\"][0] + self.vocab),(w1Total+1)/(self.modelStats[\"*classTotalFreq\"][1] + self.vocab)]))\n",
    "        #yield(\"JIMI \"+word, [w0Total, w1Total])\"\"\"\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    MRNaiveBayesTrainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beijing 0.0,1.0,0.111111111111,0.142857142857\n",
      "Chinese 1.0,5.0,0.222222222222,0.428571428571\n",
      "Japan 1.0,0.0,0.222222222222,0.0714285714286\n",
      "Macao 0.0,1.0,0.111111111111,0.142857142857\n",
      "PriorProbs 1.0,3.0,0.222222222222,0.285714285714\n",
      "Shanghai 0.0,1.0,0.111111111111,0.142857142857\n",
      "Tokyo 1.0,0.0,0.222222222222,0.0714285714286\n",
      "{'Beijing': '0.0,1.0,0.111111111111,0.142857142857', 'Chinese': '1.0,5.0,0.222222222222,0.428571428571', 'Tokyo': '1.0,0.0,0.222222222222,0.0714285714286', 'Shanghai': '0.0,1.0,0.111111111111,0.142857142857', 'PriorProbs': '1.0,3.0,0.222222222222,0.285714285714', 'Japan': '1.0,0.0,0.222222222222,0.0714285714286', 'Macao': '0.0,1.0,0.111111111111,0.142857142857'}\n"
     ]
    }
   ],
   "source": [
    "#------------------------------------------------------------------------------------\n",
    "# We have two ways to run the Naive Bayes algorithm\n",
    "# 1. Run using the command line (shown Above)\n",
    "# 2. Run using a MRJob Runner from python (very sweet way to do business). See Here\n",
    "#------------------------------------------------------------------------------------\n",
    "#HW 1.3\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "from MRNaiveBayesTrainer import MRNaiveBayesTrainer \n",
    "\n",
    "# STEP 1: Train a mulitnomial Naive Bayes      \n",
    "trainingData = 'chineseExample.txt'\n",
    "\n",
    "# create an instance of the Trainer class\n",
    "# and initiatialize it\n",
    "mr_job = MRNaiveBayesTrainer(args=[trainingData])\n",
    "modelStats={}\n",
    "with mr_job.make_runner() as runner: \n",
    "    runner.run()\n",
    "    # stream_output: get access to the output reducer/reducer_final of \n",
    "    # the last step in MRNaiveBayesTrainer\n",
    "    for line in runner.stream_output():\n",
    "        key,value =  mr_job.parse_output_line(line)\n",
    "        print key, value\n",
    "        modelStats[key] = value            \n",
    "    # Store model locally\n",
    "    with open('StatelessModel1.txt', 'w') as f:\n",
    "        for k in modelStats.keys():\n",
    "            f.writelines( k + \"\\t\"+ str(modelStats[k]) +\"\\n\")\n",
    "print modelStats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting MRNaiveBayesClassifier.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile MRNaiveBayesClassifier.py\n",
    " \n",
    "from mrjob.job import MRJob\n",
    "import sys, re, string, operator, math, os\n",
    "\n",
    "\n",
    "regex = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "\n",
    "class MRNaiveBayesClassifier(MRJob):\n",
    "\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(MRNaiveBayesClassifier, self).__init__(*args, **kwargs)\n",
    "        self.zeroProb = 0\n",
    "\n",
    "    def jobconf(self):\n",
    "        orig_jobconf = super(MRNaiveBayesClassifier, self).jobconf()        \n",
    "        custom_jobconf = {\n",
    "            'mapred.output.key.comparator.class': 'org.apache.hadoop.mapred.lib.KeyFieldBasedComparator',\n",
    "            'mapred.text.key.comparator.options': '-k1rn',\n",
    "            'mapred.reduce.tasks': '1',\n",
    "        }\n",
    "        combined_jobconf = orig_jobconf\n",
    "        combined_jobconf.update(custom_jobconf)\n",
    "        self.jobconf = combined_jobconf\n",
    "        return combined_jobconf    \n",
    "\n",
    "    def mapper_init(self):\n",
    "        self.modelStats = {}\n",
    "        \n",
    "        recordStrs = [s.split('\\n')[0].split('\\t') for s in open(\"StatelessModel1.txt\").readlines()]\n",
    "        for word, statsStr in recordStrs:\n",
    "            self.modelStats[word] = map(float, statsStr.split(\",\"))\n",
    "        \n",
    "        self.prC0 = math.log(self.modelStats[\"PriorProbs\"][2])\n",
    "        self.prC1 = math.log(self.modelStats[\"PriorProbs\"][3])\n",
    "        \n",
    "\n",
    "    \n",
    "    def mapper(self, _, line):\n",
    "        \n",
    "        docID, docClass,text = line.split(\"\\t\",2)\n",
    "        text = text.strip()\n",
    "        text = regex.sub(' ', text.lower())\n",
    "        text = re.sub( '\\s+', ' ', text )\n",
    "        words = text.split()\n",
    "        \n",
    "        for word in words:\n",
    "            p0 = self.modelStats[word][2]\n",
    "            if self.modelStats[word][2] == 0.0:\n",
    "                self.zeroProb += 1\n",
    "            p1 = self.modelStats[word][3]\n",
    "            if self.modelStats[word][3] == 0.0:\n",
    "                self.zeroProb += 1\n",
    "            wordGivenHam = math.log(p0) if p0>0.0 else math.log(1)\n",
    "            wordGivenSpam = math.log(p1) if p1>0.0 else math.log(1)\n",
    "            prHAMGivenDoc = self.prC0 + wordGivenHam\n",
    "            prSPAMGivenDoc = self.prC1 + wordGivenSpam\n",
    "        \n",
    "        predictedClass = 1 #SPAM\n",
    "        if(prHAMGivenDoc > prSPAMGivenDoc):\n",
    "            predictedClass = 0 #HAM\n",
    "        if int(docClass) == predictedClass:\n",
    "            yield (docID, 0)  #no error\n",
    "        else: \n",
    "            yield (docID, 1) # error    \n",
    "        yield(\"zero\", self.zeroProb)\n",
    "    \n",
    "    def combiner(self, word, values):\n",
    "        for value in values:\n",
    "            yield (\"t\", value)\n",
    "            \n",
    "    def reducer(self, word, values):\n",
    "        zero = 0\n",
    "        numberOfRecords = 0\n",
    "        numberWrong = 0\n",
    "        for value in values:\n",
    "            if value > 1:\n",
    "                zero = value\n",
    "            else:    \n",
    "                numberOfRecords += 1\n",
    "                numberWrong += value\n",
    "        #print (numberOfRecords, numberWrong)\n",
    "        print ('Error rate: %.4f' %(1.0*numberWrong/float(numberOfRecords)))\n",
    "        print ('Number Wrong %d, Total Records %d'  %(numberWrong, numberOfRecords))\n",
    "        print ('number of word|class with 0 probability: %d' %(zero))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    MRNaiveBayesClassifier.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: 'StatelessModel1.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-a443e26a71bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mmodelStats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mmr_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_runner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mrunner\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;31m# stream_output: get access of the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/mrjob/runner.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    471\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Job already ran!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ran_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/mrjob/sim.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_counters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invoke_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mapper'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m'reducer'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/mrjob/sim.pyc\u001b[0m in \u001b[0;36m_invoke_step\u001b[0;34m(self, step_num, step_type)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m             self._run_step(step_num, step_type, input_path, output_path,\n\u001b[0;32m--> 259\u001b[0;31m                            working_dir, env)\n\u001b[0m\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prev_outfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/mrjob/inline.pyc\u001b[0m in \u001b[0;36m_run_step\u001b[0;34m(self, step_num, step_type, input_path, output_path, working_dir, env, child_stdin)\u001b[0m\n\u001b[1;32m    155\u001b[0m                     child_instance.sandbox(stdin=child_stdin,\n\u001b[1;32m    156\u001b[0m                                            stdout=child_stdout)\n\u001b[0;32m--> 157\u001b[0;31m                     \u001b[0mchild_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhas_combiner\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/mrjob/job.pyc\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_mapper\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_mapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_combiner\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/mrjob/job.pyc\u001b[0m in \u001b[0;36mrun_mapper\u001b[0;34m(self, step_num)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmapper_init\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mout_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_value\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmapper_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m                 \u001b[0mwrite_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/z086769/MachineLearning/TargetDataScienceTraining/Week 2/MRNaiveBayesClassifier.py\u001b[0m in \u001b[0;36mmapper_init\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodelStats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mrecordStrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"StatelessModel1.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatsStr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrecordStrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodelStats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatsStr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: 'StatelessModel1.txt'"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from numpy import random\n",
    "from MRNaiveBayesClassifier import MRNaiveBayesClassifier \n",
    "\n",
    "trainingData = 'chineseExample.txt'      \n",
    "#make the model file available to the workers as \"model\"\n",
    "modelFile   = 'StatelessModel1.txt'  \n",
    "\n",
    "mr_job = MRNaiveBayesClassifier(args=[trainingData, modelFile])\n",
    "modelStats={}\n",
    "with mr_job.make_runner() as runner: \n",
    "    runner.run()\n",
    "        # stream_output: get access of the output \n",
    "    for line in runner.stream_output():\n",
    "        key,value =  mr_job.parse_output_line(line)\n",
    "        print key, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
